{"Oral": [{"id": "KS8mIvetg2", "forum": "KS8mIvetg2", "signatures": ["ICLR.cc/2024/Conference/Submission9019/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9019/Authors"], "content": {"title": {"value": "Proving Test Set Contamination in Black-Box Language Models"}, "authors": {"value": ["Yonatan Oren", "Nicole Meister", "Niladri S. Chatterji", "Faisal Ladhak", "Tatsunori Hashimoto"]}, "authorids": {"value": ["~Yonatan_Oren1", "~Nicole_Meister1", "~Niladri_S._Chatterji1", "~Faisal_Ladhak2", "~Tatsunori_Hashimoto1"]}, "keywords": {"value": ["language modeling", "memorization", "dataset contamination"]}, "abstract": {"value": "Large language models are trained on vast amounts of internet data, prompting concerns that they have memorized public benchmarks. Detecting this type of contamination is challenging because the pretraining data used by proprietary models are often not publicly accessible.\n\nWe propose a procedure for detecting test set contamination of language models with exact false positive guarantees and without access to pretraining data or model weights. Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely. In contrast, the tendency for language models to memorize example order means that a contaminated language model will find certain canonical orderings to be much more likely than others. Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples.\n\nWe demonstrate that our procedure is sensitive enough to reliably detect contamination in challenging situations, including models as small as 1.4 billion parameters, on small test sets only 1000 examples, and datasets that appear only a few times in the pretraining corpus. Finally, we evaluate LLaMA-2 to apply our test in a realistic setting and find our results to be consistent with existing contamination evaluations."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cfd79aaab7bdcd4f7c032c57fe7e607058042c80.pdf"}, "supplementary_material": {"value": "/attachment/aa53d1c5e16ec98e4af4f92f0eef6c0e5dfe7646.zip"}, "_bibtex": {"value": "@inproceedings{\noren2024proving,\ntitle={Proving Test Set Contamination for Black-Box Language Models},\nauthor={Yonatan Oren and Nicole Meister and Niladri S. Chatterji and Faisal Ladhak and Tatsunori Hashimoto},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KS8mIvetg2}\n}"}, "paperhash": {"value": "oren|proving_test_set_contamination_in_blackbox_language_models"}}, "number": 9019, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9019/-/Revision", "ICLR.cc/2024/Conference/Submission9019/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9019/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695534774121, "cdate": 1695534774121, "tmdate": 1710580368117, "mdate": 1710580368117, "pdate": 1705411055804, "version": 2}, {"id": "7Ttk3RzDeu", "forum": "7Ttk3RzDeu", "signatures": ["ICLR.cc/2024/Conference/Submission8848/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8848/Authors"], "content": {"title": {"value": "BooookScore: A systematic exploration of book-length summarization in the era of LLMs"}, "authors": {"value": ["Yapei Chang", "Kyle Lo", "Tanya Goyal", "Mohit Iyyer"]}, "authorids": {"value": ["~Yapei_Chang1", "~Kyle_Lo1", "~Tanya_Goyal1", "~Mohit_Iyyer1"]}, "keywords": {"value": ["summarization", "evaluation", "long context", "prompting", "LLM"]}, "abstract": {"value": "Summarizing book-length documents ($>$100K tokens)  that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Because human evaluation is expensive and time-consuming, we develop an automatic metric, BooookScore, that measures the proportion of sentences in a summary that do not contain any of the identified error types. BooookScore has high agreement with human annotations and allows us to systematically evaluate the impact of many other critical parameters (e.g., chunk size, base LLM) while saving \\$15K USD and 500 hours in human evaluation costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce summaries with higher BooookScore than those generated by open-source models. While LLaMA 2 falls behind other models, Mixtral achieves performance on par with GPT-3.5-Turbo. Incremental updating yields lower BooookScore but higher level of detail than hierarchical merging, a trade-off sometimes preferred by annotators. We release code and annotations to spur more principled research on book-length summarization."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/975e393e430362eb39a2c1ceb2c750bd4bb80143.pdf"}, "_bibtex": {"value": "@inproceedings{\nchang2024booookscore,\ntitle={BooookScore: A systematic exploration of book-length summarization in the era of {LLM}s},\nauthor={Yapei Chang and Kyle Lo and Tanya Goyal and Mohit Iyyer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7Ttk3RzDeu}\n}"}, "paperhash": {"value": "chang|booookscore_a_systematic_exploration_of_booklength_summarization_in_the_era_of_llms"}}, "number": 8848, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8848/-/Revision", "ICLR.cc/2024/Conference/Submission8848/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8848/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695526597280, "cdate": 1695526597280, "tmdate": 1713045491214, "mdate": 1713045491214, "pdate": 1705411051634, "version": 2}, {"id": "ANvmVS2Yr0", "forum": "ANvmVS2Yr0", "signatures": ["ICLR.cc/2024/Conference/Submission8660/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8660/Authors"], "content": {"title": {"value": "Generalization in diffusion models arises from geometry-adaptive harmonic representations"}, "authors": {"value": ["Zahra Kadkhodaie", "Florentin Guth", "Eero P Simoncelli", "St\u00e9phane Mallat"]}, "authorids": {"value": ["~Zahra_Kadkhodaie1", "~Florentin_Guth1", "~Eero_P_Simoncelli1", "~St\u00e9phane_Mallat1"]}, "keywords": {"value": ["diffusion models", "memorization", "generalization", "inductive bias", "curse of dimensionality", "denoising", "geometry-adaptive harmonic basis"]}, "abstract": {"value": "Deep neural networks (DNNs) trained for image denoising are able to generate high-quality samples with score-based reverse diffusion algorithms. These impressive capabilities seem to imply an escape from the curse of dimensionality, but recent reports of memorization of the training set raise the question of whether these networks are learning the \"true\" continuous density of the data. Here, we show that two DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, when the number of training images is large enough.  In this regime of strong generalization, diffusion-generated images are distinct from the training set, and are of high visual quality, suggesting that the inductive biases of the DNNs are well-aligned with the data density. We analyze the learned denoising functions and show that the inductive biases give rise to a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous regions. We demonstrate that trained denoisers are inductively biased towards these geometry-adaptive harmonic bases since they arise not only when the network is trained on photographic images, but also when it is trained on image classes supported on low-dimensional manifolds for which the harmonic basis is suboptimal. Finally, we show that when trained on regular image classes for which the optimal basis is known to be geometry-adaptive and harmonic, the denoising performance of the networks is near-optimal."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/84eb681ff8d070ce8c829cb2120dc133901594ce.pdf"}, "TLDR": {"value": "Diffusion models transition from memorization to generalization by being inductively biased towards geometry-adaptive harmonic representations."}, "_bibtex": {"value": "@inproceedings{\nkadkhodaie2024generalization,\ntitle={Generalization in diffusion models arises from geometry-adaptive harmonic representation},\nauthor={Zahra Kadkhodaie and Florentin Guth and Eero P Simoncelli and St{\\'e}phane Mallat},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ANvmVS2Yr0}\n}"}, "paperhash": {"value": "kadkhodaie|generalization_in_diffusion_models_arises_from_geometryadaptive_harmonic_representations"}}, "number": 8660, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8660/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8660/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520324208, "cdate": 1695520324208, "tmdate": 1712934777280, "mdate": 1712934777280, "pdate": 1705411046073, "version": 2}, {"id": "ekeyCgeRfC", "forum": "ekeyCgeRfC", "signatures": ["ICLR.cc/2024/Conference/Submission8569/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8569/Authors"], "content": {"title": {"value": "Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions"}, "authors": {"value": ["Satwik Bhattamishra", "Arkil Patel", "Phil Blunsom", "Varun Kanade"]}, "authorids": {"value": ["~Satwik_Bhattamishra1", "~Arkil_Patel1", "~Phil_Blunsom1", "~Varun_Kanade1"]}, "keywords": {"value": ["In-context learning", "Transformers", "Large language models", "Boolean functions"]}, "abstract": {"value": "In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can match the performance of gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find that certain attention-free models perform (almost) identically to Transformers on a range of tasks. (b) When provided a *teaching sequence*, i.e. a set of examples that uniquely identifies a function in a class, we show that Transformers learn more sample-efficiently. Interestingly, our results show that Transformers can learn to implement *two distinct* algorithms to solve a *single* task, and can adaptively select the more sample-efficient algorithm depending on the sequence of in-context examples. (c) Lastly, we show that extant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines on prediction tasks that are guaranteed to not be in their training set."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/816f489eb70fe677c4ebc1cf159cf38b3062956b.pdf"}, "supplementary_material": {"value": "/attachment/e414066ad28bae7c4efd18f9c257beec11cc6eb5.zip"}, "_bibtex": {"value": "@inproceedings{\nbhattamishra2024understanding,\ntitle={Understanding In-Context Learning in Transformers and {LLM}s by Learning to Learn Discrete Functions},\nauthor={Satwik Bhattamishra and Arkil Patel and Phil Blunsom and Varun Kanade},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ekeyCgeRfC}\n}"}, "paperhash": {"value": "bhattamishra|understanding_incontext_learning_in_transformers_and_llms_by_learning_to_learn_discrete_functions"}}, "number": 8569, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8569/-/Revision", "ICLR.cc/2024/Conference/Submission8569/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8569/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695515867779, "cdate": 1695515867779, "tmdate": 1710542360461, "mdate": 1710542360461, "pdate": 1705411043977, "version": 2}, {"id": "aN4Jf6Cx69", "forum": "aN4Jf6Cx69", "signatures": ["ICLR.cc/2024/Conference/Submission8504/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8504/Authors"], "content": {"title": {"value": "The mechanistic basis of data dependence and abrupt learning in an in-context classification task"}, "authors": {"value": ["Gautam Reddy"]}, "authorids": {"value": ["~Gautam_Reddy1"]}, "keywords": {"value": ["in-context learning", "mechanistic interpretability", "language models", "induction heads"]}, "TLDR": {"value": "We characterize the loss landscape of an in-context classification task and identify the factors that lead to abrupt transitions during learning."}, "abstract": {"value": "Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence, which contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4de2c24997e6d25adcda68f174ed540f41a217e8.pdf"}, "_bibtex": {"value": "@inproceedings{\nreddy2024the,\ntitle={The mechanistic basis of data dependence and abrupt learning in an in-context classification task},\nauthor={Gautam Reddy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=aN4Jf6Cx69}\n}"}, "paperhash": {"value": "reddy|the_mechanistic_basis_of_data_dependence_and_abrupt_learning_in_an_incontext_classification_task"}}, "number": 8504, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8504/-/Revision", "ICLR.cc/2024/Conference/Submission8504/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8504/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695512883715, "cdate": 1695512883715, "tmdate": 1710344148402, "mdate": 1710344148402, "pdate": 1705411042134, "version": 2}, {"id": "WNzy9bRDvG", "forum": "WNzy9bRDvG", "signatures": ["ICLR.cc/2024/Conference/Submission8410/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8410/Authors"], "content": {"title": {"value": "Improved Techniques for Training Consistency Models"}, "authors": {"value": ["Yang Song", "Prafulla Dhariwal"]}, "authorids": {"value": ["~Yang_Song1", "~Prafulla_Dhariwal1"]}, "keywords": {"value": ["Consistency Models", "Consistency Training", "Diffusion Models", "Score-Based Generative Models", "Score-Based Diffusion Models", "Distillation"]}, "abstract": {"value": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. Current consistency models achieve optimal sample quality by distilling from pre-trained diffusion models and employing learned metrics such as LPIPS. However, distillation limits the quality of consistency models to that of the pre-trained diffusion model, and LPIPS causes undesirable bias in evaluation. To tackle these challenges, we present improved techniques for consistency training, where consistency models learn directly from data without distillation. We delve into the theory behind consistency training and identify a previously overlooked flaw, which we address by eliminating Exponential Moving Average from the teacher consistency model. To replace learned metrics like LPIPS, we adopt Pseudo-Huber losses from robust statistics. Additionally, we introduce a lognormal noise schedule for the consistency training objective, and propose to double total discretization steps every set number of training iterations. Combined with better hyperparameter tuning, these modifications enable consistency models to achieve FID scores of 2.51 and 3.25 on CIFAR-10 and ImageNet $64\\times 64$ respectively in a single sampling step. These scores mark a 3.5$\\times$ and 4$\\times$ improvement compared to prior consistency training approaches. Through two-step sampling, we further reduce FID scores to 2.24 and 2.77 on these two datasets, surpassing those obtained via distillation in both one-step and two-step settings, while narrowing the gap between consistency models and other state-of-the-art generative models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "Consistency training works better than consistency distillation with improved techniques"}, "pdf": {"value": "/pdf/c40d76fe68ec3195a55ba242266828b01fdb06c5.pdf"}, "_bibtex": {"value": "@inproceedings{\nsong2024improved,\ntitle={Improved Techniques for Training Consistency Models},\nauthor={Yang Song and Prafulla Dhariwal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WNzy9bRDvG}\n}"}, "paperhash": {"value": "song|improved_techniques_for_training_consistency_models"}}, "number": 8410, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8410/-/Revision", "ICLR.cc/2024/Conference/Submission8410/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8410/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509291604, "cdate": 1695509291604, "tmdate": 1713119404391, "mdate": 1713119404391, "pdate": 1705411039848, "version": 2}, {"id": "7VPTUWkiDQ", "forum": "7VPTUWkiDQ", "signatures": ["ICLR.cc/2024/Conference/Submission8400/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8400/Authors"], "content": {"title": {"value": "Provable Compositional Generalization for Object-Centric Learning"}, "authors": {"value": ["Thadd\u00e4us Wiedemer", "Jack Brady", "Alexander Panfilov", "Attila Juhos", "Matthias Bethge", "Wieland Brendel"]}, "authorids": {"value": ["~Thadd\u00e4us_Wiedemer1", "~Jack_Brady1", "~Alexander_Panfilov1", "~Attila_Juhos1", "~Matthias_Bethge1", "~Wieland_Brendel1"]}, "keywords": {"value": ["compositional generalization", "identifiability", "object-centric learning", "generalization", "OOD generalization", "unsupervised learning", "slot attention", "disentanglement", "autoencoders", "representation learning"]}, "TLDR": {"value": "We show theoretical conditions under which compositional generalization is guaranteed for object-centric representation learning."}, "abstract": {"value": "Learning representations that generalize to novel compositions of known concepts is crucial for bridging the gap between human and machine perception. One prominent effort is learning object-centric representations, which are widely conjectured to enable compositional generalization. Yet, it remains unclear when this conjecture will be true, as a principled theoretical or empirical understanding of compositional generalization is lacking. In this work, we investigate when compositional generalization is guaranteed for object-centric representations through the lens of identifiability theory. We show that autoencoders that satisfy structural assumptions on the decoder and enforce encoder-decoder consistency will learn object-centric representations that provably generalize compositionally. We validate our theoretical result and highlight the practical relevance of our assumptions through experiments on synthetic image data."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/70cd6e52cd58ee0e0b07dfea409db6acc228b343.pdf"}, "supplementary_material": {"value": "/attachment/33fd1c9b517dded8403690a54c5761cbb95fa832.zip"}, "_bibtex": {"value": "@inproceedings{\nwiedemer2024provable,\ntitle={Provable Compositional Generalization for Object-Centric Learning},\nauthor={Thadd{\\\"a}us Wiedemer and Jack Brady and Alexander Panfilov and Attila Juhos and Matthias Bethge and Wieland Brendel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7VPTUWkiDQ}\n}"}, "paperhash": {"value": "wiedemer|provable_compositional_generalization_for_objectcentric_learning"}}, "number": 8400, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8400/-/Revision", "ICLR.cc/2024/Conference/Submission8400/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8400/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695508922068, "cdate": 1695508922068, "tmdate": 1710517264274, "mdate": 1710517264274, "pdate": 1705411039660, "version": 2}, {"id": "agPpmEgf8C", "forum": "agPpmEgf8C", "signatures": ["ICLR.cc/2024/Conference/Submission8258/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8258/Authors"], "content": {"title": {"value": "Predictive auxiliary objectives in deep RL mimic learning in the brain"}, "authors": {"value": ["Ching Fang", "Kim Stachenfeld"]}, "authorids": {"value": ["~Ching_Fang2", "~Kim_Stachenfeld1"]}, "keywords": {"value": ["hippocampus", "neuroscience", "cognitive science", "deep reinforcement learning", "representation learning", "prediction"]}, "abstract": {"value": "The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the RL system and hippocampus, an area thought to learn a predictive model to support memory-guided behavior. We also connect the encoder network and the value learning network of the RL system to visual cortex and striatum in the brain, respectively. This work demonstrates how representation learning in deep RL systems can provide an interpretable framework for modeling multi-region interactions in the brain. The deep RL perspective taken here also suggests an additional role of the hippocampus in the brain-- that of an auxiliary learning system that benefits representation learning in other regions."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/23365fd987e6b67de035adbd3b3bb679d36ddce7.pdf"}, "supplementary_material": {"value": "/attachment/82cbd73a501379a665cbc47213454979b9d5d8f2.pdf"}, "_bibtex": {"value": "@inproceedings{\nfang2024predictive,\ntitle={Predictive auxiliary objectives in deep {RL} mimic learning in the brain},\nauthor={Ching Fang and Kim Stachenfeld},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=agPpmEgf8C}\n}"}, "paperhash": {"value": "fang|predictive_auxiliary_objectives_in_deep_rl_mimic_learning_in_the_brain"}}, "number": 8258, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8258/-/Revision", "ICLR.cc/2024/Conference/Submission8258/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695502361071, "cdate": 1695502361071, "tmdate": 1707625646379, "mdate": 1707625646379, "pdate": 1705411036210, "version": 2}, {"id": "o2IEmeLL9r", "forum": "o2IEmeLL9r", "signatures": ["ICLR.cc/2024/Conference/Submission8189/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8189/Authors"], "content": {"title": {"value": "Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"}, "authors": {"value": ["Haoqi Yuan", "Zhancun Mu", "Feiyang Xie", "Zongqing Lu"]}, "authorids": {"value": ["~Haoqi_Yuan1", "~Zhancun_Mu1", "~Feiyang_Xie1", "~Zongqing_Lu2"]}, "keywords": {"value": ["reinforcement learning", "pre-training", "goal-conditioned RL", "open-world environments"]}, "abstract": {"value": "Pre-training on task-agnostic large datasets is a promising approach for enhancing the sample efficiency of reinforcement learning (RL) in solving complex tasks. We present PTGM, a novel method that pre-trains goal-based models to augment RL by providing temporal abstractions and behavior regularization. PTGM involves pre-training a low-level, goal-conditioned policy and training a high-level policy to generate goals for subsequent RL tasks. To address the challenges posed by the high-dimensional goal space, while simultaneously maintaining the agent's capability to accomplish various skills, we propose clustering goals in the dataset to form a discrete high-level action space. Additionally, we introduce a pre-trained goal prior model to regularize the behavior of the high-level policy in RL, enhancing sample efficiency and learning stability. Experimental results in a robotic simulation environment and the challenging open-world environment of Minecraft demonstrate PTGM\u2019s superiority in sample efficiency and task performance compared to baselines. Moreover, PTGM exemplifies enhanced interpretability and generalization of the acquired low-level skills."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/97ae12300fd1715ec484f1be154d49a619911fff.pdf"}, "_bibtex": {"value": "@inproceedings{\nyuan2024pretraining,\ntitle={Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning},\nauthor={Haoqi Yuan and Zhancun Mu and Feiyang Xie and Zongqing Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=o2IEmeLL9r}\n}"}, "paperhash": {"value": "yuan|pretraining_goalbased_models_for_sampleefficient_reinforcement_learning"}}, "number": 8189, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8189/-/Revision", "ICLR.cc/2024/Conference/Submission8189/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8189/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500211085, "cdate": 1695500211085, "tmdate": 1709661546710, "mdate": 1709661546710, "pdate": 1705411033730, "version": 2}, {"id": "hTEGyKf0dZ", "forum": "hTEGyKf0dZ", "signatures": ["ICLR.cc/2024/Conference/Submission7972/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7972/Authors"], "content": {"title": {"value": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"}, "authors": {"value": ["Xiangyu Qi", "Yi Zeng", "Tinghao Xie", "Pin-Yu Chen", "Ruoxi Jia", "Prateek Mittal", "Peter Henderson"]}, "authorids": {"value": ["~Xiangyu_Qi2", "~Yi_Zeng3", "~Tinghao_Xie1", "~Pin-Yu_Chen1", "~Ruoxi_Jia1", "~Prateek_Mittal1", "~Peter_Henderson1"]}, "keywords": {"value": ["AI Safety", "Large Language Models", "Fine-tuning", "Jailbreaking", "AI Alignment"]}, "TLDR": {"value": "Fine-tuning aligned Large Language Models introduces new safety risks that current alignment infrastructures fall short of addressing."}, "abstract": {"value": "Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open-source release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on customized datasets accelerate this trend. But, what are the safety costs associated with such customized fine-tuning? While existing safety alignment techniques restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than $0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing --- even if a model's initial safety alignment is impeccable, how can it be maintained after customized fine-tuning? We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the customized fine-tuning of aligned LLMs.  (This paper contains red-teaming data and model-generated content that can be offensive in nature.)"}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cf8a15c7b5a808ae67357cdde0c8f2bbd5c4b8ed.pdf"}, "_bibtex": {"value": "@inproceedings{\nqi2024finetuning,\ntitle={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},\nauthor={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hTEGyKf0dZ}\n}"}, "paperhash": {"value": "qi|finetuning_aligned_language_models_compromises_safety_even_when_users_do_not_intend_to"}}, "number": 7972, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7972/-/Revision", "ICLR.cc/2024/Conference/Submission7972/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7972/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492383773, "cdate": 1695492383773, "tmdate": 1710514437125, "mdate": 1710514437125, "pdate": 1705411025344, "version": 2}, {"id": "PdaPky8MUn", "forum": "PdaPky8MUn", "signatures": ["ICLR.cc/2024/Conference/Submission7782/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7782/Authors"], "content": {"title": {"value": "Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"}, "authors": {"value": ["Ido Amos", "Jonathan Berant", "Ankit Gupta"]}, "authorids": {"value": ["~Ido_Amos1", "~Jonathan_Berant1", "~Ankit_Gupta3"]}, "keywords": {"value": ["Pre Training", "Transformers", "State Space Models", "Long Range Models", "Fair Evaluation"]}, "abstract": {"value": "Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, *using only the downstream task data*, leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 absolute points. Subsequently, we analyze the utility of previously-proposed structured parameterizations for SSMs and show they become mostly redundant in the presence of data-driven initialization obtained through pretraining. Our work shows that, when evaluating different architectures on supervised tasks, incorporation of data-driven priors via pretraining is essential for reliable performance estimation, and can be done efficiently."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0f82cdb6beb87821d0a243ee526230c73d7ae798.pdf"}, "TLDR": {"value": "Training a model directly on a dataset from sctrach can lead to grossly under-estimated performance. For proper evaluation, one must first pretrain on the dataset and then finetune."}, "_bibtex": {"value": "@inproceedings{\namos2024never,\ntitle={Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors},\nauthor={Ido Amos and Jonathan Berant and Ankit Gupta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PdaPky8MUn}\n}"}, "paperhash": {"value": "amos|never_train_from_scratch_fair_comparison_of_longsequence_models_requires_datadriven_priors"}}, "number": 7782, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7782/-/Revision", "ICLR.cc/2024/Conference/Submission7782/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7782/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695485756547, "cdate": 1695485756547, "tmdate": 1710436135709, "mdate": 1710436135709, "pdate": 1705411020178, "version": 2}, {"id": "LzPWWPAdY4", "forum": "LzPWWPAdY4", "signatures": ["ICLR.cc/2024/Conference/Submission7536/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7536/Authors"], "content": {"title": {"value": "LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"}, "authors": {"value": ["Yixiao Li", "Yifan Yu", "Chen Liang", "Nikos Karampatziakis", "Pengcheng He", "Weizhu Chen", "Tuo Zhao"]}, "authorids": {"value": ["~Yixiao_Li2", "~Yifan_Yu4", "~Chen_Liang3", "~Nikos_Karampatziakis1", "~Pengcheng_He2", "~Weizhu_Chen1", "~Tuo_Zhao1"]}, "keywords": {"value": ["quantization", "compression", "large language models", "NLP", "machine learning", "low rank"]}, "abstract": {"value": "Quantization is an indispensable technique for serving Large Language Models (LLMs) and has recently found its way into LoRA fine-tuning (Dettmers et al., 2023). In this work we focus on the scenario where quantization and LoRA fine- tuning are applied together on a pre-trained model. In such cases it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ (LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that simultaneously quantizes an LLM and finds a proper low-rank initialization for LoRA fine-tuning. Such an initialization alleviates the discrep- ancy between the quantized and full-precision model and significantly improves the generalization in downstream tasks. We evaluate our method on natural lan- guage understanding, question answering, summarization, and natural language generation tasks. Experiments show that our method is highly effective and out- performs existing quantization methods, especially in the challenging 2-bit and 2/4-bit mixed precision regimes. We will release our code."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c8a3b2454c94e0374c1778862e8fca63e370ba5b.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024loftq,\ntitle={LoftQ: Lo{RA}-Fine-Tuning-aware Quantization for Large Language Models},\nauthor={Yixiao Li and Yifan Yu and Chen Liang and Nikos Karampatziakis and Pengcheng He and Weizhu Chen and Tuo Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LzPWWPAdY4}\n}"}, "paperhash": {"value": "li|loftq_lorafinetuningaware_quantization_for_large_language_models"}}, "number": 7536, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7536/-/Revision", "ICLR.cc/2024/Conference/Submission7536/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7536/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478136846, "cdate": 1695478136846, "tmdate": 1710583312042, "mdate": 1710583312042, "pdate": 1705411012215, "version": 2}, {"id": "oO6FsMyDBt", "forum": "oO6FsMyDBt", "signatures": ["ICLR.cc/2024/Conference/Submission7510/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7510/Authors"], "content": {"title": {"value": "Graph Neural Networks for Learning Equivariant Representations of Neural Networks"}, "authors": {"value": ["Miltiadis Kofinas", "Boris Knyazev", "Yan Zhang", "Yunlu Chen", "Gertjan J. Burghouts", "Efstratios Gavves", "Cees G. M. Snoek", "David W. Zhang"]}, "authorids": {"value": ["~Miltiadis_Kofinas2", "~Boris_Knyazev1", "~Yan_Zhang1", "~Yunlu_Chen1", "~Gertjan_J._Burghouts1", "~Efstratios_Gavves1", "~Cees_G._M._Snoek1", "~David_W._Zhang1"]}, "keywords": {"value": ["Deep weight space", "Graph neural networks", "Transformers", "Permutation equivariance", "Implicit neural representations", "Networks for networks", "Neural graphs"]}, "TLDR": {"value": "We propose graph neural networks that learn permutation equivariant representations of other neural networks"}, "abstract": {"value": "Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalization performance, and learning to optimize, while consistently outperforming state-of-the-art methods. The source code is open-sourced at https://github.com/mkofinas/neural-graphs."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/338609142f1f45e68ec5fc8b5d6c9a3c0247ee30.pdf"}, "supplementary_material": {"value": "/attachment/1e7b5b69325338b8f37fe9e58c18d76ca055edf5.zip"}, "_bibtex": {"value": "@inproceedings{\nkofinas2024graph,\ntitle={Graph Neural Networks for Learning Equivariant Representations of Neural Networks},\nauthor={Miltiadis Kofinas and Boris Knyazev and Yan Zhang and Yunlu Chen and Gertjan J. Burghouts and Efstratios Gavves and Cees G. M. Snoek and David W. Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oO6FsMyDBt}\n}"}, "paperhash": {"value": "kofinas|graph_neural_networks_for_learning_equivariant_representations_of_neural_networks"}}, "number": 7510, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7510/-/Revision", "ICLR.cc/2024/Conference/Submission7510/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7510/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695476894164, "cdate": 1695476894164, "tmdate": 1710763567050, "mdate": 1710763567050, "pdate": 1705411011331, "version": 2}, {"id": "IGzaH538fz", "forum": "IGzaH538fz", "signatures": ["ICLR.cc/2024/Conference/Submission7488/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7488/Authors"], "content": {"title": {"value": "GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"}, "authors": {"value": ["zaishuo xia", "Han Yang", "Binghui Wang", "Jinyuan Jia"]}, "authorids": {"value": ["~zaishuo_xia1", "~Han_Yang9", "~Binghui_Wang2", "~Jinyuan_Jia2"]}, "keywords": {"value": ["Adversarial attacks to graph classification; provable robustness"]}, "abstract": {"value": "Graph classification, which aims to predict a label for a graph, has many real-world applications such as malware detection, fraud detection, and healthcare. However, many studies show an attacker could carefully perturb the structure and/or node features in a graph such that a graph classifier misclassifies the perturbed graph. Such vulnerability impedes the deployment of graph classification in security/safety-critical applications. Existing empirical defenses lack formal robustness guarantees and could be broken by adaptive or unknown attacks. Existing provable defenses have the following limitations: 1)  they achieve sub-optimal robustness guarantees for graph structure perturbation, 2) they cannot provide robustness guarantees for arbitrarily node feature perturbations, 3) their robustness guarantees are probabilistic, meaning they could be incorrect with a non-zero probability, and 4) they incur large computation costs. We aim to address those limitations in this work. We propose GNNCert, a certified defense against both graph structure and node feature perturbations for graph classification. Our GNNCert provably predicts the same label for a graph when the number of perturbed edges and the number of nodes with perturbed features are bounded. Our results on 8 benchmark datasets show that GNNCert outperforms three state-of-the-art methods."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/03ea622e3c66547d24c4da2f725ddf1fe5db2233.pdf"}, "_bibtex": {"value": "@inproceedings{\nxia2024graphguard,\ntitle={GraphGuard: Provably Robust Graph Classification against Adversarial Attacks},\nauthor={zaishuo xia and Han Yang and Binghui Wang and Jinyuan Jia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IGzaH538fz}\n}"}, "paperhash": {"value": "xia|gnncert_deterministic_certification_of_graph_neural_networks_against_adversarial_perturbations"}}, "number": 7488, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7488/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7488/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695475919263, "cdate": 1695475919263, "tmdate": 1712674007298, "mdate": 1712674007298, "pdate": 1705411010869, "version": 2}, {"id": "LjivA1SLZ6", "forum": "LjivA1SLZ6", "signatures": ["ICLR.cc/2024/Conference/Submission7321/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7321/Authors"], "content": {"title": {"value": "Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning"}, "authors": {"value": ["Hyungho Na", "Yunkyeong Seo", "Il-chul Moon"]}, "authorids": {"value": ["~Hyungho_Na1", "~Yunkyeong_Seo1", "~Il-chul_Moon1"]}, "keywords": {"value": ["Multi-agent reinforcement learning", "episodic control", "episodic incentive", "state embedding"]}, "TLDR": {"value": "We introduce a framework that enhances memory utilization in cooperative multi-agent reinforcement learning to achieve a common goal through semantic embedding and episodic incentives."}, "abstract": {"value": "In cooperative multi-agent reinforcement learning (MARL), agents aim to achieve a common goal, such as defeating enemies or scoring a goal. Existing MARL algorithms are effective but still require significant learning time and often get trapped in local optima by complex tasks, subsequently failing to discover a goal-reaching policy. To address this, we introduce Efficient episodic Memory Utilization (EMU) for MARL, with two primary objectives: (a) accelerating reinforcement learning by leveraging semantically coherent memory from an episodic buffer and (b) selectively promoting desirable transitions to prevent local convergence. To achieve (a), EMU incorporates a trainable encoder/decoder structure alongside MARL, creating coherent memory embeddings that facilitate exploratory memory recall. To achieve (b), EMU introduces a novel reward structure called episodic incentive based on the desirability of states. This reward improves the TD target in Q-learning and acts as an additional incentive for desirable transitions. We provide theoretical support for the proposed incentive and demonstrate the effectiveness of EMU compared to conventional episodic control. The proposed method is evaluated in StarCraft II and Google Research Football, and empirical results indicate further performance improvement over state-of-the-art methods."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b2d5ac5539754d00bf99458a60c63157c74fbdb.pdf"}, "supplementary_material": {"value": "/attachment/aca81eae23a15faf63dd814c4dafba4d4933455a.zip"}, "_bibtex": {"value": "@inproceedings{\nna2024efficient,\ntitle={Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning},\nauthor={Hyungho Na and Yunkyeong Seo and Il-chul Moon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LjivA1SLZ6}\n}"}, "paperhash": {"value": "na|efficient_episodic_memory_utilization_of_cooperative_multiagent_reinforcement_learning"}}, "number": 7321, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7321/-/Revision", "ICLR.cc/2024/Conference/Submission7321/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7321/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695467628362, "cdate": 1695467628362, "tmdate": 1709790543033, "mdate": 1709790543033, "pdate": 1705411006224, "version": 2}, {"id": "xuY33XhEGR", "forum": "xuY33XhEGR", "signatures": ["ICLR.cc/2024/Conference/Submission7174/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7174/Authors"], "content": {"title": {"value": "ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs"}, "authors": {"value": ["Yogesh Verma", "Markus Heinonen", "Vikas Garg"]}, "authorids": {"value": ["~Yogesh_Verma1", "~Markus_Heinonen1", "~Vikas_Garg2"]}, "keywords": {"value": ["neural ODE", "time-series forecasting", "climate prediction", "physics-informed ML"]}, "TLDR": {"value": "We introduce a novel climate and weather modeling approach, inspired by physics, using ODEs that capture underlying inductive biases and allow for uncertainty quantification in predictions."}, "abstract": {"value": "Climate and weather prediction traditionally relies on complex numerical simulations of atmospheric physics. Deep learning approaches, such as transformers, have recently challenged the simulation paradigm with complex network forecasts. However, they often act as data-driven black-box models that neglect the underlying physics and lack uncertainty quantification. We address these limitations with ClimODE, a  spatiotemporal continuous-time process that implements a key principle of advection from statistical mechanics, namely, weather changes due to a spatial movement of quantities over time. ClimODE models precise weather evolution with value-conserving dynamics, learning global weather transport as a neural flow, which also enables estimating the uncertainty in predictions. Our approach outperforms existing data-driven methods in global and regional forecasting with an order of magnitude smaller parameterization, establishing a new state of the art."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d6e043c8dac8d842d6ba1816e2b687862e46f2bb.pdf"}, "supplementary_material": {"value": "/attachment/4ab11e1b180cfcb265a6b4d81efec2238b2ee878.zip"}, "_bibtex": {"value": "@inproceedings{\nverma2024climode,\ntitle={Clim{ODE}: Climate Forecasting With Physics-informed Neural {ODE}s},\nauthor={Yogesh Verma and Markus Heinonen and Vikas Garg},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xuY33XhEGR}\n}"}, "paperhash": {"value": "verma|climode_climate_and_weather_forecasting_with_physicsinformed_neural_odes"}}, "number": 7174, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7174/-/Revision", "ICLR.cc/2024/Conference/Submission7174/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7174/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695459335703, "cdate": 1695459335703, "tmdate": 1713159123312, "mdate": 1713159123312, "pdate": 1705411001076, "version": 2}, {"id": "4Ay23yeuz0", "forum": "4Ay23yeuz0", "signatures": ["ICLR.cc/2024/Conference/Submission6938/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6938/Authors"], "content": {"title": {"value": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"}, "authors": {"value": ["Hengrui Zhang", "Jiani Zhang", "Zhengyuan Shen", "Balasubramaniam Srinivasan", "Xiao Qin", "Christos Faloutsos", "Huzefa Rangwala", "George Karypis"]}, "authorids": {"value": ["~Hengrui_Zhang1", "~Jiani_Zhang2", "~Zhengyuan_Shen1", "~Balasubramaniam_Srinivasan1", "~Xiao_Qin3", "~Christos_Faloutsos1", "~Huzefa_Rangwala2", "~George_Karypis1"]}, "keywords": {"value": ["Tabular data", "tabular generation", "diffusion models"]}, "abstract": {"value": "Recent advances in tabular data generation have greatly enhanced synthetic data quality. However, extending diffusion models to tabular data is challenging due to the intricately varied distributions and a blend of data types of tabular data. This paper introduces TabSyn, a methodology that synthesizes tabular data by leveraging a diffusion model within a variational autoencoder (VAE) crafted latent space. The key advantages of the proposed Tabsyn include (1) Generality: the ability to handle a broad spectrum of data types by converting them into a single unified space and explicitly capturing inter-column relations; (2) Quality: optimizing the distribution of latent embeddings to enhance the subsequent training of diffusion models, which helps generate high-quality synthetic data; (3) Speed: much fewer number of reverse steps and faster synthesis speed than existing diffusion-based methods. Extensive experiments on six datasets with five metrics demonstrate that Tabsyn outperforms existing methods. Specifically, it reduces the error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations compared with the most competitive baselines. The code has been made available at https://github.com/amazon-science/tabsyn."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a916d9616f8be0fc9c47c323b6afe8398acf898d.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024mixedtype,\ntitle={Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space},\nauthor={Hengrui Zhang and Jiani Zhang and Zhengyuan Shen and Balasubramaniam Srinivasan and Xiao Qin and Christos Faloutsos and Huzefa Rangwala and George Karypis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4Ay23yeuz0}\n}"}, "paperhash": {"value": "zhang|mixedtype_tabular_data_synthesis_with_scorebased_diffusion_in_latent_space"}}, "number": 6938, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6938/-/Revision", "ICLR.cc/2024/Conference/Submission6938/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6938/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695447541558, "cdate": 1695447541558, "tmdate": 1709661536299, "mdate": 1709661536299, "pdate": 1705410992710, "version": 2}, {"id": "bNt7oajl2a", "forum": "bNt7oajl2a", "signatures": ["ICLR.cc/2024/Conference/Submission6886/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6886/Authors"], "content": {"title": {"value": "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement"}, "authors": {"value": ["Linlu Qiu", "Liwei Jiang", "Ximing Lu", "Melanie Sclar", "Valentina Pyatkin", "Chandra Bhagavatula", "Bailin Wang", "Yoon Kim", "Yejin Choi", "Nouha Dziri", "Xiang Ren"]}, "authorids": {"value": ["~Linlu_Qiu1", "~Liwei_Jiang2", "~Ximing_Lu1", "~Melanie_Sclar1", "~Valentina_Pyatkin1", "~Chandra_Bhagavatula1", "~Bailin_Wang3", "~Yoon_Kim1", "~Yejin_Choi1", "~Nouha_Dziri2", "~Xiang_Ren1"]}, "keywords": {"value": ["language model", "natural language processing", "inductive reasoning"]}, "abstract": {"value": "The ability to derive underlying principles from a handful of observations and then generalize to novel situations---known as inductive reasoning---is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through $\\textit{iterative hypothesis refinement}$, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal $\\textit{hypothesis proposers}$ (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the proposed set of rules, this hybrid approach achieves strong results across inductive reasoning benchmarks that require inducing causal relations, language-like instructions, and symbolic concepts. However, they also behave as puzzling $\\textit{inductive reasoners}$, showing notable performance gaps between rule induction (i.e., identifying plausible rules) and rule application (i.e., applying proposed rules to instances), suggesting that LMs are proposing hypotheses without being able to actually apply the rules. Through empirical and human analyses, we further reveal several discrepancies between the inductive reasoning processes of LMs and humans, shedding light on both the potentials and limitations of using LMs in inductive reasoning tasks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4032df754ed3bcf600b7b70606e1de283e796547.pdf"}, "_bibtex": {"value": "@inproceedings{\nqiu2024phenomenal,\ntitle={Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement},\nauthor={Linlu Qiu and Liwei Jiang and Ximing Lu and Melanie Sclar and Valentina Pyatkin and Chandra Bhagavatula and Bailin Wang and Yoon Kim and Yejin Choi and Nouha Dziri and Xiang Ren},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bNt7oajl2a}\n}"}, "paperhash": {"value": "qiu|phenomenal_yet_puzzling_testing_inductive_reasoning_capabilities_of_language_models_with_hypothesis_refinement"}}, "number": 6886, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6886/-/Revision", "ICLR.cc/2024/Conference/Submission6886/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6886/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695444342366, "cdate": 1695444342366, "tmdate": 1710791353423, "mdate": 1710791353423, "pdate": 1705410990790, "version": 2}, {"id": "HSKaGOi7Ar", "forum": "HSKaGOi7Ar", "signatures": ["ICLR.cc/2024/Conference/Submission6795/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6795/Authors"], "content": {"title": {"value": "Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"}, "authors": {"value": ["Bohang Zhang", "Jingchu Gai", "Yiheng Du", "Qiwei Ye", "Di He", "Liwei Wang"]}, "authorids": {"value": ["~Bohang_Zhang1", "~Jingchu_Gai1", "~Yiheng_Du1", "~Qiwei_Ye1", "~Di_He1", "~Liwei_Wang1"]}, "keywords": {"value": ["Graph Neural Networks", "Expressive Power", "Homomorphism", "Subgraph Counting", "Weisfeiler-Lehman"]}, "abstract": {"value": "Designing expressive Graph Neural Networks (GNNs) is a fundamental topic in the graph learning community. So far, GNN expressiveness has been primarily assessed via the Weisfeiler-Lehman (WL) hierarchy. However, such an expressivity measure has notable limitations: it is inherently coarse, qualitative, and may not well reflect practical requirements (e.g., the ability to encode substructures). In this paper, we introduce a novel framework for quantitatively studying the expressiveness of GNN architectures, addressing all the above limitations. Specifically, we identify a fundamental expressivity measure termed homomorphism expressivity, which quantifies the ability of GNN models to count graphs under homomorphism. Homomorphism expressivity offers a complete and practical assessment tool: the completeness enables direct expressivity comparisons between GNN models, while the practicality allows for understanding concrete GNN abilities such as subgraph counting. By examining four classes of prominent GNNs as case studies, we derive simple, unified, and elegant descriptions of their homomorphism expressivity for both invariant and equivariant settings. Our results provide novel insights into a series of previous work, unify the landscape of different subareas in the community, and settle several open questions. Empirically, extensive experiments on both synthetic and real-world tasks verify our theory, showing that the practical performance of GNN models aligns well with the proposed metric."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1cdf9d7930ee08e1c02c2c2819a16e7a2cc56a4b.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024beyond,\ntitle={Beyond Weisfeiler-Lehman: A Quantitative Framework for {GNN} Expressiveness},\nauthor={Bohang Zhang and Jingchu Gai and Yiheng Du and Qiwei Ye and Di He and Liwei Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HSKaGOi7Ar}\n}"}, "paperhash": {"value": "zhang|beyond_weisfeilerlehman_a_quantitative_framework_for_gnn_expressiveness"}}, "number": 6795, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6795/-/Revision", "ICLR.cc/2024/Conference/Submission6795/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6795/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695439977927, "cdate": 1695439977927, "tmdate": 1710475662290, "mdate": 1710475662290, "pdate": 1705410987419, "version": 2}, {"id": "KUNzEQMWU7", "forum": "KUNzEQMWU7", "signatures": ["ICLR.cc/2024/Conference/Submission6738/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6738/Authors"], "content": {"title": {"value": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"}, "authors": {"value": ["Pan Lu", "Hritik Bansal", "Tony Xia", "Jiacheng Liu", "Chunyuan Li", "Hannaneh Hajishirzi", "Hao Cheng", "Kai-Wei Chang", "Michel Galley", "Jianfeng Gao"]}, "authorids": {"value": ["~Pan_Lu2", "~Hritik_Bansal2", "~Tony_Xia1", "~Jiacheng_Liu2", "~Chunyuan_Li1", "~Hannaneh_Hajishirzi1", "~Hao_Cheng4", "~Kai-Wei_Chang1", "~Michel_Galley1", "~Jianfeng_Gao1"]}, "keywords": {"value": ["large language models", "large multimodal models", "mathematical reasoning", "vision-language reasoning", "foundation models and their evaluations"]}, "abstract": {"value": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/787a339a2bb6e601216540a43a659322ff3e4e9e.pdf"}, "TLDR": {"value": "We introduce MathVista, a novel benchmark for evaluating mathematical reasoning capabilities within visual contexts, and conduct extensive experiments on 11 foundation models."}, "_bibtex": {"value": "@inproceedings{\nlu2024mathvista,\ntitle={MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},\nauthor={Pan Lu and Hritik Bansal and Tony Xia and Jiacheng Liu and Chunyuan Li and Hannaneh Hajishirzi and Hao Cheng and Kai-Wei Chang and Michel Galley and Jianfeng Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KUNzEQMWU7}\n}"}, "paperhash": {"value": "lu|mathvista_evaluating_mathematical_reasoning_of_foundation_models_in_visual_contexts"}}, "number": 6738, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6738/-/Revision", "ICLR.cc/2024/Conference/Submission6738/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6738/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695437335328, "cdate": 1695437335328, "tmdate": 1710461815644, "mdate": 1710461815644, "pdate": 1705410985360, "version": 2}, {"id": "zMPHKOmQNb", "forum": "zMPHKOmQNb", "signatures": ["ICLR.cc/2024/Conference/Submission6610/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6610/Authors"], "content": {"title": {"value": "Protein Discovery with Discrete Walk-Jump Sampling"}, "authors": {"value": ["Nathan C. Frey", "Dan Berenberg", "Karina Zadorozhny", "Joseph Kleinhenz", "Julien Lafrance-Vanasse", "Isidro Hotzel", "Yan Wu", "Stephen Ra", "Richard Bonneau", "Kyunghyun Cho", "Andreas Loukas", "Vladimir Gligorijevic", "Saeed Saremi"]}, "authorids": {"value": ["~Nathan_C._Frey1", "~Dan_Berenberg1", "~Karina_Zadorozhny1", "~Joseph_Kleinhenz1", "~Julien_Lafrance-Vanasse1", "~Isidro_Hotzel1", "~Yan_Wu7", "~Stephen_Ra1", "~Richard_Bonneau2", "~Kyunghyun_Cho1", "~Andreas_Loukas1", "~Vladimir_Gligorijevic2", "~Saeed_Saremi1"]}, "keywords": {"value": ["generative modeling", "langevin mcmc", "energy-based models", "score-based models", "protein design", "protein discovery"]}, "TLDR": {"value": "We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold, and projecting back to the true data manifold with one-step denoising."}, "abstract": {"value": "We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold with Langevin Markov chain Monte Carlo (MCMC), and projecting back to the true data manifold with one-step denoising. Our $\\textit{Discrete Walk-Jump Sampling}$ formalism combines the contrastive divergence training of an energy-based model and improved sample quality of a score-based model, while simplifying training and sampling by requiring only a single noise level. We evaluate the robustness of our approach on generative modeling of antibody proteins and introduce the $\\textit{distributional conformity score}$ to benchmark protein generative models. By optimizing and sampling from our models for the proposed distributional conformity score, 97-100\\% of generated samples are successfully expressed and purified and 70\\% of functional designs show equal or improved binding affinity compared to known functional antibodies on the first attempt in a single round of laboratory experiments. We also report the first demonstration of long-run fast-mixing MCMC chains where diverse antibody protein classes are visited in a single MCMC chain."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4c55a7e5606fd6a163e0e06033dc8c454015484e.pdf"}, "_bibtex": {"value": "@inproceedings{\nfrey2024protein,\ntitle={Protein Discovery with Discrete Walk-Jump Sampling},\nauthor={Nathan C. Frey and Dan Berenberg and Karina Zadorozhny and Joseph Kleinhenz and Julien Lafrance-Vanasse and Isidro Hotzel and Yan Wu and Stephen Ra and Richard Bonneau and Kyunghyun Cho and Andreas Loukas and Vladimir Gligorijevic and Saeed Saremi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zMPHKOmQNb}\n}"}, "paperhash": {"value": "frey|protein_discovery_with_discrete_walkjump_sampling"}}, "number": 6610, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6610/-/Revision", "ICLR.cc/2024/Conference/Submission6610/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6610/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430573478, "cdate": 1695430573478, "tmdate": 1710528930260, "mdate": 1710528930260, "pdate": 1705410981054, "version": 2}, {"id": "oTRwljRgiv", "forum": "oTRwljRgiv", "signatures": ["ICLR.cc/2024/Conference/Submission6600/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6600/Authors"], "content": {"title": {"value": "ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"}, "authors": {"value": ["Kensen Shi", "Joey Hong", "Yinlin Deng", "Pengcheng Yin", "Manzil Zaheer", "Charles Sutton"]}, "authorids": {"value": ["~Kensen_Shi1", "~Joey_Hong2", "yinlind2@illinois.edu", "~Pengcheng_Yin1", "~Manzil_Zaheer1", "~Charles_Sutton1"]}, "keywords": {"value": ["Program Synthesis", "Programming By Example", "Generalization", "Compositional Generalization"]}, "TLDR": {"value": "We describe different forms of compositional generalization that are desirable in program synthesis, and present a decomposition-based approach to synthesis achieving higher compositional generalization on two domains compared to prior approaches."}, "abstract": {"value": "When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. When used with Transformer models trained from scratch, ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines. Finally, we use our benchmarks to demonstrate that LLMs struggle to compositionally generalize when asked to do programming-by-example in a few-shot setting, but an ExeDec-style prompting approach can improve the generalization ability and overall performance."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/895c33716118f7115b70f8fe1a38933f9b3a0f51.pdf"}, "_bibtex": {"value": "@inproceedings{\nshi2024exedec,\ntitle={ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis},\nauthor={Kensen Shi and Joey Hong and Yinlin Deng and Pengcheng Yin and Manzil Zaheer and Charles Sutton},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oTRwljRgiv}\n}"}, "paperhash": {"value": "shi|exedec_execution_decomposition_for_compositional_generalization_in_neural_program_synthesis"}}, "number": 6600, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6600/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6600/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430027086, "cdate": 1695430027086, "tmdate": 1710557765138, "mdate": 1710557765138, "pdate": 1705410980702, "version": 2}, {"id": "w4abltTZ2f", "forum": "w4abltTZ2f", "signatures": ["ICLR.cc/2024/Conference/Submission6581/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6581/Authors"], "content": {"title": {"value": "Batched Low-Rank Adaptation of Foundation Models"}, "authors": {"value": ["Yeming Wen", "Swarat Chaudhuri"]}, "authorids": {"value": ["~Yeming_Wen1", "~Swarat_Chaudhuri1"]}, "keywords": {"value": ["LLM Adaptation", "Low-rank", "Code Generation"]}, "abstract": {"value": "Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning foundation models by incorporating trainable low-rank matrices, thereby reducing the number of trainable parameters. While \\lora/ offers numerous advantages, its applicability for real-time serving to a diverse and global user base \nis constrained by its incapability to handle multiple task-specific adapters efficiently. This imposes a performance bottleneck in scenarios requiring personalized, task-specific adaptations for each incoming request.\n\nTo address this, we introduce FLoRA (Fast LoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching of heterogeneous requests. We empirically demonstrate that \\flora/ retains the performance merits of \\lora/, showcasing competitive results on the MultiPL-E code generation benchmark spanning over 8 languages and a multilingual speech recognition task across 6 languages."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/49eea165a2219adfe98557e7d54b6ca13ebb7db9.pdf"}, "supplementary_material": {"value": "/attachment/b123c13d023bc1349d947752af263bddf3009be5.zip"}, "TLDR": {"value": "we introduce Fast LoRA (FLoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching for diverse LLM queries."}, "_bibtex": {"value": "@inproceedings{\nwen2024batched,\ntitle={Batched Low-Rank Adaptation of Foundation Models},\nauthor={Yeming Wen and Swarat Chaudhuri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w4abltTZ2f}\n}"}, "paperhash": {"value": "wen|batched_lowrank_adaptation_of_foundation_models"}}, "number": 6581, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6581/-/Revision", "ICLR.cc/2024/Conference/Submission6581/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6581/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695429166581, "cdate": 1695429166581, "tmdate": 1711666047477, "mdate": 1711666047477, "pdate": 1705410980167, "version": 2}, {"id": "IYxDy2jDFL", "forum": "IYxDy2jDFL", "signatures": ["ICLR.cc/2024/Conference/Submission6552/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6552/Authors"], "content": {"title": {"value": "Improved Active Learning via Dependent Leverage Score Sampling"}, "authors": {"value": ["Atsushi Shimizu", "Xiaoou Cheng", "Christopher Musco", "Jonathan Weare"]}, "authorids": {"value": ["~Atsushi_Shimizu1", "~Xiaoou_Cheng1", "~Christopher_Musco1", "~Jonathan_Weare1"]}, "keywords": {"value": ["leverage score sampling", "active learning", "polynomial regression", "differential equations", "pivotal sampling"]}, "TLDR": {"value": "Better active learning (in theory and practice) in the presence of adversarial noise via non-independent leverage score sampling."}, "abstract": {"value": "We show how to obtain improved active learning methods in the agnostic (adversarial noise) setting by combining marginal leverage score sampling with non-independent sampling strategies that promote spatial coverage. In particular, we propose an easily implemented method based on the \\emph{pivotal sampling algorithm}, which we test on problems motivated by learning-based methods for parametric PDEs and uncertainty quantification. In comparison to independent sampling, our method reduces the number of samples needed to reach a given target accuracy by up to $50\\%$.\n\nWe support our findings with two theoretical results. First, we show that any non-independent leverage score sampling method that obeys a weak \\emph{one-sided $\\ell_{\\infty}$ independence condition} (which includes pivotal sampling) can actively learn $d$ dimensional linear functions with $O(d\\log d)$ samples, matching independent sampling. This result extends recent work on matrix Chernoff bounds under $\\ell_{\\infty}$ independence, and may be of interest for analyzing other sampling strategies beyond pivotal sampling. Second, we show that, for the important case of polynomial regression, our pivotal method obtains an improved bound of $O(d)$ samples."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/98b84fd00d5f25df5c6927e10d5e51cde527543e.pdf"}, "_bibtex": {"value": "@inproceedings{\nshimizu2024improved,\ntitle={Improved Active Learning via Dependent Leverage Score Sampling},\nauthor={Atsushi Shimizu and Xiaoou Cheng and Christopher Musco and Jonathan Weare},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IYxDy2jDFL}\n}"}, "paperhash": {"value": "shimizu|improved_active_learning_via_dependent_leverage_score_sampling"}}, "number": 6552, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6552/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6552/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427300576, "cdate": 1695427300576, "tmdate": 1712711315761, "mdate": 1712711315761, "pdate": 1705410979213, "version": 2}, {"id": "uNrFpDPMyo", "forum": "uNrFpDPMyo", "signatures": ["ICLR.cc/2024/Conference/Submission6547/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6547/Authors"], "content": {"title": {"value": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, "authors": {"value": ["Suyu Ge", "Yunan Zhang", "Liyuan Liu", "Minjia Zhang", "Jiawei Han", "Jianfeng Gao"]}, "authorids": {"value": ["~Suyu_Ge1", "~Yunan_Zhang1", "~Liyuan_Liu3", "~Minjia_Zhang1", "~Jiawei_Han1", "~Jianfeng_Gao1"]}, "keywords": {"value": ["Large Language Model", "Efficient Inference", "Generative Inference", "Key-Value Cache"]}, "TLDR": {"value": "We introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs) and accelerates its generation throughput."}, "abstract": {"value": "In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with negligible generation quality loss. We will release our code and the compatible CUDA kernel for reproducibility."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/757a55aa24be0345fe1687e09fa5ca448934e52f.pdf"}, "_bibtex": {"value": "@inproceedings{\nge2024model,\ntitle={Model Tells You What to Discard: Adaptive {KV} Cache Compression for {LLM}s},\nauthor={Suyu Ge and Yunan Zhang and Liyuan Liu and Minjia Zhang and Jiawei Han and Jianfeng Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uNrFpDPMyo}\n}"}, "paperhash": {"value": "ge|model_tells_you_what_to_discard_adaptive_kv_cache_compression_for_llms"}}, "number": 6547, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6547/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6547/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427043679, "cdate": 1695427043679, "tmdate": 1710571899831, "mdate": 1710571899831, "pdate": 1705410979091, "version": 2}, {"id": "0BqyZSWfzo", "forum": "0BqyZSWfzo", "signatures": ["ICLR.cc/2024/Conference/Submission6514/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6514/Authors"], "content": {"title": {"value": "One-shot Empirical Privacy Estimation for Federated Learning"}, "authors": {"value": ["Galen Andrew", "Peter Kairouz", "Sewoong Oh", "Alina Oprea", "Hugh Brendan McMahan", "Vinith Menon Suriyakumar"]}, "authorids": {"value": ["~Galen_Andrew1", "~Peter_Kairouz1", "~Sewoong_Oh3", "~Alina_Oprea1", "~Hugh_Brendan_McMahan1", "~Vinith_Menon_Suriyakumar1"]}, "keywords": {"value": ["differential privacy", "federated learning", "empirical privacy"]}, "TLDR": {"value": "Empirical estimation of privacy during training with minimal overhead, useful when tight analytical bounds are not known, e.g. when the adversary observes only the final model."}, "abstract": {"value": "Privacy estimation techniques for differentially private (DP) algorithms are useful for comparing against analytical bounds, or to empirically measure privacy loss in settings where known analytical bounds are not tight. However, existing privacy auditing techniques usually make strong assumptions on the adversary (e.g., knowledge of intermediate model iterates or the training data distribution), are tailored to specific tasks, model architectures, or DP algorithm, and/or require retraining the model many times (typically on the order of thousands). These shortcomings make deploying such techniques at scale difficult in practice, especially in federated settings where model training can take days or weeks. In this work, we present a novel \u201cone-shot\u201d approach that can systematically address these challenges, allowing efficient auditing or estimation of the privacy loss of a model during the same, single training run used to fit model parameters, and without requiring any a priori knowledge about the model architecture, task, or DP algorithm. We show that our method provides provably correct estimates for the privacy loss under the Gaussian mechanism, and we demonstrate its performance on a well-established FL benchmark dataset under several adversarial threat models."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d2e301309520604002919e0507dcb2a8bfc388d3.pdf"}, "_bibtex": {"value": "@inproceedings{\nandrew2024oneshot,\ntitle={One-shot Empirical Privacy Estimation for Federated Learning},\nauthor={Galen Andrew and Peter Kairouz and Sewoong Oh and Alina Oprea and Hugh Brendan McMahan and Vinith Menon Suriyakumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0BqyZSWfzo}\n}"}, "paperhash": {"value": "andrew|oneshot_empirical_privacy_estimation_for_federated_learning"}}, "number": 6514, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6514/-/Revision", "ICLR.cc/2024/Conference/Submission6514/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6514/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425536254, "cdate": 1695425536254, "tmdate": 1710449013966, "mdate": 1710449013966, "pdate": 1705410978238, "version": 2}, {"id": "VTF8yNQM66", "forum": "VTF8yNQM66", "signatures": ["ICLR.cc/2024/Conference/Submission6476/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6476/Authors"], "content": {"title": {"value": "SWE-bench: Can Language Models Resolve Real-world Github Issues?"}, "authors": {"value": ["Carlos E Jimenez", "John Yang", "Alexander Wettig", "Shunyu Yao", "Kexin Pei", "Ofir Press", "Karthik R Narasimhan"]}, "authorids": {"value": ["~Carlos_E_Jimenez1", "~John_Yang3", "~Alexander_Wettig1", "~Shunyu_Yao1", "~Kexin_Pei1", "~Ofir_Press1", "~Karthik_R_Narasimhan1"]}, "keywords": {"value": ["Language models", "Natural language processing", "Software engineering"]}, "TLDR": {"value": "A novel benchmark for evaluating language models that introduces software engineering as a task."}, "abstract": {"value": "Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce SWE-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in SWE-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-of-the-art proprietary models and our fine-tuned model SWE-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere 1.96% of the issues. Advances on SWE-bench represent steps towards LMs that are more practical, intelligent, and autonomous."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c2a76eb44300a738cbd7cb95f5bc04df621f4d25.pdf"}, "supplementary_material": {"value": "/attachment/26a8695734e7f6d2919446fc0aebea1ead373486.zip"}, "_bibtex": {"value": "@inproceedings{\njimenez2024swebench,\ntitle={{SWE}-bench: Can Language Models Resolve Real-world Github Issues?},\nauthor={Carlos E Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik R Narasimhan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VTF8yNQM66}\n}"}, "paperhash": {"value": "jimenez|swebench_can_language_models_resolve_realworld_github_issues"}}, "number": 6476, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6476/-/Revision", "ICLR.cc/2024/Conference/Submission6476/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6476/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423889273, "cdate": 1695423889273, "tmdate": 1710446176753, "mdate": 1710446176753, "pdate": 1705410977147, "version": 2}, {"id": "osoWxY8q2E", "forum": "osoWxY8q2E", "signatures": ["ICLR.cc/2024/Conference/Submission6429/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6429/Authors"], "content": {"title": {"value": "ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"}, "authors": {"value": ["Seyed Iman Mirzadeh", "Keivan Alizadeh-Vahid", "Sachin Mehta", "Carlo C del Mundo", "Oncel Tuzel", "Golnoosh Samei", "Mohammad Rastegari", "Mehrdad Farajtabar"]}, "authorids": {"value": ["~Seyed_Iman_Mirzadeh1", "~Keivan_Alizadeh-Vahid1", "~Sachin_Mehta1", "~Carlo_C_del_Mundo1", "~Oncel_Tuzel2", "~Golnoosh_Samei1", "~Mohammad_Rastegari2", "~Mehrdad_Farajtabar1"]}, "keywords": {"value": ["Large Language Models", "Sparsity", "Activation Function", "ReLU Activation Function"]}, "abstract": {"value": "Large Language Models (LLMs) with billions of parameters have drastically transformed AI applications. However, their demanding computation during inference has raised significant challenges for deployment on resource-constrained devices. Despite recent trends favoring alternative activation functions such as GELU or SiLU, known for increased computation, this study strongly advocates for reinstating ReLU activation in LLMs. We demonstrate that using the ReLU activation function has a negligible impact on convergence and performance while significantly reducing computation and weight transfer. This reduction is particularly valuable during the memory-bound inference step, where efficiency is paramount. Exploring sparsity patterns in ReLU-based LLMs, we unveil the reutilization of activated neurons for generating new tokens and leveraging these insights, we propose practical strategies to substantially reduce LLM inference computation up to three times, using ReLU activations with minimal performance trade-offs."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a407324c94efa754d43a6c1718e24541d34e2f24.pdf"}, "_bibtex": {"value": "@inproceedings{\nmirzadeh2024relu,\ntitle={Re{LU} Strikes Back: Exploiting Activation Sparsity in Large Language Models},\nauthor={Seyed Iman Mirzadeh and Keivan Alizadeh-Vahid and Sachin Mehta and Carlo C del Mundo and Oncel Tuzel and Golnoosh Samei and Mohammad Rastegari and Mehrdad Farajtabar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=osoWxY8q2E}\n}"}, "paperhash": {"value": "mirzadeh|relu_strikes_back_exploiting_activation_sparsity_in_large_language_models"}}, "number": 6429, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6429/-/Revision", "ICLR.cc/2024/Conference/Submission6429/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6429/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421296768, "cdate": 1695421296768, "tmdate": 1710566212279, "mdate": 1710566212279, "pdate": 1705410975733, "version": 2}, {"id": "ze7DOLi394", "forum": "ze7DOLi394", "signatures": ["ICLR.cc/2024/Conference/Submission6358/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6358/Authors"], "content": {"title": {"value": "On the Joint Interaction of Models, Data, and Features"}, "authors": {"value": ["Yiding Jiang", "Christina Baek", "J Zico Kolter"]}, "authorids": {"value": ["~Yiding_Jiang2", "~Christina_Baek2", "~J_Zico_Kolter1"]}, "keywords": {"value": ["Generalization", "feature learning", "empirical phenomena"]}, "abstract": {"value": "Learning features from data is one of the defining characteristics of deep learning,\nbut the theoretical understanding of the role features play in deep learning is still in\nearly development. To address this gap, we introduce a new tool, the interaction\ntensor, for empirically analyzing the interaction between data and model through\nfeatures. With the interaction tensor, we make several key observations about\nhow features are distributed in data and how models with different random seeds\nlearn different features. Based on these observations, we propose a conceptual\nframework for feature learning. Under this framework, the expected accuracy for a\nsingle hypothesis and agreement for a pair of hypotheses can both be derived in\nclosed form. We demonstrate that the proposed framework can explain empirically\nobserved phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with only\nunlabeled data. Further, our theory also provides explicit construction of natural\ndata distributions that break the GDE. Thus, we believe this work provides valuable\nnew insight into our understanding of feature learning."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/86a102e47488a58d90fc222cf560db16f68dc65d.pdf"}, "supplementary_material": {"value": "/attachment/7f182dd585626e040afef3bdb2c8ab2af85d88ba.zip"}, "TLDR": {"value": "We propose a framework for feature learning that can explain previously not understood phenommena in deep learning."}, "_bibtex": {"value": "@inproceedings{\njiang2024on,\ntitle={On the Joint Interaction of Models, Data, and Features},\nauthor={Yiding Jiang and Christina Baek and J Zico Kolter},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ze7DOLi394}\n}"}, "paperhash": {"value": "jiang|on_the_joint_interaction_of_models_data_and_features"}}, "number": 6358, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6358/-/Revision", "ICLR.cc/2024/Conference/Submission6358/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6358/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418673184, "cdate": 1695418673184, "tmdate": 1712367257270, "mdate": 1712367257270, "pdate": 1705410973491, "version": 2}, {"id": "dLrhRIMVmB", "forum": "dLrhRIMVmB", "signatures": ["ICLR.cc/2024/Conference/Submission6314/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6314/Authors"], "content": {"title": {"value": "Topological data analysis on noisy quantum computers"}, "authors": {"value": ["Ismail Yunus Akhalwaya", "Shashanka Ubaru", "Kenneth L. Clarkson", "Mark S. Squillante", "Vishnu Jejjala", "Yang-Hui He", "Kugendran Naidoo", "Vasileios Kalantzis", "Lior Horesh"]}, "authorids": {"value": ["~Ismail_Yunus_Akhalwaya1", "~Shashanka_Ubaru1", "~Kenneth_L._Clarkson1", "~Mark_S._Squillante1", "~Vishnu_Jejjala1", "~Yang-Hui_He1", "~Kugendran_Naidoo1", "~Vasileios_Kalantzis1", "~Lior_Horesh1"]}, "keywords": {"value": ["Topological data analysis", "quantum computing", "unsupervised learning", "feature extraction"]}, "abstract": {"value": "Topological data analysis (TDA) is a powerful technique for extracting complex and valuable shape-related summaries of high-dimensional data. However, the computational demands of classical algorithms for computing TDA are exorbitant, and quickly become impractical for high-order characteristics. Quantum computers offer the potential of achieving significant speedup for certain computational problems. Indeed, TDA has been purported to be one such problem, yet, quantum computing algorithms proposed for the problem, such as the original Quantum TDA (QTDA) formulation by Lloyd, Garnerone and Zanardi, require fault-tolerance qualifications that are currently unavailable. In this study, we present NISQ-TDA, a fully implemented end-to-end quantum machine learning algorithm needing only a short circuit-depth, that is applicable to high-dimensional classical data, and with provable asymptotic speedup for certain classes of problems. The algorithm neither suffers from the data-loading problem nor does it need to store the input data on the quantum computer explicitly. The algorithm was successfully executed on quantum computing devices, as well as on noisy quantum simulators, applied to small datasets. Preliminary empirical results suggest that the algorithm is robust to noise."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/07776ae8b91f82e5061d6b246a4e9aacc7bddb41.pdf"}, "_bibtex": {"value": "@inproceedings{\nakhalwaya2024topological,\ntitle={Topological data analysis on noisy quantum computers},\nauthor={Ismail Yunus Akhalwaya and Shashanka Ubaru and Kenneth L. Clarkson and Mark S. Squillante and Vishnu Jejjala and Yang-Hui He and Kugendran Naidoo and Vasileios Kalantzis and Lior Horesh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dLrhRIMVmB}\n}"}, "paperhash": {"value": "akhalwaya|topological_data_analysis_on_noisy_quantum_computers"}}, "number": 6314, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6314/-/Revision", "ICLR.cc/2024/Conference/-/PC_Revision", "ICLR.cc/2024/Conference/Submission6314/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6314/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416858689, "cdate": 1695416858689, "tmdate": 1713151545521, "mdate": 1713151545521, "pdate": 1705410972042, "version": 2}, {"id": "hSyW5go0v8", "forum": "hSyW5go0v8", "signatures": ["ICLR.cc/2024/Conference/Submission6283/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6283/Authors"], "content": {"title": {"value": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"}, "authors": {"value": ["Akari Asai", "Zeqiu Wu", "Yizhong Wang", "Avirup Sil", "Hannaneh Hajishirzi"]}, "authorids": {"value": ["~Akari_Asai2", "~Zeqiu_Wu1", "~Yizhong_Wang2", "~Avirup_Sil1", "~Hannaneh_Hajishirzi1"]}, "keywords": {"value": ["Retrieval-augmented Generation", "Language Models", "Retrieval-augmented LMs", "Factuality"]}, "TLDR": {"value": "We introduce Self-RAG, a new training and inference framework to enable an LM learn to retrieve, generate and critique."}, "abstract": {"value": "Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called **Self-Reflective Retrieval-Augmented Generation (Self-RAG)** that enhances an LM's quality and factuality through retrieval and self-reflection. \nOur framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. \nExperiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. \nSpecifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9a78cf641fab9032078e65ae2734293ae8e2f398.pdf"}, "_bibtex": {"value": "@inproceedings{\nasai2024selfrag,\ntitle={Self-{RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},\nauthor={Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hSyW5go0v8}\n}"}, "paperhash": {"value": "asai|selfrag_learning_to_retrieve_generate_and_critique_through_selfreflection"}}, "number": 6283, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6283/-/Revision", "ICLR.cc/2024/Conference/Submission6283/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Desk_Rejected_Submission", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6283/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415509020, "cdate": 1695415509020, "tmdate": 1710178010465, "mdate": 1710178010465, "pdate": 1706843939993, "version": 2}, {"id": "HE9eUQlAvo", "forum": "HE9eUQlAvo", "signatures": ["ICLR.cc/2024/Conference/Submission6213/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6213/Authors"], "content": {"title": {"value": "\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection"}, "authors": {"value": ["Anshuman Chhabra", "Peizhao Li", "Prasant Mohapatra", "Hongfu Liu"]}, "authorids": {"value": ["~Anshuman_Chhabra1", "~Peizhao_Li1", "~Prasant_Mohapatra1", "~Hongfu_Liu2"]}, "keywords": {"value": ["Data Selection", "Interpretability", "Fairness", "Robustness"]}, "abstract": {"value": "Classification models are ubiquitously deployed in society and necessitate high utility, fairness, and robustness performance. Current research efforts mainly focus on improving model architectures and learning algorithms on fixed datasets to achieve this goal. In contrast, in this paper, we address an orthogonal yet crucial problem: given a fixed convex learning model (or a convex surrogate for a non-convex model) and a function of interest, we assess what data benefits the model by interpreting the feature space, and then aim to improve performance as measured by this function. To this end, we propose the use of influence estimation models for interpreting the classifier's performance from the perspective of the data feature space. Additionally, we propose data selection approaches based on influence that enhance model utility, fairness, and robustness. Through extensive experiments on synthetic and real-world datasets, we validate and demonstrate the effectiveness of our approaches not only for conventional classification scenarios, but also under more challenging scenarios such as distribution shifts, fairness poisoning attacks, utility evasion attacks, online learning, and active learning."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c9c086d91e0480dcd349f7bb625a5031fabcc53a.pdf"}, "_bibtex": {"value": "@inproceedings{\nchhabra2024what,\ntitle={''What Data Benefits My Classifier?'' Enhancing Model Performance and Interpretability through Influence-Based Data Selection},\nauthor={Anshuman Chhabra and Peizhao Li and Prasant Mohapatra and Hongfu Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HE9eUQlAvo}\n}"}, "paperhash": {"value": "chhabra|what_data_benefits_my_classifier_enhancing_model_performance_and_interpretability_through_influencebased_data_selection"}}, "number": 6213, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6213/-/Revision", "ICLR.cc/2024/Conference/Submission6213/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6213/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413290465, "cdate": 1695413290465, "tmdate": 1709661528905, "mdate": 1709661528905, "pdate": 1705410969153, "version": 2}, {"id": "tUtGjQEDd4", "forum": "tUtGjQEDd4", "signatures": ["ICLR.cc/2024/Conference/Submission6045/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6045/Authors"], "content": {"title": {"value": "Generative Modeling with Phase Stochastic Bridge"}, "authors": {"value": ["Tianrong Chen", "Jiatao Gu", "Laurent Dinh", "Evangelos Theodorou", "Joshua M. Susskind", "Shuangfei Zhai"]}, "authorids": {"value": ["~Tianrong_Chen1", "~Jiatao_Gu1", "~Laurent_Dinh1", "~Evangelos_Theodorou1", "~Joshua_M._Susskind1", "~Shuangfei_Zhai3"]}, "keywords": {"value": ["Generative Modeling", "Stochastic Optimal Control", "Diffusion Model"]}, "abstract": {"value": "Diffusion models (DMs) represent state-of-the-art generative models for continuous inputs. DMs work by constructing a Stochastic Differential Equation (SDE) in the input space (ie, position space), and using a neural network to reverse it. In this work, we introduce a novel generative modeling framework grounded in \\textbf{phase space dynamics}, where a phase space is defined as {an augmented space encompassing both position and velocity.} Leveraging insights from Stochastic Optimal Control, we construct a path measure in the phase space that enables efficient sampling. {In contrast to DMs, our framework demonstrates the capability to generate realistic data points at an early stage of dynamics propagation.} This early prediction sets the stage for efficient data generation by leveraging additional velocity information along the trajectory. On standard image generation benchmarks, our model yields favorable performance over baselines in the regime of small Number of Function Evaluations (NFEs). Furthermore, our approach rivals the performance of diffusion models equipped with efficient sampling techniques, underscoring its potential as a new tool generative modeling."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a787ec0d97bdb93911c09488c8d377120ca21a33.pdf"}, "supplementary_material": {"value": "/attachment/4c8aa96d9f830e3027a2636aa174785b89edda08.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024generative,\ntitle={Generative Modeling with Phase Stochastic Bridge},\nauthor={Tianrong Chen and Jiatao Gu and Laurent Dinh and Evangelos Theodorou and Joshua M. Susskind and Shuangfei Zhai},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tUtGjQEDd4}\n}"}, "paperhash": {"value": "chen|generative_modeling_with_phase_stochastic_bridge"}}, "number": 6045, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6045/-/Revision", "ICLR.cc/2024/Conference/Submission6045/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6045/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695406134192, "cdate": 1695406134192, "tmdate": 1710520157705, "mdate": 1710520157705, "pdate": 1705410962903, "version": 2}, {"id": "9WD9KwssyT", "forum": "9WD9KwssyT", "number": 5586, "cdate": 1695391973841, "tcdate": 1695391973841, "mdate": 1712664351857, "tmdate": 1712664351857, "signatures": ["ICLR.cc/2024/Conference/Submission5586/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5586/Authors"], "content": {"title": {"value": "Zipformer: A faster and better encoder for automatic speech recognition"}, "authors": {"value": ["Zengwei Yao", "Liyong Guo", "Xiaoyu Yang", "Wei Kang", "Fangjun Kuang", "Yifan Yang", "Zengrui Jin", "Long Lin", "Daniel Povey"]}, "authorids": {"value": ["~Zengwei_Yao1", "~Liyong_Guo1", "~Xiaoyu_Yang7", "~Wei_Kang3", "~Fangjun_Kuang1", "~Yifan_Yang11", "~Zengrui_Jin1", "~Long_Lin1", "~Daniel_Povey2"]}, "keywords": {"value": ["Zipformer", "ScaledAdam", "automatic speech recognition"]}, "abstract": {"value": "The Conformer has become the most popular encoder model for automatic speech recognition (ASR).  It adds convolution modules to a transformer to learn both local and global dependencies. In this work we describe a faster, more memory-efficient, and better-performing transformer, called Zipformer.  Modeling changes include: 1) a U-Net-like encoder structure where middle stacks operate at lower frame rates; 2) reorganized block structure with more modules, within which we re-use attention weights for efficiency; 3) a modified form of LayerNorm called BiasNorm allows us to retain some length information; 4)  new activation functions SwooshR and SwooshL work better than Swish.  We also propose a new optimizer, called ScaledAdam, which scales the update by each tensor's current scale to keep the relative change about the same, and also explictly learns the parameter scale. It achieves faster converge and better performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer over other state-of-the-art ASR models. Our code is publicly available at https://github.com/k2-fsa/icefall."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/73f36dfc4a1fa9d3dd37fdb3cb11d5be19364046.pdf"}, "_bibtex": {"value": "@inproceedings{\nyao2024zipformer,\ntitle={Zipformer: A faster and better encoder for automatic speech recognition},\nauthor={Zengwei Yao and Liyong Guo and Xiaoyu Yang and Wei Kang and Fangjun Kuang and Yifan Yang and Zengrui Jin and Long Lin and Daniel Povey},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9WD9KwssyT}\n}"}, "paperhash": {"value": "yao|zipformer_a_faster_and_better_encoder_for_automatic_speech_recognition"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5586/-/Revision", "ICLR.cc/2024/Conference/Submission5586/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5586/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944313, "version": 2}, {"id": "VtmBAGCN7o", "forum": "VtmBAGCN7o", "number": 5488, "cdate": 1695388572615, "tcdate": 1695388572615, "mdate": 1710430342379, "tmdate": 1710430342379, "signatures": ["ICLR.cc/2024/Conference/Submission5488/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5488/Authors"], "content": {"title": {"value": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"}, "authors": {"value": ["Sirui Hong", "Mingchen Zhuge", "Jonathan Chen", "Xiawu Zheng", "Yuheng Cheng", "Jinlin Wang", "Ceyao Zhang", "Zili Wang", "Steven Ka Shing Yau", "Zijuan Lin", "Liyang Zhou", "Chenyu Ran", "Lingfeng Xiao", "Chenglin Wu", "J\u00fcrgen Schmidhuber"]}, "authorids": {"value": ["~Sirui_Hong1", "~Mingchen_Zhuge2", "~Jonathan_Chen3", "~Xiawu_Zheng1", "~Yuheng_Cheng1", "~Jinlin_Wang1", "~Ceyao_Zhang1", "~Zili_Wang1", "~Steven_Ka_Shing_Yau1", "~Zijuan_Lin1", "~Liyang_Zhou2", "~Chenyu_Ran1", "~Lingfeng_Xiao1", "~Chenglin_Wu2", "~J\u00fcrgen_Schmidhuber1"]}, "keywords": {"value": ["Autonomous Agent", "Meta Programming", "Multi-Agent Society", "Group Intelligence"]}, "abstract": {"value": "Recently, remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Previous LLM-based multi-agent systems can already solve simple dialogue tasks. More complex tasks, however, face challenges through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors.  MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together.  On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "This paper introduces MetaGPT, an innovative meta-programming framework for LLM-based multi-agent collaborations."}, "pdf": {"value": "/pdf/474fc6dad3bd9bf7fdb97c7cd72b2cc0649a9647.pdf"}, "_bibtex": {"value": "@inproceedings{\nhong2024metagpt,\ntitle={Meta{GPT}: Meta Programming for Multi-Agent Collaborative Framework},\nauthor={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\\\"u}rgen Schmidhuber},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VtmBAGCN7o}\n}"}, "paperhash": {"value": "hong|metagpt_meta_programming_for_a_multiagent_collaborative_framework"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5488/-/Revision", "ICLR.cc/2024/Conference/Submission5488/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5488/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940732, "version": 2}, {"id": "yV6fD7LYkF", "forum": "yV6fD7LYkF", "number": 5104, "cdate": 1695372675691, "tcdate": 1695372675691, "mdate": 1709817153338, "tmdate": 1709817153338, "signatures": ["ICLR.cc/2024/Conference/Submission5104/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5104/Authors"], "content": {"title": {"value": "ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"}, "authors": {"value": ["Kim-Celine Kahl", "Carsten T. L\u00fcth", "Maximilian Zenk", "Klaus Maier-Hein", "Paul F Jaeger"]}, "authorids": {"value": ["~Kim-Celine_Kahl1", "~Carsten_T._L\u00fcth1", "~Maximilian_Zenk1", "~Klaus_Maier-Hein1", "~Paul_F_Jaeger1"]}, "keywords": {"value": ["uncertainty", "segmentation", "validation"]}, "TLDR": {"value": "We address the flawed validation in uncertainty estimation for segmentation by introducing a framework that explores uncertainty types, essential components, and effective methods, with empirical results from simulated and real-world data."}, "abstract": {"value": "Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values"}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f1a6b968ddfb2f0ebdeb46499417239973e92e7e.pdf"}, "supplementary_material": {"value": "/attachment/da48ee545fec241de3759e5647a0b300eea57b0d.pdf"}, "_bibtex": {"value": "@inproceedings{\nkahl2024values,\ntitle={Val{UES}: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation},\nauthor={Kim-Celine Kahl and Carsten T. L{\\\"u}th and Maximilian Zenk and Klaus Maier-Hein and Paul F Jaeger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yV6fD7LYkF}\n}"}, "paperhash": {"value": "kahl|values_a_framework_for_systematic_validation_of_uncertainty_estimation_in_semantic_segmentation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5104/-/Revision", "ICLR.cc/2024/Conference/Submission5104/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5104/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927302, "version": 2}, {"id": "hnrB5YHoYu", "forum": "hnrB5YHoYu", "number": 4906, "cdate": 1695366799988, "tcdate": 1695366799988, "mdate": 1712651154627, "tmdate": 1712651154627, "signatures": ["ICLR.cc/2024/Conference/Submission4906/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4906/Authors"], "content": {"title": {"value": "Finetuning Text-to-Image Diffusion Models for Fairness"}, "authors": {"value": ["Xudong Shen", "Chao Du", "Tianyu Pang", "Min Lin", "Yongkang Wong", "Mohan Kankanhalli"]}, "authorids": {"value": ["~Xudong_Shen1", "~Chao_Du1", "~Tianyu_Pang1", "~Min_Lin1", "~Yongkang_Wong1", "~Mohan_Kankanhalli1"]}, "keywords": {"value": ["Fairness", "Alignment", "Diffusion Models", "Text-to-Image Generation"]}, "abstract": {"value": "The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a skewed worldview and restrict opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) adjusted direct finetuning of diffusion model's sampling process (adjusted DFT), which leverages an adjusted gradient to directly optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a 75% young and 25% old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We share code and various fair diffusion model adaptors at https://sail-sg.github.io/finetune-fair-diffusion/."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9fa6cd12f622fa7dffccbd1c62d26545e012eafa.pdf"}, "supplementary_material": {"value": "/attachment/755530331a7e40fd2c39db790490f008339f9711.zip"}, "TLDR": {"value": "A flexible and scalable supervised fine-tuning method is introduced to align the generated images of a text-to-image diffusion model with a desired distribution."}, "_bibtex": {"value": "@inproceedings{\nshen2024finetuning,\ntitle={Finetuning Text-to-Image Diffusion Models for Fairness},\nauthor={Xudong Shen and Chao Du and Tianyu Pang and Min Lin and Yongkang Wong and Mohan Kankanhalli},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hnrB5YHoYu}\n}"}, "paperhash": {"value": "shen|finetuning_texttoimage_diffusion_models_for_fairness"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4906/-/Revision", "ICLR.cc/2024/Conference/Submission4906/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4906/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921513, "version": 2}], "Spotlight": [{"id": "eUgS9Ig8JG", "forum": "eUgS9Ig8JG", "signatures": ["ICLR.cc/2024/Conference/Submission9491/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9491/Authors"], "content": {"title": {"value": "SaNN: Simple Yet Powerful Simplicial-aware Neural Networks"}, "authors": {"value": ["Sravanthi Gurugubelli", "Sundeep Prabhakar Chepuri"]}, "authorids": {"value": ["~Sravanthi_Gurugubelli1", "~Sundeep_Prabhakar_Chepuri1"]}, "keywords": {"value": ["Graph Neural Networks", "Higher-order Representation Learning", "Simplicial Complexes", "Simplicial Neural Networks", "Weisfeiler-Lehman Isomorphism Test"]}, "abstract": {"value": "Simplicial neural networks (SNNs) are deep models for higher-order graph representation learning. SNNs learn low-dimensional embeddings of simplices in a simplicial complex by aggregating features of their respective upper, lower, boundary, and coboundary adjacent simplices. The aggregation in SNNs is carried out during training. Since the number of simplices of various orders in a simplicial complex is significantly large, the memory and training-time requirement in SNNs is enormous. In this work, we propose a scalable simplicial-aware neural network (SaNN) model with a constant run-time and memory requirements independent of the size of the simplicial complex and the density of interactions in it. SaNN is based on pre-aggregated simplicial-aware features as inputs to a neural network, so it has a strong simplicial-structural inductive bias. We provide theoretical conditions under which SaNN is provably more powerful than the Weisfeiler-Lehman (WL) graph isomorphism test and as powerful as the simplicial Weisfeiler-Lehman (SWL) test. We also show that SaNN is permutation and orientation equivariant and satisfies simplicial-awareness of the highest order in a simplicial complex. We demonstrate via numerical experiments that despite being computationally economical, the proposed model achieves state-of-the-art performance in predicting trajectories,  simplicial closures, and classifying graphs."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b5b2e785dec69b9ea0c8b01d6e2eca5896246cce.pdf"}, "supplementary_material": {"value": "/attachment/0409d0bfd0e6b9c23876ef435a4f64eed976a61e.zip"}, "_bibtex": {"value": "@inproceedings{\ngurugubelli2024sann,\ntitle={Sa{NN}: Simple Yet Powerful Simplicial-aware Neural Networks},\nauthor={Sravanthi Gurugubelli and Sundeep Prabhakar Chepuri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eUgS9Ig8JG}\n}"}, "paperhash": {"value": "gurugubelli|sann_simple_yet_powerful_simplicialaware_neural_networks"}}, "number": 9491, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9491/-/Revision", "ICLR.cc/2024/Conference/Submission9491/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9491/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695557389659, "cdate": 1695557389659, "tmdate": 1710599804238, "mdate": 1710599804238, "pdate": 1705411064661, "version": 2}, {"id": "kmn0BhQk7p", "forum": "kmn0BhQk7p", "signatures": ["ICLR.cc/2024/Conference/Submission9451/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9451/Authors"], "content": {"title": {"value": "Beyond Memorization: Violating Privacy via Inference with Large Language Models"}, "authors": {"value": ["Robin Staab", "Mark Vero", "Mislav Balunovic", "Martin Vechev"]}, "authorids": {"value": ["~Robin_Staab1", "~Mark_Vero1", "~Mislav_Balunovic1", "~Martin_Vechev1"]}, "keywords": {"value": ["Privacy", "Large Language Models"]}, "TLDR": {"value": "We present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from texts given at inference."}, "abstract": {"value": "Current privacy research on large language models (LLMs) primarily focuses on the issue of extracting memorized training data. At the same time, models\u2019 inference capabilities have increased drastically. This raises the key question of whether current LLMs could violate individuals\u2019 privacy by inferring personal attributes from text given at inference time. In this work, we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text. We construct a dataset consisting of real Reddit profiles, and show that current LLMs can infer a wide range of personal attributes (e.g., location, income, sex), achieving up to 85% top-1 and 95% top-3 accuracy at a fraction of the cost (100x) and time (240x) required by humans. As people increasingly interact with LLM-powered chatbots across all aspects of life, we also explore the emerging threat of privacy-invasive chatbots trying to extract personal information through seemingly benign questions. Finally, we show that common mitigations, i.e., text anonymization and model alignment, are currently ineffective at protecting user privacy against LLM inference. Our findings highlight that current LLMs can infer personal data at a previously unattainable scale. In the absence of working defenses, we advocate for a broader discussion around LLM privacy implications beyond memorization, striving for stronger and wider privacy protection."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0174f3bf08c7c34d3feb07ca6e5b488bb3efc21c.pdf"}, "supplementary_material": {"value": "/attachment/61cc0fc6c710cade7f97605f0d40b5f909c094c2.zip"}, "_bibtex": {"value": "@inproceedings{\nstaab2024beyond,\ntitle={Beyond Memorization: Violating Privacy via Inference with Large Language Models},\nauthor={Robin Staab and Mark Vero and Mislav Balunovic and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kmn0BhQk7p}\n}"}, "paperhash": {"value": "staab|beyond_memorization_violating_privacy_via_inference_with_large_language_models"}}, "number": 9451, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9451/-/Revision", "ICLR.cc/2024/Conference/Submission9451/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9451/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695555710153, "cdate": 1695555710153, "tmdate": 1710503155247, "mdate": 1710503155247, "pdate": 1705411064088, "version": 2}, {"id": "SLw9fp4yI6", "forum": "SLw9fp4yI6", "signatures": ["ICLR.cc/2024/Conference/Submission9377/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9377/Authors"], "content": {"title": {"value": "Controlled Text Generation via Language Model Arithmetic"}, "authors": {"value": ["Jasper Dekoninck", "Marc Fischer", "Luca Beurer-Kellner", "Martin Vechev"]}, "authorids": {"value": ["~Jasper_Dekoninck1", "~Marc_Fischer1", "~Luca_Beurer-Kellner1", "~Martin_Vechev1"]}, "keywords": {"value": ["Controlled text generation", "LLM", "Natural Language Processing"]}, "abstract": {"value": "As Large Language Models (LLMs) are deployed more widely, customization with respect to vocabulary, style, and character becomes more important. In this work, we introduce model arithmetic, a novel inference framework for composing and biasing LLMs without the need for model (re)training or highly specific datasets. In addition, the framework allows for more precise control of generated text than direct prompting and prior controlled text generation (CTG) techniques. Using model arithmetic, we can express prior CTG techniques as simple formulas and naturally extend them to new and more effective formulations. Further, we show that speculative sampling, a technique for efficient LLM sampling, extends to our setting. This enables highly efficient text generation with multiple composed models with only marginal overhead over a single model. Our empirical evaluation demonstrates that model arithmetic allows fine-grained control of generated text while outperforming state-of-the-art on the task of toxicity reduction. We release an open source easy-to-use implementation of our framework at https://github.com/eth-sri/language-model-arithmetic."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7b09c9f1a15373444f1e3be2bef23404a9029f8b.pdf"}, "supplementary_material": {"value": "/attachment/1d589305025bfa35dc59d60e735c4678218d9c2d.zip"}, "TLDR": {"value": "We provide a principled and intuitive way to combine multiple LLMs and bias them towards and away from attributes."}, "_bibtex": {"value": "@inproceedings{\ndekoninck2024controlled,\ntitle={Controlled Text Generation via Language Model Arithmetic},\nauthor={Jasper Dekoninck and Marc Fischer and Luca Beurer-Kellner and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SLw9fp4yI6}\n}"}, "paperhash": {"value": "dekoninck|controlled_text_generation_via_language_model_arithmetic"}}, "number": 9377, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9377/-/Revision", "ICLR.cc/2024/Conference/Submission9377/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9377/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695553212922, "cdate": 1695553212922, "tmdate": 1709663052044, "mdate": 1709663052044, "pdate": 1705411062988, "version": 2}, {"id": "elMKXvhhQ9", "forum": "elMKXvhhQ9", "signatures": ["ICLR.cc/2024/Conference/Submission9315/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9315/Authors"], "content": {"title": {"value": "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision"}, "authors": {"value": ["Nan Chen", "Zemin Liu", "Bryan Hooi", "Bingsheng He", "Rizal Fathony", "Jun Hu", "Jia Chen"]}, "authorids": {"value": ["~Nan_Chen6", "~Zemin_Liu1", "~Bryan_Hooi1", "~Bingsheng_He1", "~Rizal_Fathony1", "~Jun_Hu3", "~Jia_Chen2"]}, "keywords": {"value": ["Graph anomaly detection", "consistency training", "learnable data augmentation"]}, "abstract": {"value": "Graph Anomaly Detection (GAD) has surfaced as a significant field of research, predominantly due to its substantial influence in production environments. Although existing approaches for node anomaly detection have shown effectiveness, they have yet to fully address two major challenges: operating in settings with limited supervision and managing class imbalance effectively. In response to these challenges, we propose a novel model, ConsisGAD, which is tailored for GAD in scenarios characterized by limited supervision and is anchored in the principles of consistency training. Under limited supervision, ConsisGAD effectively leverages the abundance of unlabeled data for consistency training by incorporating a novel learnable data augmentation mechanism, thereby introducing controlled noise into the dataset. Moreover, ConsisGAD takes advantage of the variance in homophily distribution between normal and anomalous nodes to craft a simplified GNN backbone, enhancing its capability to distinguish effectively between these two classes. Comprehensive experiments on several benchmark datasets validate the superior performance of ConsisGAD in comparison to state-of-the-art baselines. Our code is available at https://github.com/Xtra-Computing/ConsisGAD."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0a2aa8c65cf0939e67a21de44b554069cb961a25.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024consistency,\ntitle={Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision},\nauthor={Nan Chen and Zemin Liu and Bryan Hooi and Bingsheng He and Rizal Fathony and Jun Hu and Jia Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=elMKXvhhQ9}\n}"}, "paperhash": {"value": "chen|consistency_training_with_learnable_data_augmentation_for_graph_anomaly_detection_with_limited_supervision"}}, "number": 9315, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9315/-/Revision", "ICLR.cc/2024/Conference/Submission9315/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9315/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695550220518, "cdate": 1695550220518, "tmdate": 1710503269841, "mdate": 1710503269841, "pdate": 1705411062111, "version": 2}, {"id": "YItWKZci78", "forum": "YItWKZci78", "signatures": ["ICLR.cc/2024/Conference/Submission9271/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9271/Authors"], "content": {"title": {"value": "Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems"}, "authors": {"value": ["Juno Kim", "Kakei Yamamoto", "Kazusato Oko", "Zhuoran Yang", "Taiji Suzuki"]}, "authorids": {"value": ["~Juno_Kim1", "~Kakei_Yamamoto1", "~Kazusato_Oko1", "~Zhuoran_Yang1", "~Taiji_Suzuki1"]}, "keywords": {"value": ["mean-field Langevin dynamics", "minimax optimization", "zero-sum games", "Markov games"]}, "abstract": {"value": "In this paper, we extend mean-field Langevin dynamics to minimax optimization over probability distributions for the first time with symmetric and provably convergent updates. We propose \\emph{mean-field Langevin averaged gradient} (MFL-AG), a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging, and establish average-iterate convergence to the mixed Nash equilibrium. We also study both time and particle discretization regimes and prove a new uniform-in-time propagation of chaos result which accounts for the dependency of the particle interactions on all previous distributions. Furthermore, we propose \\emph{mean-field Langevin anchored best response} (MFL-ABR), a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence. Finally, we study applications to zero-sum Markov games and conduct simulations demonstrating long-term optimality."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ec8abe6d7a5a4ae8d6dbb94cdc4734ed2e28024f.pdf"}, "_bibtex": {"value": "@inproceedings{\nkim2024symmetric,\ntitle={Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems},\nauthor={Juno Kim and Kakei Yamamoto and Kazusato Oko and Zhuoran Yang and Taiji Suzuki},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YItWKZci78}\n}"}, "paperhash": {"value": "kim|symmetric_meanfield_langevin_dynamics_for_distributional_minimax_problems"}}, "number": 9271, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9271/-/Revision", "ICLR.cc/2024/Conference/Submission9271/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9271/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695548267570, "cdate": 1695548267570, "tmdate": 1709661553907, "mdate": 1709661553907, "pdate": 1705411061430, "version": 2}, {"id": "csukJcpYDe", "forum": "csukJcpYDe", "signatures": ["ICLR.cc/2024/Conference/Submission9245/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9245/Authors"], "content": {"title": {"value": "Generalized Policy Iteration using Tensor Approximation for Hybrid Control"}, "authors": {"value": ["Suhan Shetty", "Teng Xue", "Sylvain Calinon"]}, "authorids": {"value": ["~Suhan_Shetty1", "~Teng_Xue1", "~Sylvain_Calinon1"]}, "keywords": {"value": ["Optimal Control", "Hybrid Actions", "Robotics", "Approximate Dynamic Programming", "Tensor Approximation"]}, "TLDR": {"value": "The paper proposes a novel approximate dynamic programming algorithm that can handle hybrid action space"}, "abstract": {"value": "Control of dynamic systems involving hybrid actions is a challenging task in robotics.  To address this, we present a novel algorithm called Generalized Policy Iteration using Tensor Train (TTPI) that belongs to the class of Approximate Dynamic Programming (ADP). We use a low-rank tensor approximation technique called Tensor Train (TT) to approximate the state-value and advantage function which enables us to efficiently handle hybrid systems. We demonstrate the superiority of our approach over previous baselines for some benchmark problems with hybrid action spaces. Additionally, the robustness and generalization of the policy for hybrid systems are showcased through a real-world robotics experiment involving a non-prehensile manipulation task which is considered to be a highly challenging control problem."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a40c77cc6b21af1cc748441a1c8107b6a7896cc5.pdf"}, "supplementary_material": {"value": "/attachment/bf64c633c8b95188350edcfdeb9d8cce26f66b20.zip"}, "_bibtex": {"value": "@inproceedings{\nshetty2024generalized,\ntitle={Generalized Policy Iteration using Tensor Approximation for Hybrid Control},\nauthor={Suhan Shetty and Teng Xue and Sylvain Calinon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=csukJcpYDe}\n}"}, "paperhash": {"value": "shetty|generalized_policy_iteration_using_tensor_approximation_for_hybrid_control"}}, "number": 9245, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9245/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9245/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695547484873, "cdate": 1695547484873, "tmdate": 1710449870194, "mdate": 1710449870194, "pdate": 1705411060459, "version": 2}, {"id": "3SJE1WLB4M", "forum": "3SJE1WLB4M", "signatures": ["ICLR.cc/2024/Conference/Submission9152/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9152/Authors"], "content": {"title": {"value": "Generalization error of spectral algorithms"}, "authors": {"value": ["Maksim Velikanov", "Maxim Panov", "Dmitry Yarotsky"]}, "authorids": {"value": ["~Maksim_Velikanov1", "~Maxim_Panov1", "~Dmitry_Yarotsky1"]}, "keywords": {"value": ["gradient descent", "kernel ridge regression", "optimal algorithm", "generalization", "asymptotic error rates", "power-laws"]}, "abstract": {"value": "The asymptotically precise estimation of the generalization of kernel methods has recently received attention due to the parallels between neural networks and their associated kernels. However, prior works derive such estimates for training by kernel ridge regression (KRR), whereas neural networks are typically trained with gradient descent (GD). In the present work, we consider the training of kernels with a family of \\emph{spectral algorithms} specified by profile $h(\\lambda)$, and including KRR and GD as special cases. Then, we derive the generalization error as a functional of learning profile $h(\\lambda)$ for two data models: high-dimensional Gaussian and low-dimensional translation-invariant model. \nUnder power-law assumptions on the spectrum of the kernel and target, we use our framework to (i) give full loss asymptotics for both noisy and noiseless observations (ii) show that the loss localizes on certain spectral scales, giving a new perspective on the KRR saturation phenomenon (iii) conjecture, and demonstrate for the considered data models, the universality of the loss w.r.t. non-spectral details of the problem, but only in case of noisy observation."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2ec1e556e2638c8f90cf327da20ee024055d1426.pdf"}, "_bibtex": {"value": "@inproceedings{\nvelikanov2024generalization,\ntitle={Generalization error of spectral algorithms},\nauthor={Maksim Velikanov and Maxim Panov and Dmitry Yarotsky},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3SJE1WLB4M}\n}"}, "paperhash": {"value": "velikanov|generalization_error_of_spectral_algorithms"}}, "number": 9152, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9152/-/Revision", "ICLR.cc/2024/Conference/Submission9152/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9152/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695543309509, "cdate": 1695543309509, "tmdate": 1710753669608, "mdate": 1710753669608, "pdate": 1705411058540, "version": 2}, {"id": "Ffjc8ApSbt", "forum": "Ffjc8ApSbt", "signatures": ["ICLR.cc/2024/Conference/Submission9073/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9073/Authors"], "content": {"title": {"value": "Debiased Collaborative Filtering with Kernel-based Causal Balancing"}, "authors": {"value": ["Haoxuan Li", "Yanghao Xiao", "Chunyuan Zheng", "Peng Wu", "Zhi Geng", "Xu Chen", "Peng Cui"]}, "authorids": {"value": ["~Haoxuan_Li6", "~Yanghao_Xiao1", "~Chunyuan_Zheng1", "~Peng_Wu5", "~Zhi_Geng1", "~Xu_Chen13", "~Peng_Cui1"]}, "keywords": {"value": ["Recommender System", "Causal Inference", "Bias", "Debias", "Balancing"]}, "abstract": {"value": "Collaborative filtering builds personalized models from the collected user feedback. However, the collected data is observational rather than experimental, leading to various biases in the data, which can significantly affect the learned model. To address this issue, many studies have focused on propensity-based methods to combat the selection bias by reweighting the sample loss, and demonstrate that\nbalancing is important for debiasing both theoretically and empirically. However, there are two questions that still need to be addressed: which function class should be balanced and how to effectively balance that function class? In this paper, we first perform theoretical analysis to show the effect of balancing finite-dimensional function classes on the bias of IPS and DR methods, and based on this, we propose a universal kernel-based balancing method to balance functions on the reproducing kernel Hilbert space. In addition, we propose a novel adaptive causal balancing method during the alternating update between unbiased evaluation and training of the prediction model. Specifically, the prediction loss of the model is projected in the kernel-based covariate function space, and the projection coefficients are used to determine which functions should be prioritized for balancing to reduce the estimation bias. We conduct extensive experiments on three real-world datasets to demonstrate the effectiveness of the proposed approach."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0ae94935388659a2f02c71f507dbf734f9c1660d.pdf"}, "supplementary_material": {"value": "/attachment/1d06aad7562aef8e288285cec9bf8239695463de.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024adaptive,\ntitle={Adaptive Causal Balancing for Collaborative Filtering},\nauthor={Haoxuan Li and Yanghao Xiao and Chunyuan Zheng and Peng Wu and Xu Chen and Zhi Geng and Peng Cui},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ffjc8ApSbt}\n}"}, "paperhash": {"value": "li|debiased_collaborative_filtering_with_kernelbased_causal_balancing"}}, "number": 9073, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9073/-/Revision", "ICLR.cc/2024/Conference/Submission9073/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9073/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695537936036, "cdate": 1695537936036, "tmdate": 1709661552943, "mdate": 1709661552943, "pdate": 1705411057094, "version": 2}, {"id": "5ES5Hdlbxw", "forum": "5ES5Hdlbxw", "signatures": ["ICLR.cc/2024/Conference/Submission8925/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8925/Authors"], "content": {"title": {"value": "The Effective Horizon Explains Deep RL Performance in Stochastic Environments"}, "authors": {"value": ["Cassidy Laidlaw", "Banghua Zhu", "Stuart Russell", "Anca Dragan"]}, "authorids": {"value": ["~Cassidy_Laidlaw1", "~Banghua_Zhu1", "~Stuart_Russell1", "~Anca_Dragan1"]}, "keywords": {"value": ["reinforcement learning", "effective horizon", "RL theory", "theory of reinforcement learning", "instance-dependent bounds", "empirical validation of theory"]}, "TLDR": {"value": "We extend the recently proposed \"effective horizon\" property to stochastic MDPs and show theoretically and empirically that it can explain the performance of deep RL algorithms."}, "abstract": {"value": "Reinforcement learning (RL) theory has largely focused on proving minimax sample complexity bounds. These require strategic exploration algorithms that use relatively limited function classes for representing the policy or value function. Our goal is to explain why deep RL algorithms often perform well in practice, despite using random exploration and much more expressive function classes like neural networks. Our work arrives at an explanation by showing that many stochastic MDPs can be solved by performing only a few steps of value iteration on the random policy\u2019s Q function and then acting greedily. When this is true, we find that it is possible to separate the exploration and learning components of RL, making it much easier to analyze. We introduce a new RL algorithm, SQIRL, that iteratively learns a near-optimal policy by exploring randomly to collect rollouts and then performing a limited number of steps of fitted-Q iteration over those roll- outs. We find that any regression algorithm that satisfies basic in-distribution generalization properties can be used in SQIRL to efficiently solve common MDPs. This can explain why deep RL works with complex function approximators like neural networks, since it is empirically established that neural networks generalize well in-distribution. Furthermore, SQIRL explains why random exploration works well in practice, since we show many environments can be solved by effectively estimating the random policy\u2019s Q-function and then applying zero or a few steps of value iteration. We leverage SQIRL to derive instance-dependent sample complexity bounds for RL that are exponential only in an \u201ceffective horizon\u201d of lookahead\u2014which is typically much smaller than the full horizon\u2014and on the complexity of the class used for function approximation. Empirically, we also find that SQIRL performance strongly correlates with PPO and DQN performance in a variety of stochastic environments, supporting that our theoretical analysis is predictive of practical performance. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f82605ccc74bb3de9a73c5e505aaf9276c229c08.pdf"}, "_bibtex": {"value": "@inproceedings{\nlaidlaw2024a,\ntitle={A Theoretical Explanation of Deep {RL} Performance in Stochastic Environments},\nauthor={Cassidy Laidlaw and Banghua Zhu and Stuart Russell and Anca Dragan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5ES5Hdlbxw}\n}"}, "paperhash": {"value": "laidlaw|the_effective_horizon_explains_deep_rl_performance_in_stochastic_environments"}}, "number": 8925, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8925/-/Revision", "ICLR.cc/2024/Conference/Submission8925/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8925/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695529830663, "cdate": 1695529830663, "tmdate": 1712944043909, "mdate": 1712944043909, "pdate": 1705411053906, "version": 2}, {"id": "kC5nZDU5zf", "forum": "kC5nZDU5zf", "signatures": ["ICLR.cc/2024/Conference/Submission8895/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8895/Authors"], "content": {"title": {"value": "Selective Visual Representations Improve Convergence and Generalization for Embodied AI"}, "authors": {"value": ["Ainaz Eftekhar", "Kuo-Hao Zeng", "Jiafei Duan", "Ali Farhadi", "Aniruddha Kembhavi", "Ranjay Krishna"]}, "authorids": {"value": ["~Ainaz_Eftekhar1", "~Kuo-Hao_Zeng3", "~Jiafei_Duan1", "~Ali_Farhadi3", "~Aniruddha_Kembhavi1", "~Ranjay_Krishna1"]}, "keywords": {"value": ["Embodied-AI", "Task-conditioned Representations", "Visual Navigation", "Reinforcement Learning"]}, "abstract": {"value": "Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues.\nInspired by selective attention in humans\u2014the process through which people filter their perception based on their experiences, knowledge, and the task at hand\u2014we introduce a parameter-efficient approach to filter visual stimuli for embodied AI.\nOur approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation.\nOur experiments showcase state-of-the-art performance for object goal navigation and object displacement across $5$ benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2fbfaec8070dacca6ff1916307768a1f7ce97be6.pdf"}, "_bibtex": {"value": "@inproceedings{\neftekhar2024selective,\ntitle={Selective Visual Representations Improve Convergence and Generalization for Embodied {AI}},\nauthor={Ainaz Eftekhar and Kuo-Hao Zeng and Jiafei Duan and Ali Farhadi and Aniruddha Kembhavi and Ranjay Krishna},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kC5nZDU5zf}\n}"}, "paperhash": {"value": "eftekhar|selective_visual_representations_improve_convergence_and_generalization_for_embodied_ai"}}, "number": 8895, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8895/-/Revision", "ICLR.cc/2024/Conference/Submission8895/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8895/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695528645576, "cdate": 1695528645576, "tmdate": 1710026791817, "mdate": 1710026791817, "pdate": 1705411053154, "version": 2}, {"id": "fwCoLe3TAX", "forum": "fwCoLe3TAX", "signatures": ["ICLR.cc/2024/Conference/Submission8880/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8880/Authors"], "content": {"title": {"value": "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning"}, "authors": {"value": ["Rui Zheng", "Wei Shen", "Yuan Hua", "Wenbin Lai", "Shihan Dou", "Yuhao Zhou", "Zhiheng Xi", "Xiao Wang", "Haoran Huang", "Tao Gui", "Qi Zhang", "Xuanjing Huang"]}, "authorids": {"value": ["~Rui_Zheng1", "~Wei_Shen12", "~Yuan_Hua2", "~Wenbin_Lai1", "~Shihan_Dou1", "~Yuhao_Zhou3", "~Zhiheng_Xi1", "~Xiao_Wang12", "~Haoran_Huang1", "~Tao_Gui1", "~Qi_Zhang8", "~Xuanjing_Huang1"]}, "keywords": {"value": ["alignment", "language model", "invariant learning"]}, "abstract": {"value": "The success of AI assistants based on language models (LLMs) hinges crucially on Reinforcement Learning from Human Feedback (RLHF), which enables the generation of responses more aligned with human preferences. \nAs universal AI assistants, there's a growing expectation for them to perform consistently across various domains. \nHowever, previous work shows that Reinforcement Learning (RL) often exploits shortcuts to attain high rewards and overlooks challenging samples.\nThis focus on quick reward gains undermines both the stability in training and the model's ability to generalize to new, unseen data.\nIn this work, we propose a novel approach that can learn a consistent policy via RL across various data groups or domains. \nGiven the challenges associated with acquiring group annotations, our method automatically classifies data into different groups, deliberately maximizing performance variance.\nThen, we optimize the policy to perform well on challenging groups. \nLastly, leveraging the established groups, our approach adaptively adjusts the exploration space, allocating more learning capacity to more challenging data and preventing the model from over-optimizing on simpler data. Experimental results indicate that our approach significantly enhances training stability and model generalization."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/db0a7ea3470e4d33a4ea3826659ef675921bc697.pdf"}, "TLDR": {"value": "This paper introduces a novel method for aligning AI assistants with human preferences, boosting RLHF training stability and improving the model\u2019s generalization across various domains."}, "_bibtex": {"value": "@inproceedings{\nzheng2024improving,\ntitle={Improving Generalization of Alignment with Human Preferences through Group Invariant Learning},\nauthor={Rui Zheng and Wei Shen and Yuan Hua and Wenbin Lai and Shihan Dou and Yuhao Zhou and Zhiheng Xi and Xiao Wang and Haoran Huang and Tao Gui and Qi Zhang and Xuanjing Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fwCoLe3TAX}\n}"}, "paperhash": {"value": "zheng|improving_generalization_of_alignment_with_human_preferences_through_group_invariant_learning"}}, "number": 8880, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8880/-/Revision", "ICLR.cc/2024/Conference/Submission8880/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8880/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695528001020, "cdate": 1695528001020, "tmdate": 1712984903949, "mdate": 1712984903949, "pdate": 1705411052744, "version": 2}, {"id": "GzNaCp6Vcg", "forum": "GzNaCp6Vcg", "signatures": ["ICLR.cc/2024/Conference/Submission8858/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8858/Authors"], "content": {"title": {"value": "PINNACLE: PINN Adaptive ColLocation and Experimental points selection"}, "authors": {"value": ["Gregory Kang Ruey Lau", "Apivich Hemachandra", "See-Kiong Ng", "Bryan Kian Hsiang Low"]}, "authorids": {"value": ["~Gregory_Kang_Ruey_Lau1", "~Apivich_Hemachandra1", "~See-Kiong_Ng1", "~Bryan_Kian_Hsiang_Low1"]}, "keywords": {"value": ["Physics-informed Neural Networks", "PINNs", "adaptive training points selection"]}, "TLDR": {"value": "A novel PINN training algorithm, motivated by analysis of the Neural Tangent Kernel, that jointly selects all training point types in the composite loss function to gain large performance boosts for forward, inverse, and transfer learning problems."}, "abstract": {"value": "Physics-Informed Neural Networks (PINNs), which incorporate PDEs as soft constraints, train with a composite loss function that contains multiple training point types: different types of collocation points chosen during training to enforce each PDE and initial/boundary conditions, and experimental points which are usually costly to obtain via experiments or simulations. Training PINNs using this loss function is challenging as it typically requires selecting large numbers of points of different types, each with different training dynamics. Unlike past works that focused on the selection of either collocation or experimental points, this work introduces PINN Adaptive ColLocation and Experimental points selection (PINNACLE), the first algorithm that jointly optimizes the selection of all training point types, while automatically adjusting the proportion of collocation point types as training progresses. PINNACLE uses information on the interactions among training point types, which had not been considered before, based on an analysis of PINN training dynamics via the Neural Tangent Kernel (NTK). We theoretically show that the criterion used by PINNACLE is related to the PINN generalization error, and empirically demonstrate that PINNACLE is able to outperform existing point selection methods for forward, inverse, and transfer learning problems."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1096a49fe85df5e82fac41af2b78c13d13d4455b.pdf"}, "supplementary_material": {"value": "/attachment/b604ca26f186e6b1aab73e0e73eac05453f58908.zip"}, "_bibtex": {"value": "@inproceedings{\nlau2024pinnacle,\ntitle={{PINNACLE}: {PINN} Adaptive ColLocation and Experimental points selection},\nauthor={Gregory Kang Ruey Lau and Apivich Hemachandra and See-Kiong Ng and Bryan Kian Hsiang Low},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GzNaCp6Vcg}\n}"}, "paperhash": {"value": "lau|pinnacle_pinn_adaptive_collocation_and_experimental_points_selection"}}, "number": 8858, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8858/-/Revision", "ICLR.cc/2024/Conference/Submission8858/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8858/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695527036313, "cdate": 1695527036313, "tmdate": 1710404052876, "mdate": 1710404052876, "pdate": 1705411052068, "version": 2}, {"id": "5t57omGVMw", "forum": "5t57omGVMw", "signatures": ["ICLR.cc/2024/Conference/Submission8824/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8824/Authors"], "content": {"title": {"value": "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances"}, "authors": {"value": ["Mikhail Khodak", "Edmond Chow", "Maria Florina Balcan", "Ameet Talwalkar"]}, "authorids": {"value": ["~Mikhail_Khodak1", "~Edmond_Chow1", "~Maria_Florina_Balcan1", "~Ameet_Talwalkar1"]}, "keywords": {"value": ["scientific computing", "data-driven algorithm design", "online learning", "multi-armed bandits", "contextual bandits", "numerical analysis", "learning-augmented algorithms", "algorithms with predictions"]}, "TLDR": {"value": "We show provable guarantees for learning the relaxation parameter of linear system solvers."}, "abstract": {"value": "Solving a linear system ${\\bf Ax}={\\bf b}$ is a fundamental scientific computing primitive for which numerous solvers and preconditioners have been developed. \n\tThese come with parameters whose optimal values depend on the system being solved and are often impossible or too expensive to identify;\n\tthus in practice sub-optimal heuristics are used.\n\tWe consider the common setting in which many related linear systems need to be solved, e.g. during a single numerical simulation.\n\tIn this scenario, can we sequentially choose parameters that attain a near-optimal overall number of iterations, without extra matrix computations?\n\tWe answer in the affirmative for Successive Over-Relaxation (SOR), a standard solver whose parameter $\\omega$ has a strong impact on its runtime.\n\tFor this method, we prove that a bandit online learning algorithm\u2014using only the number of iterations as feedback\u2014can select parameters for a sequence of instances such that the overall cost approaches that of the best fixed $\\omega$ as the sequence length increases.\n\tFurthermore, when given additional structural information, we show that a _contextual_ bandit method asymptotically achieves the performance of the _instance-optimal_ policy, which selects the best $\\omega$ for each instance.\n\tOur work provides the first learning-theoretic treatment of high-precision linear system solvers and the first end-to-end guarantees for data-driven scientific computing, demonstrating theoretically the potential to speed up numerical methods using well-understood learning algorithms."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d59e005abc331ebd418505cce645cdb4e7a2459f.pdf"}, "supplementary_material": {"value": "/attachment/33e10f5af5711e4f2e735654e9558c08c4e7e509.zip"}, "_bibtex": {"value": "@inproceedings{\nkhodak2024learning,\ntitle={Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances},\nauthor={Mikhail Khodak and Edmond Chow and Maria Florina Balcan and Ameet Talwalkar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5t57omGVMw}\n}"}, "paperhash": {"value": "khodak|learning_to_relax_setting_solver_parameters_across_a_sequence_of_linear_system_instances"}}, "number": 8824, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8824/-/Revision", "ICLR.cc/2024/Conference/Submission8824/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8824/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525597516, "cdate": 1695525597516, "tmdate": 1712002505856, "mdate": 1712002505856, "pdate": 1705411050848, "version": 2}, {"id": "Ad81awoBVS", "forum": "Ad81awoBVS", "signatures": ["ICLR.cc/2024/Conference/Submission8740/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8740/Authors"], "content": {"title": {"value": "Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification"}, "authors": {"value": ["Guodong Wang", "Yunhong Wang", "Xiuguo Bao", "Di Huang"]}, "authorids": {"value": ["~Guodong_Wang3", "~Yunhong_Wang1", "~Xiuguo_Bao3", "~Di_Huang4"]}, "keywords": {"value": ["self-supervised learning", "deep one-class cilassification"]}, "abstract": {"value": "One-class classification (OCC) involves predicting whether a new data is normal or anomalous based solely on the data from a single class during training. Various attempts have been made to learn suitable representations for OCC within a self-supervised framework. Notably, discriminative methods that use geometric visual transformations, such as rotation, to generate pseudo-anomaly samples have exhibited impressive detection performance. Although rotation is commonly viewed as a distribution-shifting transformation and is widely used in the literature, the cause of its effectiveness remains a mystery. In this study, we are the first to make a surprising observation: there exists a strong linear relationship (Pearson's Correlation, $r > 0.9$) between the accuracy of rotation prediction and the performance of OCC. This suggests that a classifier that effectively distinguishes different rotations is more likely to excel in OCC, and vice versa. The root cause of this phenomenon can be attributed to the transformation bias in the dataset, where representations learned from transformations already present in the dataset tend to be less effective, making it essential to accurately estimate the transformation distribution before utilizing pretext tasks involving these transformations for reliable self-supervised representation learning. To the end, we propose a novel two-stage method to estimate the transformation distribution within the dataset. In the first stage, we learn general representations through standard contrastive pre-training. In the second stage, we select potentially semantics-preserving samples from the entire augmented dataset, which includes all rotations, by employing density matching with the provided reference distribution. By sorting samples based on semantics-preserving versus shifting transformations, we achieve improved performance on OCC benchmarks."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7bf21feb9bcffeac0dec9c48b1b50d05663b5a16.pdf"}, "TLDR": {"value": "We observe a robust relationship between the accuracy of rotation prediction and one-class classification (OCC), with a novel method proposed for estimating the transformation distribution within the dataset, thus enhancing OCC."}, "_bibtex": {"value": "@inproceedings{\nwang2024rotation,\ntitle={Rotation has two sides: Evaluating Data Augmentation for Deep One-class Classification},\nauthor={Guodong Wang and Yunhong Wang and Xiuguo Bao and Di Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ad81awoBVS}\n}"}, "paperhash": {"value": "wang|rotation_has_two_sides_evaluating_data_augmentation_for_deep_oneclass_classification"}}, "number": 8740, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8740/-/Revision", "ICLR.cc/2024/Conference/Submission8740/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8740/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523247122, "cdate": 1695523247122, "tmdate": 1713085218708, "mdate": 1713085218708, "pdate": 1705411048715, "version": 2}, {"id": "RvUVMjfp8i", "forum": "RvUVMjfp8i", "signatures": ["ICLR.cc/2024/Conference/Submission8731/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8731/Authors"], "content": {"title": {"value": "Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments"}, "authors": {"value": ["Lin-Han Jia", "Lan-Zhe Guo", "Zhi Zhou", "Yu-Feng Li"]}, "authorids": {"value": ["~Lin-Han_Jia1", "~Lan-Zhe_Guo2", "~Zhi_Zhou2", "~Yu-Feng_Li1"]}, "keywords": {"value": ["Semi-Supervised Learning; Robustness; Open Environments"]}, "abstract": {"value": "Semi-supervised learning (SSL) is a powerful paradigm for leveraging unlabeled data and has been proven to be successful across various tasks. Conventional SSL studies typically assume close environment scenarios where labeled and unlabeled examples are independently sampled from the same distribution. However, real-world tasks often involve open environment scenarios where the data distribution, label space, and feature space could differ between labeled and unlabeled data. This inconsistency introduces robustness challenges for SSL algorithms. In this paper, we first propose several robustness metrics for SSL based on the Robustness Analysis Curve (RAC), secondly, we establish a theoretical framework for studying the generalization performance and robustness of SSL algorithms in open environments, thirdly, we re-implement widely adopted SSL algorithms within a unified SSL toolkit and evaluate their performance on proposed open environment SSL benchmarks, including both image, text, and tabular datasets. By investigating the empirical and theoretical results, insightful discussions on enhancing the robustness of SSL algorithms in open environments are presented. The re-implementation and benchmark datasets are all publicly available. More details can be found at https://ygzwqzd.github.io/Robust-SSL-Benchmark."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3ab2c500841b15c2298e78836e9a91caa20ef54d.pdf"}, "_bibtex": {"value": "@inproceedings{\njia2024a,\ntitle={A Benchmark on Robust Semi-Supervised Learning in Open Environments},\nauthor={Lin-Han Jia and Lan-Zhe Guo and Zhi Zhou and Yu-Feng Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RvUVMjfp8i}\n}"}, "paperhash": {"value": "jia|realistic_evaluation_of_semisupervised_learning_algorithms_in_open_environments"}}, "number": 8731, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8731/-/Revision", "ICLR.cc/2024/Conference/Submission8731/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8731/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695522797696, "cdate": 1695522797696, "tmdate": 1710589416816, "mdate": 1710589416816, "pdate": 1705411048348, "version": 2}, {"id": "JzvIWvC9MG", "forum": "JzvIWvC9MG", "signatures": ["ICLR.cc/2024/Conference/Submission8714/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8714/Authors"], "content": {"title": {"value": "Efficient Inverse Multiagent Learning"}, "authors": {"value": ["Denizalp Goktas", "Amy Greenwald", "Sadie Zhao", "Alec Koppel", "Sumitra Ganesh"]}, "authorids": {"value": ["~Denizalp_Goktas1", "~Amy_Greenwald1", "~Sadie_Zhao1", "~Alec_Koppel1", "~Sumitra_Ganesh1"]}, "keywords": {"value": ["Inverse Game Theory", "Inverse Multiagent Reinforcement Learning"]}, "TLDR": {"value": "We provide an efficient generative adversarial characterization for the inference of parameters of a game in inverse game theory and inverse multiagent (reinforcement) learning settings."}, "abstract": {"value": "In this paper, we study inverse game theory (resp. inverse multiagent learning) in\nwhich the goal is to find parameters of a game\u2019s payoff functions for which the\nexpected (resp. sampled) behavior is an equilibrium. We formulate these problems\nas generative-adversarial (i.e., min-max) optimization problems, which we develop\npolynomial-time algorithms to solve, the former of which relies on an exact first-\norder oracle, and the latter, a stochastic one. We extend our approach to solve\ninverse multiagent simulacral learning in polynomial time and number of samples.\nIn these problems, we seek a simulacrum, meaning parameters and an associated\nequilibrium that replicate the given observations in expectation. We find that our\napproach outperforms the widely-used ARIMA method in predicting prices in\nSpanish electricity markets based on time-series data."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a9b2dbe12dc144708ce2aceac70a4d581219169b.pdf"}, "supplementary_material": {"value": "/attachment/bb488ef70b39f52dfbfad680729412a81fac0ce6.pdf"}, "_bibtex": {"value": "@inproceedings{\ngoktas2024generative,\ntitle={Generative Adversarial Inverse Multiagent Learning},\nauthor={Denizalp Goktas and Amy Greenwald and Sadie Zhao and Alec Koppel and Sumitra Ganesh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JzvIWvC9MG}\n}"}, "paperhash": {"value": "goktas|efficient_inverse_multiagent_learning"}}, "number": 8714, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8714/-/Revision", "ICLR.cc/2024/Conference/Submission8714/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8714/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695522258309, "cdate": 1695522258309, "tmdate": 1713166564643, "mdate": 1713166564643, "pdate": 1705411047737, "version": 2}, {"id": "WNLAkjUm19", "forum": "WNLAkjUm19", "signatures": ["ICLR.cc/2024/Conference/Submission8697/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8697/Authors"], "content": {"title": {"value": "On the Role of Discrete Tokenization in Visual Representation Learning"}, "authors": {"value": ["Tianqi Du", "Yifei Wang", "Yisen Wang"]}, "authorids": {"value": ["~Tianqi_Du1", "~Yifei_Wang1", "~Yisen_Wang1"]}, "keywords": {"value": ["Self-supervised learning", "Masked image modeling", "Discrete visual token"]}, "abstract": {"value": "In the realm of self-supervised learning (SSL), masked image modeling (MIM) has gained popularity alongside contrastive learning methods. MIM involves reconstructing masked regions of input images using their unmasked portions. A notable subset of MIM methodologies employs discrete tokens as the reconstruction target, but the theoretical underpinnings of this choice remain underexplored. In this paper, we explore the role of these discrete tokens, aiming to unravel their benefits and limitations. Building upon the connection between MIM and contrastive learning, we provide a comprehensive theoretical understanding on how discrete tokenization affects the model's generalization capabilities. Furthermore, we propose a novel metric named TCAS, which is specifically designed to assess the effectiveness of discrete tokens within the MIM framework. Inspired by this metric, we contribute an innovative tokenizer design and propose a corresponding MIM method named ClusterMIM. It demonstrates superior performance on a variety of benchmark datasets and ViT backbones. Code is available at \\url{https://github.com/PKU-ML/ClusterMIM}."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/df6a2badfb1ca27a043b219c9e61e43688458fdf.pdf"}, "_bibtex": {"value": "@inproceedings{\ndu2024on,\ntitle={On the Role of Discrete Tokenization in Visual Representation Learning},\nauthor={Tianqi Du and Yifei Wang and Yisen Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WNLAkjUm19}\n}"}, "paperhash": {"value": "du|on_the_role_of_discrete_tokenization_in_visual_representation_learning"}}, "number": 8697, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8697/-/Revision", "ICLR.cc/2024/Conference/Submission8697/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8697/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521722554, "cdate": 1695521722554, "tmdate": 1711543770770, "mdate": 1711543770770, "pdate": 1705411046981, "version": 2}, {"id": "n9xeGcI4Yg", "forum": "n9xeGcI4Yg", "signatures": ["ICLR.cc/2024/Conference/Submission8650/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8650/Authors"], "content": {"title": {"value": "The Consensus Game: Language Model Generation via Equilibrium Search"}, "authors": {"value": ["Athul Paul Jacob", "Yikang Shen", "Gabriele Farina", "Jacob Andreas"]}, "authorids": {"value": ["~Athul_Paul_Jacob1", "~Yikang_Shen1", "~Gabriele_Farina1", "~Jacob_Andreas1"]}, "keywords": {"value": ["language models", "decoding", "planning", "game theory"]}, "abstract": {"value": "When applied to question answering and other text generation tasks, language models (LMs) may be queried generatively (by sampling answers from their output distribution) or discriminatively (by using them to score or rank a set of candidate answers). These procedures sometimes yield very different predictions. How do we reconcile mutually incompatible scoring procedures to obtain coherent LM predictions? We introduce a new, a training-free, game-theoretic procedure for language model decoding. Our approach casts language model decoding as a regularized imperfect-information sequential signaling game\u2014which we term the concensus game\u2014in which a generator seeks to communicate an abstract correctness parameter using natural language sentences to a discriminator. We develop computational procedures for finding approximate equilibria of this game, resulting in a decoding algorithm we call equilibrium-ranking. Applied to a large number of tasks (including reading comprehension, commonsense reasoning, mathematical problem-solving, and assistive dialog), equilibrium-ranking consistently improves performance over existing LM decoding procedures. These improvements are sometimes substantial\u2014on multiple benchmarks, we observe that applying equilibrium-ranking to LLaMA-7B outperforms the much larger LLaMA-65B and PaLM-540B models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2108035fffbf49c82187ef1eff5be4d58ede3070.pdf"}, "_bibtex": {"value": "@inproceedings{\njacob2024the,\ntitle={The Consensus Game: Language Model Generation via Equilibrium Search},\nauthor={Athul Paul Jacob and Yikang Shen and Gabriele Farina and Jacob Andreas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=n9xeGcI4Yg}\n}"}, "paperhash": {"value": "jacob|the_consensus_game_language_model_generation_via_equilibrium_search"}}, "number": 8650, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8650/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8650/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695519914123, "cdate": 1695519914123, "tmdate": 1713022835219, "mdate": 1713022835219, "pdate": 1705411045856, "version": 2}, {"id": "M6XWoEdmwf", "forum": "M6XWoEdmwf", "signatures": ["ICLR.cc/2024/Conference/Submission8600/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8600/Authors"], "content": {"title": {"value": "AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents"}, "authors": {"value": ["Jake Grigsby", "Linxi Fan", "Yuke Zhu"]}, "authorids": {"value": ["~Jake_Grigsby1", "~Linxi_Fan2", "~Yuke_Zhu1"]}, "keywords": {"value": ["Meta-RL", "Generalization", "Long-Term Memory", "Transformers"]}, "abstract": {"value": "We introduce AMAGO, an in-context Reinforcement Learning (RL) agent that uses sequence models to tackle the challenges of generalization, long-term memory, and meta-learning. Recent works have shown that off-policy learning can make in-context RL with recurrent policies viable. Nonetheless, these approaches require extensive tuning and limit scalability by creating key bottlenecks in agents' memory capacity, planning horizon, and model size. AMAGO revisits and redesigns the off-policy in-context approach to successfully train long-sequence Transformers over entire rollouts in parallel with end-to-end RL. Our agent is scalable and applicable to a wide range of problems, and we demonstrate its strong performance empirically in meta-RL and long-term memory domains. AMAGO's focus on sparse rewards and off-policy data also allows in-context learning to extend to goal-conditioned problems with challenging exploration. When combined with a multi-goal hindsight relabeling scheme, AMAGO can solve a previously difficult category of open-world domains, where agents complete many possible instructions in procedurally generated environments."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6ffd1eb5dc0bd2b144d5d0309763b3ed5e114e8b.pdf"}, "supplementary_material": {"value": "/attachment/15bfe09275a056c055f122eb6f60d1aa2ef10da3.pdf"}, "_bibtex": {"value": "@inproceedings{\ngrigsby2024amago,\ntitle={{AMAGO}: Scalable In-Context Reinforcement Learning for Adaptive Agents},\nauthor={Jake Grigsby and Linxi Fan and Yuke Zhu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=M6XWoEdmwf}\n}"}, "paperhash": {"value": "grigsby|amago_scalable_incontext_reinforcement_learning_for_adaptive_agents"}}, "number": 8600, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8600/-/Revision", "ICLR.cc/2024/Conference/Submission8600/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8600/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695517213807, "cdate": 1695517213807, "tmdate": 1709661549591, "mdate": 1709661549591, "pdate": 1705411044501, "version": 2}, {"id": "OkHHJcMroY", "forum": "OkHHJcMroY", "signatures": ["ICLR.cc/2024/Conference/Submission8499/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8499/Authors"], "content": {"title": {"value": "PILOT: An $\\mathcal{O}(1/K)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation"}, "authors": {"value": ["Zhuqing Liu", "Xin Zhang", "Jia Liu", "Zhengyuan Zhu", "Songtao Lu"]}, "authorids": {"value": ["~Zhuqing_Liu2", "~Xin_Zhang16", "~Jia_Liu1", "~Zhengyuan_Zhu1", "~Songtao_Lu1"]}, "keywords": {"value": ["min-max optimization", "adaptive batch size", "policy evaluation."]}, "abstract": {"value": "Learning an accurate value function for a given policy is a critical step in solving reinforcement learning (RL) problems. So far, however, the convergence speed and sample complexity performances of most existing policy evaluation algorithms remain unsatisfactory, particularly with non-linear function approximation. This challenge motivates us to develop a new path-integrated primal-dual stochastic gradient (PILOT) method, that is able to achieve a fast convergence speed for RL policy evaluation with nonlinear function approximation. To further alleviate the periodic full gradient evaluation requirement, we further propose an enhanced method with an adaptive-batch adjustment called PILOT$^+$. The main advantages of our methods include: i) PILOT allows the use of {\\em{constant}} step sizes and achieves the $\\mathcal{O}(1/K)$ convergence rate to first-order stationary points of non-convex policy evaluation problems; ii) PILOT is a generic {\\em{single}}-timescale algorithm that is also applicable for solving a large class of non-convex strongly-concave minimax optimization problems; iii) By adaptively adjusting the batch size via historical stochastic gradient information, PILOT$^+$ is more sample-efficient empirically without loss of theoretical convergence rate. Our extensive numerical experiments verify our theoretical findings and showcase the high efficiency of the proposed PILOT and PILOT$^+$ algorithms compared with the state-of-the-art methods."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/902e07eaba32bb9c32d1b7969eb59578e7e928ca.pdf"}, "supplementary_material": {"value": "/attachment/2af42a2212b05c42e76f6101b4dc0b1a16f55d17.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024pilot,\ntitle={{PILOT}: An \\${\\textbackslash}mathcal\\{O\\}(1/T)\\$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation},\nauthor={Zhuqing Liu and Xin Zhang and Jia Liu and Zhengyuan Zhu and Songtao Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OkHHJcMroY}\n}"}, "paperhash": {"value": "liu|pilot_an_\\mathcalo1kconvergent_approach_for_policy_evaluation_with_nonlinear_function_approximation"}}, "number": 8499, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8499/-/Revision", "ICLR.cc/2024/Conference/Submission8499/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8499/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695512820331, "cdate": 1695512820331, "tmdate": 1709661548764, "mdate": 1709661548764, "pdate": 1705411041972, "version": 2}, {"id": "gkfUvn0fLU", "forum": "gkfUvn0fLU", "signatures": ["ICLR.cc/2024/Conference/Submission8460/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8460/Authors"], "content": {"title": {"value": "Confronting Reward Model Overoptimization with Constrained RLHF"}, "authors": {"value": ["Ted Moskovitz", "Aaditya K Singh", "DJ Strouse", "Tuomas Sandholm", "Ruslan Salakhutdinov", "Anca Dragan", "Stephen Marcus McAleer"]}, "authorids": {"value": ["~Ted_Moskovitz1", "~Aaditya_K_Singh1", "~DJ_Strouse1", "~Tuomas_Sandholm1", "~Ruslan_Salakhutdinov1", "~Anca_Dragan1", "~Stephen_Marcus_McAleer1"]}, "keywords": {"value": ["rlhf", "overoptimization", "constrained RL"]}, "TLDR": {"value": "We study overoptimization in composite reward models and introduce several approaches based on a constrained MDP formulation of the problem to address it."}, "abstract": {"value": "Large language models are typically aligned with human preferences by optimizing reward models (RMs) fitted to human feedback. However, human preferences are multi-faceted, and it is increasingly common to derive reward from a composition of simpler reward models which each capture a different aspect of language quality. This itself presents a challenge, as it is difficult to appropriately weight these component RMs when combining them. Compounding this difficulty, because any RM is only a proxy for human evaluation, this process is vulnerable to *overoptimization*, wherein past a certain point, accumulating higher reward is associated with worse human ratings. In this paper, we perform the first study on overoptimization in composite RMs, showing that correlation between component RMs has a significant effect on the locations of these points. We then introduce an approach to solve this issue using constrained reinforcement learning as a means of preventing the agent from exceeding each RM's threshold of usefulness. Our method addresses the problem of weighting component RMs by learning dynamic weights, naturally given by the Lagrange multipliers. As a result, each RM stays within the range at which it is an effective proxy, improving evaluation performance. Finally, we introduce an adaptive method using gradient-free optimization to identify and optimize towards these points during a single run."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9110e24405b3d1c469f8710d548cf6e5b7867692.pdf"}, "supplementary_material": {"value": "/attachment/2c42d0b0ed2c137d100785929fa5585651ecbb04.zip"}, "_bibtex": {"value": "@inproceedings{\nmoskovitz2024confronting,\ntitle={Confronting Reward Model Overoptimization with Constrained {RLHF}},\nauthor={Ted Moskovitz and Aaditya K Singh and DJ Strouse and Tuomas Sandholm and Ruslan Salakhutdinov and Anca Dragan and Stephen Marcus McAleer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gkfUvn0fLU}\n}"}, "paperhash": {"value": "moskovitz|confronting_reward_model_overoptimization_with_constrained_rlhf"}}, "number": 8460, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8460/-/Revision", "ICLR.cc/2024/Conference/Submission8460/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8460/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695511292202, "cdate": 1695511292202, "tmdate": 1710463536664, "mdate": 1710463536664, "pdate": 1705411041174, "version": 2}, {"id": "f3g5XpL9Kb", "forum": "f3g5XpL9Kb", "signatures": ["ICLR.cc/2024/Conference/Submission8433/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8433/Authors"], "content": {"title": {"value": "LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures"}, "authors": {"value": ["Vimal Thilak", "Chen Huang", "Omid Saremi", "Laurent Dinh", "Hanlin Goh", "Preetum Nakkiran", "Joshua M. Susskind", "Etai Littwin"]}, "authorids": {"value": ["~Vimal_Thilak2", "~Chen_Huang6", "~Omid_Saremi1", "~Laurent_Dinh1", "~Hanlin_Goh2", "~Preetum_Nakkiran1", "~Joshua_M._Susskind1", "~Etai_Littwin1"]}, "keywords": {"value": ["Self Supervised Learning", "Joint Embedding Architectures"]}, "TLDR": {"value": "A SOTA method for predicting linear probing performance in joint embedding architectures"}, "abstract": {"value": "Joint embedding (JE) architectures have emerged as a promising avenue for ac-\nquiring transferable data representations. A key obstacle to using JE methods,\nhowever, is the inherent challenge of evaluating learned representations without\naccess to a downstream task, and an annotated dataset. Without efficient and re-\nliable evaluation, it is difficult to iterate on architectural and training choices for\nJE methods. In this paper, we introduce LiDAR (Linear Discriminant Analysis\nRank), a metric designed to measure the quality of representations within JE archi-\ntectures. Our metric addresses several shortcomings of recent approaches based\non feature covariance rank by discriminating between informative and uninforma-\ntive features. In essence, LiDAR quantifies the rank of the Linear Discriminant\nAnalysis (LDA) matrix associated with the surrogate SSL task\u2014a measure that\nintuitively captures the information content as it pertains to solving the SSL task.\nWe empirically demonstrate that LiDAR significantly surpasses naive rank based\napproaches in its predictive power of optimal hyperparameters. Our proposed cri-\nterion presents a more robust and intuitive means of assessing the quality of rep-\nresentations within JE architectures, which we hope facilitates broader adoption\nof these powerful techniques in various domains."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fee7013fbdfbbccda18d5123b30300919a05a18f.pdf"}, "supplementary_material": {"value": "/attachment/3c4cd119567928f024cf2c9493f8f5e6f9b503d3.pdf"}, "_bibtex": {"value": "@inproceedings{\nthilak2024lidar,\ntitle={Li{DAR}: Sensing Linear Probing Performance in Joint Embedding {SSL} Architectures},\nauthor={Vimal Thilak and Chen Huang and Omid Saremi and Laurent Dinh and Hanlin Goh and Preetum Nakkiran and Joshua M. Susskind and Etai Littwin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=f3g5XpL9Kb}\n}"}, "paperhash": {"value": "thilak|lidar_sensing_linear_probing_performance_in_joint_embedding_ssl_architectures"}}, "number": 8433, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8433/-/Revision", "ICLR.cc/2024/Conference/Submission8433/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8433/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695510159779, "cdate": 1695510159779, "tmdate": 1710203501994, "mdate": 1710203501994, "pdate": 1705411040432, "version": 2}, {"id": "lOwkOIUJtx", "forum": "lOwkOIUJtx", "signatures": ["ICLR.cc/2024/Conference/Submission8429/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8429/Authors"], "content": {"title": {"value": "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling"}, "authors": {"value": ["Jiayang Liu", "Yiming Bu", "Daniel Tso", "Qinru Qiu"]}, "authorids": {"value": ["~Jiayang_Liu2", "~Yiming_Bu1", "~Daniel_Tso1", "~Qinru_Qiu1"]}, "keywords": {"value": ["Biological inspired high performance energy efficient vision system", "data efficient training", "energy saving sensoring", "learned saccade", "reinforcement learning", "foveated visual sampling", "continuous scene reconstruction."]}, "abstract": {"value": "High accuracy, low latency and high energy efficiency represent a set of contradictory goals when searching for  system solutions for image classification and detection. While high-quality images naturally result in more precise detection and classification, they also result in a heavier computational workload for imaging and processing, reduce camera refresh rates, and increase the volume of data communication between the camera and processor. Taking inspiration from the foveal-peripheral sampling mechanism, saccade mechanism observed in the human visual system and the filling-in phenomena of brain, we have developed an active scene reconstruction architecture based on multiple foveal views. This model stitches together information from foveal and peripheral vision, which are sampled from multiple glances. Assisted by a reinforcement learning-based saccade mechanism, our model reduces the required input pixels by over 90\\% per frame while maintaining the same level of performance in image recognition as with the original images. We evaluated the effectiveness of our model using the GTSRB dataset and the ImageNet dataset. Using an equal number of input pixels, our study demonstrates a 5\\% higher image recognition accuracy compared to state-of-the-art foveal-peripheral vision systems. Furthermore, we demonstrate that our foveal sampling/saccadic scene reconstruction model exhibits significantly lower complexity and higher data efficiency during the training phase compared to existing approaches."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ad265fc85f17aaf422d2fd23b3440143ba832adc.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024improved,\ntitle={Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling},\nauthor={Jiayang Liu and Yiming Bu and Daniel Tso and Qinru Qiu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lOwkOIUJtx}\n}"}, "paperhash": {"value": "liu|improved_efficiency_based_on_learned_saccade_and_continuous_scene_reconstruction_from_foveated_visual_sampling"}}, "number": 8429, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8429/-/Revision", "ICLR.cc/2024/Conference/Submission8429/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8429/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695510038947, "cdate": 1695510038947, "tmdate": 1710031100059, "mdate": 1710031100059, "pdate": 1705411040296, "version": 2}, {"id": "Tigr1kMDZy", "forum": "Tigr1kMDZy", "signatures": ["ICLR.cc/2024/Conference/Submission8426/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8426/Authors"], "content": {"title": {"value": "Overthinking the Truth: Understanding how Language Models Process False Demonstrations"}, "authors": {"value": ["Danny Halawi", "Jean-Stanislas Denain", "Jacob Steinhardt"]}, "authorids": {"value": ["~Danny_Halawi1", "~Jean-Stanislas_Denain1", "~Jacob_Steinhardt1"]}, "keywords": {"value": ["Mechanistic Interpretability", "AI Safety", "Interpretability", "Science of ML", "few-shot learning", "Large Language Models"]}, "abstract": {"value": "Modern language models can imitate complex patterns through few-shot learning, enabling them to complete challenging tasks without fine-tuning. However, imitation can also lead models to reproduce inaccuracies or harmful content if present in the context. We study harmful imitation through the lens of a model\u2019s internal representations, and identify two related phenomena: overthinking and false induction heads. The first phenomenon, overthinking, appears when we decode predictions from intermediate layers, given correct vs. incorrect few-shot demonstrations. At early layers, both demonstrations induce similar model behavior, but the behavior diverges sharply at some \u201ccritical layer\u201d, after which the accuracy given incorrect demonstrations progressively decreases. The second phenomenon, false induction heads, are a possible mechanistic cause of overthinking: these are heads in late layers that attend to and copy false information from previous demonstrations, and whose ablation reduces overthinking. Beyond scientific understanding, our results suggest that studying intermediate model computations could be a promising avenue for understanding and guarding against harmful model behaviors."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/55ea326a66e2cf61319ebe01bdea1b4ebbd8d775.pdf"}, "_bibtex": {"value": "@inproceedings{\nhalawi2024overthinking,\ntitle={Overthinking the Truth: Understanding how Language Models Process False Demonstrations},\nauthor={Danny Halawi and Jean-Stanislas Denain and Jacob Steinhardt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tigr1kMDZy}\n}"}, "paperhash": {"value": "halawi|overthinking_the_truth_understanding_how_language_models_process_false_demonstrations"}}, "number": 8426, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8426/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8426/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509994377, "cdate": 1695509994377, "tmdate": 1710224428025, "mdate": 1710224428025, "pdate": 1705411040181, "version": 2}, {"id": "Rry1SeSOQL", "forum": "Rry1SeSOQL", "signatures": ["ICLR.cc/2024/Conference/Submission8378/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8378/Authors"], "content": {"title": {"value": "MT-Ranker: Reference-free machine translation evaluation by inter-system ranking"}, "authors": {"value": ["Ibraheem Muhammad Moosa", "Rui Zhang", "Wenpeng Yin"]}, "authorids": {"value": ["~Ibraheem_Muhammad_Moosa1", "~Rui_Zhang7", "~Wenpeng_Yin1"]}, "keywords": {"value": ["Machine Translation Evaluation"]}, "TLDR": {"value": "We apply pairwise ranking approach to machine translation evaluation in reference-free scenario."}, "abstract": {"value": "Traditionally, Machine Translation (MT) Evaluation has been treated as a regression problem -- producing an absolute translation-quality score. This approach has two limitations: i) the scores lack interpretability, and human annotators struggle with giving consistent scores; ii) most scoring methods are based on (reference, translation) pairs, limiting their applicability in real-world scenarios where references are absent. In practice, we often care about whether a new MT system is better or worse than some competitors. In addition, reference-free MT evaluation is increasingly practical and necessary. Unfortunately, these two practical considerations have yet to be jointly explored. In this work, we formulate the reference-free MT evaluation into a pairwise ranking problem. Given the source sentence and a pair of translations, our system predicts which translation is better. In addition to proposing this new formulation, we further show that this new paradigm can demonstrate superior correlation with human judgments by merely using indirect supervision from natural language inference and weak supervision from our synthetic data. In the context of reference-free evaluation, MT-Ranker, trained without any human annotations, achieves state-of-the-art results on the WMT Shared Metrics Task benchmarks DARR20, MQM20, and MQM21. On a more challenging benchmark, ACES, which contains fine-grained evaluation criteria such as addition, omission, and mistranslation errors, MT-Ranker marks state-of-the-art against reference-free as well as reference-based baselines."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fa181eb3a2cd5c3485b73e3829ad16f3dffa5faa.pdf"}, "_bibtex": {"value": "@inproceedings{\nmoosa2024comparator,\ntitle={{COMPARATOR}: Reference-free machine translation evaluation by inter-system comparison},\nauthor={Ibraheem Muhammad Moosa and Rui Zhang and Wenpeng Yin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Rry1SeSOQL}\n}"}, "paperhash": {"value": "moosa|mtranker_referencefree_machine_translation_evaluation_by_intersystem_ranking"}}, "number": 8378, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8378/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8378/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695507871493, "cdate": 1695507871493, "tmdate": 1709661547967, "mdate": 1709661547967, "pdate": 1705411039030, "version": 2}, {"id": "jenyYQzue1", "forum": "jenyYQzue1", "signatures": ["ICLR.cc/2024/Conference/Submission8293/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8293/Authors"], "content": {"title": {"value": "MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning"}, "authors": {"value": ["Zayne Rea Sprague", "Xi Ye", "Kaj Bostrom", "Swarat Chaudhuri", "Greg Durrett"]}, "authorids": {"value": ["~Zayne_Rea_Sprague1", "~Xi_Ye2", "~Kaj_Bostrom1", "~Swarat_Chaudhuri1", "~Greg_Durrett1"]}, "keywords": {"value": ["Large Language Models", "Chain-of-Thought", "Textual Reasoning"]}, "TLDR": {"value": "We introduce MuSR, a new dataset for testing LLMs' abilities to do complex, structured reasoning based on generated narratives."}, "abstract": {"value": "While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our data instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy. We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0fd545b50f3dd67f4d965d2b37b07aa5d08aba77.pdf"}, "supplementary_material": {"value": "/attachment/a0fefb56255472c56c4f033db40374add9e033c1.zip"}, "_bibtex": {"value": "@inproceedings{\nsprague2024musr,\ntitle={Mu{SR}: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning},\nauthor={Zayne Rea Sprague and Xi Ye and Kaj Bostrom and Swarat Chaudhuri and Greg Durrett},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jenyYQzue1}\n}"}, "paperhash": {"value": "sprague|musr_testing_the_limits_of_chainofthought_with_multistep_soft_reasoning"}}, "number": 8293, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8293/-/Revision", "ICLR.cc/2024/Conference/Submission8293/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8293/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695503987987, "cdate": 1695503987987, "tmdate": 1710532240758, "mdate": 1710532240758, "pdate": 1705411037127, "version": 2}, {"id": "THJEa8adBn", "forum": "THJEa8adBn", "signatures": ["ICLR.cc/2024/Conference/Submission8279/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8279/Authors"], "content": {"title": {"value": "Harnessing Density Ratios for Online Reinforcement Learning"}, "authors": {"value": ["Philip Amortila", "Dylan J Foster", "Nan Jiang", "Ayush Sekhari", "Tengyang Xie"]}, "authorids": {"value": ["~Philip_Amortila1", "~Dylan_J_Foster1", "~Nan_Jiang2", "~Ayush_Sekhari1", "~Tengyang_Xie1"]}, "keywords": {"value": ["reinforcement learning theory", "online RL", "offline RL", "hybrid RL", "density ratio", "marginalized importance weight", "weight function", "general function approximation"]}, "TLDR": {"value": "The notion of density ratio modeling, an emerging topic in offline RL, has been largely absent from online RL. We show a perhaps surprising result, that density ratio-based algorithms have online counterparts."}, "abstract": {"value": "The theories of offline and online reinforcement learning, despite having evolved in parallel, have begun to show signs of the possibility for a unification, with algorithms and analysis techniques for one setting often having natural counterparts in the other. However, the notion of *density ratio modeling*, an emerging paradigm in offline RL, has been largely absent from online RL, perhaps for good reason: the very existence and boundedness of density ratios relies on access to an exploratory dataset with good coverage, but the core challenge in online RL is to collect such a dataset without having one to start.\n\nIn this work we show---perhaps surprisingly---that density ratio-based algorithms have online counterparts.  Assuming only the existence of an exploratory distribution with good coverage, a structural condition known as *coverability* (Xie et al., 2023), we give a new algorithm (GLOW) that uses density ratio realizability and value function realizability to perform sample-efficient online exploration. GLOW addresses unbounded density ratios via careful use of truncation, and combines this with optimism to guide exploration. GLOW is computationally inefficient; we complement it with a more efficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2023) wherein online RL is augmented with additional offline data. HyGLOW is derived as a special case of a more general meta-algorithm that provides a provable black-box reduction from hybrid RL to offline RL, which may be of independent interest."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2fffb35b07edd292dea91e77c2c874abdf3e831f.pdf"}, "supplementary_material": {"value": "/attachment/a794ccf758ae203e03a35ed0ecb8aeb43b32db6b.pdf"}, "_bibtex": {"value": "@inproceedings{\namortila2024harnessing,\ntitle={Harnessing Density Ratios for Online Reinforcement Learning},\nauthor={Philip Amortila and Dylan J Foster and Nan Jiang and Ayush Sekhari and Tengyang Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=THJEa8adBn}\n}"}, "paperhash": {"value": "amortila|harnessing_density_ratios_for_online_reinforcement_learning"}}, "number": 8279, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8279/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8279/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695503627046, "cdate": 1695503627046, "tmdate": 1710548057419, "mdate": 1710548057419, "pdate": 1705411036773, "version": 2}, {"id": "NgaLU2fP5D", "forum": "NgaLU2fP5D", "signatures": ["ICLR.cc/2024/Conference/Submission8234/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8234/Authors"], "content": {"title": {"value": "Predictive, scalable and interpretable knowledge tracing on structured domains"}, "authors": {"value": ["Hanqi Zhou", "Robert Bamler", "Charley M Wu", "\u00c1lvaro Tejero-Cantero"]}, "authorids": {"value": ["~Hanqi_Zhou1", "~Robert_Bamler1", "~Charley_M_Wu1", "~\u00c1lvaro_Tejero-Cantero1"]}, "keywords": {"value": ["knowledge tracing", "interpretable representations", "knowledge graphs", "probabilistic models", "variational inference", "continual learning"]}, "TLDR": {"value": "Performant and scalable knowledge tracing with the interpretability that personalized education needs."}, "abstract": {"value": "Intelligent tutoring systems optimize the selection and timing of learning materials to enhance understanding and long-term retention. This requires estimates of both the learner's progress (\"knowledge tracing\"; KT), and the prerequisite structure of the learning domain (\"knowledge mapping\"). While recent deep learning models achieve high KT accuracy, they do so at the expense of the interpretability of psychologically-inspired models. In this work, we present a solution to this trade-off. PSI-KT is a hierarchical generative approach that explicitly models how both individual cognitive traits and the prerequisite structure of knowledge influence learning dynamics, thus achieving interpretability by design. Moreover, by using scalable Bayesian inference, PSI-KT targets the real-world need for efficient personalization even with a growing body of learners and interaction data. Evaluated on three datasets from online learning platforms, PSI-KT achieves superior multi-step **p**redictive accuracy and **s**calable inference in continual-learning settings, all while providing **i**nterpretable representations of learner-specific traits and the prerequisite structure of knowledge that causally supports learning. In sum, predictive, scalable and interpretable knowledge tracing with solid knowledge mapping lays a key foundation for effective personalized learning to make education accessible to a broad, global audience."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/52c2533f0586eecd513971405b1c38d7810ec28b.pdf"}, "supplementary_material": {"value": "/attachment/5894d4b61a69bee95b6b2de7013fd1b76828d1ee.zip"}, "_bibtex": {"value": "@inproceedings{\nzhou2024predictive,\ntitle={Predictive, scalable and interpretable knowledge tracing on structured domains},\nauthor={Hanqi Zhou and Robert Bamler and Charley M Wu and {\\'A}lvaro Tejero-Cantero},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NgaLU2fP5D}\n}"}, "paperhash": {"value": "zhou|predictive_scalable_and_interpretable_knowledge_tracing_on_structured_domains"}}, "number": 8234, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8234/-/Revision", "ICLR.cc/2024/Conference/Submission8234/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8234/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501550757, "cdate": 1695501550757, "tmdate": 1710446811982, "mdate": 1710446811982, "pdate": 1705411035456, "version": 2}, {"id": "vngVydDWft", "forum": "vngVydDWft", "signatures": ["ICLR.cc/2024/Conference/Submission8194/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8194/Authors"], "content": {"title": {"value": "From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication"}, "authors": {"value": ["Irene Cannistraci", "Luca Moschella", "Marco Fumero", "Valentino Maiorca", "Emanuele Rodol\u00e0"]}, "authorids": {"value": ["~Irene_Cannistraci1", "~Luca_Moschella1", "~Marco_Fumero1", "~Valentino_Maiorca1", "~Emanuele_Rodol\u00e01"]}, "keywords": {"value": ["invariance", "latent space", "latent comunication", "zero-shot stitching", "representation learning", "relative representation"]}, "TLDR": {"value": "Incorporate invariances into neural representations to construct a product space of invariant components and unlock applications, such as merging, stitching, and reusing different neural modules."}, "abstract": {"value": "It has been observed that representations learned by distinct neural networks conceal structural similarities when the models are trained under similar inductive biases. From a geometric perspective, identifying the classes of transformations and the related invariances that connect these representations is fundamental to unlocking applications, such as merging, stitching, and reusing different neural modules. However, estimating task-specific transformations a priori can be challenging and expensive due to several factors (e.g., weights initialization, training hyperparameters, or data modality). To this end, we introduce a versatile method to directly incorporate a set of invariances into the representations, constructing a product space of invariant components on top of the latent representations without requiring prior knowledge about the optimal invariance to infuse. We validate our solution on classification and reconstruction tasks, observing consistent latent similarity and downstream performance improvements in a zero-shot stitching setting. The experimental analysis comprises three modalities (vision, text, and graphs), twelve pretrained foundational models, nine benchmarks, and several architectures trained from scratch."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4643421d3e88ae6516cd76daa15145a0b3f490d5.pdf"}, "supplementary_material": {"value": "/attachment/39a674f297f00f3cbdbaa039f347931dd4105dfd.zip"}, "_bibtex": {"value": "@inproceedings{\ncannistraci2024from,\ntitle={From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication},\nauthor={Irene Cannistraci and Luca Moschella and Marco Fumero and Valentino Maiorca and Emanuele Rodol{\\`a}},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vngVydDWft}\n}"}, "paperhash": {"value": "cannistraci|from_bricks_to_bridges_product_of_invariances_to_enhance_latent_space_communication"}}, "number": 8194, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8194/-/Revision", "ICLR.cc/2024/Conference/Submission8194/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8194/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500299591, "cdate": 1695500299591, "tmdate": 1712838253917, "mdate": 1712838253917, "pdate": 1705411033933, "version": 2}, {"id": "TFKIfhvdmZ", "forum": "TFKIfhvdmZ", "signatures": ["ICLR.cc/2024/Conference/Submission8192/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8192/Authors"], "content": {"title": {"value": "Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning"}, "authors": {"value": ["Sumeet Batra", "Bryon Tjanaka", "Matthew Christopher Fontaine", "Aleksei Petrenko", "Stefanos Nikolaidis", "Gaurav S. Sukhatme"]}, "authorids": {"value": ["~Sumeet_Batra1", "~Bryon_Tjanaka1", "~Matthew_Christopher_Fontaine1", "~Aleksei_Petrenko1", "~Stefanos_Nikolaidis1", "~Gaurav_S._Sukhatme1"]}, "keywords": {"value": ["Reinforcement Learning", "Quality Diversity", "Robotics", "Machine Learning", "Evolution Strategies"]}, "TLDR": {"value": "We present a novel QD-RL method that leverages on-policy RL and Differentiable Quality Diversity to discover a variety of high performing locomtion gaits on the challenging mujoco environment, including, for the first time in QD-RL, humanoid."}, "abstract": {"value": "Training generally capable agents that thoroughly explore their environment and\nlearn new and diverse skills is a long-term goal of robot learning. Quality Diversity\nReinforcement Learning (QD-RL) is an emerging research area that blends the\nbest aspects of both fields \u2013 Quality Diversity (QD) provides a principled form\nof exploration and produces collections of behaviorally diverse agents, while\nReinforcement Learning (RL) provides a powerful performance improvement\noperator enabling generalization across tasks and dynamic environments. Existing\nQD-RL approaches have been constrained to sample efficient, deterministic off-\npolicy RL algorithms and/or evolution strategies and struggle with highly stochastic\nenvironments. In this work, we, for the first time, adapt on-policy RL, specifically\nProximal Policy Optimization (PPO), to the Differentiable Quality Diversity (DQD)\nframework and propose several changes that enable efficient optimization and\ndiscovery of novel skills on high-dimensional, stochastic robotics tasks. Our new\nalgorithm, Proximal Policy Gradient Arborescence (PPGA), achieves state-of-\nthe-art results, including a 4x improvement in best reward over baselines on the\nchallenging humanoid domain."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f3442a5e81e1db8cb186b12c6fe204d3de0490dc.pdf"}, "supplementary_material": {"value": "/attachment/c86dc0f0cb27215dd68fdf05ef563b1b7f50bed9.zip"}, "_bibtex": {"value": "@inproceedings{\nbatra2024proximal,\ntitle={Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning},\nauthor={Sumeet Batra and Bryon Tjanaka and Matthew Christopher Fontaine and Aleksei Petrenko and Stefanos Nikolaidis and Gaurav S. Sukhatme},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TFKIfhvdmZ}\n}"}, "paperhash": {"value": "batra|proximal_policy_gradient_arborescence_for_quality_diversity_reinforcement_learning"}}, "number": 8192, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8192/-/Revision", "ICLR.cc/2024/Conference/Submission8192/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8192/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500286488, "cdate": 1695500286488, "tmdate": 1711144766046, "mdate": 1711144766046, "pdate": 1705411033765, "version": 2}, {"id": "MrR3rMxqqv", "forum": "MrR3rMxqqv", "signatures": ["ICLR.cc/2024/Conference/Submission8187/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8187/Authors"], "content": {"title": {"value": "Memorization Capacity of Multi-Head Attention in Transformers"}, "authors": {"value": ["Sadegh Mahdavi", "Renjie Liao", "Christos Thrampoulidis"]}, "authorids": {"value": ["~Sadegh_Mahdavi1", "~Renjie_Liao1", "~Christos_Thrampoulidis1"]}, "keywords": {"value": ["Learning Theory", "Expressivity", "Multi-Head Attention", "Transformers"]}, "TLDR": {"value": "We propose a lower bound for the memorization capacity of multi-head attention in Transformers"}, "abstract": {"value": "Transformers have become the go-to architecture for language and vision tasks, yet their theoretical properties, especially memorization capacity, remain elusive. This paper investigates the memorization abilities of multi-head attention mechanisms, examining how many example sequences they can memorize, as a function of the number of heads and sequence length. Motivated by experimental findings on vision transformers, we introduce novel assumptions about the linear independence of input data, distinct from the commonly used general-position assumption. Under these assumptions, we demonstrate that an attention layer with $H$ heads, dimension $d$, and context size $n < d,$ featuring $\\Theta(Hd^2)$ parameters, can memorize $\\Omega(Hn)$ examples. Our analysis sheds light on how different attention heads handle various example sequences, aided by the softmax operator\u2019s saturation property. We validate our findings through experiments on synthetic data."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/30b070a1d5057982a67ece4fdb61fca629dea9e6.pdf"}, "supplementary_material": {"value": "/attachment/7cd6fc6411a3670bad397064a9d3d6987e4e9e8c.zip"}, "_bibtex": {"value": "@inproceedings{\nmahdavi2024memorization,\ntitle={Memorization Capacity of Multi-Head Attention in Transformers},\nauthor={Sadegh Mahdavi and Renjie Liao and Christos Thrampoulidis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MrR3rMxqqv}\n}"}, "paperhash": {"value": "mahdavi|memorization_capacity_of_multihead_attention_in_transformers"}}, "number": 8187, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8187/-/Revision", "ICLR.cc/2024/Conference/Submission8187/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8187/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500128975, "cdate": 1695500128975, "tmdate": 1709661546680, "mdate": 1709661546680, "pdate": 1705411033629, "version": 2}, {"id": "fpoAYV6Wsk", "forum": "fpoAYV6Wsk", "signatures": ["ICLR.cc/2024/Conference/Submission8142/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8142/Authors"], "content": {"title": {"value": "Circuit Component Reuse Across Tasks in Transformer Language Models"}, "authors": {"value": ["Jack Merullo", "Carsten Eickhoff", "Ellie Pavlick"]}, "authorids": {"value": ["~Jack_Merullo2", "~Carsten_Eickhoff1", "~Ellie_Pavlick1"]}, "keywords": {"value": ["interpretability", "llms", "mechanistic interpretability", "circuit"]}, "TLDR": {"value": "We analyze two different tasks that are solved with very similar circuits in GPT2, informing us about how LLMs solve problems"}, "abstract": {"value": "Recent work in mechanistic interpretability has shown that behaviors in language models can be successfully reverse-engineered through circuit analysis. A common criticism, however, is that each circuit is task-specific, and thus such analysis cannot contribute to understanding the models at a higher level. In this work, we present evidence that insights (both low-level findings about specific heads and higher-level findings about general algorithms) can indeed generalize across tasks. Specifically, we study the circuit discovered in (Wang, 2022) for the Indirect Object Identification (IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that it is mostly reused to solve a seemingly different task: Colored Objects (Ippolito & Callison-Burch, 2023). We provide evidence that the process underlying both tasks is functionally very similar, and contains about a 78% overlap in in-circuit attention heads. We further present a proof-of-concept intervention experiment, in which we adjust four attention heads in middle layers in order to \u2018repair\u2019 the Colored Objects circuit and make it behave like the IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the Colored Objects task and explain most sources of error. The intervention affects downstream attention heads in specific ways predicted by their interactions in the IOI circuit, indicating that this subcircuit behavior is invariant to the different task inputs. Overall, our results provide evidence that it may yet be possible to explain large language models' behavior in terms of a relatively small number of interpretable task-general algorithmic building blocks and computational components."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/20152cb1b27ee48c1edca998e2aa13b4249cabaa.pdf"}, "supplementary_material": {"value": "/attachment/381a5e79a33251cf21950992c331af97d466296e.zip"}, "_bibtex": {"value": "@inproceedings{\nmerullo2024circuit,\ntitle={Circuit Component Reuse Across Tasks in Transformer Language Models},\nauthor={Jack Merullo and Carsten Eickhoff and Ellie Pavlick},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fpoAYV6Wsk}\n}"}, "paperhash": {"value": "merullo|circuit_component_reuse_across_tasks_in_transformer_language_models"}}, "number": 8142, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8142/-/Revision", "ICLR.cc/2024/Conference/Submission8142/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8142/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695498403101, "cdate": 1695498403101, "tmdate": 1710549167531, "mdate": 1710549167531, "pdate": 1705411032392, "version": 2}, {"id": "sojpn00o8z", "forum": "sojpn00o8z", "signatures": ["ICLR.cc/2024/Conference/Submission8130/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8130/Authors"], "content": {"title": {"value": "Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps"}, "authors": {"value": ["Henry Li", "Ronen Basri", "Yuval Kluger"]}, "authorids": {"value": ["~Henry_Li2", "~Ronen_Basri1", "~Yuval_Kluger1"]}, "keywords": {"value": ["likelihood-based modeling", "diffusion modeling", "density estimation"]}, "abstract": {"value": "Cascaded models are multi-scale generative models with a marked capacity for producing perceptually impressive samples at high resolutions. In this work, we show that they can also be excellent likelihood models, so long as we overcome a fundamental difficulty with probabilistic multi-scale models: the intractability of the likelihood function. Chiefly, in cascaded models each intermediary scale introduces extraneous variables that cannot be tractably marginalized out for likelihood evaluation. This issue vanishes by modeling the diffusion process on latent spaces induced by a class of transformations we call hierarchical volume-preserving maps, which decompose spatially structured data in a hierarchical fashion without introducing local distortions in the latent space. We demonstrate that two such maps are well-known in the literature for multiscale modeling: Laplacian pyramids and wavelet transforms. Not only do such reparameterizations allow the likelihood function to be directly expressed as a joint likelihood over the scales, we show that the Laplacian pyramid and wavelet transform also produces significant improvements to the state-of-the-art on a selection of benchmarks in likelihood modeling, including density estimation, lossless compression, and out-of-distribution detection. Investigating the theoretical basis of our empirical gains we uncover deep connections to score matching under the Earth Mover's Distance (EMD), which is a well-known surrogate for perceptual similarity."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/865dfe741f8cb5f9543b9889e222096ffcafed42.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024likelihood,\ntitle={Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps},\nauthor={Henry Li and Ronen Basri and Yuval Kluger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sojpn00o8z}\n}"}, "TLDR": {"value": "We develop a framework for cascaded diffusion modeling that supports likelihood training and evaluation."}, "paperhash": {"value": "li|likelihood_training_of_cascaded_diffusion_models_via_hierarchical_volumepreserving_maps"}}, "number": 8130, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8130/-/Revision", "ICLR.cc/2024/Conference/Submission8130/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8130/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695497830074, "cdate": 1695497830074, "tmdate": 1711459298963, "mdate": 1711459298963, "pdate": 1705411032203, "version": 2}, {"id": "yuy6cGt3KL", "forum": "yuy6cGt3KL", "signatures": ["ICLR.cc/2024/Conference/Submission8120/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8120/Authors"], "content": {"title": {"value": "Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation"}, "authors": {"value": ["Divyat Mahajan", "Ioannis Mitliagkas", "Brady Neal", "Vasilis Syrgkanis"]}, "authorids": {"value": ["~Divyat_Mahajan1", "~Ioannis_Mitliagkas1", "~Brady_Neal2", "~Vasilis_Syrgkanis1"]}, "keywords": {"value": ["Heterogeneous Treatment Effect Estimation", "Conditional Average Treatment Effect", "Causal Inference", "Model Selection"]}, "abstract": {"value": "We study the problem of model selection in causal inference, specifically for the case of conditional average treatment effect (CATE) estimation under binary treatments. Unlike model selection in machine learning, there is no perfect analogue of cross-validation as we do not observe the counterfactual potential outcome for any data point. Towards this, there have been a variety of proxy metrics proposed in the literature, that depend on auxiliary nuisance models estimated from the observed data (propensity score model, outcome regression model). However, the effectiveness of these metrics has only been studied on synthetic datasets as we can access the counterfactual data for them. We conduct an extensive empirical analysis to judge the performance of these metrics introduced in the literature, and novel ones introduced in this work, where we utilize the latest advances in generative modeling to incorporate multiple realistic datasets. Our analysis suggests novel model selection strategies based on careful hyperparameter tuning of CATE estimators and causal ensembling."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/aaafcf97a6d0ae15ece53da251364fa408af4259.pdf"}, "supplementary_material": {"value": "/attachment/b98a447f6e598c5a00557d59fe37b4cc33d3a171.zip"}, "_bibtex": {"value": "@inproceedings{\nmahajan2024empirical,\ntitle={Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation},\nauthor={Divyat Mahajan and Ioannis Mitliagkas and Brady Neal and Vasilis Syrgkanis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yuy6cGt3KL}\n}"}, "paperhash": {"value": "mahajan|empirical_analysis_of_model_selection_for_heterogeneous_causal_effect_estimation"}}, "number": 8120, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8120/-/Revision", "ICLR.cc/2024/Conference/Submission8120/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695497491969, "cdate": 1695497491969, "tmdate": 1707625645106, "mdate": 1707625645106, "pdate": 1705411031922, "version": 2}, {"id": "PQY2v6VtGe", "forum": "PQY2v6VtGe", "signatures": ["ICLR.cc/2024/Conference/Submission8068/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8068/Authors"], "content": {"title": {"value": "Confidential-DPproof: Confidential Proof of Differentially Private Training"}, "authors": {"value": ["Ali Shahin Shamsabadi", "Gefei Tan", "Tudor Ioan Cebere", "Aur\u00e9lien Bellet", "Hamed Haddadi", "Nicolas Papernot", "Xiao Wang", "Adrian Weller"]}, "authorids": {"value": ["~Ali_Shahin_Shamsabadi1", "~Gefei_Tan1", "~Tudor_Ioan_Cebere1", "~Aur\u00e9lien_Bellet1", "~Hamed_Haddadi1", "~Nicolas_Papernot1", "~Xiao_Wang11", "~Adrian_Weller1"]}, "keywords": {"value": ["privacy auditing", "zero knowledge proof", "differentially private training"]}, "abstract": {"value": "Post hoc privacy auditing techniques can be used to test the privacy guarantees of a model, but come with several limitations: (i) they can only establish lower bounds on the privacy loss, (ii) the intermediate model updates and some data must be shared with the auditor to get a better approximation of the privacy loss, and (iii) the auditor typically faces a steep computational cost to run a large number of attacks. In this paper, we propose to proactively generate a cryptographic certificate of privacy during training to forego such auditing limitations. We introduce Confidential-DPproof , a framework for Confidential Proof of Differentially Private Training, which enhances training with a certificate of the $(\\varepsilon,\\delta)$-DP guarantee achieved. To obtain this certificate without revealing information about the training data or model, we design a customized zero-knowledge proof protocol tailored to the requirements introduced by differentially private training, including random noise addition and privacy amplification by subsampling. In experiments on CIFAR-10, Confidential-DPproof trains a model achieving state-of-the-art $91$% test accuracy with a certified privacy guarantee of $(\\varepsilon=0.55,\\delta=10^{-5})$-DP in approximately 100 hours."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/94732346a3d36701b0a68d02f2366498641c54ee.pdf"}, "supplementary_material": {"value": "/attachment/9a69aba9a1dd47e6f7161a26c76cb6be03518625.zip"}, "_bibtex": {"value": "@inproceedings{\nshamsabadi2024confidentialdpproof,\ntitle={Confidential-{DP}proof: Confidential Proof of Differentially Private Training},\nauthor={Ali Shahin Shamsabadi and Gefei Tan and Tudor Ioan Cebere and Aur{\\'e}lien Bellet and Hamed Haddadi and Nicolas Papernot and Xiao Wang and Adrian Weller},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PQY2v6VtGe}\n}"}, "paperhash": {"value": "shamsabadi|confidentialdpproof_confidential_proof_of_differentially_private_training"}}, "number": 8068, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8068/-/Revision", "ICLR.cc/2024/Conference/Submission8068/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8068/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495465576, "cdate": 1695495465576, "tmdate": 1710147887188, "mdate": 1710147887188, "pdate": 1705411030203, "version": 2}, {"id": "LXVswInHOo", "forum": "LXVswInHOo", "signatures": ["ICLR.cc/2024/Conference/Submission8024/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8024/Authors"], "content": {"title": {"value": "In-Context Pretraining: Language Modeling Beyond Document Boundaries"}, "authors": {"value": ["Weijia Shi", "Sewon Min", "Maria Lomeli", "Chunting Zhou", "Margaret Li", "Xi Victoria Lin", "Noah A. Smith", "Luke Zettlemoyer", "Wen-tau Yih", "Mike Lewis"]}, "authorids": {"value": ["~Weijia_Shi1", "~Sewon_Min1", "~Maria_Lomeli2", "~Chunting_Zhou1", "~Margaret_Li1", "~Xi_Victoria_Lin1", "~Noah_A._Smith2", "~Luke_Zettlemoyer1", "~Wen-tau_Yih1", "~Mike_Lewis1"]}, "keywords": {"value": ["Large Language Models"]}, "abstract": {"value": "Language models are currently trained to predict tokens given document prefixes, enabling them to zero shot long form generation and prompting-style tasks which can be reduced to document completion. We instead present IN-CONTEXT PRETRAINING, a new approach where language models are trained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. Our approach builds on the fact that current pipelines train by concatenating random sets of shorter documents to create longer context windows; this improves efficiency even though the prior documents provide no signal for predicting the next document. Given this fact, we can do IN-CONTEXT PRETRAINING by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent batches with a graph cover algorithm. Our experiments show IN-CONTEXT PRETRAINING offers a scalable and simple approach to significantly enhance LM performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%)."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a7de9c0b47acd0a990190c7e40945c1f335d4201.pdf"}, "_bibtex": {"value": "@inproceedings{\nshi2024incontext,\ntitle={In-Context Pretraining: Language Modeling Beyond Document Boundaries},\nauthor={Weijia Shi and Sewon Min and Maria Lomeli and Chunting Zhou and Margaret Li and Xi Victoria Lin and Noah A. Smith and Luke Zettlemoyer and Wen-tau Yih and Mike Lewis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LXVswInHOo}\n}"}, "paperhash": {"value": "shi|incontext_pretraining_language_modeling_beyond_document_boundaries"}}, "number": 8024, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8024/-/Revision", "ICLR.cc/2024/Conference/Submission8024/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8024/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695494114734, "cdate": 1695494114734, "tmdate": 1710475512838, "mdate": 1710475512838, "pdate": 1705411027745, "version": 2}, {"id": "RvfPnOkPV4", "forum": "RvfPnOkPV4", "signatures": ["ICLR.cc/2024/Conference/Submission8018/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8018/Authors"], "content": {"title": {"value": "What's In My Big Data?"}, "authors": {"value": ["Yanai Elazar", "Akshita Bhagia", "Ian Helgi Magnusson", "Abhilasha Ravichander", "Dustin Schwenk", "Alane Suhr", "Evan Pete Walsh", "Dirk Groeneveld", "Luca Soldaini", "Sameer Singh", "Hannaneh Hajishirzi", "Noah A. Smith", "Jesse Dodge"]}, "authorids": {"value": ["~Yanai_Elazar1", "~Akshita_Bhagia1", "~Ian_Helgi_Magnusson1", "~Abhilasha_Ravichander2", "~Dustin_Schwenk1", "~Alane_Suhr1", "~Evan_Pete_Walsh1", "~Dirk_Groeneveld1", "~Luca_Soldaini1", "~Sameer_Singh1", "~Hannaneh_Hajishirzi1", "~Noah_A._Smith2", "~Jesse_Dodge1"]}, "keywords": {"value": ["nlp", "dataset", "analaysis", "data-statistics", "data-quality", "PII"]}, "TLDR": {"value": "We propose \"What's In My Big Data\", a framework and a set of analyses to understand what's in large text-based corpora used to train language models."}, "abstract": {"value": "Large text corpora are the backbone of language models.\nHowever, we have a limited understanding of the content of these corpora, including general statistics, quality, social factors, and inclusion of evaluation data (contamination).\nIn this work, we propose What's In My Big Data? (WIMBD), a platform and a set of sixteen analyses that allow us to reveal and compare the contents of large text corpora. WIMBD builds on two basic capabilities---count and search---*at scale*, which allows us to analyze more than 35 terabytes on a standard compute node. \nWe apply WIMBD to ten different corpora used to train popular language models, including *C4*, *The Pile*, and *RedPajama*.\nOur analysis uncovers several surprising and previously undocumented findings about these corpora, including the high prevalence of duplicate, synthetic, and low-quality content, personally identifiable information, toxic language, and benchmark contamination. \nFor instance, we find that about 50% of the documents in *RedPajama* and *LAION-2B-en* are duplicates. In addition, several datasets used for benchmarking models trained on such corpora are contaminated with respect to important benchmarks, including the Winograd Schema Challenge and parts of GLUE and SuperGLUE.\nWe open-source WIMBD's code and artifacts to provide a standard set of evaluations for new text-based corpora and to encourage more analyses and transparency around them."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8e645356fd6998459b2c368f65c8a2b3a44206af.pdf"}, "_bibtex": {"value": "@inproceedings{\nelazar2024whats,\ntitle={What's In My Big Data?},\nauthor={Yanai Elazar and Akshita Bhagia and Ian Helgi Magnusson and Abhilasha Ravichander and Dustin Schwenk and Alane Suhr and Evan Pete Walsh and Dirk Groeneveld and Luca Soldaini and Sameer Singh and Hannaneh Hajishirzi and Noah A. Smith and Jesse Dodge},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RvfPnOkPV4}\n}"}, "paperhash": {"value": "elazar|whats_in_my_big_data"}}, "number": 8018, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8018/-/Revision", "ICLR.cc/2024/Conference/Submission8018/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8018/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493936531, "cdate": 1695493936531, "tmdate": 1709668805530, "mdate": 1709668805530, "pdate": 1705411027374, "version": 2}, {"id": "lR3rk7ysXz", "forum": "lR3rk7ysXz", "signatures": ["ICLR.cc/2024/Conference/Submission7999/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7999/Authors"], "content": {"title": {"value": "On Diffusion Modeling for Anomaly Detection"}, "authors": {"value": ["Victor Livernoche", "Vineet Jain", "Yashar Hezaveh", "Siamak Ravanbakhsh"]}, "authorids": {"value": ["~Victor_Livernoche1", "~Vineet_Jain1", "~Yashar_Hezaveh1", "~Siamak_Ravanbakhsh1"]}, "keywords": {"value": ["Diffusion based models", "Anomaly detection", "Probabilistic Inference"]}, "TLDR": {"value": "Identify anomalies in a dataset by estimating the diffusion time, anomalies have higher diffusion times"}, "abstract": {"value": "Known for their impressive performance in generative modeling, diffusion models are attractive candidates for density-based anomaly detection. This paper investigates different variations of diffusion modeling for unsupervised and semi-supervised anomaly detection. In particular, we find that Denoising Diffusion Probability Models (DDPM) are performant on anomaly detection benchmarks yet computationally expensive. By simplifying DDPM in application to anomaly detection, we are naturally led to an alternative approach called Diffusion Time Estimation (DTE). DTE estimates the distribution over diffusion time for a given input and uses the mode or mean of this distribution as the anomaly score. We derive an analytical form for this density and leverage a deep neural network to improve inference efficiency. Through empirical evaluations on the ADBench benchmark, we demonstrate that all diffusion-based anomaly detection methods perform competitively for both semi-supervised and unsupervised settings. Notably, DTE achieves orders of magnitude faster inference time than DDPM, while outperforming it on this benchmark. These results establish diffusion-based anomaly detection as a scalable alternative to traditional methods and recent deep-learning techniques for standard unsupervised and semi-supervised anomaly detection settings."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c6480e4c58a2924ca498ff399ce467bb1e61ed7b.pdf"}, "supplementary_material": {"value": "/attachment/d1a5a7c4099974be80d2a2dfd690e85cceae3cae.zip"}, "_bibtex": {"value": "@inproceedings{\nlivernoche2024on,\ntitle={On Diffusion Modeling for Anomaly Detection},\nauthor={Victor Livernoche and Vineet Jain and Yashar Hezaveh and Siamak Ravanbakhsh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lR3rk7ysXz}\n}"}, "paperhash": {"value": "livernoche|on_diffusion_modeling_for_anomaly_detection"}}, "number": 7999, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7999/-/Revision", "ICLR.cc/2024/Conference/Submission7999/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7999/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493283945, "cdate": 1695493283945, "tmdate": 1710453603103, "mdate": 1710453603103, "pdate": 1705411026297, "version": 2}, {"id": "tjn2YZSHUv", "forum": "tjn2YZSHUv", "signatures": ["ICLR.cc/2024/Conference/Submission7993/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7993/Authors"], "content": {"title": {"value": "Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community"}, "authors": {"value": ["Arman Isajanyan", "Artur Shatveryan", "David Kocharian", "Zhangyang Wang", "Humphrey Shi"]}, "authorids": {"value": ["~Arman_Isajanyan1", "~Artur_Shatveryan1", "~David_Kocharian1", "~Zhangyang_Wang1", "~Humphrey_Shi1"]}, "keywords": {"value": ["human feedback", "text to image", "generative AI", "image quality scoring"]}, "abstract": {"value": "Social reward as a form of community recognition provides a strong source of\nmotivation for users of online platforms to actively engage and contribute with\ncontent to accumulate peers approval. In the realm of text-conditioned image\nsynthesis, the recent surge in progress has ushered in a collaborative era where\nusers and AI systems coalesce to refine visual creations. This co-creative pro-\ncess in the landscape of online social networks empowers users to craft original\nvisual artworks seeking for community validation. Nevertheless, assessing these\nmodels in the context of collective community preference introduces distinct chal-\nlenges. Existing evaluation methods predominantly center on limited size user\nstudies guided by image quality and alignment with prompts. This work pio-\nneers a paradigm shift, unveiling Social Reward - an innovative reward modeling\nframework that leverages implicit feedback from social network users engaged\nin creative editing of generated images. We embark on an extensive journey of\ndataset curation and refinement, drawing from Picsart: an online visual creation\nand editing platform, yielding a first million-user-scale dataset of implicit human\npreferences for user-generated visual art named Picsart Image-Social. Our anal-\nysis exposes the shortcomings of current metrics in modeling community creative\npreference of text-to-image models\u2019 outputs, compelling us to introduce a novel\npredictive model explicitly tailored to address these limitations. Rigorous quan-\ntitative experiments and user study show that our Social Reward model aligns\nbetter with social popularity than existing metrics. Furthermore, we utilize So-\ncial Reward to fine-tune text-to-image models, yielding images that are more fa-\nvored by not only Social Reward, but also other established metrics. These find-\nings highlight the relevance and effectiveness of Social Reward in assessing com-\nmunity appreciation for AI-generated artworks, establishing a closer alignment\nwith users\u2019 creative goals: creating popular visual art. Codes can be accessed at\nhttps://github.com/Picsart-AI-Research/Social-Reward"}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2deafb9f8640664b5840f46d75dd6e361f54bd88.pdf"}, "supplementary_material": {"value": "/attachment/fc3603b66054e1449993977099bb1ede5fe9f7da.zip"}, "_bibtex": {"value": "@inproceedings{\nisajanyan2024social,\ntitle={Social Reward: Evaluating and Enhancing Generative {AI} through Million-User Feedback from an Online Creative Community},\nauthor={Arman Isajanyan and Artur Shatveryan and David Kocharian and Zhangyang Wang and Humphrey Shi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tjn2YZSHUv}\n}"}, "paperhash": {"value": "isajanyan|social_reward_evaluating_and_enhancing_generative_ai_through_millionuser_feedback_from_an_online_creative_community"}}, "number": 7993, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7993/-/Revision", "ICLR.cc/2024/Conference/Submission7993/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7993/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493109287, "cdate": 1695493109287, "tmdate": 1709661544773, "mdate": 1709661544773, "pdate": 1705411026073, "version": 2}, {"id": "AfnsTnYphT", "forum": "AfnsTnYphT", "signatures": ["ICLR.cc/2024/Conference/Submission7964/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7964/Authors"], "content": {"title": {"value": "Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs"}, "authors": {"value": ["Aakash Lahoti", "Stefani Karp", "Ezra Winston", "Aarti Singh", "Yuanzhi Li"]}, "authorids": {"value": ["~Aakash_Lahoti1", "~Stefani_Karp1", "~Ezra_Winston1", "~Aarti_Singh1", "~Yuanzhi_Li1"]}, "keywords": {"value": ["Deep Learning Theory", "Sample Complexity", "Convolutional Neural Networks"]}, "TLDR": {"value": "Sample complexity separation between fully connected, locally connected and convolutional neural networks on an image-like task"}, "abstract": {"value": "Vision tasks are characterized by the properties of locality and translation invariance. \n    The superior performance of convolutional neural networks (CNNs) on these tasks is widely attributed to the inductive bias of locality and weight sharing baked into their architecture.\n    Existing attempts to quantify the statistical benefits of these biases in CNNs over locally connected convolutional neural networks (LCNs) and fully connected neural networks (FCNs) fall into one of the following categories: either they disregard the optimizer and only provide uniform convergence upper bounds with no separating lower bounds, \n    or they consider simplistic tasks that do not truly mirror the locality and translation invariance as found in real-world vision tasks.\n    To address these deficiencies, we introduce the Dynamic Signal Distribution (DSD) classification task that models an image as consisting of $k$ patches, each of dimension $d$, and the label is determined by a $d$-sparse signal vector that can freely appear in any one of the $k$ patches. \n    On this task, for any orthogonally equivariant algorithm like gradient descent, we prove that CNNs require $\\tilde{O}(k+d)$ samples, whereas LCNs require $\\Omega(kd)$ samples, establishing the statistical advantages of weight sharing in translation invariant tasks. \n    Furthermore, LCNs need $\\tilde{O}(k(k+d))$ samples, compared to $\\Omega(k^2d)$ samples for FCNs, showcasing the benefits of locality in local tasks.\n    Additionally, we develop information theoretic tools for analyzing randomized algorithms, which may be of interest for statistical research."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8956f1209e23a0bd6029fbbe9b6d595916060b56.pdf"}, "_bibtex": {"value": "@inproceedings{\nlahoti2024role,\ntitle={Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between {CNN}s, {LCN}s, and {FCN}s},\nauthor={Aakash Lahoti and Stefani Karp and Ezra Winston and Aarti Singh and Yuanzhi Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AfnsTnYphT}\n}"}, "paperhash": {"value": "lahoti|role_of_locality_and_weight_sharing_in_imagebased_tasks_a_sample_complexity_separation_between_cnns_lcns_and_fcns"}}, "number": 7964, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7964/-/Revision", "ICLR.cc/2024/Conference/Submission7964/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7964/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492120030, "cdate": 1695492120030, "tmdate": 1710558168859, "mdate": 1710558168859, "pdate": 1705411024920, "version": 2}, {"id": "e4xS9ZarDr", "forum": "e4xS9ZarDr", "signatures": ["ICLR.cc/2024/Conference/Submission7914/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7914/Authors"], "content": {"title": {"value": "Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts"}, "authors": {"value": ["Lizhang Chen", "Bo Liu", "Kaizhao Liang", "qiang liu"]}, "authorids": {"value": ["~Lizhang_Chen1", "~Bo_Liu13", "~Kaizhao_Liang1", "~qiang_liu4"]}, "keywords": {"value": ["Lion", "Optimization", "Lyapunov Analysis"]}, "TLDR": {"value": "This work shows that the lion optimizer is performing a constrained optimization, and the key design choices of lion is equivalent to performing a hamiltonian mirror descent."}, "abstract": {"value": "Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It achieves results comparable to AdamW but with greater memory efficiency. As what we can expect from the result of the random search, Lion blends a number of elements from existing algorithms, including signed momentum, decoupled weight decay,  Polayk and Nesterov momentum, but doesn't fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This absence of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy. This work aims to demystify Lion. Using both continuous-time and discrete-time analysis, we demonstrate that Lion is a novel and theoretically grounded approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint $||x||_\\infty \\leq 1/\\lambda$. Lion achieves this through the incorporation of decoupled weight decay, where $\\lambda$ represents the weight decay coefficient. Our analysis is facilitated by the development of a new Lyapunov function for the Lion updates. It applies to a wide range of Lion-$\\phi$ algorithms, where the  $sign(\\cdot)$ operator in Lion is replaced by the subgradient of a convex function $\\phi$, leading to the solution of the general composite optimization problem $\\min_x f(x) + \\phi^*(x)$. Our findings provide valuable insights into the dynamics of Lion and pave the way for further enhancements and extensions of Lion-related algorithms."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/047d98267da6d3c0f4e849a336a3c5bbb1b54cb3.pdf"}, "supplementary_material": {"value": "/attachment/f312447ae5de7c3fe14343dff00c27e7f97c7ca6.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024lion,\ntitle={Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts},\nauthor={Lizhang Chen and Bo Liu and Kaizhao Liang and qiang liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=e4xS9ZarDr}\n}"}, "paperhash": {"value": "chen|lion_secretly_solves_a_constrained_optimization_as_lyapunov_predicts"}}, "number": 7914, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7914/-/Revision", "ICLR.cc/2024/Conference/Submission7914/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7914/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490352975, "cdate": 1695490352975, "tmdate": 1712180647802, "mdate": 1712180647802, "pdate": 1705411023291, "version": 2}, {"id": "TTrzgEZt9s", "forum": "TTrzgEZt9s", "signatures": ["ICLR.cc/2024/Conference/Submission7912/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7912/Authors"], "content": {"title": {"value": "Distributionally Robust Optimization with Bias and Variance Reduction"}, "authors": {"value": ["Ronak Mehta", "Vincent Roulet", "Krishna Pillutla", "Zaid Harchaoui"]}, "authorids": {"value": ["~Ronak_Mehta2", "~Vincent_Roulet1", "~Krishna_Pillutla1", "~Zaid_Harchaoui1"]}, "keywords": {"value": ["stochastic optimization", "convex optimization", "distributionally robust learning", "spectral risk measures", "incremental optimization"]}, "TLDR": {"value": "We propose a linearly convergent stochastic (a.k.a. incremental) algorithm that optimizes spectral risk measures, which are distributionally robust objectives that include the superquantile."}, "abstract": {"value": "We consider the distributionally robust optimization (DRO) problem, wherein a learner optimizes the worst-case empirical risk achievable by reweighing the observed training examples. We present Prospect, a stochastic gradient-based algorithm that only requires tuning a single learning rate hyperparameter, and prove that it enjoys linear convergence for smooth regularized losses. This contrasts with previous algorithms that either require tuning multiple hyperparameters or potentially fail to converge due to biased gradient estimates or inadequate regularization. Empirically, we show that Prospect can converge 2-3x faster than baselines such as SGD and stochastic saddle-point methods on distribution shift and fairness benchmarks spanning tabular, vision, and language domains."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6c3d461c90f544421c04e52861860e354c20c157.pdf"}, "_bibtex": {"value": "@inproceedings{\nmehta2024distributionally,\ntitle={Distributionally Robust Optimization with Bias \\& Variance Reduced Gradients},\nauthor={Ronak Mehta and Vincent Roulet and Krishna Pillutla and Zaid Harchaoui},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TTrzgEZt9s}\n}"}, "paperhash": {"value": "mehta|distributionally_robust_optimization_with_bias_and_variance_reduction"}}, "number": 7912, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7912/-/Revision", "ICLR.cc/2024/Conference/Submission7912/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7912/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490331626, "cdate": 1695490331626, "tmdate": 1713145696642, "mdate": 1713145696642, "pdate": 1705411023258, "version": 2}, {"id": "tbVWug9f2h", "forum": "tbVWug9f2h", "signatures": ["ICLR.cc/2024/Conference/Submission7870/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7870/Authors"], "content": {"title": {"value": "A Benchmark for Learning to Translate a New Language from One Grammar Book"}, "authors": {"value": ["Garrett Tanzer", "Mirac Suzgun", "Eline Visser", "Dan Jurafsky", "Luke Melas-Kyriazi"]}, "authorids": {"value": ["~Garrett_Tanzer1", "~Mirac_Suzgun1", "~Eline_Visser1", "~Dan_Jurafsky1", "~Luke_Melas-Kyriazi1"]}, "keywords": {"value": ["low-resource languages", "indigenous languages", "endangered languages", "long context", "field linguistics", "unseen tasks", "large language models", "machine translation", "benchmark"]}, "abstract": {"value": "Large language models (LLMs) can perform impressive feats with in-context learning or lightweight finetuning. It is natural to wonder how well these models adapt to genuinely new tasks, but how does one find tasks that are unseen in internet-scale training sets? We turn to a field that is explicitly motivated and bottlenecked by a scarcity of web data: low-resource languages. In this paper, we introduce MTOB (Machine Translation from One Book), a benchmark for learning to translate between English and Kalamang\u2014a language with less than 200 speakers and therefore virtually no presence on the web\u2014using several hundred pages of field linguistics reference materials. This task framing is novel in that it asks a model to learn a language from a single human-readable book of grammar explanations, rather than a large mined corpus of in-domain data, more akin to L2 language learning than L1 language acquisition. We demonstrate that baselines using current LLMs are promising but fall short of human performance, achieving 44.7 chrF on Kalamang to English translation and 45.8 chrF on English to Kalamang translation, compared to 51.6 and 57.0 chrF by a human who learned Kalamang from the same reference materials. We hope that MTOB will help measure LLM capabilities along a new dimension, and that the methods developed to solve it could help expand access to language technology for underserved communities by leveraging qualitatively different kinds of data than traditional machine translation."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/410fe170bf3313698302de77b1641b5a9ea9eaa3.pdf"}, "_bibtex": {"value": "@inproceedings{\ntanzer2024a,\ntitle={A Benchmark for Learning to Translate a New Language from One Grammar Book},\nauthor={Garrett Tanzer and Mirac Suzgun and Eline Visser and Dan Jurafsky and Luke Melas-Kyriazi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tbVWug9f2h}\n}"}, "paperhash": {"value": "tanzer|a_benchmark_for_learning_to_translate_a_new_language_from_one_grammar_book"}}, "number": 7870, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7870/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7870/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695488647415, "cdate": 1695488647415, "tmdate": 1710501852937, "mdate": 1710501852937, "pdate": 1705411022170, "version": 2}, {"id": "MCl0TLboP1", "forum": "MCl0TLboP1", "signatures": ["ICLR.cc/2024/Conference/Submission7779/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7779/Authors"], "content": {"title": {"value": "Improving Offline RL by Blending Heuristics"}, "authors": {"value": ["Sinong Geng", "Aldo Pacchiano", "Andrey Kolobov", "Ching-An Cheng"]}, "authorids": {"value": ["~Sinong_Geng1", "~Aldo_Pacchiano1", "~Andrey_Kolobov1", "~Ching-An_Cheng1"]}, "keywords": {"value": ["offline RL", "heuristic", "RL", "MDP", "sequential decision-making"]}, "abstract": {"value": "We propose **H**e**u**ristic **Bl**ending (HUBL), a simple performance-improving technique for a broad class of offline RL algorithms based on value bootstrapping. HUBL modifies the Bellman operators used in these algorithms, partially replacing the bootstrapped values with heuristic ones that are estimated with Monte-Carlo returns. For trajectories with higher returns, HUBL relies more on the heuristic values and less on bootstrapping; otherwise, it leans more heavily on bootstrapping. HUBL is very easy to combine with many existing offline RL implementations by relabeling the offline datasets with adjusted rewards and discount factors. We derive a theory that explains HUBL's effect on offline RL as reducing offline RL's complexity and thus increasing its finite-sample performance.  Furthermore, we empirically demonstrate that HUBL consistently improves the policy quality of four state-of-the-art bootstrapping-based offline RL algorithms (ATAC, CQL, TD3+BC, and IQL), by 9% on average over 27 datasets of the D4RL and Meta-World benchmarks."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/16cac64e07aa3a54bc305bc6025b1b1e3326c1f7.pdf"}, "supplementary_material": {"value": "/attachment/1b7439e34830a952f22a2f547e16b7305f0ff7e4.zip"}, "TLDR": {"value": "A method for improving many existing offline RL algorithms' performance by blending Monte-Carlo-based heuristic state value estimates into these algorithms' Bellman operators."}, "_bibtex": {"value": "@inproceedings{\ngeng2024improving,\ntitle={Improving Offline {RL} by Blending Heuristics},\nauthor={Sinong Geng and Aldo Pacchiano and Andrey Kolobov and Ching-An Cheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MCl0TLboP1}\n}"}, "paperhash": {"value": "geng|improving_offline_rl_by_blending_heuristics"}}, "number": 7779, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7779/-/Revision", "ICLR.cc/2024/Conference/Submission7779/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7779/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695485651019, "cdate": 1695485651019, "tmdate": 1710552204954, "mdate": 1710552204954, "pdate": 1705411020068, "version": 2}, {"id": "af2c8EaKl8", "forum": "af2c8EaKl8", "signatures": ["ICLR.cc/2024/Conference/Submission7737/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7737/Authors"], "content": {"title": {"value": "Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making"}, "authors": {"value": ["Jeonghye Kim", "Suyoung Lee", "Woojun Kim", "Youngchul Sung"]}, "authorids": {"value": ["~Jeonghye_Kim1", "~Suyoung_Lee4", "~Woojun_Kim1", "~Youngchul_Sung1"]}, "keywords": {"value": ["MetaFormer", "Convolution", "Reinforcement Learning", "Representation Learning"]}, "abstract": {"value": "The recent success of Transformer in natural language processing has sparked its use in various domains. In offline reinforcement learning (RL), Decision Transformer (DT) is emerging as a promising model based on Transformer. However, we discovered that the attention module of DT is not appropriate to capture the inherent local dependence pattern in trajectories of RL modeled as a Markov decision process. To overcome the limitations of DT, we propose a novel action sequence predictor, named Decision ConvFormer (DC), based on the architecture of MetaFormer, which is a general structure to process multiple entities in parallel and understand the interrelationship among the multiple entities. DC employs local convolution filtering as the token mixer and can effectively capture the inherent local associations of the RL dataset. In extensive experiments, DC achieved state-of-the-art performance across various standard RL benchmarks while requiring fewer resources. Furthermore, we show that DC better understands the underlying meaning in data and exhibits enhanced generalization capability."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d34443d3c25936596abdb44faed04a15cdf3e290.pdf"}, "supplementary_material": {"value": "/attachment/5325aaf4b979b27fa67304cceb5c8f8905e5cb82.zip"}, "TLDR": {"value": "We propose Decision ConvFormer, a new decision-maker based on MetaFormer with three convolution filters for offline RL, which excels in decision-making by understanding local associations and has an enhanced generalization capability."}, "_bibtex": {"value": "@inproceedings{\nkim2024decision,\ntitle={Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making},\nauthor={Jeonghye Kim and Suyoung Lee and Woojun Kim and Youngchul Sung},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=af2c8EaKl8}\n}"}, "paperhash": {"value": "kim|decision_convformer_local_filtering_in_metaformer_is_sufficient_for_decision_making"}}, "number": 7737, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7737/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7737/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695484341270, "cdate": 1695484341270, "tmdate": 1710517965420, "mdate": 1710517965420, "pdate": 1705411019026, "version": 2}, {"id": "vSh5ePa0ph", "forum": "vSh5ePa0ph", "signatures": ["ICLR.cc/2024/Conference/Submission7726/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7726/Authors"], "content": {"title": {"value": "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?"}, "authors": {"value": ["Jingfeng Wu", "Difan Zou", "Zixiang Chen", "Vladimir Braverman", "Quanquan Gu", "Peter Bartlett"]}, "authorids": {"value": ["~Jingfeng_Wu1", "~Difan_Zou1", "~Zixiang_Chen1", "~Vladimir_Braverman1", "~Quanquan_Gu1", "~Peter_Bartlett1"]}, "keywords": {"value": ["in-context learning", "linear regression", "ridge regression", "Bayes optimality"]}, "abstract": {"value": "Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2afad356cf9372d0067c51eea7b8c4169effbe2c.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024how,\ntitle={How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?},\nauthor={Jingfeng Wu and Difan Zou and Zixiang Chen and Vladimir Braverman and Quanquan Gu and Peter Bartlett},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vSh5ePa0ph}\n}"}, "paperhash": {"value": "wu|how_many_pretraining_tasks_are_needed_for_incontext_learning_of_linear_regression"}}, "number": 7726, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7726/-/Revision", "ICLR.cc/2024/Conference/Submission7726/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7726/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483910120, "cdate": 1695483910120, "tmdate": 1710467009155, "mdate": 1710467009155, "pdate": 1705411018694, "version": 2}, {"id": "d94x0gWTUX", "forum": "d94x0gWTUX", "signatures": ["ICLR.cc/2024/Conference/Submission7704/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7704/Authors"], "content": {"title": {"value": "Tool-Augmented Reward Modeling"}, "authors": {"value": ["Lei Li", "Yekun Chai", "Shuohuan Wang", "Yu Sun", "Hao Tian", "Ningyu Zhang", "Hua Wu"]}, "authorids": {"value": ["~Lei_Li18", "~Yekun_Chai1", "~Shuohuan_Wang1", "~Yu_Sun13", "~Hao_Tian1", "~Ningyu_Zhang1", "~Hua_Wu4"]}, "keywords": {"value": ["Reward Model", "Large Language Model", "Tool Learning", "Augmented Language Model"]}, "TLDR": {"value": "This paper introduces tool-augmented reward models for reinforcement learning from human feedback (RLHF), improving precision and interpretability and contributing a comprehensive dataset from seven diverse tool APIs to advance the field."}, "abstract": {"value": "Reward modeling (*a.k.a.*, preference modeling) is instrumental for aligning large language models with human preferences, particularly within the context of reinforcement learning from human feedback (RLHF). While conventional reward models (RMs) have exhibited remarkable scalability, they oft struggle with fundamental functionality such as arithmetic computation, code execution, and factual lookup. In this paper, we propose a tool-augmented preference modeling approach, named Themis, to address these limitations by empowering RMs with access to external environments, including calculators and search engines. This approach not only fosters synergy between tool utilization and reward grading but also enhances interpretive capacity and scoring reliability. Our study delves into the integration of external tools into RMs, enabling them to interact with diverse external sources and construct task-specific tool engagement and reasoning traces in an autoregressive manner. We validate our approach across a wide range of domains, incorporating seven distinct external tools. Our experimental results demonstrate a noteworthy overall improvement of 17.7% across eight tasks in preference ranking. Furthermore, our approach outperforms Gopher 280B by 7.3% on TruthfulQA task in zero-shot evaluation. In human evaluations, RLHF trained with Themis attains an average win rate of 32% when compared to baselines across four distinct tasks. Additionally, we provide a comprehensive collection of tool-related RM datasets, incorporating data from seven distinct tool APIs, totaling 15,000 instances. We have made the code, data, and model checkpoints publicly available to facilitate and inspire further research advancements (https://github.com/ernie-research/Tool-Augmented-Reward-Model)."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/65b055ecf7ec43b68562fc8ca3ce916f8c400085.pdf"}, "supplementary_material": {"value": "/attachment/225148b4886e0f42aaa7c2c8fe8dfe870dab4c52.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024toolaugmented,\ntitle={Tool-Augmented Reward Modeling},\nauthor={Lei Li and Yekun Chai and Shuohuan Wang and Yu Sun and Hao Tian and Ningyu Zhang and Hua Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d94x0gWTUX}\n}"}, "paperhash": {"value": "li|toolaugmented_reward_modeling"}}, "number": 7704, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7704/-/Revision", "ICLR.cc/2024/Conference/Submission7704/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7704/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483315652, "cdate": 1695483315652, "tmdate": 1709661542216, "mdate": 1709661542216, "pdate": 1705411017827, "version": 2}, {"id": "GSBHKiw19c", "forum": "GSBHKiw19c", "signatures": ["ICLR.cc/2024/Conference/Submission7694/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7694/Authors"], "content": {"title": {"value": "Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning"}, "authors": {"value": ["Fan-Ming Luo", "Tian Xu", "Xingchen Cao", "Yang Yu"]}, "authorids": {"value": ["~Fan-Ming_Luo1", "~Tian_Xu2", "~Xingchen_Cao1", "~Yang_Yu5"]}, "keywords": {"value": ["model-based offline reinforcement learning", "dynamics reward", "reward-consistent dynamics model learning"]}, "abstract": {"value": "Learning a precise dynamics model can be crucial for offline reinforcement learning, which, unfortunately, has been found to be quite challenging. Dynamics models that are learned by fitting historical transitions often struggle to generalize to unseen transitions. In this study, we identify a hidden but pivotal factor termed dynamics reward that remains consistent across transitions, offering a pathway to better generalization. Therefore, we propose the idea of reward-consistent dynamics models: any trajectory generated by the dynamics model should maximize the dynamics reward derived from the data. We implement this idea as the MOREC (Model-based Offline reinforcement learning with Reward Consistency) method, which can be seamlessly integrated into previous offline model-based reinforcement learning (MBRL) methods. MOREC learns a generalizable dynamics reward function from offline data, which is subsequently employed as a transition filter in any offline MBRL method: when generating transitions, the dynamics model generates a batch of transitions and selects the one with the highest dynamics reward value. On a synthetic task, we visualize that MOREC has a strong generalization ability and can surprisingly recover some distant unseen transitions. On 21 offline tasks in D4RL and NeoRL benchmarks, MOREC improves the previous state-of-the-art performance by a significant margin, i.e., 4.6\\% on D4RL tasks and 25.9\\% on NeoRL tasks. Notably, MOREC is the first method that can achieve above 95\\% online RL performance in 6 out of 12 D4RL tasks and 3 out of 9 NeoRL tasks. Code is available at https://github.com/polixir/morec."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b755072e1d772c902d9b57e9ad4a0ff78b0df063.pdf"}, "TLDR": {"value": "We introduce MOREC, which enhances model-based offline RL by leveraging a discovered \"dynamics reward\" to improve the fidelity of the generated trajectories, improving the previous state-of-the-art performance by a significant margin."}, "_bibtex": {"value": "@inproceedings{\nluo2024rewardconsistent,\ntitle={Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning},\nauthor={Fan-Ming Luo and Tian Xu and Xingchen Cao and Yang Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GSBHKiw19c}\n}"}, "paperhash": {"value": "luo|rewardconsistent_dynamics_models_are_strongly_generalizable_for_offline_reinforcement_learning"}}, "number": 7694, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7694/-/Revision", "ICLR.cc/2024/Conference/Submission7694/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7694/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483069336, "cdate": 1695483069336, "tmdate": 1710573337035, "mdate": 1710573337035, "pdate": 1705411017380, "version": 2}, {"id": "6yv8UHVJn4", "forum": "6yv8UHVJn4", "signatures": ["ICLR.cc/2024/Conference/Submission7647/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7647/Authors"], "content": {"title": {"value": "Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback"}, "authors": {"value": ["Haolin Liu", "Chen-Yu Wei", "Julian Zimmert"]}, "authorids": {"value": ["~Haolin_Liu8", "~Chen-Yu_Wei1", "~Julian_Zimmert1"]}, "keywords": {"value": ["adversarial MDPs", "policy optimization", "bandit feedback"]}, "TLDR": {"value": "We study online reinformencent learning in adversarial linear MDPs, proposing the first rate-optimal inefficent algorithm and an efficient algorithm that significantly improves prior results."}, "abstract": {"value": "We study online reinforcement learning in linear Markov decision processes with adversarial losses and bandit feedback. We introduce two algorithms that achieve improved regret performance compared to existing approaches. The first algorithm, although computationally inefficient, achieves a regret of $\\widetilde{O}(\\sqrt{K})$ without relying on simulators, where $K$ is the number of episodes. This is the first rate-optimal result in the considered setting. The second algorithm is computationally efficient and achieves a regret of  $\\widetilde{O}(K^{\\frac{3}{4}})$ . These results significantly improve over the prior state-of-the-art: a computationally inefficient algorithm by Kong et al. (2023) with $\\widetilde{O}(K^{\\frac{4}{5}}+1/\\lambda_{\\min})$ regret, and a computationally efficient algorithm by Sherman et al. (2023b) with $\\widetilde{O}(K^{\\frac{6}{7}})$ regret."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/364346cf68aee0e5e5761a8aad4c6a42391b9e05.pdf"}, "supplementary_material": {"value": "/attachment/97cfc74718dacde70485e3eecc6104b316b73157.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024towards,\ntitle={Towards Optimal Regret in Adversarial Linear {MDP}s with Bandit Feedback},\nauthor={Haolin Liu and Chen-Yu Wei and Julian Zimmert},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6yv8UHVJn4}\n}"}, "paperhash": {"value": "liu|towards_optimal_regret_in_adversarial_linear_mdps_with_bandit_feedback"}}, "number": 7647, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7647/-/Revision", "ICLR.cc/2024/Conference/Submission7647/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7647/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481699696, "cdate": 1695481699696, "tmdate": 1712967794155, "mdate": 1712967794155, "pdate": 1705411016092, "version": 2}, {"id": "xt9Bu66rqv", "forum": "xt9Bu66rqv", "signatures": ["ICLR.cc/2024/Conference/Submission7641/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7641/Authors"], "content": {"title": {"value": "Dual RL: Unification and New Methods for Reinforcement and Imitation Learning"}, "authors": {"value": ["Harshit Sikchi", "Qinqing Zheng", "Amy Zhang", "Scott Niekum"]}, "authorids": {"value": ["~Harshit_Sikchi1", "~Qinqing_Zheng1", "~Amy_Zhang1", "~Scott_Niekum1"]}, "keywords": {"value": ["Robot Learning", "Offline Imitation Learning", "Offline Reinforcement Learning", "Deep Reinforcement Learning"]}, "TLDR": {"value": "A unification of RL and IL methods through the lens of duality that allows us to propose new methods for discriminator-free imitation learning and stable offline reinforcement learning."}, "abstract": {"value": "The goal of reinforcement learning (RL) is to find a policy that maximizes the expected cumulative return. It has been shown that this objective can be represented as an optimization problem of state-action visitation distribution under linear constraints. The dual problem of this formulation, which we refer to as *dual RL*, is unconstrained and easier to optimize. In this work, we first cast several state-of-the-art offline RL and offline imitation learning (IL) algorithms as instances of dual RL approaches with shared structures. Such unification allows us to identify the root cause of the shortcomings of prior methods. For offline IL, our analysis shows that prior methods are based on a restrictive coverage assumption that greatly limits their performance in practice. To fix this limitation, we propose a new discriminator-free method ReCOIL that learns to imitate from arbitrary off-policy data to obtain near-expert performance. For offline RL, our analysis frames a recent offline RL method XQL in the dual framework, and we further propose a new method $f$-DVL that provides alternative choices to the Gumbel regression loss that fixes the known training instability issue of XQL. The performance improvements by both of our proposed methods, ReCOIL and $f$-DVL, in IL and RL are validated on an extensive suite of simulated robot locomotion and manipulation tasks."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/981af9a85be76008d6063c6ddd1477450c3bf463.pdf"}, "supplementary_material": {"value": "/attachment/a980e449192699b610c6e3ee69309be5fbbd5161.zip"}, "_bibtex": {"value": "@inproceedings{\nsikchi2024dual,\ntitle={Dual {RL}: Unification and New Methods for Reinforcement and Imitation Learning},\nauthor={Harshit Sikchi and Qinqing Zheng and Amy Zhang and Scott Niekum},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xt9Bu66rqv}\n}"}, "paperhash": {"value": "sikchi|dual_rl_unification_and_new_methods_for_reinforcement_and_imitation_learning"}}, "number": 7641, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7641/-/Revision", "ICLR.cc/2024/Conference/Submission7641/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7641/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481445327, "cdate": 1695481445327, "tmdate": 1709661541700, "mdate": 1709661541700, "pdate": 1705411015846, "version": 2}, {"id": "Bo6GpQ3B9a", "forum": "Bo6GpQ3B9a", "signatures": ["ICLR.cc/2024/Conference/Submission7586/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7586/Authors"], "content": {"title": {"value": "Out-Of-Domain Unlabeled Data Improves Generalization"}, "authors": {"value": ["seyed amir hossein saberi", "Amir Najafi", "Alireza Heidari", "Mohammad Hosein Movasaghinia", "Abolfazl Motahari", "Babak Khalaj"]}, "authorids": {"value": ["~seyed_amir_hossein_saberi1", "~Amir_Najafi1", "~Alireza_Heidari2", "~Mohammad_Hosein_Movasaghinia1", "~Abolfazl_Motahari1", "~Babak_Khalaj1"]}, "keywords": {"value": ["Out-of-domain data", "Semi-supervised learing", "learning theory", "generalization bound", "adversarial robustness"]}, "TLDR": {"value": "We propose a framework to incorporate unlabeled out-of-domain samples in order to enhance the generalization error. We derive explicit bounds for Gaussian mixture models, and test our method on real datasets."}, "abstract": {"value": "We propose a novel framework for incorporating unlabeled data into semi-supervised classification problems, where scenarios involving the minimization of either i) adversarially robust or ii) non-robust loss functions have been considered. Notably, we allow the unlabeled samples to deviate slightly (in total variation sense) from the in-domain distribution. The core idea behind our framework is to combine Distributionally Robust Optimization (DRO) with self-supervised training. As a result, we also leverage efficient polynomial-time algorithms for the training stage. From a theoretical standpoint, we apply our framework on the classification problem of a mixture of two Gaussians in $\\mathbb{R}^d$, where in addition to the $m$ independent and labeled samples from the true distribution, a set of $n$ (usually with $n\\gg m$) out of domain and unlabeled samples are gievn as well. Using only the labeled data, it is known that the generalization error can be bounded by $\\propto\\left(d/m\\right)^{1/2}$. However, using our method on both isotropic and non-isotropic Gaussian mixture models, one can derive a new set of analytically explicit and non-asymptotic bounds which show substantial improvement on the generalization error compared ERM. Our results underscore two significant insights: 1) out-of-domain samples, even when unlabeled, can be harnessed to narrow the generalization gap, provided that the true data distribution adheres to a form of the \"cluster assumption\", and 2) the semi-supervised learning paradigm can be regarded as a special case of our framework when there are no distributional shifts. We validate our claims through experiments conducted on a variety of synthetic and real-world datasets."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/db772b639656e2c5123c187ceacfb10805558c17.pdf"}, "supplementary_material": {"value": "/attachment/a2cea249ca3822ce041c96c11af8757a5f681aa1.zip"}, "_bibtex": {"value": "@inproceedings{\nsaberi2024outofdomain,\ntitle={Out-Of-Domain Unlabeled Data Improves Generalization},\nauthor={seyed amir hossein saberi and Amir Najafi and Alireza Heidari and Mohammad Hosein Movasaghinia and Abolfazl Motahari and Babak Khalaj},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Bo6GpQ3B9a}\n}"}, "paperhash": {"value": "saberi|outofdomain_unlabeled_data_improves_generalization"}}, "number": 7586, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7586/-/Revision", "ICLR.cc/2024/Conference/Submission7586/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7586/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480012089, "cdate": 1695480012089, "tmdate": 1710347149059, "mdate": 1710347149059, "pdate": 1705411014135, "version": 2}, {"id": "r42tSSCHPh", "forum": "r42tSSCHPh", "signatures": ["ICLR.cc/2024/Conference/Submission7533/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7533/Authors"], "content": {"title": {"value": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation"}, "authors": {"value": ["Yangsibo Huang", "Samyak Gupta", "Mengzhou Xia", "Kai Li", "Danqi Chen"]}, "authorids": {"value": ["~Yangsibo_Huang2", "~Samyak_Gupta1", "~Mengzhou_Xia1", "~Kai_Li8", "~Danqi_Chen1"]}, "keywords": {"value": ["Large Language Model", "Alignment", "Attack"]}, "TLDR": {"value": "We show that disrupting the alignment of current open-source LLMs does not require complex methods: by exploiting different generation strategies,  we increase the misalignment rate from 0% to more than 95% across 11 language models."}, "abstract": {"value": "The rapid progress in open-source large language models (LLMs) is significantly advancing AI development. Extensive efforts have been made before model release to align their behavior with human values, with the primary goal of ensuring their helpfulness and harmlessness. However, even carefully aligned models can be manipulated maliciously, leading to unintended behaviors, known as ``jailbreaks\". These jailbreaks are typically triggered by specific text inputs, often referred to as adversarial prompts. In this work, we propose the generation exploitation attack, an extremely simple approach that disrupts model alignment by only manipulating variations of decoding methods. By exploiting different generation strategies, including varying decoding hyper-parameters and sampling methods, we increase the attack success rate from $0\\%$ to more than $95\\%$ across 11 language models including LLaMA2, Vicuna, Falcon, and MPT families, outperforming state-of-the-art attacks with $30\\times$ lower computational cost. Finally, we propose an effective alignment method that explores diverse generation strategies, which can reasonably reduce the attack success rate under our attack. Altogether, our study underscores a major failure in current safety evaluation and alignment procedures for open-source LLMs, strongly advocating for more comprehensive red teaming and better alignment before releasing such models."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/721e3e663ee57023772f0b3b63424ccc43e71e44.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024catastrophic,\ntitle={Catastrophic Jailbreak of Open-source {LLM}s via Exploiting Generation},\nauthor={Yangsibo Huang and Samyak Gupta and Mengzhou Xia and Kai Li and Danqi Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=r42tSSCHPh}\n}"}, "paperhash": {"value": "huang|catastrophic_jailbreak_of_opensource_llms_via_exploiting_generation"}}, "number": 7533, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7533/-/Revision", "ICLR.cc/2024/Conference/Submission7533/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7533/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478063666, "cdate": 1695478063666, "tmdate": 1710551587824, "mdate": 1710551587824, "pdate": 1705411012102, "version": 2}, {"id": "y21ZO6M86t", "forum": "y21ZO6M86t", "signatures": ["ICLR.cc/2024/Conference/Submission7529/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7529/Authors"], "content": {"title": {"value": "PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters"}, "authors": {"value": ["Jingyu Chen", "Runlin Lei", "Zhewei Wei"]}, "authorids": {"value": ["~Jingyu_Chen4", "~Runlin_Lei1", "~Zhewei_Wei1"]}, "keywords": {"value": ["Graph Contrastive Learning", "Spectral Graph Neural Networks", "Polynomial Filter", "Heterophilic Graph Representation Learning"]}, "abstract": {"value": "Recently, Graph Contrastive Learning (GCL) has achieved significantly superior performance in self-supervised graph representation learning. \nHowever, the existing GCL technique has inherent smooth characteristics because of its low-pass GNN encoder and objective based on homophily assumption, which poses a challenge when applying it to heterophilic graphs.\nIn supervised learning tasks, spectral GNNs with polynomial approximation excel in both homophilic and heterophilic settings by adaptively fitting graph filters of arbitrary shapes. \nYet, their applications in unsupervised learning are rarely explored.\nBased on the above analysis, a natural question arises: Can we incorporate the excellent properties of spectral polynomial filters into graph contrastive learning?\nIn this paper, we address the question by studying the necessity of introducing high-pass information for heterophily from a spectral perspective.\nWe propose PolyGCL, a GCL pipeline that utilizes polynomial filters to achieve contrastive learning between the low-pass and high-pass views.\nSpecifically, PolyGCL utilizes polynomials with learnable filter functions to generate different spectral views and an objective that incorporates high-pass information through a linear combination. \nWe theoretically prove that PolyGCL outperforms previous GCL paradigms when applied to graphs with varying levels of homophily.\nWe conduct extensive experiments on both synthetic and real-world datasets, which demonstrate the promising performance of PolyGCL on homophilic and heterophilic graphs."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We introduce spectral polynomial filters into graph contrastive learning to model heterophilic graphs."}, "pdf": {"value": "/pdf/e0bdb5536d418b614a12c003721153c1e6fbaf4b.pdf"}, "supplementary_material": {"value": "/attachment/5876143cef4cd4ade92f0e9af3c112be7cd4dfe8.zip"}, "_bibtex": {"value": "@inproceedings{\nchen2024polygcl,\ntitle={Poly{GCL}: {GRAPH} {CONTRASTIVE} {LEARNING} via Learnable Spectral Polynomial Filters},\nauthor={Jingyu Chen and Runlin Lei and Zhewei Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=y21ZO6M86t}\n}"}, "paperhash": {"value": "chen|polygcl_graph_contrastive_learning_via_learnable_spectral_polynomial_filters"}}, "number": 7529, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7529/-/Revision", "ICLR.cc/2024/Conference/Submission7529/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7529/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695477915632, "cdate": 1695477915632, "tmdate": 1710487680116, "mdate": 1710487680116, "pdate": 1705411011930, "version": 2}, {"id": "hB2hXtxIPH", "forum": "hB2hXtxIPH", "signatures": ["ICLR.cc/2024/Conference/Submission7432/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7432/Authors"], "content": {"title": {"value": "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution"}, "authors": {"value": ["Shanqi Liu", "Dong Xing", "Pengjie Gu", "Xinrun Wang", "Bo An", "Yong Liu"]}, "authorids": {"value": ["~Shanqi_Liu1", "~Dong_Xing1", "~Pengjie_Gu1", "~Xinrun_Wang1", "~Bo_An2", "~Yong_Liu11"]}, "keywords": {"value": ["Multi-Agent Cooperation", "Credit Assignment", "Homogeneous and Heterogeneous Cooperative Tasks"]}, "abstract": {"value": "Cooperative multi-agent reinforcement learning (MARL) is extensively used for solving complex cooperative tasks, and value decomposition methods are a prevalent approach for this domain. However, these methods have not been successful in addressing both homogeneous and heterogeneous tasks simultaneously which is a crucial aspect for the practical application of cooperative agents. \nOn one hand, value decomposition methods demonstrate superior performance in homogeneous tasks. Nevertheless, they tend to produce agents with similar policies, which is unsuitable for heterogeneous tasks. On the other hand, solutions based on personalized observation or assigned roles are well-suited for heterogeneous tasks. However, they often lead to a trade-off situation where the agent's performance in homogeneous scenarios is negatively affected due to the aggregation of distinct policies. An alternative approach is to adopt sequential execution policies, which offer a flexible form for learning both types of tasks. However, learning sequential execution policies poses challenges in terms of credit assignment, and the limited information about subsequently executed agents can lead to sub-optimal solutions, which is known as the relative over-generalization problem. To tackle these issues, this paper proposes Greedy Sequential Execution (GSE) as a solution to learn the optimal policy that covers both scenarios. In the proposed GSE framework, we introduce an individual utility function into the framework of value decomposition to consider the complex interactions between agents. \nThis function is capable of representing both the homogeneous and heterogeneous optimal policies. Furthermore, we utilize greedy marginal contribution calculated by the utility function as the credit value of the sequential execution policy to address the credit assignment and relative over-generalization problem. We evaluated GSE in both homogeneous and heterogeneous scenarios. The results demonstrate that GSE achieves significant improvement in performance across multiple domains, especially in scenarios involving both homogeneous and heterogeneous tasks."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e91e10a20d5e17ec8a9a469f872e7d0ec680cb37.pdf"}, "supplementary_material": {"value": "/attachment/7e9be8b7a794a18e534aae22eb9529c2452ec7c9.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024greedy,\ntitle={Greedy Sequential Execution: Solving Homogeneous and Heterogeneous Cooperative Tasks with a Unified Framework},\nauthor={Shanqi Liu and Dong Xing and Pengjie Gu and Bo An and Yong Liu and Xinrun Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hB2hXtxIPH}\n}"}, "paperhash": {"value": "liu|solving_homogeneous_and_heterogeneous_cooperative_tasks_with_greedy_sequential_execution"}}, "number": 7432, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7432/-/Revision", "ICLR.cc/2024/Conference/Submission7432/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7432/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695473426000, "cdate": 1695473426000, "tmdate": 1709661539970, "mdate": 1709661539970, "pdate": 1705411009539, "version": 2}, {"id": "Xkf2EBj4w3", "forum": "Xkf2EBj4w3", "signatures": ["ICLR.cc/2024/Conference/Submission7416/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7416/Authors"], "content": {"title": {"value": "Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data"}, "authors": {"value": ["Chongyi Zheng", "Benjamin Eysenbach", "Homer Rich Walke", "Patrick Yin", "Kuan Fang", "Ruslan Salakhutdinov", "Sergey Levine"]}, "authorids": {"value": ["~Chongyi_Zheng1", "~Benjamin_Eysenbach1", "~Homer_Rich_Walke1", "~Patrick_Yin1", "~Kuan_Fang3", "~Ruslan_Salakhutdinov1", "~Sergey_Levine1"]}, "keywords": {"value": ["reinforcement learning", "self-supervised learning", "contrastive learning", "goal-conditioned RL", "offline RL", "robotics"]}, "abstract": {"value": "Robotic systems that rely primarily on self-supervised learning have the potential to decrease the amount of human annotation and engineering effort required to learn control strategies. In the same way that prior robotic systems have leveraged self-supervised techniques from computer vision (CV) and natural language processing (NLP), our work builds on prior work showing that the reinforcement learning (RL) itself can be cast as a self-supervised problem: learning to reach any goal without human-specified rewards or labels. Despite the seeming appeal, little (if any) prior work has demonstrated how self-supervised RL methods can be practically deployed on robotic systems. By first studying a challenging simulated version of this task, we discover design decisions about architectures and hyperparameters that increase the success rate by $2 \\times$. These findings lay the groundwork for our main result: we demonstrate that a self-supervised RL algorithm based on contrastive learning can solve real-world, image-based robotic manipulation tasks, with tasks being specified by a single goal image provided after training."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d61ac5544c95c3239516e7c46f315bce6b00ce8b.pdf"}, "supplementary_material": {"value": "/attachment/dee6fa973ab448942dd839bf64eff1ac100991dc.zip"}, "_bibtex": {"value": "@inproceedings{\nzheng2024stabilizing,\ntitle={Stabilizing Contrastive {RL}: Techniques for Robotic Goal Reaching from Offline Data},\nauthor={Chongyi Zheng and Benjamin Eysenbach and Homer Rich Walke and Patrick Yin and Kuan Fang and Ruslan Salakhutdinov and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Xkf2EBj4w3}\n}"}, "paperhash": {"value": "zheng|stabilizing_contrastive_rl_techniques_for_robotic_goal_reaching_from_offline_data"}}, "number": 7416, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7416/-/Revision", "ICLR.cc/2024/Conference/Submission7416/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7416/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695472665146, "cdate": 1695472665146, "tmdate": 1710103610706, "mdate": 1710103610706, "pdate": 1705411009025, "version": 2}, {"id": "OGtnhKQJms", "forum": "OGtnhKQJms", "signatures": ["ICLR.cc/2024/Conference/Submission7393/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7393/Authors"], "content": {"title": {"value": "Multi-View Causal Representation Learning with Partial Observability"}, "authors": {"value": ["Dingling Yao", "Danru Xu", "Sebastien Lachapelle", "Sara Magliacane", "Perouz Taslakian", "Georg Martius", "Julius von K\u00fcgelgen", "Francesco Locatello"]}, "authorids": {"value": ["~Dingling_Yao1", "~Danru_Xu1", "~Sebastien_Lachapelle1", "~Sara_Magliacane1", "~Perouz_Taslakian1", "~Georg_Martius1", "~Julius_von_K\u00fcgelgen2", "~Francesco_Locatello1"]}, "keywords": {"value": ["causal representation learning; identifiability"]}, "abstract": {"value": "We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related.\nWe prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. \nWe also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous work on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. \nOverall, we find that access to multiple partial views offers unique opportunities for identifiable representation learning, enabling the discovery of latent structures from purely observational data."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c4477da8d3ff31861069faeb5e0c7ebdb054e07f.pdf"}, "supplementary_material": {"value": "/attachment/588f040d55bc584efe7c1d4783ce0a25b7e3fac0.zip"}, "_bibtex": {"value": "@inproceedings{\nyao2024multiview,\ntitle={Multi-View Causal Representation Learning with Partial Observability},\nauthor={Dingling Yao and Danru Xu and Sebastien Lachapelle and Sara Magliacane and Perouz Taslakian and Georg Martius and Julius von K{\\\"u}gelgen and Francesco Locatello},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OGtnhKQJms}\n}"}, "paperhash": {"value": "yao|multiview_causal_representation_learning_with_partial_observability"}}, "number": 7393, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7393/-/Revision", "ICLR.cc/2024/Conference/Submission7393/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7393/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695471165007, "cdate": 1695471165007, "tmdate": 1709912685350, "mdate": 1709912685350, "pdate": 1705411008386, "version": 2}, {"id": "SQrHpTllXa", "forum": "SQrHpTllXa", "signatures": ["ICLR.cc/2024/Conference/Submission7376/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7376/Authors"], "content": {"title": {"value": "CABINET: Content Relevance-based Noise Reduction for Table Question Answering"}, "authors": {"value": ["Sohan Patnaik", "Heril Changwal", "Milan Aggarwal", "Sumit Bhatia", "Yaman Kumar", "Balaji Krishnamurthy"]}, "authorids": {"value": ["~Sohan_Patnaik1", "~Heril_Changwal1", "~Milan_Aggarwal2", "~Sumit_Bhatia1", "~Yaman_Kumar1", "~Balaji_Krishnamurthy1"]}, "keywords": {"value": ["Table Question Answering", "Large Language Models", "Noise Reduction", "Unsupervised Relevance Scoring", "Table Parsing", "Relevant Cell Highlighting"]}, "abstract": {"value": "Table understanding capability of Large Language Models (LLMs) has been extensively studied through the task of question-answering (QA) over tables. Typically, only a small part of the whole table is relevant to derive the answer for a given question. The irrelevant parts act as noise and are distracting information, resulting in sub-optimal performance due to the vulnerability of LLMs to noise. To mitigate this, we propose CABINET (Content RelevAnce-Based NoIse ReductioN for TablE QuesTion-Answering) \u2013 a framework to enable LLMs to focus on relevant tabular data by suppressing extraneous information. CABINET comprises an Unsupervised Relevance Scorer (URS), trained differentially with the QA LLM, that weighs the table content based on its relevance to the input question before feeding it to the question answering LLM (QA LLM). To further aid the relevance scorer, CABINET employs a weakly supervised module that generates a parsing statement describing the criteria of rows and columns relevant to the question and highlights the content of corresponding table cells. CABINET significantly outperforms various tabular LLM baselines, as well as GPT3-based in-context learning methods, is more robust to noise, maintains outperformance on tables of varying sizes, and establishes new SoTA performance on WikiTQ, FeTaQA, and WikiSQL datasets. We release our code and datasets here."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0a15c1a222a5d423ce19524261f01484f4e7b695.pdf"}, "TLDR": {"value": "A content relevance based noise reduction framework for table QA that weighs the table content based on its relevance to question without removing table content explicitly."}, "_bibtex": {"value": "@inproceedings{\npatnaik2024cabinet,\ntitle={{CABINET}: Content Relevance-based Noise Reduction for Table Question Answering},\nauthor={Sohan Patnaik and Heril Changwal and Milan Aggarwal and Sumit Bhatia and Yaman Kumar and Balaji Krishnamurthy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SQrHpTllXa}\n}"}, "paperhash": {"value": "patnaik|cabinet_content_relevancebased_noise_reduction_for_table_question_answering"}}, "number": 7376, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7376/-/Revision", "ICLR.cc/2024/Conference/Submission7376/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7376/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470637604, "cdate": 1695470637604, "tmdate": 1709840163776, "mdate": 1709840163776, "pdate": 1705411007651, "version": 2}, {"id": "TyFrPOKYXw", "forum": "TyFrPOKYXw", "signatures": ["ICLR.cc/2024/Conference/Submission7372/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7372/Authors"], "content": {"title": {"value": "Safe RLHF: Safe Reinforcement Learning from Human Feedback"}, "authors": {"value": ["Josef Dai", "Xuehai Pan", "Ruiyang Sun", "Jiaming Ji", "Xinbo Xu", "Mickel Liu", "Yizhou Wang", "Yaodong Yang"]}, "authorids": {"value": ["~Josef_Dai1", "~Xuehai_Pan1", "~Ruiyang_Sun2", "~Jiaming_Ji2", "~Xinbo_Xu1", "~Mickel_Liu1", "~Yizhou_Wang1", "~Yaodong_Yang1"]}, "keywords": {"value": ["Safe Reinforcement Learning", "Reinforcement Learning from Human Feedback", "Large Language Model", "AI Safety"]}, "TLDR": {"value": "Safe Reinforcement Learning from Human Feedback"}, "abstract": {"value": "With the development of large language models (LLMs), striking a balance between the performance and safety of AI systems has never been more critical. However, the inherent tension between the objectives of helpfulness and harmlessness presents a significant challenge during LLM training. To address this issue, we propose Safe Reinforcement Learning from Human Feedback (Safe RLHF), a novel algorithm for human value alignment. Safe RLHF explicitly decouples human preferences regarding helpfulness and harmlessness, effectively avoiding the crowd workers' confusion about the tension and allowing us to train separate reward and cost models. We formalize the safety concern of LLMs as an optimization task of maximizing the reward function while satisfying specified cost constraints. Leveraging the Lagrangian method to solve this constrained problem, Safe RLHF dynamically adjusts the balance between the two objectives during fine-tuning. Through a three-round fine-tuning using Safe RLHF, we demonstrate a superior ability to mitigate harmful responses while enhancing model performance compared to existing value-aligned algorithms. Experimentally, we fine-tuned the Alpaca-7B using Safe RLHF and aligned it with collected human preferences, significantly improving its helpfulness and harmlessness according to human evaluations.\n\nCode is available at https://github.com/PKU-Alignment/safe-rlhf.\n\n\nWarning: This paper contains example data that may be offensive or harmful."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/167f78f80026293931185287f276ab819080611c.pdf"}, "supplementary_material": {"value": "/attachment/b217a456a924d098f0a67e06e943ad2a9a18a040.zip"}, "_bibtex": {"value": "@inproceedings{\ndai2024safe,\ntitle={Safe {RLHF}: Safe Reinforcement Learning from Human Feedback},\nauthor={Josef Dai and Xuehai Pan and Ruiyang Sun and Jiaming Ji and Xinbo Xu and Mickel Liu and Yizhou Wang and Yaodong Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TyFrPOKYXw}\n}"}, "paperhash": {"value": "dai|safe_rlhf_safe_reinforcement_learning_from_human_feedback"}}, "number": 7372, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7372/-/Revision", "ICLR.cc/2024/Conference/Submission7372/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7372/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470439334, "cdate": 1695470439334, "tmdate": 1713084034220, "mdate": 1713084034220, "pdate": 1705411007480, "version": 2}, {"id": "wprSv7ichW", "forum": "wprSv7ichW", "signatures": ["ICLR.cc/2024/Conference/Submission7354/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7354/Authors"], "content": {"title": {"value": "Benchmarking Algorithms for Federated Domain Generalization"}, "authors": {"value": ["Ruqi Bai", "Saurabh Bagchi", "David I. Inouye"]}, "authorids": {"value": ["~Ruqi_Bai1", "~Saurabh_Bagchi1", "~David_I._Inouye1"]}, "keywords": {"value": ["federated learning", "distributed learning", "domain generalization", "out-of-distribution generalization", "benchmarking", "data paritioning."]}, "abstract": {"value": "While prior federated learning (FL) methods mainly consider client heterogeneity, we focus on the *Federated Domain Generalization (DG)* task, which introduces train-test heterogeneity in the FL context. Existing evaluations in this field are limited in terms of the scale of the clients and dataset diversity. Thus, we propose a Federated DG benchmark that aim to test the limits of current methods with high client heterogeneity, large numbers of clients, and diverse datasets. Towards this objective, we introduce a novel data partition method that allows us to distribute any domain dataset among few or many clients while controlling client heterogeneity. We then introduce and apply our methodology to evaluate 14 DG methods, which include centralized DG methods adapted to the FL context, FL methods that handle client heterogeneity, and methods designed specifically for Federated DG on 7 datasets. Our results suggest that, despite some progress, significant performance gaps remain in Federated DG, especially when evaluating with a large number of clients, high client heterogeneity, or more realistic datasets. Furthermore, our extendable benchmark code will be publicly released to aid in benchmarking future Federated DG approaches."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/216358074a4ed3ebfdc3beb60b624a2b6647445d.pdf"}, "_bibtex": {"value": "@inproceedings{\nbai2024benchmarking,\ntitle={Benchmarking Algorithms for Federated Domain Generalization},\nauthor={Ruqi Bai and Saurabh Bagchi and David I. Inouye},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wprSv7ichW}\n}"}, "paperhash": {"value": "bai|benchmarking_algorithms_for_federated_domain_generalization"}}, "number": 7354, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7354/-/Revision", "ICLR.cc/2024/Conference/Submission7354/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7354/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695469588759, "cdate": 1695469588759, "tmdate": 1712785746847, "mdate": 1712785746847, "pdate": 1705411007033, "version": 2}, {"id": "PczQtTsTIX", "forum": "PczQtTsTIX", "signatures": ["ICLR.cc/2024/Conference/Submission7329/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7329/Authors"], "content": {"title": {"value": "CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity"}, "authors": {"value": ["Aditya Bhatt", "Daniel Palenicek", "Boris Belousov", "Max Argus", "Artemij Amiranashvili", "Thomas Brox", "Jan Peters"]}, "authorids": {"value": ["~Aditya_Bhatt1", "~Daniel_Palenicek1", "~Boris_Belousov1", "~Max_Argus2", "~Artemij_Amiranashvili1", "~Thomas_Brox1", "~Jan_Peters3"]}, "keywords": {"value": ["Deep Reinforcement Learning"]}, "abstract": {"value": "Sample efficiency is a crucial problem in deep reinforcement learning. Recent algorithms, such as REDQ and DroQ, found a way to improve the sample efficiency by increasing the update-to-data (UTD) ratio to 20 gradient update steps on the critic per environment sample.\nHowever, this comes at the expense of a greatly increased computational cost. To reduce this computational burden, we introduce CrossQ:\nA lightweight algorithm for continuous control tasks that makes careful use of Batch Normalization and removes target networks to surpass the current state-of-the-art in sample efficiency while maintaining a low UTD ratio of 1. Notably, CrossQ does not rely on advanced bias-reduction schemes used in current methods. CrossQ's contributions are threefold: (1) it matches or surpasses current state-of-the-art methods in terms of sample efficiency, (2) it substantially reduces the computational cost compared to REDQ and DroQ, (3) it is easy to implement, requiring just a few lines of code on top of SAC."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/750ae12418a1dc0f2dd3d9ff5ef5013234515fe6.pdf"}, "_bibtex": {"value": "@inproceedings{\nbhatt2024crossq,\ntitle={Cross\\$Q\\$: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity},\nauthor={Aditya Bhatt and Daniel Palenicek and Boris Belousov and Max Argus and Artemij Amiranashvili and Thomas Brox and Jan Peters},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PczQtTsTIX}\n}"}, "paperhash": {"value": "bhatt|crossq_batch_normalization_in_deep_reinforcement_learning_for_greater_sample_efficiency_and_simplicity"}}, "number": 7329, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7329/-/Revision", "ICLR.cc/2024/Conference/Submission7329/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7329/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695468251623, "cdate": 1695468251623, "tmdate": 1712326990122, "mdate": 1712326990122, "pdate": 1705411006440, "version": 2}, {"id": "eJ0dzPJq1F", "forum": "eJ0dzPJq1F", "signatures": ["ICLR.cc/2024/Conference/Submission7290/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7290/Authors"], "content": {"title": {"value": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement"}, "authors": {"value": ["Xuefeng Liu", "Takuma Yoneda", "Rick Stevens", "Matthew Walter", "Yuxin Chen"]}, "authorids": {"value": ["~Xuefeng_Liu2", "~Takuma_Yoneda1", "~Rick_Stevens1", "~Matthew_Walter1", "~Yuxin_Chen1"]}, "keywords": {"value": ["imitation learning", "reinforcement learning", "multiple experts"]}, "abstract": {"value": "While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. To address the demand for robust policy improvement in real-world scenarios, we introduce a novel algorithm, Robust Policy Improvement (RPI), which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration\u2014an aspect that is notably challenging in sparse-reward RL\u2014particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the oracles or learn from its own value function when the learner\u2019s performance surpasses that of the oracles in a specific state. Empirical evaluations and theoretical analysis validate that RPI excels in comparison to existing state-of-the-art methodologies, demonstrating superior performance across various benchmark domains."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bdad46427f76d0c9b2c72d8012d5b33aeddc4e8e.pdf"}, "supplementary_material": {"value": "/attachment/29d7ecd6488ac0ea3b63e1056815ca1030a60fd7.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024blending,\ntitle={Blending Imitation and Reinforcement Learning for Robust Policy Improvement},\nauthor={Xuefeng Liu and Takuma Yoneda and Rick Stevens and Matthew Walter and Yuxin Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eJ0dzPJq1F}\n}"}, "paperhash": {"value": "liu|blending_imitation_and_reinforcement_learning_for_robust_policy_improvement"}}, "number": 7290, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7290/-/Revision", "ICLR.cc/2024/Conference/Submission7290/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7290/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695465823358, "cdate": 1695465823358, "tmdate": 1713121697472, "mdate": 1713121697472, "pdate": 1705411005390, "version": 2}, {"id": "LYG6tBlEX0", "forum": "LYG6tBlEX0", "signatures": ["ICLR.cc/2024/Conference/Submission7263/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7263/Authors"], "content": {"title": {"value": "H-GAP: Humanoid Control with a Generalist Planner"}, "authors": {"value": ["zhengyao jiang", "Yingchen Xu", "Nolan Wagener", "Yicheng Luo", "Michael Janner", "Edward Grefenstette", "Tim Rockt\u00e4schel", "Yuandong Tian"]}, "authorids": {"value": ["~zhengyao_jiang2", "~Yingchen_Xu2", "~Nolan_Wagener1", "~Yicheng_Luo1", "~Michael_Janner1", "~Edward_Grefenstette1", "~Tim_Rockt\u00e4schel1", "~Yuandong_Tian1"]}, "keywords": {"value": ["Generative Modelling", "Humanoid Control", "Model Predictive Control", "Model-based Reinforcement Learning", "Offline Reinforcement Learning"]}, "TLDR": {"value": "We present Humanoid Generalist Autoencoding Planner (H-GAP), a state-action trajectory generative model capable of adeptly handling downstream control tasks with Model Predictive Control."}, "abstract": {"value": "Humanoid control is an important research challenge offering avenues for integration into human-centric infrastructures and enabling physics-driven humanoid animations.\nThe daunting challenges in this field stem from the difficulty of optimizing in high-dimensional action spaces and the instability introduced by the bipedal morphology of humanoids. \nHowever, the extensive collection of human motion-captured data and the derived datasets of humanoid trajectories, such as MoCapAct, paves the way to tackle these challenges. In this context, we present Humanoid Generalist Autoencoding Planner (H-GAP), a state-action trajectory generative model trained on humanoid trajectories derived from human motion-captured data, capable of adeptly handling downstream control tasks with Model Predictive Control (MPC).\nFor 56 degrees of freedom humanoid, we empirically demonstrate that H-GAP learns to represent and generate a wide range of motor behaviors. Further, without any learning from online interactions, it can also flexibly transfer these behaviours to solve novel downstream control tasks via planning. Notably, H-GAP excels established MPC baselines with access to the ground truth model, and is superior or comparable to offline RL methods trained for individual tasks.\nFinally, we do a series of empirical studies on the scaling properties of H-GAP, showing the potential for performance gains via additional data but not computing."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5572333360c59f829af61902b8f2157f4a2e4109.pdf"}, "_bibtex": {"value": "@inproceedings{\njiang2024hgap,\ntitle={H-{GAP}: Humanoid Control with a Generalist Planner},\nauthor={zhengyao jiang and Yingchen Xu and Nolan Wagener and Yicheng Luo and Michael Janner and Edward Grefenstette and Tim Rockt{\\\"a}schel and Yuandong Tian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LYG6tBlEX0}\n}"}, "paperhash": {"value": "jiang|hgap_humanoid_control_with_a_generalist_planner"}}, "number": 7263, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7263/-/Revision", "ICLR.cc/2024/Conference/Submission7263/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7263/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695463947009, "cdate": 1695463947009, "tmdate": 1711297775565, "mdate": 1711297775565, "pdate": 1705411004284, "version": 2}, {"id": "OwtMhMSybu", "forum": "OwtMhMSybu", "signatures": ["ICLR.cc/2024/Conference/Submission7257/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7257/Authors"], "content": {"title": {"value": "Unlocking the Power of Representations in Long-term Novelty-based Exploration"}, "authors": {"value": ["Alaa Saade", "Steven Kapturowski", "Daniele Calandriello", "Charles Blundell", "Pablo Sprechmann", "Leopoldo Sarra", "Oliver Groth", "Michal Valko", "Bilal Piot"]}, "authorids": {"value": ["~Alaa_Saade1", "~Steven_Kapturowski1", "~Daniele_Calandriello1", "~Charles_Blundell1", "~Pablo_Sprechmann1", "~Leopoldo_Sarra1", "~Oliver_Groth1", "~Michal_Valko1", "~Bilal_Piot1"]}, "keywords": {"value": ["Deep RL", "exploration", "density estimation", "representation learning"]}, "TLDR": {"value": "We introduce a new novelty estimator for exploration in deep RL which can preserve long-term memory and be used with any representation learning techniques"}, "abstract": {"value": "We introduce Robust Exploration via Clustering-based Online Density Estimation (RECODE), a non-parametric method for novelty-based exploration that estimates visitation counts for clusters of states based on their similarity in a chosen embedding space. By adapting classical clustering to the nonstationary setting of Deep RL, RECODE can efficiently track state visitation counts over thousands of episodes. We further propose a novel generalization of the inverse dynamics loss, which leverages masked transformer architectures for multi-step prediction; which in conjunction with \\DETOCS achieves a new state-of-the-art in a suite of challenging 3D-exploration tasks in DM-Hard-8. RECODE also sets new state-of-the-art in hard exploration Atari games, and is the first agent to reach the end screen in \"Pitfall!\""}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/97bd16e3685d8761abc10cf118ffd94e8ae31b77.pdf"}, "_bibtex": {"value": "@inproceedings{\nsaade2024unlocking,\ntitle={Unlocking the Power of Representations in Long-term Novelty-based Exploration},\nauthor={Alaa Saade and Steven Kapturowski and Daniele Calandriello and Charles Blundell and Pablo Sprechmann and Leopoldo Sarra and Oliver Groth and Michal Valko and Bilal Piot},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OwtMhMSybu}\n}"}, "paperhash": {"value": "saade|unlocking_the_power_of_representations_in_longterm_noveltybased_exploration"}}, "number": 7257, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7257/-/Revision", "ICLR.cc/2024/Conference/Submission7257/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7257/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695463508006, "cdate": 1695463508006, "tmdate": 1711062954017, "mdate": 1711062954017, "pdate": 1705411004026, "version": 2}, {"id": "UpgRVWexaD", "forum": "UpgRVWexaD", "signatures": ["ICLR.cc/2024/Conference/Submission7242/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7242/Authors"], "content": {"title": {"value": "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling"}, "authors": {"value": ["Hong Wang", "Zhongkai Hao", "Jie Wang", "Zijie Geng", "Zhen Wang", "Bin Li", "Feng Wu"]}, "authorids": {"value": ["~Hong_Wang14", "~Zhongkai_Hao1", "~Jie_Wang1", "~Zijie_Geng1", "~Zhen_Wang30", "~Bin_Li8", "~Feng_Wu1"]}, "keywords": {"value": ["AI4PDE; Neural Operator; Data Generation; Krylov Subspace"]}, "TLDR": {"value": "This paper proposes a novel method, namely SKR, to boost the data generation efficiency for neural operator training based on Krylov subspace recycling."}, "abstract": {"value": "Learning neural operators for solving partial differential equations (PDEs) has attracted great attention due to its high inference efficiency.\nHowever, training such operators requires generating a substantial amount of labeled data, i.e., PDE problems together with their solutions.\nThe data generation process is exceptionally time-consuming, as it involves solving numerous systems of linear equations to obtain numerical solutions to the PDEs.\nMany existing methods solve these systems independently without considering their inherent similarities, resulting in extremely redundant computations.\nTo tackle this problem, we propose a novel method, namely **S**orting **K**rylov **R**ecycling (**SKR**), to boost the efficiency of solving these systems, thus significantly accelerating data generation for neural operators training.\nTo the best of our knowledge, SKR is the first attempt to address the time-consuming nature of data generation for learning neural operators.\nThe working horse of SKR is Krylov subspace recycling, a powerful technique for solving a series of interrelated systems by leveraging their inherent similarities.\nSpecifically, SKR employs a sorting algorithm to arrange these systems in a sequence, where adjacent systems exhibit high similarities.\nThen it equips a solver with Krylov subspace recycling to solve the systems sequentially instead of independently, thus effectively enhancing the solving efficiency.\nBoth theoretical analysis and extensive experiments demonstrate that SKR can significantly accelerate neural operator data generation, achieving a remarkable speedup of up to 13.9 times."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ff0efe03064ef3409c6562ca6ccdf6ff02fb9cba.pdf"}, "supplementary_material": {"value": "/attachment/ec667f577e769a42f2ddddb89616e6e42d98ea62.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024accelerating,\ntitle={Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling},\nauthor={Hong Wang and Zhongkai Hao and Jie Wang and Zijie Geng and Zhen Wang and Bin Li and Feng Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UpgRVWexaD}\n}"}, "paperhash": {"value": "wang|accelerating_data_generation_for_neural_operators_via_krylov_subspace_recycling"}}, "number": 7242, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7242/-/Revision", "ICLR.cc/2024/Conference/Submission7242/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7242/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462934407, "cdate": 1695462934407, "tmdate": 1710485039867, "mdate": 1710485039867, "pdate": 1705411003397, "version": 2}, {"id": "cJs4oE4m9Q", "forum": "cJs4oE4m9Q", "signatures": ["ICLR.cc/2024/Conference/Submission7228/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7228/Authors"], "content": {"title": {"value": "Deep Orthogonal Hypersphere Compression for Anomaly Detection"}, "authors": {"value": ["Yunhe Zhang", "Yan Sun", "Jinyu Cai", "Jicong Fan"]}, "authorids": {"value": ["~Yunhe_Zhang1", "~Yan_Sun7", "~Jinyu_Cai2", "~Jicong_Fan2"]}, "keywords": {"value": ["Anomaly Detection", "Deep Learning"]}, "abstract": {"value": "Many well-known and effective anomaly detection methods assume that a reasonable decision boundary has a hypersphere shape, which however is difficult to obtain in practice and is not sufficiently compact, especially when the data are in high-dimensional spaces. In this paper, we first propose a novel deep anomaly detection model that improves the original hypersphere learning through an orthogonal projection layer, which ensures that the training data distribution is consistent with the hypersphere hypothesis, thereby increasing the true positive rate and decreasing the false negative rate. Moreover, we propose a bi-hypersphere compression method to obtain a hyperspherical shell that yields a more compact decision region than a hyperball, which is demonstrated theoretically and numerically.  The proposed methods are not confined to common datasets such as image and tabular data, but are also extended to a more challenging but promising scenario, graph-level anomaly detection, which learns graph representation with maximum mutual information between the substructure and global structure features while exploring orthogonal single- or bi-hypersphere anomaly decision boundaries. The numerical and visualization results on benchmark datasets demonstrate the superiority of our methods in comparison to many baselines and state-of-the-art methods."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b8052c3c7a3cfeccc963ae2d0d24045831b4d84e.pdf"}, "supplementary_material": {"value": "/attachment/0fc6dd7a1e70242c23faf3056a487f5bc0724b4e.zip"}, "_bibtex": {"value": "@inproceedings{\nzhang2024deep,\ntitle={Deep Orthogonal Hypersphere Compression for Anomaly Detection},\nauthor={Yunhe Zhang and Yan Sun and Jinyu Cai and Jicong Fan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cJs4oE4m9Q}\n}"}, "paperhash": {"value": "zhang|deep_orthogonal_hypersphere_compression_for_anomaly_detection"}}, "number": 7228, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7228/-/Revision", "ICLR.cc/2024/Conference/Submission7228/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7228/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462338670, "cdate": 1695462338670, "tmdate": 1710815843331, "mdate": 1710815843331, "pdate": 1705411002872, "version": 2}, {"id": "JSS9rKHySk", "forum": "JSS9rKHySk", "signatures": ["ICLR.cc/2024/Conference/Submission7145/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7145/Authors"], "content": {"title": {"value": "On the Role of General Function Approximation in Offline Reinforcement Learning"}, "authors": {"value": ["Chenjie Mao", "Qiaosheng Zhang", "Zhen Wang", "Xuelong Li"]}, "authorids": {"value": ["~Chenjie_Mao1", "~Qiaosheng_Zhang2", "~Zhen_Wang11", "~Xuelong_Li2"]}, "keywords": {"value": ["reinforcement learning theory", "offline reinforcement learning", "general function approximation", "learnability", "minimax lower bounds"]}, "TLDR": {"value": "This paper clarifies the use of general function approximation in offline RL and proposes lower bounds for learnability."}, "abstract": {"value": "We study offline reinforcement learning (RL) with general function approximation. General function approximation is a powerful tool for algorithm design and analysis, but its adaptation to offline RL encounters several challenges due to varying approximation targets and assumptions that blur the real meanings of function assumptions. In this paper, we try to formulate and clarify the treatment of general function approximation in offline RL in two aspects: (1) analyzing different types of assumptions and their practical usage, and (2) understanding its role as a restriction on underlying MDPs from information-theoretic perspectives. Additionally, we introduce a new insight for lower bound establishing: one can exploit model-realizability to establish general-purpose lower bounds that can be generalized into other functions. Building upon this insight, we propose two generic lower bounds that contribute to a better understanding of offline RL with general function approximation."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8621c59f51343401b65a5d8c4ba33ef5a631dd93.pdf"}, "_bibtex": {"value": "@inproceedings{\nmao2024on,\ntitle={On the Role of General Function Approximation in Offline Reinforcement Learning},\nauthor={Chenjie Mao and Qiaosheng Zhang and Zhen Wang and Xuelong Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JSS9rKHySk}\n}"}, "paperhash": {"value": "mao|on_the_role_of_general_function_approximation_in_offline_reinforcement_learning"}}, "number": 7145, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7145/-/Revision", "ICLR.cc/2024/Conference/Submission7145/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7145/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695457613799, "cdate": 1695457613799, "tmdate": 1712985838781, "mdate": 1712985838781, "pdate": 1705411000105, "version": 2}, {"id": "mYWsyTuiRp", "forum": "mYWsyTuiRp", "signatures": ["ICLR.cc/2024/Conference/Submission7136/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7136/Authors"], "content": {"title": {"value": "Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Map"}, "authors": {"value": ["Goro Kobayashi", "Tatsuki Kuribayashi", "Sho Yokoi", "Kentaro Inui"]}, "authorids": {"value": ["~Goro_Kobayashi1", "~Tatsuki_Kuribayashi1", "~Sho_Yokoi1", "~Kentaro_Inui1"]}, "keywords": {"value": ["Transformer", "Attention map", "Feed-forward", "Contextualization", "Interpretation", "Analysis", "Pre-trained models", "Masked language models", "Causal language models"]}, "TLDR": {"value": "We analyze the input contextualization effects of Feed-Forward blocks in Transformer-based models by rendering them in the attention maps."}, "abstract": {"value": "Given that Transformers are ubiquitous in wide tasks, interpreting their internals is a pivotal issue. \nStill, their particular components, feed-forward (FF) blocks, have typically been less analyzed despite their substantial parameter amounts.\nWe analyze the input contextualization effects of FF blocks by rendering them in the attention maps as a human-friendly visualization scheme.\nOur experiments with both masked- and causal-language models reveal that \nFF networks modify the input contextualization to emphasize specific types of linguistic compositions. \nIn addition, FF and its surrounding components tend to cancel out each other's effects, suggesting potential redundancy in the processing of the Transformer layer."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e23fcde65d5c750dec1134c35162cec70145cdb2.pdf"}, "_bibtex": {"value": "@inproceedings{\nkobayashi2024analyzing,\ntitle={Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Map},\nauthor={Goro Kobayashi and Tatsuki Kuribayashi and Sho Yokoi and Kentaro Inui},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mYWsyTuiRp}\n}"}, "paperhash": {"value": "kobayashi|analyzing_feedforward_blocks_in_transformers_through_the_lens_of_attention_map"}}, "number": 7136, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7136/-/Revision", "ICLR.cc/2024/Conference/Submission7136/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456913252, "cdate": 1695456913252, "tmdate": 1707625637978, "mdate": 1707625637978, "pdate": 1705410999760, "version": 2}, {"id": "i9Vs5NGDpk", "forum": "i9Vs5NGDpk", "signatures": ["ICLR.cc/2024/Conference/Submission7125/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7125/Authors"], "content": {"title": {"value": "Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning"}, "authors": {"value": ["Pratik Patil", "Daniel LeJeune"]}, "authorids": {"value": ["~Pratik_Patil1", "~Daniel_LeJeune1"]}, "keywords": {"value": ["asymptotic freeness", "sketching", "ensembles", "ridge regression", "generalized cross-validation", "tuning"]}, "TLDR": {"value": "We show consistency of generalized cross-validation for tuning asymptotically free sketched ridge ensembles under mild data assumptions."}, "abstract": {"value": "We employ random matrix theory to establish consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles, enabling efficient and consistent tuning of regularization and sketching parameters. Our results hold for a broad class of asymptotically free sketches under very mild data assumptions. For squared prediction risk, we provide a decomposition into an unsketched equivalent implicit ridge bias and a sketching-based variance, and prove that the risk can be globally optimized by only tuning sketch size in infinite ensembles. For general subquadratic prediction risk functionals, we extend GCV to construct consistent risk estimators, and thereby obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric. This in particular allows construction of prediction intervals with asymptotically correct coverage conditional on the training data. We also propose an \"ensemble trick\" whereby the risk for unsketched ridge regression can be efficiently estimated via GCV using small sketched ridge ensembles. We empirically validate our theoretical results using both synthetic and real large-scale datasets with practical sketches including CountSketch and subsampled randomized discrete cosine transforms."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/28ddc17b08b8df3bdcb23d2393cdb2d882b39eef.pdf"}, "supplementary_material": {"value": "/attachment/2e22cf2dbfc472ba57b5af7250bc243fcc899eb8.zip"}, "_bibtex": {"value": "@inproceedings{\npatil2024asymptotically,\ntitle={Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning},\nauthor={Pratik Patil and Daniel LeJeune},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i9Vs5NGDpk}\n}"}, "paperhash": {"value": "patil|asymptotically_free_sketched_ridge_ensembles_risks_crossvalidation_and_tuning"}}, "number": 7125, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7125/-/Revision", "ICLR.cc/2024/Conference/Submission7125/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7125/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456441776, "cdate": 1695456441776, "tmdate": 1710891035848, "mdate": 1710891035848, "pdate": 1705410999229, "version": 2}, {"id": "zmJDzPh1Dm", "forum": "zmJDzPh1Dm", "signatures": ["ICLR.cc/2024/Conference/Submission7114/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7114/Authors"], "content": {"title": {"value": "Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models"}, "authors": {"value": ["Shuai Fu", "Xiequn Wang", "Qiushi Huang", "Yu Zhang"]}, "authorids": {"value": ["~Shuai_Fu1", "~Xiequn_Wang1", "~Qiushi_Huang1", "~Yu_Zhang3"]}, "keywords": {"value": ["Vision-language models; Soft-prompt tuning; Low-norm effect; Normalizing soft prompts"]}, "TLDR": {"value": "This paper first uncovers a Low-Norm Effect phenomenon that occurs in soft prompt-tuning vision-language models (VLMs) and proposes a method for normalizing the soft prompts of VLMs to achieve better performance."}, "abstract": {"value": "With the prevalence of large-scale pretrained vision-language models (VLMs), such as CLIP, soft-prompt tuning has become a popular method for adapting these models to various downstream tasks. However, few works delve into the inherent properties of learnable soft-prompt vectors, specifically the impact of their norms to the performance of VLMs. This motivates us to pose an unexplored research question: ``Do we need to normalize the soft prompts in VLMs?'' To fill this research gap, we first uncover a phenomenon, called the $\\textbf{Low-Norm Effect}$ by performing extensive corruption experiments, suggesting that reducing the norms of certain learned prompts occasionally enhances the performance of VLMs, while increasing them often degrades it. To harness this effect, we propose a novel method named $\\textbf{N}$ormalizing th$\\textbf{e}$ soft-pro$\\textbf{m}$pt v$\\textbf{e}$ctors of vi$\\textbf{si}$on-language model$\\textbf{s}$ ($\\textbf{Nemesis}$) to normalize soft-prompt vectors in VLMs. To the best of our knowledge, our work is the first to systematically investigate the role of norms of soft-prompt vector in VLMs, offering valuable insights for future research in soft-prompt tuning."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/13b62a20df81ff095be76d919e6602f6f86780bf.pdf"}, "_bibtex": {"value": "@inproceedings{\nfu2024nemesis,\ntitle={Nemesis: Normalizing the soft-prompt vectors of vision-language models},\nauthor={Shuai Fu and Xiequn Wang and Qiushi Huang and Yu Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zmJDzPh1Dm}\n}"}, "paperhash": {"value": "fu|nemesis_normalizing_the_softprompt_vectors_of_visionlanguage_models"}}, "number": 7114, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7114/-/Revision", "ICLR.cc/2024/Conference/Submission7114/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7114/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695455931736, "cdate": 1695455931736, "tmdate": 1710485132875, "mdate": 1710485132875, "pdate": 1705410998766, "version": 2}, {"id": "9OevMUdods", "forum": "9OevMUdods", "signatures": ["ICLR.cc/2024/Conference/Submission7061/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7061/Authors"], "content": {"title": {"value": "Towards Understanding Factual Knowledge of Large Language Models"}, "authors": {"value": ["Xuming Hu", "Junzhe Chen", "Xiaochuan Li", "Yufei Guo", "Lijie Wen", "Philip S. Yu", "Zhijiang Guo"]}, "authorids": {"value": ["~Xuming_Hu1", "~Junzhe_Chen1", "~Xiaochuan_Li3", "~Yufei_Guo3", "~Lijie_Wen1", "~Philip_S._Yu1", "~Zhijiang_Guo2"]}, "keywords": {"value": ["Large Language Models", "Resource and Evaluation", "Interpretability", "NLP Application"]}, "abstract": {"value": "Large language models (LLMs) have recently driven striking performance improvements across a range of natural language processing tasks. The factual knowledge acquired during pretraining and instruction tuning can be useful in various downstream tasks, such as question answering, and language generation. Unlike conventional Knowledge Bases (KBs) that explicitly store factual knowledge, LLMs implicitly store facts in their parameters. Content generated by the LLMs can often exhibit inaccuracies or deviations from the truth, due to facts that can be incorrectly induced or become obsolete over time. To this end, we aim to explore the extent and scope of factual knowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains 20K diverse factual questions that span different sources, timelines, domains, regions, and languages. Furthermore, we investigate whether LLMs can compose multiple facts, update factual knowledge temporally, reason over multiple pieces of facts, identify subtle factual differences, and resist adversarial examples. Extensive experiments on different sizes and types of LLMs show that existing LLMs still lack factual knowledge and suffer from various spurious correlations. We believe this is a critical bottleneck for realizing trustworthy artificial intelligence. The dataset Pinocchio and our codes are publicly available at: https://github.com/THU-BPM/Pinocchio."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/025c1d2beaec72d3724b68ca610dd61083362fdc.pdf"}, "supplementary_material": {"value": "/attachment/51a07766af2dbf3f53f933abc73c84392c2f0628.zip"}, "_bibtex": {"value": "@inproceedings{\nhu2024do,\ntitle={Do Large Language Models Know about Facts?},\nauthor={Xuming Hu and Junzhe Chen and Xiaochuan Li and Yufei Guo and Lijie Wen and Philip S. Yu and Zhijiang Guo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9OevMUdods}\n}"}, "paperhash": {"value": "hu|towards_understanding_factual_knowledge_of_large_language_models"}}, "number": 7061, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7061/-/Revision", "ICLR.cc/2024/Conference/Submission7061/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7061/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695453247533, "cdate": 1695453247533, "tmdate": 1710315214714, "mdate": 1710315214714, "pdate": 1705410996749, "version": 2}, {"id": "E78OaH2s3f", "forum": "E78OaH2s3f", "signatures": ["ICLR.cc/2024/Conference/Submission7028/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7028/Authors"], "content": {"title": {"value": "CAS: A Probability-Based Approach for Universal Condition Alignment Score"}, "authors": {"value": ["Chunsan Hong", "ByungHee Cha", "Tae-Hyun Oh"]}, "authorids": {"value": ["~Chunsan_Hong1", "~ByungHee_Cha1", "~Tae-Hyun_Oh3"]}, "keywords": {"value": ["Generative model", "diffusion model", "score-based prior", "conditional diffusion model", "text-to-image alignment score", "inversion process", "image quality assessment", "T2I alignment score"]}, "abstract": {"value": "Recent conditional diffusion models have shown remarkable advancements and have been widely applied in fascinating real-world applications. However, samples generated by these models often do not strictly comply with user-provided conditions. Due to this, there have been few attempts to evaluate this alignment via pre-trained scoring models to select well-generated samples. Nonetheless, current studies are confined to the text-to-image domain and require large training datasets. This suggests that crafting alignment scores for various conditions will demand considerable resources in the future. In this context, we introduce a universal condition alignment score that leverages the conditional probability measurable through the diffusion process. Our technique operates across all conditions and requires no additional models beyond the diffusion model used for generation, effectively enabling self-rejection. Our experiments validate that our met- ric effectively applies in diverse conditional generations, such as text-to-image, {instruction, image}-to-image, edge-/scribble-to-image, and text-to-audio."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f985d33f22b4298cf2016099ca2640c09738d070.pdf"}, "_bibtex": {"value": "@inproceedings{\nhong2024cas,\ntitle={{CAS}: A Probability-Based Approach for Universal Condition Alignment Score},\nauthor={Chunsan Hong and ByungHee Cha and Tae-Hyun Oh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=E78OaH2s3f}\n}"}, "paperhash": {"value": "hong|cas_a_probabilitybased_approach_for_universal_condition_alignment_score"}}, "number": 7028, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7028/-/Revision", "ICLR.cc/2024/Conference/Submission7028/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7028/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452041230, "cdate": 1695452041230, "tmdate": 1712694151322, "mdate": 1712694151322, "pdate": 1705410995424, "version": 2}, {"id": "5BCFlnfE1g", "forum": "5BCFlnfE1g", "signatures": ["ICLR.cc/2024/Conference/Submission7019/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7019/Authors"], "content": {"title": {"value": "Demystifying CLIP Data"}, "authors": {"value": ["Hu Xu", "Saining Xie", "Xiaoqing Tan", "Po-Yao Huang", "Russell Howes", "Vasu Sharma", "Shang-Wen Li", "Gargi Ghosh", "Luke Zettlemoyer", "Christoph Feichtenhofer"]}, "authorids": {"value": ["~Hu_Xu1", "~Saining_Xie2", "~Xiaoqing_Tan1", "~Po-Yao_Huang2", "~Russell_Howes1", "~Vasu_Sharma1", "~Shang-Wen_Li1", "~Gargi_Ghosh3", "~Luke_Zettlemoyer1", "~Christoph_Feichtenhofer4"]}, "keywords": {"value": ["multi-modal pretraining", "CLIP", "image", "text"]}, "TLDR": {"value": "CLIP data curation and scaling"}, "abstract": {"value": "Contrastive Language-Image Pre-training (CLIP) is an approach that has advanced research and applications in computer vision, fueling modern recognition systems and generative models. We believe that the main ingredient to the success of CLIP is its \\textit{data} and \\textit{not} the \\textit{model} architecture or pre-training {objective}. However, CLIP only provides very limited information about its data and how it has been collected, leading to works that aim to reproduce CLIP's data by filtering with its model parameters. In this work, we intend to reveal CLIP's data curation approach and in our pursuit of making it open to the community introduce Metadata-Curated Language-Image Pre-training (MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's concepts) and yields a balanced subset over the metadata distribution. Our experimental study rigorously isolates the model and training settings, concentrating solely on data. MetaCLIP applied to CommonCrawl with 400M image-text data pairs outperforms CLIP's data on multiple standard benchmarks. In zero-shot ImageNet classification, MetaCLIP achieves 70.8\\% accuracy, surpassing CLIP's 68.3\\% on \\mbox{ViT-B} models. Scaling to 1B data, while maintaining the same training budget, attains \\textbf{72.4\\%}. Our observations hold across various model sizes, exemplified by ViT-H achieving \\textbf{80.5\\%}, without any bells-and-whistles. Curation code and training data distribution over metadata will be made available."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9c2e91f6f4a65a812be7ea55d1d89e0fd4844e26.pdf"}, "_bibtex": {"value": "@inproceedings{\nxu2024demystifying,\ntitle={Demystifying {CLIP} Data},\nauthor={Hu Xu and Saining Xie and Xiaoqing Tan and Po-Yao Huang and Russell Howes and Vasu Sharma and Shang-Wen Li and Gargi Ghosh and Luke Zettlemoyer and Christoph Feichtenhofer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5BCFlnfE1g}\n}"}, "paperhash": {"value": "xu|demystifying_clip_data"}}, "number": 7019, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7019/-/Revision", "ICLR.cc/2024/Conference/Submission7019/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7019/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695451644998, "cdate": 1695451644998, "tmdate": 1712185458482, "mdate": 1712185458482, "pdate": 1705410995110, "version": 2}, {"id": "o8tjamaJ80", "forum": "o8tjamaJ80", "signatures": ["ICLR.cc/2024/Conference/Submission6937/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6937/Authors"], "content": {"title": {"value": "Adversarial AutoMixup"}, "authors": {"value": ["Huafeng Qin", "Xin Jin", "Yun Jiang", "Moun\u00eem El-Yacoubi", "Xinbo Gao"]}, "authorids": {"value": ["~Huafeng_Qin1", "~Xin_Jin20", "~Yun_Jiang2", "~Moun\u00eem_El-Yacoubi1", "~Xinbo_Gao5"]}, "keywords": {"value": ["Data Augmentation", "Mixup", "Image Classification"]}, "abstract": {"value": "Data mixing augmentation has been widely applied to improve the generalization ability of deep neural networks. Recently, offline data mixing augmentation, e.g. handcrafted and saliency information-based mixup, has been gradually replaced by automatic mixing approaches. Through minimizing two sub-tasks, namely, mixed sample generation and mixup classification in an end-to-end way, AutoMix significantly improves accuracy on image classification tasks. However, as the optimization objective is consistent for the two sub-tasks, this approach is prone to generating consistent instead of diverse mixed samples, which results in overfitting for target task training. In this paper, we propose AdAutomixup, an adversarial automatic mixup augmentation approach that generates challenging samples to train a robust classifier for image classification, by alternatively optimizing the classifier and the mixup sample generator. AdAutomixup comprises two modules, a mixed example generator, and a target classifier. The mixed sample generator aims to produce hard mixed examples to challenge the target classifier, while the target classifier's aim is to learn robust features from hard mixed examples to improve generalization. To prevent the collapse of the inherent meanings of images, we further introduce an exponential moving average (EMA) teacher and cosine similarity to train AdAutomixup in an end-to-end way. Extensive experiments on seven image benchmarks consistently prove that our approach outperforms the state of the art in various classification scenarios. The source code is available at \nhttps://github.com/JinXins/Adversarial-AutoMixup."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/47a0f838e2a5b9d0158f56d2adb6432f9f878803.pdf"}, "supplementary_material": {"value": ""}, "_bibtex": {"value": "@inproceedings{\nqin2024adversarial,\ntitle={Adversarial AutoMixup},\nauthor={Huafeng Qin and Xin Jin and Yun Jiang and Moun{\\^\\i}m El-Yacoubi and Xinbo Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=o8tjamaJ80}\n}"}, "paperhash": {"value": "qin|adversarial_automixup"}}, "number": 6937, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6937/-/Revision", "ICLR.cc/2024/Conference/Submission6937/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6937/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695447438799, "cdate": 1695447438799, "tmdate": 1709661536192, "mdate": 1709661536192, "pdate": 1705410992655, "version": 2}, {"id": "Ts95eXsPBc", "forum": "Ts95eXsPBc", "signatures": ["ICLR.cc/2024/Conference/Submission6931/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6931/Authors"], "content": {"title": {"value": "Spatially-Aware Transformers for Embodied Agents"}, "authors": {"value": ["Junmo Cho", "Jaesik Yoon", "Sungjin Ahn"]}, "authorids": {"value": ["~Junmo_Cho1", "~Jaesik_Yoon1", "~Sungjin_Ahn1"]}, "keywords": {"value": ["Episodic Memory", "Spatial Inference", "Prediction", "Generation", "Reinforcement Learning"]}, "TLDR": {"value": "We propose a transformer-based episodic memory model, the Spatially-Aware Episodic Transformer, that incorporates both temporal and spatial dimensions to improve memory utilization and downstream task accuracy."}, "abstract": {"value": "Episodic memory plays a crucial role in various cognitive processes, such as the ability to mentally recall past events. While cognitive science emphasizes the significance of spatial context in the formation and retrieval of episodic memory, the current primary approach to implementing episodic memory in AI systems is through transformers that store temporally ordered experiences, which overlooks the spatial dimension. As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information. These models enable the creation of place-centric episodic memory that considers both temporal and spatial dimensions. Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanced accuracy in various place-centric downstream tasks. Additionally, we propose the Adaptive Memory Allocator, a memory management method based on reinforcement learning that aims to optimize efficiency of memory utilization. Our experiments demonstrate the advantages of our proposed model in various environments and across multiple downstream tasks, including prediction, generation, reasoning, and reinforcement learning. The source code for our models and experiments will be available at \\href{https://github.com/spatially_aware_transformer}{https://github.com/spatially_aware_transformer}."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1dc0ff45874e872749597c38bcfc2df0fa7ed0d6.pdf"}, "_bibtex": {"value": "@inproceedings{\ncho2024spatiallyaware,\ntitle={Spatially-Aware Transformers for Embodied Agents},\nauthor={Junmo Cho and Jaesik Yoon and Sungjin Ahn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ts95eXsPBc}\n}"}, "paperhash": {"value": "cho|spatiallyaware_transformers_for_embodied_agents"}}, "number": 6931, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6931/-/Revision", "ICLR.cc/2024/Conference/Submission6931/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6931/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446964971, "cdate": 1695446964971, "tmdate": 1712303192278, "mdate": 1712303192278, "pdate": 1705410992399, "version": 2}, {"id": "qoHeuRAcSl", "forum": "qoHeuRAcSl", "signatures": ["ICLR.cc/2024/Conference/Submission6834/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6834/Authors"], "content": {"title": {"value": "Grounding Language Plans in Demonstrations Through Counterfactual Perturbations"}, "authors": {"value": ["Yanwei Wang", "Tsun-Hsuan Wang", "Jiayuan Mao", "Michael Hagenow", "Julie Shah"]}, "authorids": {"value": ["~Yanwei_Wang1", "~Tsun-Hsuan_Wang2", "~Jiayuan_Mao1", "hagenow@mit.edu", "~Julie_Shah2"]}, "keywords": {"value": ["Grounding LLM", "Learning Mode Abstractions for Manipulation", "Learning from Demonstration", "Robotics", "Task and Motion Planning"]}, "abstract": {"value": "Grounding the common-sense reasoning of Large Language Models in physical domains remains a pivotal yet unsolved problem for embodied AI. Whereas prior works have focused on leveraging LLMs directly for planning in symbolic spaces, this work uses LLMs to guide the search of task structures and constraints implicit in multi-step demonstrations. Specifically, we borrow from manipulation planning literature the concept of mode families, which group robot configurations by specific motion constraints, to serve as an abstraction layer between the high-level language representations of an LLM and the low-level physical trajectories of a robot. By replaying a few human demonstrations with synthetic perturbations, we generate coverage over the demonstrations' state space with additional successful executions as well as counterfactuals that fail the task. Our explanation-based learning framework trains an end-to-end differentiable neural network to predict successful trajectories from failures and as a by-product learns classifiers that ground low-level states and images in mode families without dense labeling. The learned grounding classifiers can further be used to translate language plans into reactive policies in the physical domain in an interpretable manner. We show our approach improves the interpretability and reactivity of imitation learning through 2D navigation and simulated and real robot manipulation tasks. Website: https://yanweiw.github.io/glide/"}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/095205c11ca0cd7a485da10923a605bbfd899160.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024grounding,\ntitle={Grounding Language Plans in Demonstrations Through Counter-Factual Perturbations},\nauthor={Yanwei Wang and Tsun-Hsuan Wang and Jiayuan Mao and Michael Hagenow and Julie Shah},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qoHeuRAcSl}\n}"}, "paperhash": {"value": "wang|grounding_language_plans_in_demonstrations_through_counterfactual_perturbations"}}, "number": 6834, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6834/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6834/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441511520, "cdate": 1695441511520, "tmdate": 1713159662438, "mdate": 1713159662438, "pdate": 1705410988968, "version": 2}, {"id": "DFTHW0MyiW", "forum": "DFTHW0MyiW", "signatures": ["ICLR.cc/2024/Conference/Submission6801/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6801/Authors"], "content": {"title": {"value": "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies"}, "authors": {"value": ["Xiangyu Liu", "Chenghao Deng", "Yanchao Sun", "Yongyuan Liang", "Furong Huang"]}, "authorids": {"value": ["~Xiangyu_Liu4", "~Chenghao_Deng1", "~Yanchao_Sun1", "~Yongyuan_Liang1", "~Furong_Huang1"]}, "keywords": {"value": ["robust reinforcement learning; beyond worse-case"]}, "abstract": {"value": "In light of the burgeoning success of reinforcement learning (RL) in diverse real-world applications, considerable focus has been directed towards ensuring RL policies are robust to adversarial attacks during test time. Current approaches largely revolve around solving a minimax problem to prepare for potential worst-case scenarios. While effective against strong attacks, these methods often compromise performance in the absence of attacks or the presence of only weak attacks. To address this, we study policy robustness under the well-accepted state-adversarial attack model, extending our focus beyond merely worst-case attacks. We first formalize this task at test time as a regret minimization problem and establish its intrinsic difficulty in achieving sublinear regret when the baseline policy is from a general continuous policy class, $\\Pi$. This finding prompts us to \\textit{refine} the baseline policy class $\\Pi$ prior to test time, aiming for efficient adaptation within a compact, finite policy class $\\tilde{\\Pi}$, which can resort to an adversarial bandit subroutine. In light of the importance of a finite and compact $\\tilde{\\Pi}$, we propose a novel training-time algorithm to iteratively discover \\textit{non-dominated policies}, forming a near-optimal and minimal $\\tilde{\\Pi}$, thereby ensuring both robustness and test-time efficiency. Empirical validation on the Mujoco corroborates the superiority of our approach in terms of natural and robust performance, as well as adaptability to various attack scenarios."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a7e93789afc93e70c42ccbaecde9d7a6bb824d01.pdf"}, "TLDR": {"value": "We developed a general framework to improve victim performance against attacks beyond worst-case scenarios while maintaining robustness against worse-case attacks."}, "_bibtex": {"value": "@inproceedings{\nliu2024beyond,\ntitle={Beyond Worst-case Attacks: Robust {RL} with Adaptive Defense via Non-dominated Policies},\nauthor={Xiangyu Liu and Chenghao Deng and Yanchao Sun and Yongyuan Liang and Furong Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DFTHW0MyiW}\n}"}, "paperhash": {"value": "liu|beyond_worstcase_attacks_robust_rl_with_adaptive_defense_via_nondominated_policies"}}, "number": 6801, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6801/-/Revision", "ICLR.cc/2024/Conference/Submission6801/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6801/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695440205286, "cdate": 1695440205286, "tmdate": 1712683675271, "mdate": 1712683675271, "pdate": 1705410987603, "version": 2}, {"id": "eFWG9Cy3WK", "forum": "eFWG9Cy3WK", "signatures": ["ICLR.cc/2024/Conference/Submission6785/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6785/Authors"], "content": {"title": {"value": "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy"}, "authors": {"value": ["Pingzhi Li", "Zhenyu Zhang", "Prateek Yadav", "Yi-Lin Sung", "Yu Cheng", "Mohit Bansal", "Tianlong Chen"]}, "authorids": {"value": ["~Pingzhi_Li1", "~Zhenyu_Zhang4", "~Prateek_Yadav1", "~Yi-Lin_Sung1", "~Yu_Cheng1", "~Mohit_Bansal2", "~Tianlong_Chen1"]}, "keywords": {"value": ["Sparse Mixture-of-Experts", "Efficiency", "Merging", "Compression"]}, "abstract": {"value": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise to scale up the learning capacity of neural networks, however, they have issues like: ($a$) $\\textit{High Memory Usage,}$ due to duplication of the network layers into multiple copies as experts; and ($b$) $\\textit{Redundancy in Experts,}$ as common learning-based routing policies suffer from representational collapse. Therefore, vanilla SMoE models are memory inefficient and non-scalable, especially for resource-constrained downstream scenarios. In this paper, we ask: Can we craft a compact SMoE model by consolidating expert information? What is the best recipe to merge multiple experts into fewer but more knowledgeable experts? Our pilot investigation reveals that conventional model merging methods fail to be effective in such expert merging for SMoE. The potential reasons are: ($1$) redundant information overshadows critical experts; ($2$) appropriate neuron permutation for each expert is missing to bring all of them in alignment. To address these challenges, we propose a novel merging algorithm for SMoE, $\\textit{i.e.}$, $\\texttt{M-SMoE}$, which leverages routing statistics to guide expert merging. Specifically, it starts with neuron permutation alignment for experts; then, dominant experts and their \"group members\" are formed based on routing policies; lastly, every expert group is merged into a single expert by utilizing each expert's activation frequency as their weight for merging, thus diminishing the impact of insignificant experts. Moreover, we draw an interesting observation that our proposed merging promotes a low dimensionality in the merged expert's weight space, naturally paving the way for additional compression. Hence, our final method, $\\texttt{MC-SMoE}$ ($\\textit{i.e.}$, Merge, then Compress SMoE), further decomposes the merged experts into low-rank and structural sparse alternatives. Extensive experiments across $8$ benchmarks validate the effectiveness of our proposals. For instance, our $\\texttt{MC-SMoE}$ achieves up to $80\\%$ memory and a $20\\%$ FLOPs reduction, with virtually no loss in performance. Our code is provided as supplementary material."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We propose an SMoE merging and compression framework, which leverages routing statistics as guidance, achieveing impressive results of both memory- and parameter- efficiency."}, "pdf": {"value": "/pdf/93b33eef04948ce274bfc922884b3a34062628c7.pdf"}, "supplementary_material": {"value": "/attachment/09585d578b64d66fcb29e8a9d5553f0d13c2975a.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024merge,\ntitle={Merge, Then Compress: Demystify Efficient {SM}oE with Hints from Its Routing Policy},\nauthor={Pingzhi Li and Zhenyu Zhang and Prateek Yadav and Yi-Lin Sung and Yu Cheng and Mohit Bansal and Tianlong Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eFWG9Cy3WK}\n}"}, "paperhash": {"value": "li|merge_then_compress_demystify_efficient_smoe_with_hints_from_its_routing_policy"}}, "number": 6785, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6785/-/Revision", "ICLR.cc/2024/Conference/Submission6785/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6785/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695439648331, "cdate": 1695439648331, "tmdate": 1709803091321, "mdate": 1709803091321, "pdate": 1705410987045, "version": 2}, {"id": "i2Phucne30", "forum": "i2Phucne30", "signatures": ["ICLR.cc/2024/Conference/Submission6759/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6759/Authors"], "content": {"title": {"value": "On Bias-Variance Alignment in Deep Models"}, "authors": {"value": ["Lin Chen", "Michal Lukasik", "Wittawat Jitkrittum", "Chong You", "Sanjiv Kumar"]}, "authorids": {"value": ["~Lin_Chen14", "~Michal_Lukasik1", "~Wittawat_Jitkrittum1", "~Chong_You2", "~Sanjiv_Kumar1"]}, "keywords": {"value": ["bias-variance decomposition", "ensemble", "deep learning"]}, "abstract": {"value": "Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \\emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \\emph{aligned} at a sample level, where squared bias is approximately \\emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/178a29fe5352a6013ac367fcb6cc4e69d501cb81.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024on,\ntitle={On Bias-Variance Alignment in Deep Models},\nauthor={Lin Chen and Michal Lukasik and Wittawat Jitkrittum and Chong You and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i2Phucne30}\n}"}, "paperhash": {"value": "chen|on_biasvariance_alignment_in_deep_models"}}, "number": 6759, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6759/-/Revision", "ICLR.cc/2024/Conference/Submission6759/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6759/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695438409662, "cdate": 1695438409662, "tmdate": 1710553494085, "mdate": 1710553494085, "pdate": 1705410986122, "version": 2}, {"id": "3oTPsORaDH", "forum": "3oTPsORaDH", "signatures": ["ICLR.cc/2024/Conference/Submission6713/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6713/Authors"], "content": {"title": {"value": "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases"}, "authors": {"value": ["Yang Liu", "Jiashun Cheng", "Haihong Zhao", "Tingyang Xu", "Peilin Zhao", "Fugee Tsung", "Jia Li", "Yu Rong"]}, "authorids": {"value": ["~Yang_Liu21", "~Jiashun_Cheng1", "~Haihong_Zhao2", "~Tingyang_Xu1", "~Peilin_Zhao2", "~Fugee_Tsung1", "~Jia_Li4", "~Yu_Rong1"]}, "keywords": {"value": ["Equivariant Graph Neural Network", "Graph Neural Network"]}, "abstract": {"value": "Graph Neural Networks (GNNs) with equivariant properties have emerged as powerful tools for modeling complex dynamics of multi-object physical systems. However, their generalization ability is limited by the inadequate consideration of physical inductive biases: (1) Existing studies overlook the continuity of transitions among system states, opting to employ several discrete transformation layers to learn the direct mapping between two adjacent states; (2) Most models only account for first-order velocity information, despite the fact that many physical systems are governed by second-order motion laws. To incorporate these inductive biases, we propose the Second-order Equivariant Graph Neural Ordinary Differential Equation (SEGNO). Specifically, we show how the second-order continuity can be incorporated into GNNs while maintaining the equivariant property. Furthermore, we offer theoretical insights into SEGNO, highlighting that it can learn a unique trajectory between adjacent states, which is crucial for model generalization. Additionally, we prove that the discrepancy between this learned trajectory of SEGNO and the true trajectory is bounded. Extensive experiments on complex dynamical systems including molecular dynamics and motion capture demonstrate that our model yields a significant improvement over the state-of-the-art baselines."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4acee75d595246c171ea11abc7187435b10862ea.pdf"}, "supplementary_material": {"value": "/attachment/39e5fdfd3c0682b49cf79245d7776f22592626f6.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024improving,\ntitle={Improving Generalization in Equivariant Graph Neural Networks with Physical Inductive Biases},\nauthor={Yang Liu and Jiashun Cheng and Haihong Zhao and Tingyang Xu and Peilin Zhao and Fugee Tsung and Jia Li and Yu Rong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3oTPsORaDH}\n}"}, "paperhash": {"value": "liu|segno_generalizing_equivariant_graph_neural_networks_with_physical_inductive_biases"}}, "number": 6713, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6713/-/Revision", "ICLR.cc/2024/Conference/Submission6713/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6713/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436389247, "cdate": 1695436389247, "tmdate": 1710228449727, "mdate": 1710228449727, "pdate": 1705410984493, "version": 2}, {"id": "OeQE9zsztS", "forum": "OeQE9zsztS", "signatures": ["ICLR.cc/2024/Conference/Submission6707/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6707/Authors"], "content": {"title": {"value": "Spectrally Transformed Kernel Regression"}, "authors": {"value": ["Runtian Zhai", "Rattana Pukdee", "Roger Jin", "Maria Florina Balcan", "Pradeep Kumar Ravikumar"]}, "authorids": {"value": ["~Runtian_Zhai1", "~Rattana_Pukdee1", "rrjin@andrew.cmu.edu", "~Maria_Florina_Balcan1", "~Pradeep_Kumar_Ravikumar1"]}, "keywords": {"value": ["Learning Theory", "Unlabeled Data", "Kernel Methods", "Semi-supervised Learning", "Representation Learning", "Label Propagation"]}, "TLDR": {"value": "STKR leverages unlabeled data by mixing the information from a kernel and data distribution via diffusion. We provide new STKR estimators applicable to the inductive setting, together with statistical guarantees and complexity analysis."}, "abstract": {"value": "Unlabeled data is a key component of modern machine learning. In general, the role\nof unlabeled data is to impose a form of smoothness, usually from the similarity\ninformation encoded in a base kernel, such as the \u03f5-neighbor kernel or the adjacency\nmatrix of a graph. This work revisits the classical idea of spectrally transformed\nkernel regression (STKR), and provides a new class of general and scalable STKR\nestimators able to leverage unlabeled data. Intuitively, via spectral transformation,\nSTKR exploits the data distribution for which unlabeled data can provide additional\ninformation. First, we show that STKR is a principled and general approach,\nby characterizing a universal type of \u201ctarget smoothness\u201d, and proving that any\nsufficiently smooth function can be learned by STKR. Second, we provide scalable\nSTKR implementations for the inductive setting and a general transformation\nfunction, while prior work is mostly limited to the transductive setting. Third, we\nderive statistical guarantees for two scenarios: STKR with a known polynomial\ntransformation, and STKR with kernel PCA when the transformation is unknown.\nOverall, we believe that this work helps deepen our understanding of how to work\nwith unlabeled data, and its generality makes it easier to inspire new methods."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cb1d12d196c77a2a26e09caff4a57bf370c27871.pdf"}, "supplementary_material": {"value": "/attachment/df1eff62179d298e2e70f547081871cd21b3dff6.zip"}, "_bibtex": {"value": "@inproceedings{\nzhai2024spectrally,\ntitle={Spectrally Transformed Kernel Regression},\nauthor={Runtian Zhai and Rattana Pukdee and Roger Jin and Maria Florina Balcan and Pradeep Kumar Ravikumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OeQE9zsztS}\n}"}, "paperhash": {"value": "zhai|spectrally_transformed_kernel_regression"}}, "number": 6707, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6707/-/Revision", "ICLR.cc/2024/Conference/Submission6707/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6707/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436086640, "cdate": 1695436086640, "tmdate": 1709661533672, "mdate": 1709661533672, "pdate": 1705410984226, "version": 2}, {"id": "KbetDM33YG", "forum": "KbetDM33YG", "signatures": ["ICLR.cc/2024/Conference/Submission6661/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6661/Authors"], "content": {"title": {"value": "Online GNN Evaluation Under Test-time Graph Distribution Shifts"}, "authors": {"value": ["Xin Zheng", "Dongjin Song", "Qingsong Wen", "Bo Du", "Shirui Pan"]}, "authorids": {"value": ["~Xin_Zheng4", "~Dongjin_Song2", "~Qingsong_Wen2", "~Bo_Du3", "~Shirui_Pan1"]}, "keywords": {"value": ["Graph neural networks", "Model evaluation", "Distribution shift"]}, "abstract": {"value": "Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. \nDue to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time.\nIn this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts.\nConcretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. \nThrough a novel GNN re-training strategy with a parameter-free optimality criterion, the proposed LeBeD comprehensively integrates learning behavior discrepancies from both node prediction and structure reconstruction perspectives.\nThis enables the effective evaluation of the well-trained GNNs' ability to capture test node semantics and structural representations, making it an expressive metric for estimating the generalization error in online GNN evaluation.\nExtensive experiments on real-world test graphs under diverse graph distribution shifts could verify the effectiveness of the proposed method, revealing its strong correlation with ground-truth test errors on various well-trained GNN models."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3b5dbcc5108726d3892b0ca05c69f9fa4eca4529.pdf"}, "_bibtex": {"value": "@inproceedings{\nzheng2024online,\ntitle={Online {GNN} Evaluation Under Test-time Graph Distribution Shifts},\nauthor={Xin Zheng and Dongjin Song and Qingsong Wen and Bo Du and Shirui Pan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KbetDM33YG}\n}"}, "paperhash": {"value": "zheng|online_gnn_evaluation_under_testtime_graph_distribution_shifts"}}, "number": 6661, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6661/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6661/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695433740416, "cdate": 1695433740416, "tmdate": 1710463526358, "mdate": 1710463526358, "pdate": 1705410982809, "version": 2}, {"id": "TjhUtloBZU", "forum": "TjhUtloBZU", "signatures": ["ICLR.cc/2024/Conference/Submission6649/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6649/Authors"], "content": {"title": {"value": "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks"}, "authors": {"value": ["Hao Chen", "Jindong Wang", "Ankit Shah", "Ran Tao", "Hongxin Wei", "Xing Xie", "Masashi Sugiyama", "Bhiksha Raj"]}, "authorids": {"value": ["~Hao_Chen15", "~Jindong_Wang1", "~Ankit_Shah1", "~Ran_Tao2", "~Hongxin_Wei1", "~Xing_Xie3", "~Masashi_Sugiyama1", "~Bhiksha_Raj1"]}, "keywords": {"value": ["Pre training", "Noisy model learning", "Label noise", "Noise mitigation"]}, "abstract": {"value": "Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a light-weight black-box tuning method (NMTune) to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models. We conduct practical experiments on popular vision and language models that are pre-trained on noisy data for evaluation of our approach. Our analysis and results show the importance of this interesting and novel research direction, which we term Noisy Model Learning."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ae1d6d7106b28a7cb9cacfd2f2b5dd34c10f0ce0.pdf"}, "supplementary_material": {"value": "/attachment/385394a5c9241244693eea1636b2cf1916324236.zip"}, "_bibtex": {"value": "@inproceedings{\nchen2024understanding,\ntitle={Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks},\nauthor={Hao Chen and Jindong Wang and Ankit Shah and Ran Tao and Hongxin Wei and Xing Xie and Masashi Sugiyama and Bhiksha Raj},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TjhUtloBZU}\n}"}, "paperhash": {"value": "chen|understanding_and_mitigating_the_label_noise_in_pretraining_on_downstream_tasks"}}, "number": 6649, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6649/-/Revision", "ICLR.cc/2024/Conference/Submission6649/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6649/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695433044030, "cdate": 1695433044030, "tmdate": 1710172359908, "mdate": 1710172359908, "pdate": 1705410982414, "version": 2}, {"id": "Bl8u7ZRlbM", "forum": "Bl8u7ZRlbM", "signatures": ["ICLR.cc/2024/Conference/Submission6648/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6648/Authors"], "content": {"title": {"value": "(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild"}, "authors": {"value": ["Wenting Zhao", "Xiang Ren", "Jack Hessel", "Claire Cardie", "Yejin Choi", "Yuntian Deng"]}, "authorids": {"value": ["~Wenting_Zhao1", "~Xiang_Ren1", "~Jack_Hessel1", "~Claire_Cardie1", "~Yejin_Choi1", "~Yuntian_Deng2"]}, "keywords": {"value": ["new corpus", "user study", "dialogues", "conversations", "chatGPT", "instruction fine-tuning", "toxicity", "safe guarding", "AI safety"]}, "TLDR": {"value": "We collect over 570K user-chatGPT conversations in the wild."}, "abstract": {"value": "Chatbots such as GPT-4 and ChatGPT are now serving millions of users. Despite their widespread use, there remains a lack of public datasets showcasing how these tools are used by a population of users in practice. To bridge this gap, we offered free access to ChatGPT for online users in exchange for their affirmative, consensual, opt-in for anonymous collection of their chat transcripts. From this, we compiled (InThe)WildChat, a corpus of 570K user-ChatGPT conversations, which consists of over 1.5 million interaction turns. We compare WildChat with other popular user-chatbot interaction datasets, and find that our dataset offers the most diverse user prompts, contains the largest number of languages, and presents the richest variety of potentially toxic use-cases for researchers to study. In particular, in WildChat we find that a majority of the potentially unsafe use is produced by users attempting to \u201cjailbreak\u201d the model using prompts posted on online platforms; these are successful more than 70% of the time for ChatGPT. Finally, because it captures a broad range of use cases, we demonstrate the dataset\u2019s potential utility in fine-tuning state-of-the-art instruction following models. WildLlama, a chatbot fine-tuned on WildChat, outperforms the latest Vicuna model of the same size on MT-Bench, which shows that WildChat has a high utility in addition to being a source for toxicity study. We will release WildChat and WildLlama with a license that emphasizes on accountability, collaboration, and transparency. The clean portion of WildChat will be publicly available, and the portion that contains potentially unsafe content will be made available upon request with a justification for AI safety research."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fe0e5ea5a8ee74a30354ee1d2cd4c8bc9becebbe.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhao2024inthewildchat,\ntitle={(InThe)WildChat: 570K Chat{GPT} Interaction Logs In The Wild},\nauthor={Wenting Zhao and Xiang Ren and Jack Hessel and Claire Cardie and Yejin Choi and Yuntian Deng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Bl8u7ZRlbM}\n}"}, "paperhash": {"value": "zhao|inthewildchat_570k_chatgpt_interaction_logs_in_the_wild"}}, "number": 6648, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6648/-/Revision", "ICLR.cc/2024/Conference/Submission6648/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695432877022, "cdate": 1695432877022, "tmdate": 1707625633972, "mdate": 1707625633972, "pdate": 1705410982341, "version": 2}, {"id": "IRcv4yFX6z", "forum": "IRcv4yFX6z", "signatures": ["ICLR.cc/2024/Conference/Submission6646/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6646/Authors"], "content": {"title": {"value": "Learning Hierarchical Image Segmentation For Recognition and By Recognition"}, "authors": {"value": ["Tsung-Wei Ke", "Sangwoo Mo", "Stella X. Yu"]}, "authorids": {"value": ["~Tsung-Wei_Ke2", "~Sangwoo_Mo1", "~Stella_X._Yu2"]}, "keywords": {"value": ["segmentation in the loop for recognition", "hierarchical segmentation", "part-to-whole recognition", "vision transformer"]}, "TLDR": {"value": "We propose a learning framework that integrates segmentation in the loop for recognition, enabling concurrent hierarchical segmentation and recognition using a single model."}, "abstract": {"value": "Image segmentation and recognition occur simultaneously, with recognition relying on the underlying segmentation to form a continuous visual grouping hierarchy. For example, the same object can be parsed into different part-to-whole structures, resulting in varying recognitions. Despite this, most prior works treated segmentation and recognition as separate tasks.\nIn this paper, we aim to devise a learning framework that involves segmentation in the recognition process, utilizing hierarchical segmentation *for* recognition, which is learned *by* recognition. Specifically, we propose CAST, which realizes this concept through designs inspired by vision transformers, enabling concurrent segmentation and recognition with a single model. The core idea of CAST is to employ adaptive segment tokens that group the finest pixels into coarser segments, using the latest embedding to represent the entire image for recognition. Trained solely on image recognition objectives, CAST automatically discovers the hierarchy of segments.\nOur experiments demonstrate that CAST provides consistent hierarchical segmentation and recognition, which is impossible with state-of-the-art segmentation methods such as SAM. Additionally, CAST offers several advantages over the standard ViT, including improved semantic segmentation, computational efficiency, and object-centric attention.  Code available at [https://github.com/twke18/CAST](https://github.com/twke18/CAST)."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1dad3ae953093521ef26de14c6672c8c04440b65.pdf"}, "supplementary_material": {"value": "/attachment/24d9d0bb53be30feea6b1af0b4ef0e187b93f269.zip"}, "_bibtex": {"value": "@inproceedings{\nke2024learning,\ntitle={Learning Hierarchical Image Segmentation For Recognition and By Recognition},\nauthor={Tsung-Wei Ke and Sangwoo Mo and Stella X. Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IRcv4yFX6z}\n}"}, "paperhash": {"value": "ke|learning_hierarchical_image_segmentation_for_recognition_and_by_recognition"}}, "number": 6646, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6646/-/Revision", "ICLR.cc/2024/Conference/Submission6646/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6646/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695432627282, "cdate": 1695432627282, "tmdate": 1713152568926, "mdate": 1713152568926, "pdate": 1705410982263, "version": 2}, {"id": "plmBsXHxgR", "forum": "plmBsXHxgR", "signatures": ["ICLR.cc/2024/Conference/Submission6613/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6613/Authors"], "content": {"title": {"value": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models"}, "authors": {"value": ["Erfan Shayegani", "Yue Dong", "Nael Abu-Ghazaleh"]}, "authorids": {"value": ["~Erfan_Shayegani1", "~Yue_Dong2", "~Nael_Abu-Ghazaleh2"]}, "keywords": {"value": ["Adversarial attacks", "Vision encoders", "Jailbreak", "Prompt Injection", "Security", "Embedding space attacks", "Black box", "LLM", "Vision-Language Models", "Multi-Modal Models", "VLM", "Alignment", "Cross-Modality alignment"]}, "abstract": {"value": "We introduce new jailbreak attacks on vision language models (VLMs), which use aligned LLMs and are resilient to text-only jailbreak attacks. Specifically, we develop cross-modality attacks on alignment where we pair adversarial images going through the vision encoder with textual prompts to break the alignment of the language model. Our attacks employ a novel compositional strategy that combines an image, adversarially targeted towards toxic embeddings, with generic prompts to accomplish the jailbreak. Thus, the LLM draws the context to answer the generic prompt from the adversarial image. The generation of benign-appearing adversarial images leverages a novel embedding-space-based methodology, operating with no access to the LLM model. Instead, the attacks require access only to the vision encoder and utilize one of our four embedding space targeting strategies. By not requiring access to the LLM, the attacks lower the entry barrier for attackers, particularly when vision encoders such as CLIP are embedded in closed-source LLMs. The attacks achieve a high success rate across different VLMs, highlighting the risk of cross-modality alignment vulnerabilities, and the need for new alignment approaches for multi-modal models."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/73245653c0cb13379877051e65dbc93ef4aa85cd.pdf"}, "supplementary_material": {"value": "/attachment/35ff9ea0935ed48be01503d14fdd0b2dbabb0ad0.zip"}, "_bibtex": {"value": "@inproceedings{\nshayegani2024jailbreak,\ntitle={Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models},\nauthor={Erfan Shayegani and Yue Dong and Nael Abu-Ghazaleh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=plmBsXHxgR}\n}"}, "paperhash": {"value": "shayegani|jailbreak_in_pieces_compositional_adversarial_attacks_on_multimodal_language_models"}}, "number": 6613, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6613/-/Revision", "ICLR.cc/2024/Conference/Submission6613/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6613/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430607462, "cdate": 1695430607462, "tmdate": 1710179346282, "mdate": 1710179346282, "pdate": 1705410981152, "version": 2}, {"id": "GURqUuTebY", "forum": "GURqUuTebY", "signatures": ["ICLR.cc/2024/Conference/Submission6601/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6601/Authors"], "content": {"title": {"value": "DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow"}, "authors": {"value": ["Kyungmin Lee", "Kihyuk Sohn", "Jinwoo Shin"]}, "authorids": {"value": ["~Kyungmin_Lee1", "~Kihyuk_Sohn1", "~Jinwoo_Shin1"]}, "keywords": {"value": ["Text-to-3D generation", "Diffusion model", "Score Distillation Sampling"]}, "abstract": {"value": "Recent progress in text-to-3D generation has been achieved through the utilization of score distillation methods: they make use of the pre-trained text-to-image (T2I) diffusion models by distilling via the diffusion model training objective. However, such an approach inevitably results in the use of random timesteps at each update, which increases the variance of the gradient and ultimately prolongs the optimization process. In this paper, we propose to enhance the text-to-3D optimization by leveraging the T2I diffusion prior in the generative sampling process with a predetermined timestep schedule. To this end, we interpret text-to-3D optimization as a multi-view image-to-image translation problem, and propose a solution by approximating the probability flow. By leveraging the proposed novel optimization algorithm, we design DreamFlow, a practical three-stage coarse-to-fine text-to-3D optimization framework that enables fast generation of high-quality and high-resolution (i.e., 1024\u00d71024) 3D contents. For example, we demonstrate that DreamFlow is 5 times faster than the existing state-of-the-art text-to-3D method, while producing more photorealistic 3D contents."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/65b059da26adcac6aded2561eda017af0181ec6d.pdf"}, "supplementary_material": {"value": "/attachment/1c19ac7a118cf01ab18c80ecc40b65451328e55d.zip"}, "_bibtex": {"value": "@inproceedings{\nlee2024dreamflow,\ntitle={DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow},\nauthor={Kyungmin Lee and Kihyuk Sohn and Jinwoo Shin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GURqUuTebY}\n}"}, "paperhash": {"value": "lee|dreamflow_highquality_textto3d_generation_by_approximating_probability_flow"}}, "number": 6601, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6601/-/Revision", "ICLR.cc/2024/Conference/Submission6601/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6601/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430122864, "cdate": 1695430122864, "tmdate": 1710946898517, "mdate": 1710946898517, "pdate": 1705410980771, "version": 2}, {"id": "XVhm3X8Fum", "forum": "XVhm3X8Fum", "signatures": ["ICLR.cc/2024/Conference/Submission6568/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6568/Authors"], "content": {"title": {"value": "Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns"}, "authors": {"value": ["Brian DuSell", "David Chiang"]}, "authorids": {"value": ["~Brian_DuSell1", "~David_Chiang1"]}, "keywords": {"value": ["transformer", "attention", "context-free languages", "pushdown automata", "formal languages", "language modeling", "machine translation"]}, "TLDR": {"value": "We propose new attention operators that use stacks as a latent model of syntax, improving transformer language modeling on context-free languages and natural language."}, "abstract": {"value": "Attention, specifically scaled dot-product attention, has proven effective for natural language, but it does not have a mechanism for handling hierarchical patterns of arbitrary nesting depth, which limits its ability to recognize certain syntactic structures. To address this shortcoming, we propose stack attention: an attention operator that incorporates stacks, inspired by their theoretical connections to context-free languages (CFLs). We show that stack attention is analogous to standard attention, but with a latent model of syntax that requires no syntactic supervision. We propose two variants: one related to deterministic pushdown automata (PDAs) and one based on nondeterministic PDAs, which allows transformers to recognize arbitrary CFLs. We show that transformers with stack attention are very effective at learning CFLs that standard transformers struggle on, achieving strong results on a CFL with theoretically maximal parsing difficulty. We also show that stack attention is more effective at natural language modeling under a constrained parameter budget, and we include results on machine translation."}, "pdf": {"value": "/pdf/1725d2a5bfd546b5acdabab5eb5d281caf92d1e4.pdf"}, "supplementary_material": {"value": "/attachment/e1831149abdf78111ed7c5f362c2bd0628013755.zip"}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\ndusell2024stack,\ntitle={Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns},\nauthor={Brian DuSell and David Chiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XVhm3X8Fum}\n}"}, "paperhash": {"value": "dusell|stack_attention_improving_the_ability_of_transformers_to_model_hierarchical_patterns"}}, "number": 6568, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6568/-/Revision", "ICLR.cc/2024/Conference/Submission6568/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6568/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695428327787, "cdate": 1695428327787, "tmdate": 1709661532643, "mdate": 1709661532643, "pdate": 1705410979684, "version": 2}, {"id": "mM7VurbA4r", "forum": "mM7VurbA4r", "signatures": ["ICLR.cc/2024/Conference/Submission6556/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6556/Authors"], "content": {"title": {"value": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents"}, "authors": {"value": ["Xuhui Zhou", "Hao Zhu", "Leena Mathur", "Ruohong Zhang", "Haofei Yu", "Zhengyang Qi", "Louis-Philippe Morency", "Yonatan Bisk", "Daniel Fried", "Graham Neubig", "Maarten Sap"]}, "authorids": {"value": ["~Xuhui_Zhou1", "~Hao_Zhu1", "~Leena_Mathur1", "~Ruohong_Zhang1", "~Haofei_Yu1", "~Zhengyang_Qi1", "~Louis-Philippe_Morency1", "~Yonatan_Bisk1", "~Daniel_Fried1", "~Graham_Neubig1", "~Maarten_Sap1"]}, "keywords": {"value": ["Social", "Interaction", "Agent", "Social intelligence", "Large Language Models", "Evaluation", "Theory of Mind"]}, "abstract": {"value": "*Humans are social beings*; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and *interact* under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completion rate than humans and struggles to exhibit social commonsense reasoning and strategic communication skills. These findings demonstrate SOTOPIA's promise as a general platform for research on evaluating and improving social intelligence in artificial agents."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6aece1f9088fc415196df5830f1ca62e6dbf37d3.pdf"}, "TLDR": {"value": "SOTOPIA is a novel, challenging, and interactive benchmark that could serve as the perfect test-bed and potential incubator for social intelligence."}, "_bibtex": {"value": "@inproceedings{\nzhou2024sotopia,\ntitle={{SOTOPIA}: Interactive Evaluation for Social Intelligence in Language Agents},\nauthor={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mM7VurbA4r}\n}"}, "paperhash": {"value": "zhou|sotopia_interactive_evaluation_for_social_intelligence_in_language_agents"}}, "number": 6556, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6556/-/Revision", "ICLR.cc/2024/Conference/Submission6556/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6556/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427641667, "cdate": 1695427641667, "tmdate": 1710962984540, "mdate": 1710962984540, "pdate": 1705410979326, "version": 2}, {"id": "rvUq3cxpDF", "forum": "rvUq3cxpDF", "signatures": ["ICLR.cc/2024/Conference/Submission6510/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6510/Authors"], "content": {"title": {"value": "Learning to Act without Actions"}, "authors": {"value": ["Dominik Schmidt", "Minqi Jiang"]}, "authorids": {"value": ["~Dominik_Schmidt2", "~Minqi_Jiang1"]}, "keywords": {"value": ["reinforcement learning", "world models", "inverse dynamics models", "imitation learning", "representation learning"]}, "abstract": {"value": "Pre-training large models on vast amounts of web data has proven to be an effective approach for obtaining powerful, general models in domains such as language and vision. However, this paradigm has not yet taken hold in reinforcement learning. This is because videos, the most abundant form of embodied behavioral data on the web, lack the action labels required by existing methods for imitating behavior from demonstrations. We introduce **Latent Action Policies** (LAPO), a method for recovering latent action information\u2014and thereby latent-action policies, world models, and inverse dynamics models\u2014purely from videos. LAPO is the first method able to recover the structure of the true action space just from observed dynamics, even in challenging procedurally-generated environments. LAPO enables training latent-action policies that can be rapidly fine-tuned into expert-level policies, either offline using a small action-labeled dataset, or online with rewards. LAPO takes a first step towards pre-training powerful, generalist policies and world models on the vast amounts of videos readily available on the web. Our code is available here: \n[https://github.com/schmidtdominik/LAPO](https://github.com/schmidtdominik/LAPO)."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3828f51b4c06dfddf96ff09f99344482461b30d4.pdf"}, "TLDR": {"value": "We introduce Latent Action Policies (LAPO), a method for recovering latent action information\u2014and thereby latent-action policies, world models, and inverse dynamics models\u2014purely from videos."}, "_bibtex": {"value": "@inproceedings{\nschmidt2024learning,\ntitle={Learning to Act without Actions},\nauthor={Dominik Schmidt and Minqi Jiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rvUq3cxpDF}\n}"}, "paperhash": {"value": "schmidt|learning_to_act_without_actions"}}, "number": 6510, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6510/-/Revision", "ICLR.cc/2024/Conference/Submission6510/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6510/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425345849, "cdate": 1695425345849, "tmdate": 1711496075115, "mdate": 1711496075115, "pdate": 1705410978138, "version": 2}, {"id": "zMvMwNvs4R", "forum": "zMvMwNvs4R", "signatures": ["ICLR.cc/2024/Conference/Submission6463/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6463/Authors"], "content": {"title": {"value": "Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models"}, "authors": {"value": ["Tianjian Li", "Haoran Xu", "Philipp Koehn", "Daniel Khashabi", "Kenton Murray"]}, "authorids": {"value": ["~Tianjian_Li1", "~Haoran_Xu3", "~Philipp_Koehn2", "~Daniel_Khashabi2", "~Kenton_Murray1"]}, "keywords": {"value": ["language generation", "language modeling", "machine translation", "robustness", "estimating data quality"]}, "TLDR": {"value": "We propose to truncate tokens with high L2 error norm to improve robustness of text generation models to noise."}, "abstract": {"value": "Text generation models are notoriously vulnerable to errors in the training data. With the wide-spread availability of massive amounts of web-crawled data becoming more commonplace, how can we enhance the robustness of models trained on a massive amount of noisy web-crawled text? In our work, we propose Error Norm Truncation (ENT), a robust enhancement method to the standard training objective that truncates noisy data. Compared to methods that only uses the negative log-likelihood loss to estimate data quality, our method provides a more accurate estimation by considering the distribution of non-target tokens, which is often overlooked by previous work. Through comprehensive experiments across language modeling, machine translation, and text summarization, we show that equipping text generation models with ENT improves generation quality over standard training and previous soft and hard truncation methods. Furthermore, we show that our method improves the robustness of models against two of the most detrimental types of noise in machine translation, resulting in an increase of more than 2 BLEU points over the MLE baseline when up to 50\\% of noise is added to the data."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f26c396130ee811d490f099f908c0b8c99a3382.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024error,\ntitle={Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models},\nauthor={Tianjian Li and Haoran Xu and Philipp Koehn and Daniel Khashabi and Kenton Murray},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zMvMwNvs4R}\n}"}, "paperhash": {"value": "li|error_norm_truncation_robust_training_in_the_presence_of_data_noise_for_text_generation_models"}}, "number": 6463, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6463/-/Revision", "ICLR.cc/2024/Conference/Submission6463/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6463/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423273678, "cdate": 1695423273678, "tmdate": 1710789588825, "mdate": 1710789588825, "pdate": 1705410976696, "version": 2}, {"id": "z3L59iGALM", "forum": "z3L59iGALM", "signatures": ["ICLR.cc/2024/Conference/Submission6446/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6446/Authors"], "content": {"title": {"value": "Massively Scalable Inverse Reinforcement Learning in Google Maps"}, "authors": {"value": ["Matt Barnes", "Matthew Abueg", "Oliver F. Lange", "Matt Deeds", "Jason Trader", "Denali Molitor", "Markus Wulfmeier", "Shawn O'Banion"]}, "authorids": {"value": ["~Matt_Barnes1", "~Matthew_Abueg1", "~Oliver_F._Lange1", "~Matt_Deeds1", "~Jason_Trader1", "~Denali_Molitor1", "~Markus_Wulfmeier1", "~Shawn_O'Banion1"]}, "keywords": {"value": ["Inverse reinforcement learning", "route optimization"]}, "abstract": {"value": "Inverse reinforcement learning (IRL) offers a powerful and general framework for learning humans' latent preferences in route recommendation, yet no approach has successfully addressed planetary-scale problems with hundreds of millions of states and demonstration trajectories. In this paper, we introduce scaling techniques based on graph compression, spatial parallelization, and improved initialization conditions inspired by a connection to eigenvector algorithms. We revisit classic IRL methods in the routing context, and make the key observation that there exists a trade-off between the use of cheap, deterministic planners and expensive yet robust stochastic policies. This insight is leveraged in Receding Horizon Inverse Planning (RHIP), a new generalization of classic IRL algorithms that provides fine-grained control over performance trade-offs via its planning horizon. Our contributions culminate in a policy that achieves a 16-24% improvement in route quality at a global scale, and to the best of our knowledge, represents the largest published study of IRL algorithms in a real-world setting to date. We conclude by conducting an ablation study of key components, presenting negative results from alternative eigenvalue solvers, and identifying opportunities to further improve scalability via IRL-specific batching strategies."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4d44d3413d097944d3e6328c02e01436c56a3fac.pdf"}, "_bibtex": {"value": "@inproceedings{\nbarnes2024massively,\ntitle={Massively Scalable Inverse Reinforcement Learning for Route Optimization},\nauthor={Matt Barnes and Matthew Abueg and Oliver F. Lange and Matt Deeds and Jason Trader and Denali Molitor and Markus Wulfmeier and Shawn O'Banion},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=z3L59iGALM}\n}"}, "paperhash": {"value": "barnes|massively_scalable_inverse_reinforcement_learning_in_google_maps"}}, "number": 6446, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6446/-/Revision", "ICLR.cc/2024/Conference/Submission6446/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6446/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695422215421, "cdate": 1695422215421, "tmdate": 1709675572715, "mdate": 1709675572715, "pdate": 1705410976198, "version": 2}, {"id": "KsUh8MMFKQ", "forum": "KsUh8MMFKQ", "signatures": ["ICLR.cc/2024/Conference/Submission6426/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6426/Authors"], "content": {"title": {"value": "Thin-Shell Object Manipulations With Differentiable Physics Simulations"}, "authors": {"value": ["Yian Wang", "Juntian Zheng", "Zhehuan Chen", "Zhou Xian", "Gu Zhang", "Chao Liu", "Chuang Gan"]}, "authorids": {"value": ["~Yian_Wang1", "~Juntian_Zheng1", "~Zhehuan_Chen1", "~Zhou_Xian1", "~Gu_Zhang1", "~Chao_Liu9", "~Chuang_Gan1"]}, "keywords": {"value": ["differentiable physics simulation", "thin-shell object manipulation"]}, "abstract": {"value": "In this work, we aim to teach robots to manipulate various thin-shell materials. \nPrior works studying thin-shell object manipulation mostly rely on heuristic policies or learn policies from real-world video demonstrations, and only focus on limited material types and tasks (e.g., cloth unfolding). However, these approaches face significant challenges when extended to a wider variety of thin-shell materials and a diverse range of tasks.\nOn the other hand, while virtual simulations are shown to be effective in diverse robot skill learning and evaluation, prior thin-shell simulation environments only support a subset of thin-shell materials, which also limits their supported range of tasks. \nTo fill in this gap, we introduce ThinShellLab - a fully differentiable simulation platform tailored for robotic interactions with diverse thin-shell materials possessing varying material properties, enabling flexible thin-shell manipulation skill learning and evaluation. Building on top of our developed simulation engine, we design a diverse set of manipulation tasks centered around different thin-shell objects. Our experiments suggest that manipulating thin-shell objects presents several unique challenges: 1) thin-shell manipulation relies heavily on frictional forces due to the objects' co-dimensional nature, 2) the materials being manipulated are highly sensitive to minimal variations in interaction actions, and 3) the constant and frequent alteration in contact pairs makes trajectory optimization methods susceptible to local optima, and neither standard reinforcement learning algorithms nor trajectory optimization methods (either gradient-based or gradient-free) are able to solve the tasks alone. To overcome these challenges, we present an optimization scheme that couples sampling-based trajectory optimization and gradient-based optimization, boosting both learning efficiency and converged performance across various proposed tasks. In addition, the differentiable nature of our platform facilitates a smooth sim-to-real transition. By tuning simulation parameters with a minimal set of real-world data, we demonstrate successful deployment of the learned skills to real-robot settings.  ThinShellLab will be publicly available. Video demonstration and more information can be found on the project website https://vis-www.cs.umass.edu/ThinShellLab/."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/edbd3be2c1ca4369cdf41d2d892af284a0c21cc3.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024thinshell,\ntitle={Thin-Shell Object Manipulations With Differentiable Physics Simulations},\nauthor={Yian Wang and Juntian Zheng and Zhehuan Chen and Zhou Xian and Gu Zhang and Chao Liu and Chuang Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KsUh8MMFKQ}\n}"}, "paperhash": {"value": "wang|thinshell_object_manipulations_with_differentiable_physics_simulations"}}, "number": 6426, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6426/-/Revision", "ICLR.cc/2024/Conference/Submission6426/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6426/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421181666, "cdate": 1695421181666, "tmdate": 1711771754560, "mdate": 1711771754560, "pdate": 1705410975647, "version": 2}, {"id": "7erlRDoaV8", "forum": "7erlRDoaV8", "signatures": ["ICLR.cc/2024/Conference/Submission6400/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6400/Authors"], "content": {"title": {"value": "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks"}, "authors": {"value": ["Vaidehi Patil", "Peter Hase", "Mohit Bansal"]}, "authorids": {"value": ["~Vaidehi_Patil1", "~Peter_Hase1", "~Mohit_Bansal2"]}, "keywords": {"value": ["Sensitive Information Deletion", "Privacy Attacks", "Model editing", "Language Models"]}, "abstract": {"value": "Pretrained language models sometimes possess knowledge that we do not wish them to, including memorized personal information and knowledge that could be used to harm people. They can also output toxic or harmful text. To mitigate these safety and informational issues, we propose an attack-and-defense framework for studying the task of deleting sensitive information directly from model weights. We study direct edits to model weights because (1) this approach should guarantee that particular deleted information is never extracted by future prompt attacks, and (2) it should protect against whitebox attacks, which is necessary for making claims about safety/privacy in a setting where publicly available model weights could be used to elicit sensitive information. Our threat model assumes that an attack succeeds if the answer to a sensitive question is located among a set of B generated candidates, based on scenarios where the information would be insecure if the answer is among B candidates. Experimentally, we show that even state-of-the-art model editing methods such as ROME struggle to truly delete factual information from models like GPT-J, as our whitebox and blackbox attacks can recover \u201cdeleted\u201d information from an edited model 38% of the time. These attacks leverage two key observations: (1) that traces of deleted information can be found in intermediate model hidden states, and (2) that applying an editing method for one question may not delete information across rephrased versions of the question. Finally, we provide new defense methods that protect against some extraction attacks, but we do not find a single universally effective defense method. Our results suggest that truly deleting sensitive information is a tractable but difficult problem, since even relatively low attack success rates have potentially severe implications for the deployment of language models in a world where individuals enjoy ownership of their personal data, a right to privacy, and safety from harmful model outputs."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/58461c89ea8f999b82924f883aa34b627914dc42.pdf"}, "supplementary_material": {"value": "/attachment/fb642952d68748c4c3da0a925fd0602ac68ae134.zip"}, "_bibtex": {"value": "@inproceedings{\npatil2024can,\ntitle={Can Sensitive Information Be Deleted From {LLM}s? Objectives for Defending Against Extraction Attacks},\nauthor={Vaidehi Patil and Peter Hase and Mohit Bansal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7erlRDoaV8}\n}"}, "paperhash": {"value": "patil|can_sensitive_information_be_deleted_from_llms_objectives_for_defending_against_extraction_attacks"}}, "number": 6400, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6400/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6400/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695420227031, "cdate": 1695420227031, "tmdate": 1710599679223, "mdate": 1710599679223, "pdate": 1705410974777, "version": 2}, {"id": "ta26LtNq2r", "forum": "ta26LtNq2r", "signatures": ["ICLR.cc/2024/Conference/Submission6368/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6368/Authors"], "content": {"title": {"value": "Learning to Reject for Balanced Error and Beyond"}, "authors": {"value": ["Harikrishna Narasimhan", "Aditya Krishna Menon", "Wittawat Jitkrittum", "Neha Gupta", "Sanjiv Kumar"]}, "authorids": {"value": ["~Harikrishna_Narasimhan1", "~Aditya_Krishna_Menon1", "~Wittawat_Jitkrittum1", "~Neha_Gupta1", "~Sanjiv_Kumar1"]}, "keywords": {"value": ["Learning to reject", "balanced error", "evaluation metrics", "selective classification", "plug-in approach", "long-tail learning", "class imbalance", "non-decomposable metrics"]}, "TLDR": {"value": "Theoretically-grounded approach for learning to reject with general evaluation metrics including the balanced and worst-group errors"}, "abstract": {"value": "Learning to reject (L2R) is a classical problem where one seeks a classifier capable of abstaining on low-confidence samples. Most prior work on L2R has focused on minimizing the standard misclassification error. However, in many real-world applications, the label distribution is highly imbalanced,  necessitating alternate evaluation metrics such as the balanced error or the worst-group error that enforce equitable performance across both the head and tail classes. In this paper, we establish that traditional L2R methods can be grossly sub-optimal for such metrics, and show that this is due to an intricate  dependence in the objective between the label costs and the rejector. We then derive the form of the Bayes-optimal classifier and rejector for the balanced error, propose a novel plug-in approach to mimic this solution, and extend our results to general evaluation metrics. Through experiments on benchmark  image classification tasks, we show that our approach yields better trade-offs in both the balanced and worst-group error compared to L2R baselines."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fc5aa3e0c38abb3e7d2f07196f6dbdbc4ff705dc.pdf"}, "_bibtex": {"value": "@inproceedings{\nnarasimhan2024learning,\ntitle={Learning to Reject for Balanced Error and Beyond},\nauthor={Harikrishna Narasimhan and Aditya Krishna Menon and Wittawat Jitkrittum and Neha Gupta and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ta26LtNq2r}\n}"}, "paperhash": {"value": "narasimhan|learning_to_reject_for_balanced_error_and_beyond"}}, "number": 6368, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6368/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6368/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418806719, "cdate": 1695418806719, "tmdate": 1711398755278, "mdate": 1711398755278, "pdate": 1705410973784, "version": 2}, {"id": "Tj3xLVuE9f", "forum": "Tj3xLVuE9f", "signatures": ["ICLR.cc/2024/Conference/Submission6363/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6363/Authors"], "content": {"title": {"value": "On the Foundations of Shortcut Learning"}, "authors": {"value": ["Katherine Hermann", "Hossein Mobahi", "Thomas FEL", "Michael Curtis Mozer"]}, "authorids": {"value": ["~Katherine_Hermann1", "~Hossein_Mobahi2", "~Thomas_FEL1", "~Michael_Curtis_Mozer1"]}, "keywords": {"value": ["shortcut learning", "spurious correlations", "architectural inductive bias"]}, "abstract": {"value": "Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on *predictivity*---how reliably a feature indicates training-set labels---but also on *availability*---how easily the feature can be extracted from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and we quantify a model's shortcut bias---its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less available, more predictive) feature. We find that linear models are relatively unbiased, but introducing a single hidden layer with ReLU or Tanh units yields a bias. Our empirical findings are consistent with a theoretical account based on Neural Tangent Kernels. Finally, we study how models used in practice trade off predictivity and availability in naturalistic datasets, discovering availability manipulations which increase models' degree of shortcut bias. Taken together, these findings suggest that the propensity to learn shortcut features is a fundamental characteristic of deep nonlinear architectures warranting systematic study given its role in shaping how models solve tasks."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3f47b29f0e35691e7047d9fbfa0e4c47ea966e49.pdf"}, "_bibtex": {"value": "@inproceedings{\nhermann2024on,\ntitle={On the Foundations of Shortcut Learning},\nauthor={Katherine Hermann and Hossein Mobahi and Thomas FEL and Michael Curtis Mozer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tj3xLVuE9f}\n}"}, "paperhash": {"value": "hermann|on_the_foundations_of_shortcut_learning"}}, "number": 6363, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6363/-/Revision", "ICLR.cc/2024/Conference/Submission6363/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6363/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418758228, "cdate": 1695418758228, "tmdate": 1710544298787, "mdate": 1710544298787, "pdate": 1705410973678, "version": 2}, {"id": "x5txICnnjC", "forum": "x5txICnnjC", "signatures": ["ICLR.cc/2024/Conference/Submission6281/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6281/Authors"], "content": {"title": {"value": "Synaptic Weight Distributions Depend on the Geometry of Plasticity"}, "authors": {"value": ["Roman Pogodin", "Jonathan Cornford", "Arna Ghosh", "Gauthier Gidel", "Guillaume Lajoie", "Blake Aaron Richards"]}, "authorids": {"value": ["~Roman_Pogodin1", "~Jonathan_Cornford1", "~Arna_Ghosh1", "~Gauthier_Gidel1", "~Guillaume_Lajoie1", "~Blake_Aaron_Richards1"]}, "keywords": {"value": ["synaptic weight distributions", "synaptic plasticity", "biologically plausible learning", "mirror descent"]}, "TLDR": {"value": "different algorithms result in different synaptic weight distributions, and the log-normal one is consistent with exponentiated gradient"}, "abstract": {"value": "A growing literature in computational neuroscience leverages gradient descent and learning algorithms that approximate it to study synaptic plasticity in the brain. However, the vast majority of this work ignores a critical underlying assumption: the choice of distance for synaptic changes - i.e. the geometry of synaptic plasticity. Gradient descent assumes that the distance is Euclidean, but many other distances are possible, and there is no reason that biology necessarily uses Euclidean geometry. Here, using the theoretical tools provided by mirror descent, we show that the distribution of synaptic weights will depend on the geometry of synaptic plasticity. We use these results to show that experimentally-observed log-normal weight distributions found in several brain areas are not consistent with standard gradient descent (i.e. a Euclidean geometry), but rather with non-Euclidean distances. Finally, we show that it should be possible to experimentally test for different synaptic geometries by comparing synaptic weight distributions before and after learning. Overall, our work shows that the current paradigm in theoretical work on synaptic plasticity that assumes Euclidean synaptic geometry may be misguided and that it should be possible to experimentally determine the true geometry of synaptic plasticity in the brain."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bfba522bee31428aed87f14e95fb1c48baff7080.pdf"}, "supplementary_material": {"value": "/attachment/bc85f823c1bbd6cef9bc82ae4e690f0f95420683.zip"}, "_bibtex": {"value": "@inproceedings{\npogodin2024synaptic,\ntitle={Synaptic Weight Distributions Depend on the Geometry of Plasticity},\nauthor={Roman Pogodin and Jonathan Cornford and Arna Ghosh and Gauthier Gidel and Guillaume Lajoie and Blake Aaron Richards},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=x5txICnnjC}\n}"}, "paperhash": {"value": "pogodin|synaptic_weight_distributions_depend_on_the_geometry_of_plasticity"}}, "number": 6281, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6281/-/Revision", "ICLR.cc/2024/Conference/Submission6281/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6281/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415467475, "cdate": 1695415467475, "tmdate": 1709661529575, "mdate": 1709661529575, "pdate": 1705410970716, "version": 2}, {"id": "ijK5hyxs0n", "forum": "ijK5hyxs0n", "signatures": ["ICLR.cc/2024/Conference/Submission6278/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6278/Authors"], "content": {"title": {"value": "Graph Metanetworks for Processing Diverse Neural Architectures"}, "authors": {"value": ["Derek Lim", "Haggai Maron", "Marc T. Law", "Jonathan Lorraine", "James Lucas"]}, "authorids": {"value": ["~Derek_Lim1", "~Haggai_Maron1", "~Marc_T._Law1", "~Jonathan_Lorraine1", "~James_Lucas1"]}, "keywords": {"value": ["Metanetwork", "graph", "equivariance", "expressivity"]}, "TLDR": {"value": "We develop metanetworks that allow expressive, permutation equivariant processing of diverse neural network architectures."}, "abstract": {"value": "Neural networks efficiently encode learned information within their parameters. Consequently, many tasks can be unified by treating neural networks themselves as input data. When doing so, recent studies demonstrated the importance of accounting for the symmetries and geometry of parameter spaces. However, those works developed architectures tailored to specific networks such as MLPs and CNNs without normalization layers, and generalizing such architectures to other types of networks can be challenging. In this work, we overcome these challenges by building new metanetworks --- neural networks that take weights from other neural networks as input. Put simply, we carefully build graphs representing the input neural networks and process the graphs using graph neural networks. Our approach, Graph Metanetworks (GMNs), generalizes to neural architectures where competing methods struggle, such as multi-head attention layers, normalization layers, convolutional layers, ResNet blocks, and group-equivariant linear layers. We prove that GMNs are expressive and equivariant to parameter permutation symmetries that leave the input neural network functions unchanged. We validate the effectiveness of our method on several metanetwork tasks over diverse neural network architectures."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/461000be3cc4ed15947307020c46aafa982c40ae.pdf"}, "_bibtex": {"value": "@inproceedings{\nlim2024graph,\ntitle={Graph Metanetworks for Processing Diverse Neural Architectures},\nauthor={Derek Lim and Haggai Maron and Marc T. Law and Jonathan Lorraine and James Lucas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ijK5hyxs0n}\n}"}, "paperhash": {"value": "lim|graph_metanetworks_for_processing_diverse_neural_architectures"}}, "number": 6278, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6278/-/Revision", "ICLR.cc/2024/Conference/Submission6278/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6278/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415400220, "cdate": 1695415400220, "tmdate": 1710339485460, "mdate": 1710339485460, "pdate": 1705410970663, "version": 2}, {"id": "06lrITXVAx", "forum": "06lrITXVAx", "signatures": ["ICLR.cc/2024/Conference/Submission6272/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6272/Authors"], "content": {"title": {"value": "Dropout Enhanced Bilevel Training"}, "authors": {"value": ["Peiran Yu", "Junyi Li", "Heng Huang"]}, "authorids": {"value": ["~Peiran_Yu1", "~Junyi_Li1", "~Heng_Huang1"]}, "keywords": {"value": ["Bilevel Optimization", "Overfitting"]}, "abstract": {"value": "Bilevel optimization problems appear in many widely used machine learning tasks. Bilevel optimization models are sensitive to small changes, and bilevel training tasks typically involve limited datasets. Therefore, overfitting is a common challenge in bilevel training tasks. This paper considers the use of dropout to address this problem. We propose a bilevel optimization model that depends on the distribution of dropout masks. We investigate how the dropout rate affects the hypergradient of this model. We propose a dropout bilevel method to solve the dropout bilevel optimization model. Subsequently, we analyze the resulting dropout bilevel method from an optimization perspective. Analyzing the optimization properties of methods with dropout is essential because it provides convergence guarantees for methods using dropout. However, there has been limited investigation in this research direction. We provide the complexity of the resulting dropout bilevel method in terms of reaching an $\\epsilon$ stationary point of the proposed stochastic bilevel model. Empirically, we demonstrate that overfitting occurs in data cleaning problems, and the method proposed in this work mitigates this issue."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/09304d5bf3e31448450004ee461830870db26085.pdf"}, "supplementary_material": {"value": "/attachment/3f2da4776df25e60924b0709b573e4fe323b121d.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024dropout,\ntitle={Dropout Enhanced Bilevel Training},\nauthor={Peiran Yu and Junyi Li and Heng Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=06lrITXVAx}\n}"}, "paperhash": {"value": "yu|dropout_enhanced_bilevel_training"}}, "number": 6272, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6272/-/Revision", "ICLR.cc/2024/Conference/Submission6272/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6272/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415248638, "cdate": 1695415248638, "tmdate": 1710217378699, "mdate": 1710217378699, "pdate": 1705410970577, "version": 2}, {"id": "xUzWmFdglP", "forum": "xUzWmFdglP", "signatures": ["ICLR.cc/2024/Conference/Submission6261/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6261/Authors"], "content": {"title": {"value": "Privacy Amplification for Matrix Mechanisms"}, "authors": {"value": ["Christopher A. Choquette-Choo", "Arun Ganesh", "Thomas Steinke", "Abhradeep Guha Thakurta"]}, "authorids": {"value": ["~Christopher_A._Choquette-Choo1", "~Arun_Ganesh1", "~Thomas_Steinke2", "~Abhradeep_Guha_Thakurta1"]}, "keywords": {"value": ["differential privacy", "privacy amplification", "matrix mechanism"]}, "TLDR": {"value": "We propose an algorithm for computing privacy guarantees of the matrix mechanism with privacy amplification."}, "abstract": {"value": "Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's success in machine learning (ML), but, is not readily applicable to the newer state-of-the-art (SOTA) algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD.\n\nIn this paper, we propose \"MMCC'' (matrix mechanism conditional composition), the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as $\\epsilon\\to0$. \nTo analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our \"conditional composition theorem'' has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our algorithm also has practical empirical utility. We show that amplification leads to significant improvement in the privacy/utility trade-offs for DP-FTRL style algorithms for standard benchmark tasks."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f4107c113add2f5ec1249dac4d4dfa313bfb5c5.pdf"}, "supplementary_material": {"value": "/attachment/1825a069e10ffb0a1e2a70a032983fc9a0f10735.pdf"}, "_bibtex": {"value": "@inproceedings{\nchoquette-choo2024privacy,\ntitle={Privacy Amplification for Matrix Mechanisms},\nauthor={Christopher A. Choquette-Choo and Arun Ganesh and Thomas Steinke and Abhradeep Guha Thakurta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xUzWmFdglP}\n}"}, "paperhash": {"value": "choquettechoo|privacy_amplification_for_matrix_mechanisms"}}, "number": 6261, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6261/-/Revision", "ICLR.cc/2024/Conference/Submission6261/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6261/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414861905, "cdate": 1695414861905, "tmdate": 1710345151147, "mdate": 1710345151147, "pdate": 1705410970317, "version": 2}, {"id": "lsxeNvYqCj", "forum": "lsxeNvYqCj", "signatures": ["ICLR.cc/2024/Conference/Submission6260/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6260/Authors"], "content": {"title": {"value": "Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation"}, "authors": {"value": ["Thomas Kleine Buening", "Aadirupa Saha", "Christos Dimitrakakis", "Haifeng Xu"]}, "authorids": {"value": ["~Thomas_Kleine_Buening1", "~Aadirupa_Saha1", "~Christos_Dimitrakakis1", "~Haifeng_Xu1"]}, "keywords": {"value": ["bandits", "mechanism design", "incentive-aware learning", "nash equilibrium"]}, "TLDR": {"value": "We introduce the strategic click-bandit problem and design an incentive-aware learning algorithm that induces desirable arm strategies while simultaneously minimizing regret."}, "abstract": {"value": "We study a strategic variant of the multi-armed bandit problem, which we coin the strategic click-bandit. This model is motivated by applications in online recommendation where the choice of recommended items depends on both the click-through rates and the post-click rewards. Like in classical bandits, rewards follow a fixed unknown distribution. However, we assume that the click-rate of each arm is chosen  strategically by the arm (e.g., a host on Airbnb)  in order to maximize  the number of times it gets clicked. The algorithm designer does not know the post-click rewards nor the arms' actions (i.e., strategically chosen click-rates) in advance, and must learn both values over time. To solve this problem, we design an incentive-aware learning algorithm, UCB-S, which achieves two goals simultaneously: (a) incentivizing desirable arm behavior under uncertainty; (b) minimizing regret by learning unknown parameters.  We approximately characterize all Nash equilibria of the arms under UCB-S and show a $\\tilde{\\mathcal{O}} (\\sqrt{KT})$ regret bound uniformly in every equilibrium. We also show that incentive-unaware algorithms generally fail to achieve low regret in the strategic click-bandit. Finally, we support our theoretical results by simulations of strategic arm behavior which confirm the effectiveness and robustness of our proposed incentive design."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8dcfb207122a45da36a445b1322405bc5aafef25.pdf"}, "supplementary_material": {"value": "/attachment/f795d33127e6fcaa20ae9722fd1e4b2e7fecba63.pdf"}, "_bibtex": {"value": "@inproceedings{\nbuening2024bandits,\ntitle={Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation},\nauthor={Thomas Kleine Buening and Aadirupa Saha and Christos Dimitrakakis and Haifeng Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lsxeNvYqCj}\n}"}, "paperhash": {"value": "buening|bandits_meet_mechanism_design_to_combat_clickbait_in_online_recommendation"}}, "number": 6260, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6260/-/Revision", "ICLR.cc/2024/Conference/Submission6260/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6260/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414842925, "cdate": 1695414842925, "tmdate": 1710511722752, "mdate": 1710511722752, "pdate": 1705410970306, "version": 2}, {"id": "3mnWvUZIXt", "forum": "3mnWvUZIXt", "signatures": ["ICLR.cc/2024/Conference/Submission6169/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6169/Authors"], "content": {"title": {"value": "Towards Principled Representation Learning from Videos for Reinforcement Learning"}, "authors": {"value": ["Dipendra Misra", "Akanksha Saran", "Tengyang Xie", "Alex Lamb", "John Langford"]}, "authorids": {"value": ["~Dipendra_Misra1", "~Akanksha_Saran1", "~Tengyang_Xie1", "~Alex_Lamb1", "~John_Langford1"]}, "keywords": {"value": ["Reinforcement Learning", "Representation Learning"]}, "abstract": {"value": "We study pre-training representations for decision-making using video data, which is abundantly available for tasks such as game agents and software testing. Even though significant empirical advances have been made on this problem, a theoretical understanding remains absent. We initiate the theoretical investigation into principled approaches for representation learning and focus on learning the latent state representations of the underlying MDP using video data. We study two types of settings: one where there is iid noise in the observation, and a more challenging setting where there is also the presence of exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background. We study three commonly used approaches: autoencoding, temporal contrastive learning, and forward modeling. We prove upper bounds for temporal contrastive learning and forward modeling in the presence of only iid noise. We show that these approaches can learn the latent state and use it to do efficient downstream RL with polynomial sample complexity. When exogenous noise is also present, we establish a lower bound result showing that the sample complexity of learning from video data can be exponentially worse than learning from action-labeled trajectory data. This partially explains why reinforcement learning with video pre-training is hard. We evaluate these representational learning methods in two visual domains, yielding results that are consistent with our theoretical findings."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c43b265454249a8f020eea381e9f22b35afa8033.pdf"}, "TLDR": {"value": "Theoretical analysis and experiments concerning the value reinforcement learning can gain from pretrained representations of unlabeled video data."}, "_bibtex": {"value": "@inproceedings{\nmisra2024towards,\ntitle={Towards Principled Representation Learning from Videos for Reinforcement Learning},\nauthor={Dipendra Misra and Akanksha Saran and Tengyang Xie and Alex Lamb and John Langford},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3mnWvUZIXt}\n}"}, "paperhash": {"value": "misra|towards_principled_representation_learning_from_videos_for_reinforcement_learning"}}, "number": 6169, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6169/-/Revision", "ICLR.cc/2024/Conference/Submission6169/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6169/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695411369674, "cdate": 1695411369674, "tmdate": 1713125412231, "mdate": 1713125412231, "pdate": 1705410967838, "version": 2}, {"id": "NU9AYHJvYe", "forum": "NU9AYHJvYe", "signatures": ["ICLR.cc/2024/Conference/Submission6157/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6157/Authors"], "content": {"title": {"value": "Optimal Sample Complexity of Contrastive Learning"}, "authors": {"value": ["Noga Alon", "Dmitrii Avdiukhin", "Dor Elboim", "Orr Fischer", "Grigory Yaroslavtsev"]}, "authorids": {"value": ["~Noga_Alon1", "~Dmitrii_Avdiukhin1", "~Dor_Elboim1", "~Orr_Fischer1", "~Grigory_Yaroslavtsev1"]}, "keywords": {"value": ["learning theory", "sample complexity", "vc dimension", "contrastive learning", "metric learning"]}, "TLDR": {"value": "We provide tight bounds on the sample complexity of contrastive learning in various settings, without any assumptions on the data distribution"}, "abstract": {"value": "Contrastive learning is a highly successful technique for learning representations of data from labeled tuples, specifying the distance relations within the tuple. We study the sample complexity of contrastive learning, i.e. the minimum number of labeled tuples sufficient for getting high generalization accuracy. We give tight bounds on the sample complexity in a variety of settings, focusing on arbitrary distance functions,  $\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal bound on the sample complexity of learning $\\ell_p$-distances for integer $p$. For any $p \\ge 1$, we show that $\\tilde \\Theta(nd)$ labeled tuples are necessary and sufficient for learning $d$-dimensional representations of $n$-point datasets. Our results hold for an arbitrary distribution of the input samples and are based on giving the corresponding bounds on the Vapnik-Chervonenkis/Natarajan dimension of the associated problems. We further show that the theoretical bounds on sample complexity obtained via VC/Natarajan dimension can have strong predictive power for experimental results, in contrast with the folklore belief about a substantial gap between the statistical learning theory and the practice of deep learning."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/00a6d5623a59e634ef01b7ebdd71bd1b30b22500.pdf"}, "supplementary_material": {"value": "/attachment/36c855234f04aea83e5509d335a3040d5b6ea1f8.zip"}, "_bibtex": {"value": "@inproceedings{\nalon2024optimal,\ntitle={Optimal Sample Complexity of Contrastive Learning},\nauthor={Noga Alon and Dmitrii Avdiukhin and Dor Elboim and Orr Fischer and Grigory Yaroslavtsev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NU9AYHJvYe}\n}"}, "paperhash": {"value": "alon|optimal_sample_complexity_of_contrastive_learning"}}, "number": 6157, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6157/-/Revision", "ICLR.cc/2024/Conference/Submission6157/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6157/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410627881, "cdate": 1695410627881, "tmdate": 1710465920896, "mdate": 1710465920896, "pdate": 1705410967233, "version": 2}, {"id": "FM5xfcaR2Y", "forum": "FM5xfcaR2Y", "signatures": ["ICLR.cc/2024/Conference/Submission6102/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6102/Authors"], "content": {"title": {"value": "Post-hoc bias scoring is optimal for fair classification"}, "authors": {"value": ["Wenlong Chen", "Yegor Klochkov", "Yang Liu"]}, "authorids": {"value": ["~Wenlong_Chen1", "~Yegor_Klochkov2", "~Yang_Liu3"]}, "keywords": {"value": ["group fairness", "post-hoc fair classification", "Bayes optimal classifier", "accuracy-fairness trade-off"]}, "abstract": {"value": "We consider a binary classification problem under group fairness constraints, which can be one of Demographic Parity (DP), Equalized Opportunity (EOp), or Equalized Odds (EO). We propose an explicit characterization of Bayes optimal classifier under the fairness constraints, which turns out to be a simple modification rule of the unconstrained classifier. Namely, we introduce a novel instance-level measure of bias, which we call bias score, and the modification rule is a simple linear rule on top of the finite amount of bias scores. Based on this characterization, we develop a post-hoc approach that allows us to adapt to fairness constraints while maintaining high accuracy. In the case of DP and EOp constraints, the modification rule is thresholding a single bias score, while in the case of EO constraints we are required to fit a linear modification rule with 2 parameters. The method can also be applied for composite group-fairness criteria, such as ones involving several sensitive attributes. We achieve competitive or better performance compared to both in-processing and post-processing methods across three datasets: Adult, COMPAS, and CelebA. Unlike most post-processing methods, we do not require access to sensitive attributes during the inference time."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/76bd92c39da18e17fb34a06d39a4c5bb7e7573ba.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024posthoc,\ntitle={Post-hoc bias scoring is optimal for fair classification},\nauthor={Wenlong Chen and Yegor Klochkov and Yang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FM5xfcaR2Y}\n}"}, "paperhash": {"value": "chen|posthoc_bias_scoring_is_optimal_for_fair_classification"}}, "number": 6102, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6102/-/Revision", "ICLR.cc/2024/Conference/Submission6102/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6102/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695408909539, "cdate": 1695408909539, "tmdate": 1710503456175, "mdate": 1710503456175, "pdate": 1705410964678, "version": 2}, {"id": "bxITGFPVWh", "forum": "bxITGFPVWh", "signatures": ["ICLR.cc/2024/Conference/Submission6100/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6100/Authors"], "content": {"title": {"value": "Sharpness-Aware Data Poisoning Attack"}, "authors": {"value": ["Pengfei He", "Han Xu", "Jie Ren", "Yingqian Cui", "Shenglai Zeng", "Hui Liu", "Charu C. Aggarwal", "Jiliang Tang"]}, "authorids": {"value": ["~Pengfei_He2", "~Han_Xu1", "~Jie_Ren6", "~Yingqian_Cui1", "~Shenglai_Zeng2", "~Hui_Liu8", "~Charu_C._Aggarwal2", "~Jiliang_Tang1"]}, "keywords": {"value": ["Data poisoning attack; generalization; deep learning"]}, "abstract": {"value": "Recent research has highlighted the vulnerability of Deep Neural Networks (DNNs) against data poisoning attacks. These attacks aim to inject poisoning samples into the models' training dataset such that the trained models have inference failures. While previous studies have executed different types of attacks, one major challenge that greatly limits their effectiveness is the \nuncertainty of the re-training process after the injection of poisoning samples. It includes the uncertainty of training initialization, algorithm and model architecture. To address this challenge, we propose a new strategy called **Sharpness-Aware Data Poisoning Attack (SAPA)**. In particular, it leverages the concept of DNNs' loss landscape sharpness to optimize the poisoning effect on the (approximately) worst re-trained model. Extensive experiments demonstrate that SAPA offers a general and principled strategy that significantly enhances various types of poisoning attacks against various types of re-training uncertainty."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c5b9990eda79f25ade2e1cff4e9d53d63490c7fc.pdf"}, "_bibtex": {"value": "@inproceedings{\nhe2024sharpnessaware,\ntitle={Sharpness-Aware Data Poisoning Attack},\nauthor={Pengfei He and Han Xu and Jie Ren and Yingqian Cui and Shenglai Zeng and Hui Liu and Charu C. Aggarwal and Jiliang Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bxITGFPVWh}\n}"}, "paperhash": {"value": "he|sharpnessaware_data_poisoning_attack"}}, "number": 6100, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6100/-/Revision", "ICLR.cc/2024/Conference/Submission6100/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6100/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695408826220, "cdate": 1695408826220, "tmdate": 1710520665071, "mdate": 1710520665071, "pdate": 1705410964563, "version": 2}, {"id": "z4Hcegjzph", "forum": "z4Hcegjzph", "signatures": ["ICLR.cc/2024/Conference/Submission6074/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6074/Authors"], "content": {"title": {"value": "Pre-training with Random Orthogonal Projection Image Modeling"}, "authors": {"value": ["Maryam Haghighat", "Peyman Moghadam", "Shaheer Mohamed", "Piotr Koniusz"]}, "authorids": {"value": ["~Maryam_Haghighat1", "~Peyman_Moghadam1", "~Shaheer_Mohamed1", "~Piotr_Koniusz1"]}, "keywords": {"value": ["Random Projection", "Self-supervised Learning", "Image Modelling", "Representation Learning", "Vision Transformer"]}, "TLDR": {"value": "Pre-training with Random Orthogonal Projection Image Modeling"}, "abstract": {"value": "Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual pre-training without the use of labels. MIM applies random crops to input images, processes them with an encoder, and then recovers the masked inputs with a decoder, which encourages the network to capture and learn structural information about objects and scenes. The intermediate feature representations obtained from MIM are suitable for fine-tuning on downstream tasks. In this paper, we propose an Image Modeling framework based on random orthogonal projection instead of binary masking as in MIM. Our proposed Random Orthogonal Projection Image Modeling (ROPIM) reduces spatially-wise token information under guaranteed bound on the noise variance and can be considered as masking entire spatial image area under locally varying masking degrees. Since ROPIM uses a random subspace for the projection that realizes the masking step, the readily available complement of the subspace can be used during unmasking to promote recovery of removed information. In this paper, we show that using random orthogonal projection leads to superior performance compared to crop-based masking. We demonstrate state-of-the-art results on several popular benchmarks."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/10fbc610db66b05362ea4434c03c92835ba7f338.pdf"}, "_bibtex": {"value": "@inproceedings{\nhaghighat2024pretraining,\ntitle={Pre-training with Random Orthogonal Projection Image Modeling},\nauthor={Maryam Haghighat and Peyman Moghadam and Shaheer Mohamed and Piotr Koniusz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=z4Hcegjzph}\n}"}, "paperhash": {"value": "haghighat|pretraining_with_random_orthogonal_projection_image_modeling"}}, "number": 6074, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6074/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6074/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695407988491, "cdate": 1695407988491, "tmdate": 1713020942989, "mdate": 1713020942989, "pdate": 1705410963798, "version": 2}, {"id": "Nshk5YpdWE", "forum": "Nshk5YpdWE", "signatures": ["ICLR.cc/2024/Conference/Submission6062/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6062/Authors"], "content": {"title": {"value": "Lagrangian Flow Networks for Conservation Laws"}, "authors": {"value": ["Fabricio Arend Torres", "Marcello Massimo Negri", "Marco Inversi", "Jonathan Aellen", "Volker Roth"]}, "authorids": {"value": ["~Fabricio_Arend_Torres1", "~Marcello_Massimo_Negri1", "~Marco_Inversi1", "~Jonathan_Aellen1", "~Volker_Roth1"]}, "keywords": {"value": ["Physics-informed Neural Network", "Fluid Dynamics", "Conservation Law", "Partial Differential Equation", "Conditional Normalizing Flows", "Bird-Migration"]}, "TLDR": {"value": "An approach for modeling fluid densities and velocities continuously in space and time while satisfying the continuity equation by construction."}, "abstract": {"value": "We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities and velocities continuously in space and time.\nBy construction, the proposed LFlows satisfy the continuity equation,\na PDE describing mass conservation in its differential form. \nOur model is based on the insight that solutions to the continuity equation can be expressed as\ntime-dependent density transformations via differentiable and invertible maps.\nThis follows from classical theory of the existence and uniqueness of Lagrangian flows for smooth vector fields.\nHence, we model fluid densities by transforming a base density with parameterized diffeomorphisms conditioned on time.\nThe key benefit compared to methods relying on numerical ODE solvers or PINNs is that the analytic expression of the velocity is always consistent with changes in density.\nFurthermore, we require neither expensive numerical solvers, nor additional penalties to enforce the PDE.\nLFlows show higher predictive accuracy in density modeling tasks compared to competing models in 2D and 3D,\nwhile being computationally efficient.\nAs a real-world application, we model bird migration based on sparse weather radar measurements."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/53607a671ffb6900fcf4870e6bd3c5866146e9b4.pdf"}, "supplementary_material": {"value": "/attachment/5e9e73c6ab9ffc4b808ff5bcacb15bbf346bfedb.zip"}, "_bibtex": {"value": "@inproceedings{\ntorres2024lagrangian,\ntitle={Lagrangian Flow Networks for Conservation Laws},\nauthor={Fabricio Arend Torres and Marcello Massimo Negri and Marco Inversi and Jonathan Aellen and Volker Roth},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Nshk5YpdWE}\n}"}, "paperhash": {"value": "torres|lagrangian_flow_networks_for_conservation_laws"}}, "number": 6062, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6062/-/Revision", "ICLR.cc/2024/Conference/Submission6062/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6062/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695407172578, "cdate": 1695407172578, "tmdate": 1710262898799, "mdate": 1710262898799, "pdate": 1705410963470, "version": 2}, {"id": "w7LU2s14kE", "forum": "w7LU2s14kE", "signatures": ["ICLR.cc/2024/Conference/Submission6053/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6053/Authors"], "content": {"title": {"value": "Linearity of Relation Decoding in Transformer Language Models"}, "authors": {"value": ["Evan Hernandez", "Arnab Sen Sharma", "Tal Haklay", "Kevin Meng", "Martin Wattenberg", "Jacob Andreas", "Yonatan Belinkov", "David Bau"]}, "authorids": {"value": ["~Evan_Hernandez1", "~Arnab_Sen_Sharma1", "~Tal_Haklay1", "~Kevin_Meng1", "~Martin_Wattenberg1", "~Jacob_Andreas1", "~Yonatan_Belinkov1", "~David_Bau1"]}, "keywords": {"value": ["Natural language processing", "interpretability", "language models"]}, "abstract": {"value": "Much of the knowledge encoded in transformer language models (LMs) may be expressed in terms of relations: relations between words and their synonyms, entities and their attributes, etc. We show that, for a subset of relations, this computation is well-approximated by a single linear transformation on the subject representation. Linear relation representations may be obtained by constructing a first-order approximation to the LM from a single prompt, and they exist for a variety of factual, commonsense, and linguistic relations. However, we also identify many cases in which LM predictions capture relational knowledge accurately, but this knowledge is not linearly encoded in their representations. Our results thus reveal a simple, interpretable, but heterogeneously deployed knowledge representation strategy in transformer LMs."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/548eac40ba455c0509185e199cc8f49f2f96523c.pdf"}, "supplementary_material": {"value": "/attachment/fa08ed208ce5ef0c0f0a4e42a0b7b2932c1391aa.zip"}, "_bibtex": {"value": "@inproceedings{\nhernandez2024linearity,\ntitle={Linearity of Relation Decoding in Transformer Language Models},\nauthor={Evan Hernandez and Arnab Sen Sharma and Tal Haklay and Kevin Meng and Martin Wattenberg and Jacob Andreas and Yonatan Belinkov and David Bau},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w7LU2s14kE}\n}"}, "paperhash": {"value": "hernandez|linearity_of_relation_decoding_in_transformer_language_models"}}, "number": 6053, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6053/-/Revision", "ICLR.cc/2024/Conference/Submission6053/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6053/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695406731831, "cdate": 1695406731831, "tmdate": 1709661527195, "mdate": 1709661527195, "pdate": 1705410963204, "version": 2}, {"id": "xIHi5nxu9P", "forum": "xIHi5nxu9P", "signatures": ["ICLR.cc/2024/Conference/Submission5955/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5955/Authors"], "content": {"title": {"value": "Subtractive Mixture Models via Squaring: Representation and Learning"}, "authors": {"value": ["Lorenzo Loconte", "Aleksanteri Mikulus Sladek", "Stefan Mengel", "Martin Trapp", "Arno Solin", "Nicolas Gillis", "Antonio Vergari"]}, "authorids": {"value": ["~Lorenzo_Loconte1", "~Aleksanteri_Mikulus_Sladek1", "~Stefan_Mengel1", "~Martin_Trapp2", "~Arno_Solin1", "~Nicolas_Gillis1", "~Antonio_Vergari3"]}, "keywords": {"value": ["tractable inference", "distribution estimation", "probabilistic circuits", "tensor networks"]}, "TLDR": {"value": "We show how to effectively represent and learn a generic class of (deep) mixture models encoding subtractions of probability distributions, and theoretically prove they can be exponentially more expressive than addition-only mixture models."}, "abstract": {"value": "Mixture models are traditionally represented and learned by adding several distributions as components. Allowing mixtures to subtract probability mass or density can drastically reduce the number of components needed to model complex distributions. However, learning such subtractive mixtures while ensuring they still encode a non-negative function is challenging. We investigate how to learn and perform inference on deep subtractive mixtures by squaring them. We do this in the framework of probabilistic circuits, which enable us to represent tensorized mixtures and generalize several other subtractive models. We theoretically prove that the class of squared circuits allowing subtractions can be exponentially more expressive than traditional additive mixtures; and, we empirically show this increased expressiveness on a series of real-world distribution estimation tasks."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/89ac006120a307aae2c7421743f6559426440aaf.pdf"}, "_bibtex": {"value": "@inproceedings{\nloconte2024subtractive,\ntitle={Subtractive Mixture Models via Squaring: Representation and Learning},\nauthor={Lorenzo Loconte and Aleksanteri Mikulus Sladek and Stefan Mengel and Martin Trapp and Arno Solin and Nicolas Gillis and Antonio Vergari},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xIHi5nxu9P}\n}"}, "paperhash": {"value": "loconte|subtractive_mixture_models_via_squaring_representation_and_learning"}}, "number": 5955, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5955/-/Revision", "ICLR.cc/2024/Conference/Submission5955/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5955/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695403011850, "cdate": 1695403011850, "tmdate": 1710584841721, "mdate": 1710584841721, "pdate": 1705410959717, "version": 2}, {"id": "rmXXKxQpOR", "forum": "rmXXKxQpOR", "signatures": ["ICLR.cc/2024/Conference/Submission5938/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5938/Authors"], "content": {"title": {"value": "On the Provable Advantage of Unsupervised Pretraining"}, "authors": {"value": ["Jiawei Ge", "Shange Tang", "Jianqing Fan", "Chi Jin"]}, "authorids": {"value": ["~Jiawei_Ge3", "~Shange_Tang1", "~Jianqing_Fan1", "~Chi_Jin1"]}, "keywords": {"value": ["unsupervised pretraining; representation learning; sample complexity"]}, "abstract": {"value": "Unsupervised pretraining, which learns a useful representation using a large amount of unlabeled data to facilitate the learning of downstream tasks, is a critical component of modern large-scale machine learning systems. Despite its tremendous empirical success, the rigorous theoretical understanding of why unsupervised pretraining generally helps remains rather limited---most existing results are restricted to particular methods or approaches for unsupervised pretraining with specialized structural assumptions. This paper studies a generic framework,\nwhere the unsupervised representation learning task is specified by an abstract class of latent variable models $\\Phi$ and the downstream task is specified by a class of prediction functions $\\Psi$. We consider a natural approach of using Maximum Likelihood Estimation (MLE) for unsupervised pretraining and Empirical Risk Minimization (ERM) for learning downstream tasks. We prove that, under a mild ``informative'' condition, our algorithm achieves an excess risk of $\\\\tilde{\\\\mathcal{O}}(\\sqrt{\\mathcal{C}\\_\\Phi/m} + \\sqrt{\\mathcal{C}\\_\\Psi/n})$ for downstream tasks, where $\\mathcal{C}\\_\\Phi, \\mathcal{C}\\_\\Psi$ are complexity measures of function classes $\\Phi, \\Psi$, and $m, n$ are the number of unlabeled and labeled data respectively. Comparing to the baseline of $\\tilde{\\mathcal{O}}(\\sqrt{\\mathcal{C}\\_{\\Phi \\circ \\Psi}/n})$ achieved by performing supervised learning using only the labeled data, our result rigorously shows the benefit of unsupervised pretraining when $m \\gg n$ and $\\mathcal{C}\\_{\\Phi\\circ \\Psi} > \\mathcal{C}\\_\\Psi$. This paper further shows that our generic framework covers a wide range of approaches for unsupervised pretraining, including factor models, Gaussian mixture models, and contrastive learning."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0acbd62d42fa6cae47b05447238cec98212499f9.pdf"}, "supplementary_material": {"value": "/attachment/01e63193367ae76955c420470175e0f38dedf7ca.pdf"}, "_bibtex": {"value": "@inproceedings{\nge2024on,\ntitle={On the Provable Advantage of Unsupervised Pretraining},\nauthor={Jiawei Ge and Shange Tang and Jianqing Fan and Chi Jin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rmXXKxQpOR}\n}"}, "paperhash": {"value": "ge|on_the_provable_advantage_of_unsupervised_pretraining"}}, "number": 5938, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5938/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5938/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695402566992, "cdate": 1695402566992, "tmdate": 1709661526288, "mdate": 1709661526288, "pdate": 1705410959056, "version": 2}, {"id": "QxItoEAVMb", "forum": "QxItoEAVMb", "signatures": ["ICLR.cc/2024/Conference/Submission5935/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5935/Authors"], "content": {"title": {"value": "TorchRL: A data-driven decision-making library for PyTorch"}, "authors": {"value": ["Albert Bou", "Matteo Bettini", "Sebastian Dittert", "Vikash Kumar", "Shagun Sodhani", "Xiaomeng Yang", "Gianni De Fabritiis", "Vincent Moens"]}, "authorids": {"value": ["~Albert_Bou1", "~Matteo_Bettini1", "~Sebastian_Dittert1", "~Vikash_Kumar2", "~Shagun_Sodhani1", "~Xiaomeng_Yang1", "~Gianni_De_Fabritiis1", "~Vincent_Moens3"]}, "keywords": {"value": ["Reinforcement Learning", "pytorch", "control", "robotics"]}, "TLDR": {"value": "We present TorchRL, a new generalistic RL and control library for PyTorch. TorchRL offers a modular, lightweight, and agnostic tool for training reinforcement learning agents and other decision-making paradigms."}, "abstract": {"value": "PyTorch has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments. To address this issue, we propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. We introduce a new and flexible PyTorch primitive, the TensorDict, which facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We provide a detailed description of the building blocks and an extensive overview of the library across domains and tasks. Finally, we experimentally demonstrate its reliability and flexibility, and show comparative benchmarks to demonstrate its computational efficiency. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community. The code is open-sourced on GitHub."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/74ac7ade66fbb7c4ade0e5391457625d3599377c.pdf"}, "_bibtex": {"value": "@inproceedings{\nbou2024torchrl,\ntitle={Torch{RL}: A data-driven decision-making library for PyTorch},\nauthor={Albert Bou and Matteo Bettini and Sebastian Dittert and Vikash Kumar and Shagun Sodhani and Xiaomeng Yang and Gianni De Fabritiis and Vincent Moens},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QxItoEAVMb}\n}"}, "paperhash": {"value": "bou|torchrl_a_datadriven_decisionmaking_library_for_pytorch"}}, "number": 5935, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5935/-/Revision", "ICLR.cc/2024/Conference/Submission5935/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5935/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695402393325, "cdate": 1695402393325, "tmdate": 1710428667998, "mdate": 1710428667998, "pdate": 1705410958924, "version": 2}, {"id": "5hAMmCU0bK", "forum": "5hAMmCU0bK", "signatures": ["ICLR.cc/2024/Conference/Submission5914/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5914/Authors"], "content": {"title": {"value": "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption"}, "authors": {"value": ["Rui Yang", "Han Zhong", "Jiawei Xu", "Amy Zhang", "Chongjie Zhang", "Lei Han", "Tong Zhang"]}, "authorids": {"value": ["~Rui_Yang8", "~Han_Zhong1", "~Jiawei_Xu1", "~Amy_Zhang1", "~Chongjie_Zhang1", "~Lei_Han1", "~Tong_Zhang2"]}, "keywords": {"value": ["Offline RL", "robust RL", "data corruption", "training-time attack"]}, "TLDR": {"value": "We investigate the robustness of offline RL algorithms under diverse data corruption, and introduce a novel algorithm RIQL that exhibits significantly improved robustness."}, "abstract": {"value": "Offline reinforcement learning (RL) presents a promising approach for learning reinforced policies from offline datasets without the need for costly or unsafe interactions with the environment. However, datasets collected by humans in real-world environments are often noisy and may even be maliciously corrupted, which can significantly degrade the performance of offline RL. In this work, we first investigate the performance of current offline RL algorithms under comprehensive data corruption, including states, actions, rewards, and dynamics. Our extensive experiments reveal that implicit Q-learning (IQL) demonstrates remarkable resilience to data corruption among various offline RL algorithms. Furthermore, we conduct both empirical and theoretical analyses to understand IQL's robust performance, identifying its supervised policy learning scheme as the key factor. Despite its relative robustness, IQL still suffers from heavy-tail targets of Q functions under dynamics corruption. To tackle this challenge, we draw inspiration from robust statistics to employ the Huber loss to handle the heavy-tailedness and utilize quantile estimators to balance penalization for corrupted data and learning stability. By incorporating these simple yet effective modifications into IQL, we propose a more robust offline RL approach named Robust IQL (RIQL). Extensive experiments demonstrate that RIQL exhibits highly robust performance when subjected to diverse data corruption scenarios."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/60415c1f68bdc23484417721aa0069e22923b3b7.pdf"}, "supplementary_material": {"value": "/attachment/b59d032fee8c352db24e853035e62321928542aa.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024towards,\ntitle={Towards Robust Offline Reinforcement Learning under Diverse Data Corruption},\nauthor={Rui Yang and Han Zhong and Jiawei Xu and Amy Zhang and Chongjie Zhang and Lei Han and Tong Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5hAMmCU0bK}\n}"}, "paperhash": {"value": "yang|towards_robust_offline_reinforcement_learning_under_diverse_data_corruption"}}, "number": 5914, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5914/-/Revision", "ICLR.cc/2024/Conference/Submission5914/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5914/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695401500382, "cdate": 1695401500382, "tmdate": 1710001799627, "mdate": 1710001799627, "pdate": 1705410958315, "version": 2}, {"id": "Sx7BIiPzys", "forum": "Sx7BIiPzys", "signatures": ["ICLR.cc/2024/Conference/Submission5903/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5903/Authors"], "content": {"title": {"value": "Variational Bayesian Last Layers"}, "authors": {"value": ["James Harrison", "John Willes", "Jasper Snoek"]}, "authorids": {"value": ["~James_Harrison1", "~John_Willes2", "~Jasper_Snoek1"]}, "keywords": {"value": ["bayesian deep learning", "variational methods", "bayesian last layers", "neural linear models"]}, "TLDR": {"value": "We introduce a deterministic variational formulation for training Bayesian last layer neural networks that improves accuracy and calibration for free."}, "abstract": {"value": "We introduce a deterministic variational formulation for training Bayesian last layer neural networks. This yields a sampling-free, single-pass model and loss that effectively improves uncertainty estimation. Our variational Bayesian last layer (VBLL) can be trained and evaluated with only quadratic complexity in last layer width, and is thus (nearly) computationally free to add to standard architectures. We experimentally investigate VBLLs, and show that they improve predictive accuracy, calibration, and out of distribution detection over baselines across both regression and classification. Finally, we investigate combining VBLL layers with variational Bayesian feature learning, yielding a lower variance collapsed variational inference method for Bayesian neural networks."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/60aaa131dccd0ce0a263698149f1661e9ffe3a5e.pdf"}, "_bibtex": {"value": "@inproceedings{\nharrison2024variational,\ntitle={Variational Bayesian Last Layers},\nauthor={James Harrison and John Willes and Jasper Snoek},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Sx7BIiPzys}\n}"}, "paperhash": {"value": "harrison|variational_bayesian_last_layers"}}, "number": 5903, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5903/-/Revision", "ICLR.cc/2024/Conference/Submission5903/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5903/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695401031804, "cdate": 1695401031804, "tmdate": 1713123493766, "mdate": 1713123493766, "pdate": 1705410957699, "version": 2}, {"id": "7gUrYE50Rb", "forum": "7gUrYE50Rb", "signatures": ["ICLR.cc/2024/Conference/Submission5897/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5897/Authors"], "content": {"title": {"value": "EQA-MX: Embodied Question Answering using Multimodal Expression"}, "authors": {"value": ["Md Mofijul Islam", "Alexi Gladstone", "Riashat Islam", "Tariq Iqbal"]}, "authorids": {"value": ["~Md_Mofijul_Islam1", "~Alexi_Gladstone1", "~Riashat_Islam1", "~Tariq_Iqbal1"]}, "keywords": {"value": ["multimodal representation learning", "visual-language models", "embodied question answering"]}, "TLDR": {"value": "We present EQA-MX, a dataset and benchmark tasks for embodied multimodal QA, and VQ-Fusion model, enhancing visual-language alignment that outperforming existing models by 13%."}, "abstract": {"value": "Humans predominantly use verbal utterances and nonverbal gestures (e.g., eye gaze and pointing gestures) in their natural interactions. For instance, pointing gestures and verbal information is often required to comprehend questions such as \"what object is that?\" Thus, this question-answering (QA) task involves complex reasoning of multimodal expressions (verbal utterances and nonverbal gestures). However, prior works have explored QA tasks in non-embodied settings, where questions solely contain verbal utterances from a single verbal and visual perspective. In this paper, we have introduced 8 novel embodied question answering (EQA) tasks to develop learning models to comprehend embodied questions with multimodal expressions. We have developed a novel large-scale dataset, EQA-MX, with over 8 million diverse embodied QA data samples involving multimodal expressions from multiple visual and verbal perspectives. To learn salient multimodal representations from discrete verbal embeddings and continuous wrapping of multiview visual representations, we propose a vector-quantization (VQ) based multimodal representation learning model, VQ-Fusion, for the EQA tasks. Our extensive experimental results suggest that VQ-Fusion can improve the performance of existing state-of-the-art visual-language models up to 13% across EQA tasks."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f2829b2f4bb32e56e54abc38d0fe382ae50c7361.pdf"}, "_bibtex": {"value": "@inproceedings{\nislam2024eqamx,\ntitle={{EQA}-{MX}: Embodied Question Answering using Multimodal Expression},\nauthor={Md Mofijul Islam and Alexi Gladstone and Riashat Islam and Tariq Iqbal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7gUrYE50Rb}\n}"}, "paperhash": {"value": "islam|eqamx_embodied_question_answering_using_multimodal_expression"}}, "number": 5897, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5897/-/Revision", "ICLR.cc/2024/Conference/Submission5897/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5897/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400834842, "cdate": 1695400834842, "tmdate": 1710479196355, "mdate": 1710479196355, "pdate": 1705410956917, "version": 2}, {"id": "ZlQRiFmq7Y", "forum": "ZlQRiFmq7Y", "signatures": ["ICLR.cc/2024/Conference/Submission5882/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5882/Authors"], "content": {"title": {"value": "Retrieval-based Disentangled Representation Learning with Natural Language Supervision"}, "authors": {"value": ["Jiawei Zhou", "Xiaoguang Li", "Lifeng Shang", "Xin Jiang", "Qun Liu", "Lei Chen"]}, "authorids": {"value": ["~Jiawei_Zhou2", "~Xiaoguang_Li1", "~Lifeng_Shang1", "~Xin_Jiang1", "~Qun_Liu1", "~Lei_Chen7"]}, "keywords": {"value": ["Disentangled representation learning", "information retriever", "sparse retriever"]}, "TLDR": {"value": "We extend the functionality of lexical retriever to handle multi-modal data and harness this enhancement to facilitate disentangled representation learning."}, "abstract": {"value": "Disentangled representation learning remains challenging as the underlying factors of variation in the data do not naturally exist. The inherent complexity of real-world data makes it unfeasible to exhaustively enumerate and encapsulate all its variations within a finite set of factors. However, it is worth noting that most real-world data have linguistic equivalents, typically in the form of textual descriptions. These linguistic counterparts can represent the data and effortlessly decomposed into distinct tokens. In light of this, we present Vocabulary Disentangled Retrieval (VDR), a retrieval-based framework that harnesses natural language as proxies of the underlying data variation to drive disentangled representation learning. Our approach employ a bi-encoder model to represent both data and natural language in a vocabulary space, enabling the model to distinguish dimensions that capture intrinsic characteristics within data through its natural language counterpart, thus facilitating disentanglement. We extensively assess the performance of VDR across 15 retrieval benchmark datasets, covering text-to-text and cross-modal retrieval scenarios, as well as human evaluation. Our experimental results compellingly demonstrate the superiority of VDR over previous bi-encoder retrievers with comparable model size and training costs, achieving an impressive 8.7% improvement in NDCG@10 on the BEIR benchmark, a 5.3\\% increase on MS COCO, and a 6.0% increase on Flickr30k in terms of mean recall in the zero-shot setting. Moreover, The results from human evaluation indicate that interpretability of our method is on par with SOTA captioning models."}, "pdf": {"value": "/pdf/806a04ba3fc6094730d982164ed4de6b3cf4f351.pdf"}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "supplementary_material": {"value": "/attachment/eaa410373cb8076609f407d8cbc60709ce5ea389.zip"}, "_bibtex": {"value": "@inproceedings{\nzhou2024retrievalbased,\ntitle={Retrieval-based Disentangled Representation Learning with Natural Language Supervision},\nauthor={Jiawei Zhou and Xiaoguang Li and Lifeng Shang and Xin Jiang and Qun Liu and Lei Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZlQRiFmq7Y}\n}"}, "paperhash": {"value": "zhou|retrievalbased_disentangled_representation_learning_with_natural_language_supervision"}}, "number": 5882, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5882/-/Revision", "ICLR.cc/2024/Conference/Submission5882/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5882/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400404648, "cdate": 1695400404648, "tmdate": 1710035412505, "mdate": 1710035412505, "pdate": 1705410956160, "version": 2}, {"id": "Kn7tWhuetn", "forum": "Kn7tWhuetn", "signatures": ["ICLR.cc/2024/Conference/Submission5854/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5854/Authors"], "content": {"title": {"value": "On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods"}, "authors": {"value": ["Montgomery Bohde", "Meng Liu", "Alexandra Saxton", "Shuiwang Ji"]}, "authorids": {"value": ["~Montgomery_Bohde1", "~Meng_Liu3", "~Alexandra_Saxton1", "~Shuiwang_Ji1"]}, "keywords": {"value": ["Neural Algorithmic Reasoning"]}, "abstract": {"value": "Neural algorithmic reasoning is an emerging research direction that endows neural networks with the ability to mimic algorithmic executions step-by-step. A common paradigm in existing designs involves the use of historical embeddings in predicting the results of future execution steps. Our observation in this work is that such historical dependence intrinsically contradicts the Markov nature of algorithmic reasoning tasks. Based on this motivation, we present our ForgetNet, which does not use historical embeddings and thus is consistent with the Markov nature of the tasks. To address challenges in training ForgetNet at early stages, we further introduce G-ForgetNet, which uses a gating mechanism to allow for the selective integration of historical embeddings. Such an enhanced capability provides valuable computational pathways during the model's early training phase. Our extensive experiments, based on the CLRS-30 algorithmic reasoning benchmark, demonstrate that both ForgetNet and G-ForgetNet achieve better generalization capability than existing methods. Furthermore, we investigate the behavior of the gating mechanism, highlighting its degree of alignment with our intuitions and its effectiveness for robust performance. Our code is publicly available at https://github.com/divelab/ForgetNet."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/46ea9907175ecd6c88621bba3b5478fb9390eea8.pdf"}, "TLDR": {"value": "This work reveals the importance of aligning model design with the Markov nature in neural algorithmic reasoning tasks."}, "_bibtex": {"value": "@inproceedings{\nbohde2024on,\ntitle={On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods},\nauthor={Montgomery Bohde and Meng Liu and Alexandra Saxton and Shuiwang Ji},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Kn7tWhuetn}\n}"}, "paperhash": {"value": "bohde|on_the_markov_property_of_neural_algorithmic_reasoning_analyses_and_methods"}}, "number": 5854, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5854/-/Revision", "ICLR.cc/2024/Conference/Submission5854/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5854/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399613559, "cdate": 1695399613559, "tmdate": 1710538643867, "mdate": 1710538643867, "pdate": 1705410952704, "version": 2}, {"id": "kxebDHZ7b7", "forum": "kxebDHZ7b7", "signatures": ["ICLR.cc/2024/Conference/Submission5847/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5847/Authors"], "content": {"title": {"value": "TRAM: Bridging Trust Regions and Sharpness Aware Minimization"}, "authors": {"value": ["Tom Sherborne", "Naomi Saphra", "Pradeep Dasigi", "Hao Peng"]}, "authorids": {"value": ["~Tom_Sherborne2", "~Naomi_Saphra1", "~Pradeep_Dasigi1", "~Hao_Peng4"]}, "keywords": {"value": ["sharpness-aware minimization", "sam", "trust region", "optimization", "cross-lingual transfer", "language modeling"]}, "TLDR": {"value": "We propose a trust region motivated variant of SAM which scales learning with a trust region constraint to jointly optimize for low sharpness parameters and low curvature representations."}, "abstract": {"value": "Sharpness-aware minimization (SAM) reports improving domain generalization by\nreducing the loss surface curvature in the parameter space. However,\ngeneralization during _fine-tuning_ is often more dependent on the\ntransferability of _representations_ in the function space. Trust-region\nmethods (TR) target this goal by regularizing representation curvature to reduce\ncatastrophic forgetting of pre-trained task-agnostic information while adopting\ntask-specific skills. We consider unifying these strategies for low curvature in\nboth parameter space and function space to improve out-of-domain (OOD)\ngeneralization. We propose **Trust Region Aware Minimization** (TRAM), a\nSAM algorithm fine-tuning for low parameter sharpness and smooth, informative\nrepresentations preserving pre-trained structure. TRAM uses a trust region bound\nto inform the SAM adversarial neighborhood, introducing an awareness of function\ncurvature within optimization for flatter minima. We empirically validate TRAM\nin vision (cross-dataset adaptation) and text (OOD language modeling, zero-shot\ncross-lingual transfer) tasks where robust domain transfer and representation\ngenerality are critical. TRAM outperforms SAM- and TR-based optimization across\nall tasks, notably surpassing competing methods for hard transfer between\n_anticorrelated_ domains. TRAM establishes a novel standard in\nfine-tuning for domain-generalizable models with minimal additional computation\nover previous sharpness-aware methods."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/15fa46e9fb64654d30da84732fc37543dd3a94ca.pdf"}, "_bibtex": {"value": "@inproceedings{\nsherborne2024tram,\ntitle={{TRAM}: Bridging Trust Regions and Sharpness Aware Minimization},\nauthor={Tom Sherborne and Naomi Saphra and Pradeep Dasigi and Hao Peng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kxebDHZ7b7}\n}"}, "paperhash": {"value": "sherborne|tram_bridging_trust_regions_and_sharpness_aware_minimization"}}, "number": 5847, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5847/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5847/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399391793, "cdate": 1695399391793, "tmdate": 1710249457434, "mdate": 1710249457434, "pdate": 1705410952425, "version": 2}, {"id": "rzBskAEmoc", "forum": "rzBskAEmoc", "signatures": ["ICLR.cc/2024/Conference/Submission5726/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5726/Authors"], "content": {"title": {"value": "CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images"}, "authors": {"value": ["Olga Fourkioti", "Matt De Vries", "Chris Bakal"]}, "authorids": {"value": ["~Olga_Fourkioti2", "~Matt_De_Vries1", "~Chris_Bakal1"]}, "keywords": {"value": ["Multiple Instance Learning", "Histopathology", "Nearest Neighbors", "Graph Representation"]}, "TLDR": {"value": "We develop a multiple instance learning model for cancer detection and subtyping in whole slide images that leverages dependencies and imposis contextual constraints between tiles. This lead to state-of-the-art classification on two public datasets."}, "abstract": {"value": "The visual examination of tissue biopsy sections is fundamental for cancer diagnosis, with pathologists analyzing sections at multiple magnifications to discern tumor cells and their subtypes. However, existing attention-based multiple instance learning (MIL) models used for analyzing Whole Slide Images (WSIs) in cancer diagnostics often overlook the contextual information of tumor and neighboring tiles, leading to misclassifications. To address this, we propose the Context-Aware Multiple Instance Learning (CAMIL) architecture. CAMIL incorporates neighbor-constrained attention to consider dependencies among tiles within a WSI and integrates contextual constraints as prior knowledge into the MIL model. We evaluated CAMIL on subtyping non-small cell lung cancer (TCGA-NSCLC) and detecting lymph node (CAMELYON16 and CAMELYON17) metastasis, achieving test AUCs of 97.5\\%, 95.9\\%, and 88.1\\%, respectively, outperforming other state-of-the-art methods. Additionally, CAMIL enhances model interpretability by identifying regions of high diagnostic value. Our code is available at https://github.com/olgarithmics/ICLR_CAMIL."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b4d6251d3b1639d170a910826e7643be5d050285.pdf"}, "_bibtex": {"value": "@inproceedings{\nfourkioti2024camil,\ntitle={{CAMIL}: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images},\nauthor={Olga Fourkioti and Matt De Vries and Chris Bakal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rzBskAEmoc}\n}"}, "paperhash": {"value": "fourkioti|camil_contextaware_multiple_instance_learning_for_cancer_detection_and_subtyping_in_whole_slide_images"}}, "number": 5726, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5726/-/Revision", "ICLR.cc/2024/Conference/Submission5726/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5726/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396430184, "cdate": 1695396430184, "tmdate": 1712936759857, "mdate": 1712936759857, "pdate": 1705410948088, "version": 2}, {"id": "MnMWa94t12", "forum": "MnMWa94t12", "signatures": ["ICLR.cc/2024/Conference/Submission5714/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5714/Authors"], "content": {"title": {"value": "DyST: Towards Dynamic Neural Scene Representations on Real-World Videos"}, "authors": {"value": ["Maximilian Seitzer", "Sjoerd van Steenkiste", "Thomas Kipf", "Klaus Greff", "Mehdi S. M. Sajjadi"]}, "authorids": {"value": ["~Maximilian_Seitzer1", "~Sjoerd_van_Steenkiste1", "~Thomas_Kipf2", "~Klaus_Greff1", "~Mehdi_S._M._Sajjadi1"]}, "keywords": {"value": ["neural scene representations", "scene representations", "representation learning", "novel view synthesis"]}, "abstract": {"value": "Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cb1c5f7dc44ea3c18ca42146caaee182fe578c30.pdf"}, "supplementary_material": {"value": "/attachment/0350fddb5115fc6cb18a87230fa541096caec734.zip"}, "TLDR": {"value": "We introduce the Dynamic Scene Transformer, a model which learns scene representations from real videos and achieves separate control over camera and dynamics."}, "_bibtex": {"value": "@inproceedings{\nseitzer2024dyst,\ntitle={Dy{ST}: Towards Dynamic Neural Scene Representations on Real-World Videos},\nauthor={Maximilian Seitzer and Sjoerd van Steenkiste and Thomas Kipf and Klaus Greff and Mehdi S. M. Sajjadi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MnMWa94t12}\n}"}, "paperhash": {"value": "seitzer|dyst_towards_dynamic_neural_scene_representations_on_realworld_videos"}}, "number": 5714, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5714/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5714/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396074581, "cdate": 1695396074581, "tmdate": 1709661524182, "mdate": 1709661524182, "pdate": 1705410947645, "version": 2}, {"id": "LqRGsGWOTX", "forum": "LqRGsGWOTX", "number": 5665, "cdate": 1695394432951, "tcdate": 1695394432951, "mdate": 1709661524042, "tmdate": 1709661524042, "signatures": ["ICLR.cc/2024/Conference/Submission5665/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5665/Authors"], "content": {"title": {"value": "Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis"}, "authors": {"value": ["Jie Hao", "Xiaochuan Gong", "Mingrui Liu"]}, "authorids": {"value": ["~Jie_Hao3", "~Xiaochuan_Gong1", "~Mingrui_Liu2"]}, "keywords": {"value": ["Bilevel Optimization", "Unbounded Smoothness", "Deep Learning"]}, "TLDR": {"value": "This paper design and analyze a new algorithm for bilevel optimization under unbounded smoothness, with empirical validation on deep learning tasks."}, "abstract": {"value": "Bilevel optimization is an important formulation for many machine learning problems, such as meta-learning and hyperparameter optimization. Current bilevel optimization algorithms assume that the gradient of the upper-level function is Lipschitz (i.e., the upper-level function has a bounded smoothness parameter). However, recent studies reveal that certain neural networks such as recurrent neural networks (RNNs) and long-short-term memory networks (LSTMs) exhibit potential unbounded smoothness, rendering conventional bilevel optimization algorithms unsuitable for these neural networks. In this paper, we design a new bilevel optimization algorithm, namely BO-REP, to address this challenge. This algorithm updates the upper-level variable using normalized momentum and incorporates two novel techniques for updating the lower-level variable: \\textit{initialization refinement} and \\textit{periodic updates}. Specifically, once the upper-level variable is initialized, a subroutine is invoked to obtain a refined estimate of the corresponding optimal lower-level variable, and the lower-level variable is updated only after every specific period instead of each iteration. When the upper-level problem is nonconvex and unbounded smooth, and the lower-level problem is strongly convex, we prove that our algorithm requires $\\widetilde{\\mathcal{O}}(1/\\epsilon^4)$ \\footnote{Here $\\widetilde{\\mathcal{O}}(\\cdot)$ compresses logarithmic factors of $1/\\epsilon$ and $1/\\delta$, where $\\delta\\in(0,1)$ denotes the failure probability.} iterations to find an $\\epsilon$-stationary point in the stochastic setting, where each iteration involves calling a stochastic gradient or Hessian-vector product oracle. Notably, this result matches the state-of-the-art complexity results under the bounded smoothness setting and without mean-squared smoothness of the stochastic gradient, up to logarithmic factors. Our proof relies on novel technical lemmas for the periodically updated lower-level variable, which are of independent interest. Our experiments on hyper-representation learning, hyperparameter optimization, and data hyper-cleaning for text classification tasks demonstrate the effectiveness of our proposed algorithm. The code is available at [https://github.com/MingruiLiu-ML-Lab/Bilevel-Optimization-under-Unbounded-Smoothness](https://github.com/MingruiLiu-ML-Lab/Bilevel-Optimization-under-Unbounded-Smoothness)."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a528233198d471612305777bb97f41d0ae5d81a2.pdf"}, "supplementary_material": {"value": "/attachment/4b091666fc773fbe140fe445b244cc73438b2120.zip"}, "_bibtex": {"value": "@inproceedings{\nhao2024bilevel,\ntitle={Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis},\nauthor={Jie Hao and Xiaochuan Gong and Mingrui Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LqRGsGWOTX}\n}"}, "paperhash": {"value": "hao|bilevel_optimization_under_unbounded_smoothness_a_new_algorithm_and_convergence_analysis"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5665/-/Revision", "ICLR.cc/2024/Conference/Submission5665/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5665/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410946500, "version": 2}, {"id": "d3xKPQVjSc", "forum": "d3xKPQVjSc", "number": 5647, "cdate": 1695394045762, "tcdate": 1695394045762, "mdate": 1712926283490, "tmdate": 1712926283490, "signatures": ["ICLR.cc/2024/Conference/Submission5647/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5647/Authors"], "content": {"title": {"value": "Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation"}, "authors": {"value": ["Valentyn Melnychuk", "Dennis Frauen", "Stefan Feuerriegel"]}, "authorids": {"value": ["~Valentyn_Melnychuk1", "~Dennis_Frauen1", "~Stefan_Feuerriegel1"]}, "keywords": {"value": ["causal inference", "representation learning", "individualized treatment effect estimation"]}, "abstract": {"value": "State-of-the-art methods for conditional average treatment effect (CATE) estimation make widespread use of representation learning. Here, the idea is to reduce the variance of the low-sample CATE estimation by a (potentially constrained) low-dimensional representation. However, low-dimensional representations can lose information about the observed confounders and thus lead to bias, because of which the validity of representation learning for CATE estimation is typically violated. In this paper, we propose a new, representation-agnostic refutation framework for estimating bounds on the representation-induced confounding bias that comes from dimensionality reduction (or other constraints on the representations) in CATE estimation. First, we establish theoretically under which conditions CATE is non-identifiable given low-dimensional (constrained) representations. Second, as our remedy, we propose a neural refutation framework which performs partial identification of CATE or, equivalently, aims at estimating lower and upper bounds of the representation-induced confounding bias. We demonstrate the effectiveness of our bounds in a series of experiments. In sum, our refutation framework is of direct relevance in practice where the validity of CATE estimation is of importance."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/da779678dcc11b0b082bd4373d54a1aaacb92f7e.pdf"}, "_bibtex": {"value": "@inproceedings{\nmelnychuk2024bounds,\ntitle={Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation},\nauthor={Valentyn Melnychuk and Dennis Frauen and Stefan Feuerriegel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d3xKPQVjSc}\n}"}, "TLDR": {"value": "Bounding bias of representations for estimating conditional average treatment effect"}, "paperhash": {"value": "melnychuk|bounds_on_representationinduced_confounding_bias_for_treatment_effect_estimation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5647/-/Revision", "ICLR.cc/2024/Conference/Submission5647/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5647/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945897, "version": 2}, {"id": "sY5N0zY5Od", "forum": "sY5N0zY5Od", "number": 5605, "cdate": 1695392549935, "tcdate": 1695392549935, "mdate": 1710590090646, "tmdate": 1710590090646, "signatures": ["ICLR.cc/2024/Conference/Submission5605/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5605/Authors"], "content": {"title": {"value": "DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines"}, "authors": {"value": ["Omar Khattab", "Arnav Singhvi", "Paridhi Maheshwari", "Zhiyuan Zhang", "Keshav Santhanam", "Sri Vardhamanan A", "Saiful Haq", "Ashutosh Sharma", "Thomas T. Joshi", "Hanna Moazam", "Heather Miller", "Matei Zaharia", "Christopher Potts"]}, "authorids": {"value": ["~Omar_Khattab1", "~Arnav_Singhvi1", "~Paridhi_Maheshwari1", "~Zhiyuan_Zhang4", "~Keshav_Santhanam1", "~Sri_Vardhamanan_A1", "~Saiful_Haq1", "~Ashutosh_Sharma1", "~Thomas_T._Joshi1", "~Hanna_Moazam1", "~Heather_Miller1", "~Matei_Zaharia1", "~Christopher_Potts1"]}, "keywords": {"value": ["programming models", "prompting techniques", "in-context learning", "few-shot learning", "chain of thought", "multi-hop reasoning", "language agents"]}, "TLDR": {"value": "We propose a programming model that unifies LM prompting, finetuning, and augmentation techniques. We evaluate simple strategies to bootstrap and optimize complex and multi-stage reasoning chains, establishing strong results with small and large LMs."}, "abstract": {"value": "The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded \u201cprompt templates\u201d, i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, or imperative computational graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric, by creating and collecting demonstrations. We conduct two case studies, showing that succinct DSPy programs can express and optimize pipelines that reason about math word problems, tackle multi-hop retrieval, answer complex questions, and control agent loops. Within minutes of compiling, DSPy can automatically produce pipelines that outperform out-of-the-box few-shot prompting as well as expert-created demonstrations for GPT-3.5 and Llama2-13b-chat. On top of that, DSPy programs compiled for relatively small LMs like 770M parameter T5 and Llama2-13b-chat are competitive with many approaches that rely on large and proprietary LMs like GPT-3.5 and on expert-written prompt chains. DSPy is available at https://github.com/stanfordnlp/dspy"}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/41028bc2988c119c4fb5c213ab3919ceae696846.pdf"}, "_bibtex": {"value": "@inproceedings{\nkhattab2024dspy,\ntitle={{DSP}y: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines},\nauthor={Omar Khattab and Arnav Singhvi and Paridhi Maheshwari and Zhiyuan Zhang and Keshav Santhanam and Sri Vardhamanan A and Saiful Haq and Ashutosh Sharma and Thomas T. Joshi and Hanna Moazam and Heather Miller and Matei Zaharia and Christopher Potts},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sY5N0zY5Od}\n}"}, "paperhash": {"value": "khattab|dspy_compiling_declarative_language_model_calls_into_stateoftheart_pipelines"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5605/-/Revision", "ICLR.cc/2024/Conference/Submission5605/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5605/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944859, "version": 2}, {"id": "xJEd8PkdNz", "forum": "xJEd8PkdNz", "number": 5597, "cdate": 1695392351658, "tcdate": 1695392351658, "mdate": 1709661523328, "tmdate": 1709661523328, "signatures": ["ICLR.cc/2024/Conference/Submission5597/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5597/Authors"], "content": {"title": {"value": "Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control"}, "authors": {"value": ["Wenhan Cao", "Wei Pan"]}, "authorids": {"value": ["~Wenhan_Cao1", "~Wei_Pan2"]}, "keywords": {"value": ["Integral Reinforcement Learning", "Bayesian Quadrature", "Newton's Method"]}, "abstract": {"value": "Integral reinforcement learning (IntRL) demands the precise computation of the utility function's integral at its policy evaluation (PEV) stage. This is achieved through quadrature rules, which are weighted sums of utility functions evaluated from state samples obtained in discrete time. Our research reveals a critical yet underexplored phenomenon: the choice of the computational method -- in this case, the quadrature rule -- can significantly impact control performance. This impact is traced back to the fact that computational errors introduced in the PEV stage can affect the policy iteration's convergence behavior, which in turn affects the learned controller. To elucidate how computation impacts control, we draw a parallel between IntRL's policy iteration and Newton's method applied to the Hamilton-Jacobi-Bellman equation. In this light, computational error in PEV manifests as an extra error term in each iteration of Newton's method, with its upper bound proportional to the computational error. Further, we demonstrate that when the utility function resides in a reproducing kernel Hilbert space (RKHS), the optimal quadrature is achievable by employing Bayesian quadrature with the RKHS-inducing kernel function. We prove that the local convergence rates for IntRL using the trapezoidal rule and Bayesian quadrature with a Mat\u00e9rn kernel to be $O(N^{-2})$ and $O(N^{-b})$, where $N$ is the number of evenly-spaced samples and $b$ is the Mat\u00e9rn kernel's smoothness parameter. These theoretical findings are finally validated by two canonical control tasks."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9eca44e1414a070f87a6a21de74fc149bd37de96.pdf"}, "_bibtex": {"value": "@inproceedings{\ncao2024impact,\ntitle={Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control},\nauthor={Wenhan Cao and Wei Pan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xJEd8PkdNz}\n}"}, "paperhash": {"value": "cao|impact_of_computation_in_integral_reinforcement_learning_for_continuoustime_control"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5597/-/Revision", "ICLR.cc/2024/Conference/Submission5597/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5597/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944647, "version": 2}, {"id": "qODvxQ8TXW", "forum": "qODvxQ8TXW", "number": 5571, "cdate": 1695391295244, "tcdate": 1695391295244, "mdate": 1709661522985, "tmdate": 1709661522985, "signatures": ["ICLR.cc/2024/Conference/Submission5571/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5571/Authors"], "content": {"title": {"value": "Masks, Signs, And Learning Rate Rewinding"}, "authors": {"value": ["Advait Harshal Gadhikar", "Rebekka Burkholz"]}, "authorids": {"value": ["~Advait_Harshal_Gadhikar2", "~Rebekka_Burkholz1"]}, "keywords": {"value": ["sparsity", "pruning", "lottery tickets", "learning rate rewinding", "iterative magnitude pruning"]}, "TLDR": {"value": "We give provable insights on the benefits of Learning Rate Rewinding over Iterative Magnitude Pruning"}, "abstract": {"value": "Learning Rate Rewinding (LRR) has been established as a strong variant of Iterative Magnitude Pruning (IMP) to find lottery tickets in deep overparameterized neural networks. While both iterative pruning schemes couple structure and parameter learning, understanding how LRR excels in both aspects can bring us closer to the design of more flexible deep learning algorithms that can optimize diverse sets of sparse architectures. To this end, we conduct experiments that disentangle the effect of mask learning and parameter optimization and how both benefit from overparameterization. The ability of LRR to flip parameter signs early and stay robust to sign perturbations seems to make it not only more effective in mask identification but also in optimizing  diverse sets of masks, including random ones. In support of this hypothesis, we prove in a simplified single hidden neuron setting that LRR succeeds in more cases than IMP, as it can escape initially problematic sign configurations."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8049c38689012fa79be944abb2bec1446b8ed012.pdf"}, "supplementary_material": {"value": "/attachment/94d8718d41b8c2359f2d77aca617b6155b927ba7.zip"}, "_bibtex": {"value": "@inproceedings{\ngadhikar2024masks,\ntitle={Masks, Signs, And Learning Rate Rewinding},\nauthor={Advait Harshal Gadhikar and Rebekka Burkholz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qODvxQ8TXW}\n}"}, "paperhash": {"value": "gadhikar|masks_signs_and_learning_rate_rewinding"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5571/-/Revision", "ICLR.cc/2024/Conference/Submission5571/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5571/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410943700, "version": 2}, {"id": "iTTZFKrlGV", "forum": "iTTZFKrlGV", "number": 5543, "cdate": 1695390376167, "tcdate": 1695390376167, "mdate": 1712474756111, "tmdate": 1712474756111, "signatures": ["ICLR.cc/2024/Conference/Submission5543/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5543/Authors"], "content": {"title": {"value": "Gradual Domain Adaptation via Gradient Flow"}, "authors": {"value": ["Zhan Zhuang", "Yu Zhang", "Ying Wei"]}, "authorids": {"value": ["~Zhan_Zhuang1", "~Yu_Zhang3", "~Ying_Wei1"]}, "keywords": {"value": ["Domain adaptation", "gradual domain adaptation", "gradient flow"]}, "TLDR": {"value": "A domain adaptation method that dynamically generates intermediate domains and gradually updates the classifier."}, "abstract": {"value": "Domain shift degrades classification models on new data distributions. Conventional unsupervised domain adaptation (UDA) aims to learn features that bridge labeled source and unlabeled target domains. In contrast to feature learning, gradual domain adaptation (GDA) leverages extra continuous intermediate domains with pseudo-labels to boost the source classifier. However, real intermediate domains are sometimes unavailable or ineffective. In this paper, we propose $\\textbf{G}$radual Domain Adaptation via $\\textbf{G}$radient $\\textbf{F}$low (GGF) to generate intermediate domains with preserving labels, thereby enabling us a fine-tuning method for GDA. We employ the Wasserstein gradient flow in Kullback\u2013Leibler divergence to transport samples from the source to the target domain. To simulate the dynamics, we utilize the Langevin algorithm. Since the Langevin algorithm disregards label information and introduces diffusion noise, we introduce classifier-based and sample-based potentials to avoid label switching and dramatic deviations in the sampling process. For the proposed GGF model, we analyze its generalization bound. Experiments on several benchmark datasets demonstrate the superiority of the proposed GGF method compared to state-of-the-art baselines."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f37f9822abe7e0aa8e88eb76e03a633bbb5d707e.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhuang2024gradual,\ntitle={Gradual Domain Adaptation via Gradient Flow},\nauthor={Zhan Zhuang and Yu Zhang and Ying Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iTTZFKrlGV}\n}"}, "paperhash": {"value": "zhuang|gradual_domain_adaptation_via_gradient_flow"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5543/-/Revision", "ICLR.cc/2024/Conference/Submission5543/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5543/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942724, "version": 2}, {"id": "tmqOhBC4a5", "forum": "tmqOhBC4a5", "number": 5524, "cdate": 1695389604435, "tcdate": 1695389604435, "mdate": 1709898624441, "tmdate": 1709898624441, "signatures": ["ICLR.cc/2024/Conference/Submission5524/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5524/Authors"], "content": {"title": {"value": "Maximum Entropy Heterogeneous-Agent Reinforcement Learning"}, "authors": {"value": ["Jiarong Liu", "Yifan Zhong", "Siyi Hu", "Haobo Fu", "QIANG FU", "Xiaojun Chang", "Yaodong Yang"]}, "authorids": {"value": ["~Jiarong_Liu1", "~Yifan_Zhong2", "~Siyi_Hu1", "~Haobo_Fu2", "~QIANG_FU8", "~Xiaojun_Chang4", "~Yaodong_Yang1"]}, "keywords": {"value": ["cooperative multi-agent reinforcement learning", "heterogeneous-agent soft actor-critic", "maximum entropy heterogeneous-agent mirror learning"]}, "TLDR": {"value": "A unified framework for learning stochastic policies in cooperative MARL."}, "abstract": {"value": "*Multi-agent reinforcement learning* (MARL) has been shown effective for cooperative games in recent years. However, existing state-of-the-art methods face challenges related to sample complexity, training instability, and the risk of converging to a suboptimal Nash Equilibrium. In this paper, we propose a unified framework for learning \\emph{stochastic} policies to resolve these issues. We embed cooperative MARL problems into probabilistic graphical models, from which we derive the maximum entropy (MaxEnt) objective for MARL. Based on the MaxEnt framework, we propose *Heterogeneous-Agent Soft Actor-Critic* (HASAC) algorithm. Theoretically, we prove the monotonic improvement and convergence to *quantal response equilibrium* (QRE) properties of HASAC. Furthermore, we generalize a unified template for MaxEnt algorithmic design named *Maximum Entropy Heterogeneous-Agent Mirror Learning* (MEHAML), which provides any induced method with the same guarantees as HASAC. We evaluate HASAC on six benchmarks: Bi-DexHands, Multi-Agent MuJoCo, StarCraft Multi-Agent Challenge, Google Research Football, Multi-Agent Particle Environment, and Light Aircraft Game. Results show that HASAC consistently outperforms strong baselines, exhibiting better sample efficiency, robustness, and sufficient exploration."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/82bacc9b0a9551bf4922e43270f4c315044f70af.pdf"}, "supplementary_material": {"value": "/attachment/1c3bd6fb94ae9e95cde9e6f6d69189eba2c4221a.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024maximum,\ntitle={Maximum Entropy Heterogeneous-Agent Reinforcement Learning},\nauthor={Jiarong Liu and Yifan Zhong and Siyi Hu and Haobo Fu and QIANG FU and Xiaojun Chang and Yaodong Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tmqOhBC4a5}\n}"}, "paperhash": {"value": "liu|maximum_entropy_heterogeneousagent_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5524/-/Revision", "ICLR.cc/2024/Conference/Submission5524/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5524/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941952, "version": 2}, {"id": "BBD6KXIGJL", "forum": "BBD6KXIGJL", "number": 5507, "cdate": 1695389074115, "tcdate": 1695389074115, "mdate": 1710426984568, "tmdate": 1710426984568, "signatures": ["ICLR.cc/2024/Conference/Submission5507/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5507/Authors"], "content": {"title": {"value": "Hybrid Directional Graph Neural Network for Molecules"}, "authors": {"value": ["Junyi An", "Chao Qu", "Zhipeng Zhou", "Fenglei Cao", "Xu Yinghui", "Yuan Qi", "Furao Shen"]}, "authorids": {"value": ["~Junyi_An1", "~Chao_Qu3", "~Zhipeng_Zhou3", "~Fenglei_Cao1", "~Xu_Yinghui3", "~Yuan_Qi2", "~Furao_Shen1"]}, "keywords": {"value": ["Graph Neural Networks; Equivariance; Molecular model"]}, "abstract": {"value": "Equivariant message passing neural networks have emerged as the prevailing approach for predicting chemical properties of molecules due to their ability to leverage translation and rotation symmetries, resulting in a strong inductive bias. However, the equivariant operations in each layer can impose excessive constraints on the function form and network flexibility. To address these challenges, we introduce a novel network called the Hybrid Directional Graph Neural Network (HDGNN), which effectively combines strictly equivariant operations with learnable modules. We evaluate the performance of HDGNN on the QM9 dataset and the IS2RE dataset of OC20, demonstrating its state-of-the-art performance on several tasks and competitive performance on others. Our code is anonymously released on https://github.com/ajy112/HDGNN."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fdaba18af51e693376f79fad547fdec1e1913044.pdf"}, "supplementary_material": {"value": "/attachment/bc98d38347f0c395dece9bd36609fe3ae80bf6a0.pdf"}, "_bibtex": {"value": "@inproceedings{\nan2024hybrid,\ntitle={Hybrid Directional Graph Neural Network for Molecules},\nauthor={Junyi An and Chao Qu and Zhipeng Zhou and Fenglei Cao and Xu Yinghui and Yuan Qi and Furao Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BBD6KXIGJL}\n}"}, "paperhash": {"value": "an|hybrid_directional_graph_neural_network_for_molecules"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5507/-/Revision", "ICLR.cc/2024/Conference/Submission5507/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5507/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941392, "version": 2}, {"id": "uWVC5FVidc", "forum": "uWVC5FVidc", "number": 5485, "cdate": 1695388503672, "tcdate": 1695388503672, "mdate": 1712289008164, "tmdate": 1712289008164, "signatures": ["ICLR.cc/2024/Conference/Submission5485/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5485/Authors"], "content": {"title": {"value": "Unbiased Watermark for Large Language Models"}, "authors": {"value": ["Zhengmian Hu", "Lichang Chen", "Xidong Wu", "Yihan Wu", "Hongyang Zhang", "Heng Huang"]}, "authorids": {"value": ["~Zhengmian_Hu1", "~Lichang_Chen2", "~Xidong_Wu1", "~Yihan_Wu1", "~Hongyang_Zhang1", "~Heng_Huang1"]}, "keywords": {"value": ["watermark", "bias"]}, "TLDR": {"value": "Watermark doesn't affect output performance, and cannot be detected by users"}, "abstract": {"value": "The recent advancements in large language models (LLMs) have sparked a growing apprehension regarding the potential misuse. One approach to mitigating this risk is to incorporate watermarking techniques into LLMs, allowing for the tracking and attribution of model outputs. This study examines a crucial aspect of watermarking: how significantly watermarks impact the quality of model-generated outputs. Previous studies have suggested a trade-off between watermark strength and output quality. However, our research demonstrates that it is possible to integrate watermarks without affecting the output probability distribution with appropriate implementation. We refer to this type of watermark as an unbiased watermark. This has significant implications for the use of LLMs, as it becomes impossible for users to discern whether a service provider has incorporated watermarks or not. Furthermore, the presence of watermarks does not compromise the performance of the model in downstream tasks, ensuring that the overall utility of the language model is preserved. Our findings contribute to the ongoing discussion around responsible AI development, suggesting that unbiased watermarks can serve as an effective means of tracking and attributing model outputs without sacrificing output quality."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fdb6b7b2517ce71ee9ed99a12175e4a0273d2b3f.pdf"}, "supplementary_material": {"value": "/attachment/f221b7b10e511ac76c89062cfb5ca17cdda3d379.zip"}, "_bibtex": {"value": "@inproceedings{\nhu2024unbiased,\ntitle={Unbiased Watermark for Large Language Models},\nauthor={Zhengmian Hu and Lichang Chen and Xidong Wu and Yihan Wu and Hongyang Zhang and Heng Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uWVC5FVidc}\n}"}, "paperhash": {"value": "hu|unbiased_watermark_for_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5485/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5485/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940577, "version": 2}, {"id": "EriR6Ec69a", "forum": "EriR6Ec69a", "number": 5484, "cdate": 1695388443633, "tcdate": 1695388443633, "mdate": 1709661521829, "tmdate": 1709661521829, "signatures": ["ICLR.cc/2024/Conference/Submission5484/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5484/Authors"], "content": {"title": {"value": "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control"}, "authors": {"value": ["Neehal Tumma", "Mathias Lechner", "Noel Loo", "Ramin Hasani", "Daniela Rus"]}, "authorids": {"value": ["~Neehal_Tumma1", "~Mathias_Lechner1", "~Noel_Loo1", "~Ramin_Hasani1", "~Daniela_Rus1"]}, "keywords": {"value": ["Low-rank", "sparsity", "closed-loop", "recurrent neural networks"]}, "TLDR": {"value": "Low-rank and sparse recurrent matrices of RNNs can help generalization to closed-loop settings and distribution-shifts"}, "abstract": {"value": "Developing autonomous agents that can interact with changing environments is an open challenge in machine learning. Robustness is particularly important in these settings as agents are often fit offline on expert demonstrations but deployed online where they must generalize to the closed feedback loop within the environment. In this work, we explore the application of recurrent neural networks to tasks of this nature and understand how a parameterization of their recurrent connectivity influences robustness in closed-loop settings. Specifically, we represent the recurrent connectivity as a function of rank and sparsity and show both theoretically and empirically that modulating these two variables has desirable effects on network dynamics. The proposed low-rank, sparse connectivity induces an interpretable prior on the network that proves to be most amenable for a class of models known as closed-form continuous-time neural networks (CfCs). We find that CfCs with fewer parameters can outperform their full-rank, fully-connected counterparts in the online setting under distribution shift. This yields memory-efficient and robust agents while opening a new perspective on how we can modulate network dynamics through connectivity."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/480e9c477c5c570d2bb4494763d1237fdf11f122.pdf"}, "supplementary_material": {"value": "/attachment/662426f547309d5ecb1ad0a1f00d15aea2fc559b.zip"}, "_bibtex": {"value": "@inproceedings{\ntumma2024leveraging,\ntitle={Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control},\nauthor={Neehal Tumma and Mathias Lechner and Noel Loo and Ramin Hasani and Daniela Rus},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EriR6Ec69a}\n}"}, "paperhash": {"value": "tumma|leveraging_lowrank_and_sparse_recurrent_connectivity_for_robust_closedloop_control"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5484/-/Revision", "ICLR.cc/2024/Conference/Submission5484/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5484/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940559, "version": 2}, {"id": "DjzvJCRsVf", "forum": "DjzvJCRsVf", "number": 5422, "cdate": 1695386168997, "tcdate": 1695386168997, "mdate": 1709661520928, "tmdate": 1709661520928, "signatures": ["ICLR.cc/2024/Conference/Submission5422/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5422/Authors"], "content": {"title": {"value": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction"}, "authors": {"value": ["Size Wu", "Wenwei Zhang", "Lumin Xu", "Sheng Jin", "Xiangtai Li", "Wentao Liu", "Chen Change Loy"]}, "authorids": {"value": ["~Size_Wu1", "~Wenwei_Zhang1", "~Lumin_Xu1", "~Sheng_Jin1", "~Xiangtai_Li1", "~Wentao_Liu1", "~Chen_Change_Loy2"]}, "keywords": {"value": ["open-vocabulary object detection", "open-vocabulary image segmentation"]}, "abstract": {"value": "Open-vocabulary dense prediction tasks including object detection and image segmentation have been advanced by the success of Contrastive Language-Image Pre-training (CLIP). CLIP models, particularly those incorporating vision transformers (ViTs), have exhibited remarkable generalization ability in zero-shot image classification. However, when transferring the vision-language alignment of CLIP from global image representation to local region representation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer from the domain shift from full images to local image regions. In this paper, we embark on an in-depth analysis of the region-language alignment in CLIP models, which is essential for downstream open-vocabulary dense prediction tasks. Subsequently, we propose an approach named CLIPSelf, which adapts the image-level recognition ability of CLIP ViT to local image regions without needing any region-text pairs. CLIPSelf empowers ViTs to distill itself by aligning a region representation extracted from its dense feature map with the image-level representation of the corresponding image crop. With the enhanced CLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary object detection, semantic segmentation, and panoptic segmentation across various benchmarks. Models and code are released at https://github.com/wusize/CLIPSelf."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/126c5bcbf7072558944cfd391f4b42a43cdd40b1.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024clipself,\ntitle={{CLIPS}elf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction},\nauthor={Size Wu and Wenwei Zhang and Lumin Xu and Sheng Jin and Xiangtai Li and Wentao Liu and Chen Change Loy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DjzvJCRsVf}\n}"}, "paperhash": {"value": "wu|clipself_vision_transformer_distills_itself_for_openvocabulary_dense_prediction"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5422/-/Revision", "ICLR.cc/2024/Conference/Submission5422/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5422/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938498, "version": 2}, {"id": "QzTpTRVtrP", "forum": "QzTpTRVtrP", "number": 5418, "cdate": 1695386059400, "tcdate": 1695386059400, "mdate": 1712475935304, "tmdate": 1712475935304, "signatures": ["ICLR.cc/2024/Conference/Submission5418/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5418/Authors"], "content": {"title": {"value": "Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI"}, "authors": {"value": ["Weibang Jiang", "Liming Zhao", "Bao-liang Lu"]}, "authorids": {"value": ["~Weibang_Jiang2", "~Liming_Zhao3", "~Bao-liang_Lu1"]}, "keywords": {"value": ["EEG", "brain-computer interface", "representation learning"]}, "abstract": {"value": "The current electroencephalogram (EEG) based deep learning models are typically designed for specific datasets and applications in brain-computer interaction (BCI), limiting the scale of the models and thus diminishing their perceptual capabilities and generalizability. Recently, Large Language Models (LLMs) have achieved unprecedented success in text processing, prompting us to explore the capabilities of Large EEG Models (LEMs). We hope that LEMs can break through the limitations of different task types of EEG datasets, and obtain universal perceptual capabilities of EEG signals through unsupervised pre-training. Then the models can be fine-tuned for different downstream tasks. However, compared to text data, the volume of EEG datasets is generally small and the format varies widely. For example, there can be mismatched numbers of electrodes, unequal length data samples, varied task designs, and low signal-to-noise ratio. To overcome these challenges, we propose a unified foundation model for EEG called Large Brain Model (LaBraM). LaBraM enables cross-dataset learning by segmenting the EEG signals into EEG channel patches. Vector-quantized neural spectrum prediction is used to train a semantically rich neural tokenizer that encodes continuous raw EEG channel patches into compact neural codes. We then pre-train neural Transformers by predicting the original neural codes for the masked EEG channel patches. The LaBraMs were pre-trained on about 2,500 hours of various types of EEG signals from around 20 datasets and validated on multiple different types of downstream tasks. Experiments on abnormal detection, event type classification, emotion recognition, and gait prediction show that our LaBraM outperforms all compared SOTA methods in their respective fields. Our code is available at https://github.com/935963004/LaBraM."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ce4dc6959056452394dc1ad7b8f64005d65d2165.pdf"}, "_bibtex": {"value": "@inproceedings{\njiang2024large,\ntitle={Large Brain Model for Learning Generic Representations with Tremendous {EEG} Data in {BCI}},\nauthor={Weibang Jiang and Liming Zhao and Bao-liang Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QzTpTRVtrP}\n}"}, "paperhash": {"value": "jiang|large_brain_model_for_learning_generic_representations_with_tremendous_eeg_data_in_bci"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5418/-/Revision", "ICLR.cc/2024/Conference/Submission5418/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5418/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938330, "version": 2}, {"id": "vrBVFXwAmi", "forum": "vrBVFXwAmi", "number": 5408, "cdate": 1695385828590, "tcdate": 1695385828590, "mdate": 1712760532747, "tmdate": 1712760532747, "signatures": ["ICLR.cc/2024/Conference/Submission5408/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5408/Authors"], "content": {"title": {"value": "Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark"}, "authors": {"value": ["Yehui Tang", "Hao Xiong", "Nianzu Yang", "Tailong Xiao", "Junchi Yan"]}, "authorids": {"value": ["~Yehui_Tang3", "~Hao_Xiong5", "~Nianzu_Yang1", "~Tailong_Xiao1", "~Junchi_Yan2"]}, "keywords": {"value": ["quantum property estimation", "pretraining", "finetuning"]}, "abstract": {"value": "Estimating the properties of quantum systems such as quantum phase has been critical in addressing the essential quantum many-body problems in physics and chemistry. Deep learning models have been recently introduced to property estimation, surpassing  conventional statistical approaches. However, these methods are tailored to the specific task and quantum data at hand. It remains an open and attractive question for devising a more universal task-agnostic pretraining model for quantum property estimation. In this paper, we propose LLM4QPE, a large language model style quantum task-agnostic pretraining and finetuning paradigm that 1) performs unsupervised pretraining on diverse quantum systems with different physical conditions; 2) uses the pretrained model for supervised finetuning and delivers high performance with limited training data, on downstream tasks. It mitigates the cost for quantum data collection and speeds up convergence. Extensive experiments show the promising efficacy of LLM4QPE in various tasks including classifying quantum phases of matter on Rydberg atom model and predicting two-body correlation function on anisotropic Heisenberg model."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/511ed0e0d3b143e5589b96afaba84da894f71df7.pdf"}, "_bibtex": {"value": "@inproceedings{\ntang2024qtape,\ntitle={Q-{TAPE}: A Task-Agnostic Pre-Trained Approach for Quantum Properties Estimation},\nauthor={Yehui Tang and Hao Xiong and Nianzu Yang and Tailong Xiao and Junchi Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vrBVFXwAmi}\n}"}, "paperhash": {"value": "tang|towards_llm4qpe_unsupervised_pretraining_of_quantum_property_estimation_and_a_benchmark"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5408/-/Revision", "ICLR.cc/2024/Conference/Submission5408/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5408/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938055, "version": 2}, {"id": "F7QnIKlC1N", "forum": "F7QnIKlC1N", "signatures": ["ICLR.cc/2024/Conference/Submission5387/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5387/Authors"], "content": {"title": {"value": "GTMGC: Using Graph Transformer to Predict Molecule\u2019s Ground-State Conformation"}, "authors": {"value": ["Guikun Xu", "Yongquan Jiang", "PengChuan Lei", "Yan Yang", "Jim Chen"]}, "authorids": {"value": ["~Guikun_Xu1", "~Yongquan_Jiang1", "~PengChuan_Lei1", "~Yan_Yang8", "~Jim_Chen2"]}, "keywords": {"value": ["molecular conformation prediction", "molecule modeling", "graph neural network", "graph transformer"]}, "TLDR": {"value": "We propose a Graph-Transformer network which uses a novel self-attention mechanism we developed for molecular structure modeling, achieving SOTA performance in predicting a molecule\u2019s ground-state 3D conformation from its 2D topology graph."}, "abstract": {"value": "The ground-state conformation of a molecule is often decisive for its properties. However, experimental or computational methods, such as density functional theory (DFT), are time-consuming and labor-intensive for obtaining this conformation. Deep learning (DL) based molecular representation learning (MRL) has made significant advancements in molecular modeling and has achieved remarkable results in various tasks. Consequently, it has emerged as a promising approach for directly predicting the ground-state conformation of molecules. In this regard, we introduce GTMGC, a novel network based on Graph-Transformer (GT) that seamlessly predicts the spatial configuration of molecules in a 3D space from their 2D topological architecture in an end-to-end manner. Moreover, we propose a novel self-attention mechanism called Molecule Structural Residual Self-Attention (MSRSA) for molecular structure modeling. This mechanism not only guarantees high model performance and easy implementation but also lends itself well to other molecular modeling tasks. Our method has been evaluated on the Molecule3D benchmark dataset and the QM9 dataset. Experimental results demonstrate that our approach achieves remarkable performance and outperforms current state-of-the-art methods as well as the widely used open-source software RDkit."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c141834e1d331e6055ab503795d49d4e4b8548fb.pdf"}, "_bibtex": {"value": "@inproceedings{\nxu2024gtmgc,\ntitle={{GTMGC}: Using Graph Transformer to Predict Molecule{\\textquoteright}s Ground-State Conformation},\nauthor={Guikun Xu and Yongquan Jiang and PengChuan Lei and Yan Yang and Jim Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=F7QnIKlC1N}\n}"}, "paperhash": {"value": "xu|gtmgc_using_graph_transformer_to_predict_molecules_groundstate_conformation"}}, "number": 5387, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5387/-/Revision", "ICLR.cc/2024/Conference/Submission5387/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5387/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695384763922, "cdate": 1695384763922, "tmdate": 1709732142234, "mdate": 1709732142234, "pdate": 1705410937310, "version": 2}, {"id": "tMzPZTvz2H", "forum": "tMzPZTvz2H", "number": 5374, "cdate": 1695384375100, "tcdate": 1695384375100, "mdate": 1710436178903, "tmdate": 1710436178903, "signatures": ["ICLR.cc/2024/Conference/Submission5374/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5374/Authors"], "content": {"title": {"value": "Generalization of Scaled Deep ResNets in the Mean-Field Regime"}, "authors": {"value": ["Yihang Chen", "Fanghui Liu", "Yiping Lu", "Grigorios Chrysos", "Volkan Cevher"]}, "authorids": {"value": ["~Yihang_Chen1", "~Fanghui_Liu1", "~Yiping_Lu1", "~Grigorios_Chrysos1", "~Volkan_Cevher1"]}, "keywords": {"value": ["ResNet", "mean field", "generalization", "Rademacher complexity"]}, "abstract": {"value": "Despite the widespread empirical success of ResNet, the generalization properties of deep ResNet are rarely explored beyond the lazy training regime. In this work, we investigate scaled ResNet in the limit of infinitely deep and wide neural networks, of which the gradient flow is described by a partial differential equation in the large-neural network limit, i.e., the mean-field regime. To derive the generalization bounds under this setting, our analysis necessitates a shift from the conventional time-invariant Gram matrix employed in the lazy training regime to a time-variant, distribution-dependent version. To this end, we provide a global lower bound on the minimum eigenvalue of the Gram matrix under the mean-field regime. Besides, for the traceability of the dynamic of Kullback-Leibler (KL) divergence, we establish the linear convergence of the empirical error and estimate the upper bound of the KL divergence over parameters distribution. Finally, we build the uniform convergence for generalization bound via Rademacher complexity. Our results offer new insights into the generalization ability of deep ResNet beyond the lazy training regime and contribute to advancing the understanding of the fundamental properties of deep neural networks."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/72b4830ed0321f0098f96447794bfcc965134752.pdf"}, "supplementary_material": {"value": ""}, "_bibtex": {"value": "@inproceedings{\nchen2024generalization,\ntitle={Generalization of Deep ResNets in the Mean-Field Regime},\nauthor={Yihang Chen and Fanghui Liu and Yiping Lu and Grigorios Chrysos and Volkan Cevher},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tMzPZTvz2H}\n}"}, "paperhash": {"value": "chen|generalization_of_scaled_deep_resnets_in_the_meanfield_regime"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5374/-/Revision", "ICLR.cc/2024/Conference/Submission5374/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5374/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410936781, "version": 2}, {"id": "pxI5IPeWgW", "forum": "pxI5IPeWgW", "number": 5372, "cdate": 1695384355212, "tcdate": 1695384355212, "mdate": 1710346006521, "tmdate": 1710346006521, "signatures": ["ICLR.cc/2024/Conference/Submission5372/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5372/Authors"], "content": {"title": {"value": "ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference"}, "authors": {"value": ["Krzysztof Kacprzyk", "Samuel Holt", "Jeroen Berrevoets", "Zhaozhi Qian", "Mihaela van der Schaar"]}, "authorids": {"value": ["~Krzysztof_Kacprzyk1", "~Samuel_Holt1", "~Jeroen_Berrevoets1", "~Zhaozhi_Qian1", "~Mihaela_van_der_Schaar2"]}, "keywords": {"value": ["Treatment Effects over Time"]}, "abstract": {"value": "Inferring unbiased treatment effects has received widespread attention in the machine learning community. In recent years, our community has proposed numerous solutions in standard settings, high-dimensional treatment settings, and even longitudinal settings. While very diverse, the solution has mostly relied on neural networks for inference and simultaneous correction of assignment bias. New approaches typically build on top of previous approaches by proposing new (or refined) architectures and learning algorithms. However, the end result\u2014a neural-network-based inference machine\u2014remains unchallenged. In this paper, we introduce a different type of solution in the longitudinal setting: a closed-form ordinary differential equation (ODE). While we still rely on continuous optimization to learn an ODE, the resulting inference machine is no longer a neural network. Doing so yields several advantages such as interpretability, irregular sampling, and a different set of identification assumptions. Above all, we consider the introduction of a completely new type of solution to be our most important contribution as it may spark entirely new innovations in treatment effects in general. We facilitate this by formulating our contribution as a framework that can transform any ODE discovery method into a treatment effects method."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2e710a9328ce1b12daf4fde40da8165ca071d5db.pdf"}, "_bibtex": {"value": "@inproceedings{\nholt2024ode,\ntitle={{ODE} Discovery for Longitudinal Heterogeneous Treatment Effects Inference},\nauthor={Samuel Holt and Jeroen Berrevoets and Krzysztof Kacprzyk and Zhaozhi Qian and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pxI5IPeWgW}\n}"}, "paperhash": {"value": "kacprzyk|ode_discovery_for_longitudinal_heterogeneous_treatment_effects_inference"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5372/-/Revision", "ICLR.cc/2024/Conference/Submission5372/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5372/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410936718, "version": 2}, {"id": "TjCDNssXKU", "forum": "TjCDNssXKU", "number": 5350, "cdate": 1695383417507, "tcdate": 1695383417507, "mdate": 1710525588897, "tmdate": 1710525588897, "signatures": ["ICLR.cc/2024/Conference/Submission5350/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5350/Authors"], "content": {"title": {"value": "Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics"}, "authors": {"value": ["Christian Gumbsch", "Noor Sajid", "Georg Martius", "Martin V. Butz"]}, "authorids": {"value": ["~Christian_Gumbsch1", "~Noor_Sajid1", "~Georg_Martius1", "~Martin_V._Butz2"]}, "keywords": {"value": ["world models", "temporal abstraction", "hierarchical learning", "model-based reinforcement learning", "hierarchical planning"]}, "TLDR": {"value": "We propose an algorithm to learn a hierarchy of world models from sparse latent state changes for explainable, long-horizon planning."}, "abstract": {"value": "Hierarchical world models can significantly improve model-based reinforcement learning (MBRL) and planning by enabling reasoning across multiple time scales. Nonetheless, the majority of state-of-the-art MBRL methods employ flat, non-hierarchical models. We propose Temporal Hierarchies from Invariant Context Kernels (THICK), an algorithm that learns a world model hierarchy via discrete latent dynamics. The lower level of THICK updates parts of its latent state sparsely in time, forming invariant contexts. The higher level exclusively predicts situations involving context changes. Our experiments demonstrate that THICK learns categorical, interpretable, temporal abstractions on the high level, while maintaining precise low-level predictions. Furthermore, we show that the emergent hierarchical predictive model seamlessly enhances the abilities of MBRL or planning methods. We believe that THICK contributes to the further development of hierarchical agents capable of more sophisticated planning and reasoning abilities."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3e5df2ed6659f21032c8784d5836ef8147d1413a.pdf"}, "_bibtex": {"value": "@inproceedings{\ngumbsch2024learning,\ntitle={Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics},\nauthor={Christian Gumbsch and Noor Sajid and Georg Martius and Martin V. Butz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TjCDNssXKU}\n}"}, "paperhash": {"value": "gumbsch|learning_hierarchical_world_models_with_adaptive_temporal_abstractions_from_discrete_latent_dynamics"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5350/-/Revision", "ICLR.cc/2024/Conference/Submission5350/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5350/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935840, "version": 2}, {"id": "SCQfYpdoGE", "forum": "SCQfYpdoGE", "number": 5341, "cdate": 1695382858837, "tcdate": 1695382858837, "mdate": 1707625621428, "tmdate": 1707625621428, "signatures": ["ICLR.cc/2024/Conference/Submission5341/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5341/Authors"], "content": {"title": {"value": "Prediction without Preclusion: Recourse Verification with Reachable Sets"}, "authors": {"value": ["Avni Kothari", "Bogdan Kulynych", "Tsui-Wei Weng", "Berk Ustun"]}, "authorids": {"value": ["~Avni_Kothari1", "~Bogdan_Kulynych1", "~Tsui-Wei_Weng1", "~Berk_Ustun1"]}, "keywords": {"value": ["algorithmic recourse", "algorithmic fairness", "trustworthy AI"]}, "abstract": {"value": "Machine learning models are often used to decide who receives a loan, a job interview, or a public benefit. Standard methods to learn such models use features about people but overlook their actionability. As a result, models can assign predictions that are fixed \u2013 meaning that consumers who are denied loans, interviews, or benefits are precluded from access to credit, employment, or assistance. In this work, we present a task called recourse verification to flag models that assign fixed predictions under a rich class of real-world actionability constraints. We develop methods to check if a model can provide recourse using reachable sets. We demonstrate how our tools can verify recourse in real-world lending datasets. Our results highlight how models can inadvertently assign fixed predictions that permanently bar access, and underscore the need to account for actionability in model development."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/acd8d0450c58d07bdc49b30bee20c424d6f97e06.pdf"}, "_bibtex": {"value": "@inproceedings{\nkothari2024prediction,\ntitle={Prediction without Preclusion: Recourse Verification with Reachable Sets},\nauthor={Avni Kothari and Bogdan Kulynych and Tsui-Wei Weng and Berk Ustun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SCQfYpdoGE}\n}"}, "paperhash": {"value": "kothari|prediction_without_preclusion_recourse_verification_with_reachable_sets"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5341/-/Revision", "ICLR.cc/2024/Conference/Submission5341/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935406, "version": 2}, {"id": "L8UNn7Llt4", "forum": "L8UNn7Llt4", "number": 5312, "cdate": 1695381376617, "tcdate": 1695381376617, "mdate": 1709661519528, "tmdate": 1709661519528, "signatures": ["ICLR.cc/2024/Conference/Submission5312/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5312/Authors"], "content": {"title": {"value": "ODICE: Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update"}, "authors": {"value": ["Liyuan Mao", "Haoran Xu", "Weinan Zhang", "Xianyuan Zhan"]}, "authorids": {"value": ["~Liyuan_Mao2", "~Haoran_Xu4", "~Weinan_Zhang1", "~Xianyuan_Zhan1"]}, "keywords": {"value": ["offline reinforcement learning", "imitation learning", "distribution correction estimation"]}, "abstract": {"value": "In this study, we investigate the DIstribution Correction Estimation (DICE) methods, an important line of work in offline reinforcement learning (RL) and imitation learning (IL). DICE-based methods impose state-action-level behavior constraint, which is an ideal choice for offline learning. However, they typically perform much worse than current state-of-the-art (SOTA) methods that solely use action-level behavior constraint. After revisiting DICE-based methods, we find there exist two gradient terms when learning the value function using true-gradient update: forward gradient (taken on the current state) and backward gradient (taken on the next state). Using forward gradient bears a large similarity to many offline RL methods, and thus can be regarded as applying action-level constraint. However, directly adding the backward gradient may degenerate or cancel out its effect if these two gradients have conflicting directions. To resolve this issue, we propose a simple yet effective modification that projects the backward gradient onto the normal plane of the forward gradient, resulting in an orthogonal-gradient update, a new learning rule for DICE-based methods. We conduct thorough theoretical analyses and find that the projected backward gradient brings state-level behavior regularization, which reveals the mystery of DICE-based methods: the value learning objective does try to impose state-action-level constraint, but needs to be used in a corrected way. Through toy examples and extensive experiments on complex offline RL and IL tasks, we demonstrate that DICE-based methods using orthogonal-gradient updates achieve SOTA performance and great robustness."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/833ece7fade579c01692e5603d476db35ce59989.pdf"}, "TLDR": {"value": "A simple modification to DICE-based method could achieve SOTA performance and great robustness."}, "_bibtex": {"value": "@inproceedings{\nmao2024revealing,\ntitle={Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update},\nauthor={Liyuan Mao and Haoran Xu and Weinan Zhang and Xianyuan Zhan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L8UNn7Llt4}\n}"}, "paperhash": {"value": "mao|odice_revealing_the_mystery_of_distribution_correction_estimation_via_orthogonalgradient_update"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5312/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5312/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410934430, "version": 2}, {"id": "FYKVPOHCpE", "forum": "FYKVPOHCpE", "number": 5244, "cdate": 1695377907218, "tcdate": 1695377907218, "mdate": 1711616155380, "tmdate": 1711616155380, "signatures": ["ICLR.cc/2024/Conference/Submission5244/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5244/Authors"], "content": {"title": {"value": "Improving Non-Transferable Representation Learning by Harnessing Content and Style"}, "authors": {"value": ["Ziming Hong", "Zhenyi Wang", "Li Shen", "Yu Yao", "Zhuo Huang", "Shiming Chen", "Chuanwu Yang", "Mingming Gong", "Tongliang Liu"]}, "authorids": {"value": ["~Ziming_Hong1", "~Zhenyi_Wang1", "~Li_Shen1", "~Yu_Yao3", "~Zhuo_Huang2", "~Shiming_Chen1", "~Chuanwu_Yang1", "~Mingming_Gong1", "~Tongliang_Liu1"]}, "keywords": {"value": ["non-transferable representation learning", "domain adaptation", "transfer learning"]}, "abstract": {"value": "Non-transferable learning (NTL) aims to restrict the generalization of models toward the target domain(s). To this end, existing works learn non-transferable representations by reducing statistical dependence between the source and target domain. However, such statistical methods essentially neglect to distinguish between *styles* and *contents*, leading them to inadvertently fit (i) spurious correlation between *styles* and *labels*, and (ii) fake independence between *contents* and *labels*. Consequently, their performance will be limited when natural distribution shifts occur or malicious intervention is imposed. In this paper, we propose a novel method (dubbed as H-NTL) to understand and advance the NTL problem by introducing a causal model to separately model *content* and *style* as two latent factors, based on which we disentangle and harness them as guidances for learning non-transferable representations with intrinsically causal relationships. Speci\ufb01cally, to avoid fitting spurious correlation and fake independence, we propose a variational inference framework to disentangle the naturally mixed *content factors* and *style factors* under our causal model. Subsequently, based on dual-path knowledge distillation, we harness the disentangled two *factors* as guidances for non-transferable representation learning: (i) we constraint the source domain representations to fit *content factors* (which are the intrinsic cause of *labels*), and (ii) we enforce that the target domain representations fit *style factors* which barely can predict labels. As a result, the learned feature representations follow optimal untransferability toward the target domain and minimal negative influence on the source domain, thus enabling better NTL performance. Empirically, the proposed H-NTL signi\ufb01cantly outperforms competing methods by a large margin."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4d359626d33d8cb2e10f6d1cf6728b805a2b5316.pdf"}, "_bibtex": {"value": "@inproceedings{\nhong2024improving,\ntitle={Improving Non-Transferable Representation Learning by Harnessing Content and Style},\nauthor={Ziming Hong and Zhenyi Wang and Li Shen and Yu Yao and Zhuo Huang and Shiming Chen and Chuanwu Yang and Mingming Gong and Tongliang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FYKVPOHCpE}\n}"}, "paperhash": {"value": "hong|improving_nontransferable_representation_learning_by_harnessing_content_and_style"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5244/-/Revision", "ICLR.cc/2024/Conference/Submission5244/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5244/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932686, "version": 2}, {"id": "vpJMJerXHU", "forum": "vpJMJerXHU", "number": 5228, "cdate": 1695376973403, "tcdate": 1695376973403, "mdate": 1711094465056, "tmdate": 1711094465056, "signatures": ["ICLR.cc/2024/Conference/Submission5228/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5228/Authors"], "content": {"title": {"value": "ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis"}, "authors": {"value": ["Luo donghao", "wang xue"]}, "authorids": {"value": ["~Luo_donghao2", "~wang_xue3"]}, "keywords": {"value": ["Time Series Analysis", "Deep Learning"]}, "TLDR": {"value": "We take a seldom-explored way in time series community to successfully bring convolution back to time series analysis. Our pure convolution structure achieves consistent state-of-the-art in five mainstream time series analysis tasks."}, "abstract": {"value": "Recently, Transformer-based and MLP-based models have emerged rapidly and\nwon dominance in time series analysis. In contrast, convolution is losing steam\nin time series tasks nowadays for inferior performance. This paper studies the\nopen question of how to better use convolution in time series analysis and makes\nefforts to bring convolution back to the arena of time series analysis. To this end,\nwe modernize the traditional TCN and conduct time series related modifications\nto make it more suitable for time series tasks. As the outcome, we propose\nModernTCN and successfully solve this open question through a seldom-explored\nway in time series community. As a pure convolution structure, ModernTCN still\nachieves the consistent state-of-the-art performance on five mainstream time series\nanalysis tasks while maintaining the efficiency advantage of convolution-based\nmodels, therefore providing a better balance of efficiency and performance than\nstate-of-the-art Transformer-based and MLP-based models. Our study further\nreveals that, compared with previous convolution-based models, our ModernTCN\nhas much larger effective receptive fields (ERFs), therefore can better unleash the\npotential of convolution in time series analysis. Code is available at this repository:\nhttps://github.com/luodhhh/ModernTCN."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c0de77eed380b4b2736dfe855ed3cf0d62f7d8c1.pdf"}, "_bibtex": {"value": "@inproceedings{\ndonghao2024moderntcn,\ntitle={Modern{TCN}: A Modern Pure Convolution Structure for General Time Series Analysis},\nauthor={Luo donghao and wang xue},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vpJMJerXHU}\n}"}, "paperhash": {"value": "donghao|moderntcn_a_modern_pure_convolution_structure_for_general_time_series_analysis"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5228/-/Revision", "ICLR.cc/2024/Conference/Submission5228/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5228/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932199, "version": 2}, {"id": "tPEwSYPtAC", "forum": "tPEwSYPtAC", "number": 5162, "cdate": 1695374511331, "tcdate": 1695374511331, "mdate": 1710124752527, "tmdate": 1710124752527, "signatures": ["ICLR.cc/2024/Conference/Submission5162/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5162/Authors"], "content": {"title": {"value": "Towards Robust Out-of-Distribution Generalization Bounds via Sharpness"}, "authors": {"value": ["Yingtian Zou", "Kenji Kawaguchi", "Yingnan Liu", "Jiashuo Liu", "Mong-Li Lee", "Wynne Hsu"]}, "authorids": {"value": ["~Yingtian_Zou1", "~Kenji_Kawaguchi1", "~Yingnan_Liu1", "~Jiashuo_Liu1", "~Mong-Li_Lee1", "~Wynne_Hsu1"]}, "keywords": {"value": ["Out-of-Distribution generalization", "Sharpness", "Robustness"]}, "TLDR": {"value": "In this paper, we propose a sharpness-based OOD generalization bound by considering the model robustness."}, "abstract": {"value": "Generalizing to out-of-distribution (OOD) data or unseen domain, termed OOD generalization, still lacks appropriate theoretical guarantees. Canonical OOD bounds focus on different distance measurements between source and target domains but fail to consider the optimization property of the learned model. As empirically shown in recent work, sharpness of learned minimum influences OOD generalization. To bridge this gap between optimization and OOD generalization, we study the effect of sharpness on how a model tolerates data change in domain shift which is usually captured by \"robustness\" in generalization. In this paper, we give a rigorous connection between sharpness and robustness, which gives better OOD guarantees for robust algorithms. It also provides a theoretical backing for \"flat minima leads to better OOD generalization\". Overall, we propose a sharpness-based OOD generalization bound by taking robustness into consideration, resulting in a tighter bound than non-robust guarantees. Our findings are supported by the experiments on a ridge regression model, as well as the experiments on deep learning classification tasks."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/36904eee9458f8a5da9944cdcd92446a053dfa88.pdf"}, "_bibtex": {"value": "@inproceedings{\nzou2024towards,\ntitle={Towards Robust Out-of-Distribution Generalization Bounds via Sharpness},\nauthor={Yingtian Zou and Kenji Kawaguchi and Yingnan Liu and Jiashuo Liu and Mong-Li Lee and Wynne Hsu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tPEwSYPtAC}\n}"}, "paperhash": {"value": "zou|towards_robust_outofdistribution_generalization_bounds_via_sharpness"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5162/-/Revision", "ICLR.cc/2024/Conference/Submission5162/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5162/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929955, "version": 2}, {"id": "itGkF993gz", "forum": "itGkF993gz", "number": 5141, "cdate": 1695373881938, "tcdate": 1695373881938, "mdate": 1709661517727, "tmdate": 1709661517727, "signatures": ["ICLR.cc/2024/Conference/Submission5141/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5141/Authors"], "content": {"title": {"value": "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding"}, "authors": {"value": ["Lirong Wu", "Yijun Tian", "Yufei Huang", "Siyuan Li", "Haitao Lin", "Nitesh V Chawla", "Stan Z. Li"]}, "authorids": {"value": ["~Lirong_Wu1", "~Yijun_Tian1", "~Yufei_Huang4", "~Siyuan_Li6", "~Haitao_Lin2", "~Nitesh_V_Chawla1", "~Stan_Z._Li2"]}, "keywords": {"value": ["Bioinformatics", "Protein-Protein Interaction", "Protein Sequence-Structure Co-Modeling"]}, "abstract": {"value": "Protein-Protein Interactions (PPIs) are fundamental in various biological processes and play a key role in life activities. The growing demand and cost of experimental PPI assays require computational methods for efficient PPI prediction. While existing methods rely heavily on protein sequence for PPI prediction, it is the protein structure that is the key to determine the interactions. To take both protein modalities into account, we define the microenvironment of an amino acid residue by its sequence and structural contexts, which describe the surrounding chemical properties and geometric features. In addition, microenvironments defined in previous work are largely based on experimentally assayed physicochemical properties, for which the \"vocabulary\" is usually extremely small. This makes it difficult to cover the diversity and complexity of microenvironments. In this paper, we propose Microenvironment-Aware Protein Embedding for PPI prediction (MPAE-PPI), which encodes microenvironments into chemically meaningful discrete codes via a sufficiently large microenvironment \"vocabulary\" (i.e., codebook). Moreover, we propose a novel pre-training strategy, namely Masked Codebook Modeling (MCM), to capture the dependencies between different microenvironments by randomly masking the codebook and reconstructing the input. With the learned microenvironment codebook, we can reuse it as an off-the-shelf tool to efficiently and effectively encode proteins of different sizes and functions for large-scale PPI prediction. Extensive experiments show that MAPE-PPI can scale to PPI prediction with millions of PPIs with superior trade-offs between effectiveness and computational efficiency than the state-of-the-art competitors."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/72464b5e34ef4de8f928bfdd6309981dbe271cf6.pdf"}, "TLDR": {"value": "In this paper, we propose Microenvironment-Aware Protein Embedding for PPI prediction (MPAE-PPI), which encodes microenvironments into chemically meaningful discrete codes via a sufficiently large microenvironment ``vocabulary\" (i.e., codebook)."}, "_bibtex": {"value": "@inproceedings{\nwu2024mapeppi,\ntitle={{MAPE}-{PPI}: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding},\nauthor={Lirong Wu and Yijun Tian and Yufei Huang and Siyuan Li and Haitao Lin and Nitesh V Chawla and Stan Z. Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=itGkF993gz}\n}"}, "paperhash": {"value": "wu|mapeppi_towards_effective_and_efficient_proteinprotein_interaction_prediction_via_microenvironmentaware_protein_embedding"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5141/-/Revision", "ICLR.cc/2024/Conference/Submission5141/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5141/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929076, "version": 2}, {"id": "xUO1HXz4an", "forum": "xUO1HXz4an", "number": 5140, "cdate": 1695373767831, "tcdate": 1695373767831, "mdate": 1710238468822, "tmdate": 1710238468822, "signatures": ["ICLR.cc/2024/Conference/Submission5140/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5140/Authors"], "content": {"title": {"value": "Negative Label Guided OOD Detection with Pretrained Vision-Language Models"}, "authors": {"value": ["Xue Jiang", "Feng Liu", "Zhen Fang", "Hong Chen", "Tongliang Liu", "Feng Zheng", "Bo Han"]}, "authorids": {"value": ["~Xue_Jiang3", "~Feng_Liu2", "~Zhen_Fang2", "~Hong_Chen1", "~Tongliang_Liu1", "~Feng_Zheng1", "~Bo_Han1"]}, "keywords": {"value": ["OOD detection"]}, "abstract": {"value": "Out-of-distribution (OOD) detection aims at identifying samples from unknown classes, playing a crucial role in trustworthy models against errors on unexpected inputs.  \nExtensive research has been dedicated to exploring OOD detection in the vision modality. \n{Vision-language models (VLMs) can leverage both textual and visual information for various multi-modal applications, whereas few OOD detection methods take into account information from the text modality. \nIn this paper, we propose a novel post hoc OOD detection method, called NegLabel, which takes a vast number of negative labels from extensive corpus databases. We design a novel scheme for the OOD score collaborated with negative labels.\nTheoretical analysis helps to understand the mechanism of negative labels. Extensive experiments demonstrate that our method NegLabel achieves state-of-the-art performance on various OOD detection benchmarks and generalizes well on multiple VLM architectures. Furthermore, our method NegLabel exhibits remarkable robustness against diverse domain shifts. The codes are available at https://github.com/tmlr-group/NegLabel."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/91d27446713fac0e8088c043103df8020d343ff7.pdf"}, "_bibtex": {"value": "@inproceedings{\njiang2024negative,\ntitle={Negative Label Guided {OOD} Detection with Pretrained Vision-Language Models},\nauthor={Xue Jiang and Feng Liu and Zhen Fang and Hong Chen and Tongliang Liu and Feng Zheng and Bo Han},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xUO1HXz4an}\n}"}, "paperhash": {"value": "jiang|negative_label_guided_ood_detection_with_pretrained_visionlanguage_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5140/-/Revision", "ICLR.cc/2024/Conference/Submission5140/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5140/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929048, "version": 2}, {"id": "47hDbAMLbc", "forum": "47hDbAMLbc", "number": 5108, "cdate": 1695372750311, "tcdate": 1695372750311, "mdate": 1709898724771, "tmdate": 1709898724771, "signatures": ["ICLR.cc/2024/Conference/Submission5108/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5108/Authors"], "content": {"title": {"value": "OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS"}, "authors": {"value": ["Lijia Yu", "Xiao-Shan Gao", "Lijun Zhang"]}, "authorids": {"value": ["~Lijia_Yu2", "~Xiao-Shan_Gao2", "~Lijun_Zhang2"]}, "keywords": {"value": ["Memorization", "expressive power of network", "optimal robust memorization", "computation complexity", "Lipschitz constant"]}, "TLDR": {"value": "The difficulty and possibility of implementing robust network are demonstrated from the perspective of memorization and computation complexity."}, "abstract": {"value": "Memorization with neural networks is to study the expressive power of neural networks to interpolate a finite classification data set, which is closely related to the generalizability of deep learning. However, the important problem of robust memorization has not been thoroughly studied. In this paper, several basic problems about robust memorization are solved. First, we prove that it is NP-hard to compute neural networks with certain simple structures, which are robust memorization. A network hypothesis space is called optimal robust memorization for a data set if it can achieve robust memorization for any budget less than half the separation bound of the data set. Second, we explicitly construct neural networks with O(N n) parameters for optimal robust memorization of any data set with dimension n and size N . We also give a lower bound for the width of networks to achieve optimal robust memorization. Finally, we explicitly construct neural networks with\nO(N n log n) parameters for optimal robust memorization of any binary classification data set by controlling the Lipschitz constant of the network."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c5be8a576cab367723fcf91c4b950557846a3e1a.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024optimal,\ntitle={{OPTIMAL} {ROBUST} {MEMORIZATION} {WITH} {RELU} {NEURAL} {NETWORKS}},\nauthor={Lijia Yu and Xiao-Shan Gao and Lijun Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=47hDbAMLbc}\n}"}, "paperhash": {"value": "yu|optimal_robust_memorization_with_relu_neural_networks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5108/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5108/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927404, "version": 2}, {"id": "iAYIRHOYy8", "forum": "iAYIRHOYy8", "number": 5107, "cdate": 1695372721302, "tcdate": 1695372721302, "mdate": 1710322463590, "tmdate": 1710322463590, "signatures": ["ICLR.cc/2024/Conference/Submission5107/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5107/Authors"], "content": {"title": {"value": "Neural Contractive Dynamical Systems"}, "authors": {"value": ["Hadi Beik Mohammadi", "S\u00f8ren Hauberg", "Georgios Arvanitidis", "Nadia Figueroa", "Gerhard Neumann", "Leonel Rozo"]}, "authorids": {"value": ["~Hadi_Beik_Mohammadi1", "~S\u00f8ren_Hauberg1", "~Georgios_Arvanitidis1", "~Nadia_Figueroa1", "~Gerhard_Neumann2", "~Leonel_Rozo1"]}, "keywords": {"value": ["learning from demonstration", "dynamical systems", "contraction theory"]}, "TLDR": {"value": "The paper introduces the Neural Contractive Dynamical System (NCDS), providing a flexible and stable approach for learning contractive dynamics, and extends it to high-dimensional systems with obstacle avoidance capabilities."}, "abstract": {"value": "Stability guarantees are crucial when ensuring that a fully autonomous robot does not take undesirable or potentially harmful actions. Unfortunately, global stability guarantees are hard to provide in dynamical systems learned from data, especially when the learned dynamics are governed by neural networks. We propose a novel methodology to learn \\emph{neural contractive dynamical systems}, where our neural architecture ensures contraction, and hence, global stability. To efficiently scale the method to high-dimensional dynamical systems, we develop a variant of the variational autoencoder that learns dynamics in a low-dimensional latent representation space while retaining contractive stability after decoding. We further extend our approach to learning contractive systems on the Lie group of rotations to account for full-pose end-effector dynamic motions. The result is the first highly flexible learning architecture that provides contractive stability guarantees with capability to perform obstacle avoidance. Empirically, we demonstrate that our approach encodes the desired dynamics more accurately than the current state-of-the-art, which provides less strong stability guarantees."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a89591eec311a0efbd01f7135555a21d2d682c1c.pdf"}, "supplementary_material": {"value": "/attachment/58947be005497ff04d158bb31e64b18f6186222b.zip"}, "_bibtex": {"value": "@inproceedings{\nmohammadi2024neural,\ntitle={Neural Contractive Dynamical Systems},\nauthor={Hadi Beik Mohammadi and S{\\o}ren Hauberg and Georgios Arvanitidis and Nadia Figueroa and Gerhard Neumann and Leonel Rozo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iAYIRHOYy8}\n}"}, "paperhash": {"value": "mohammadi|neural_contractive_dynamical_systems"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5107/-/Revision", "ICLR.cc/2024/Conference/Submission5107/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5107/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927374, "version": 2}, {"id": "Tzh6xAJSll", "forum": "Tzh6xAJSll", "number": 5072, "cdate": 1695371744750, "tcdate": 1695371744750, "mdate": 1710533766557, "tmdate": 1710533766557, "signatures": ["ICLR.cc/2024/Conference/Submission5072/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5072/Authors"], "content": {"title": {"value": "Scaling Laws for Associative Memories"}, "authors": {"value": ["Vivien Cabannes", "Elvis Dohmatob", "Alberto Bietti"]}, "authorids": {"value": ["~Vivien_Cabannes1", "~Elvis_Dohmatob1", "~Alberto_Bietti1"]}, "keywords": {"value": ["scaling law", "associative memory", "mechanistic interpretability", "Hopfield network"]}, "TLDR": {"value": "Mechanistic interpretability of memorization (modeling transformer intermediate layers)"}, "abstract": {"value": "Learning arguably involves the discovery and memorization of abstract rules. The aim of this paper is to study associative memory mechanisms. Our model is based on high-dimensional matrices consisting of outer products of embeddings, which relates to the inner layers of transformer language models. We derive precise scaling laws with respect to sample size and parameter size, and discuss the statistical efficiency of different estimators, including optimization-based algorithms. We provide extensive numerical experiments to validate and interpret theoretical results, including fine-grained visualizations of the stored memory associations."}, "pdf": {"value": "/pdf/ba075a88abc0ad2b7f00577253a950d3264c5f2f.pdf"}, "supplementary_material": {"value": "/attachment/87508fd941eec802b081163b0addc6d35a34c788.zip"}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\ncabannes2024scaling,\ntitle={Scaling Laws for Associative Memories},\nauthor={Vivien Cabannes and Elvis Dohmatob and Alberto Bietti},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tzh6xAJSll}\n}"}, "paperhash": {"value": "cabannes|scaling_laws_for_associative_memories"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5072/-/Revision", "ICLR.cc/2024/Conference/Submission5072/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5072/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926342, "version": 2}, {"id": "tUM39YTRxH", "forum": "tUM39YTRxH", "number": 5039, "cdate": 1695370584620, "tcdate": 1695370584620, "mdate": 1709661516294, "tmdate": 1709661516294, "signatures": ["ICLR.cc/2024/Conference/Submission5039/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5039/Authors"], "content": {"title": {"value": "Text2Reward: Reward Shaping with Language Models for Reinforcement Learning"}, "authors": {"value": ["Tianbao Xie", "Siheng Zhao", "Chen Henry Wu", "Yitao Liu", "Qian Luo", "Victor Zhong", "Yanchao Yang", "Tao Yu"]}, "authorids": {"value": ["~Tianbao_Xie1", "~Siheng_Zhao1", "~Chen_Henry_Wu1", "~Yitao_Liu2", "~Qian_Luo1", "~Victor_Zhong1", "~Yanchao_Yang1", "~Tao_Yu5"]}, "keywords": {"value": ["reinforcement learning; large language models; robotics"]}, "abstract": {"value": "Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation and shaping of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates shaped dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes or unshaped dense rewards with a constant function across timesteps, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes. For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%. Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world. Finally, Text2Reward further improves the policies by refining their reward functions with human feedback. Video results are available at https://text-to-reward.github.io/"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a52e7202163a42116fae8ada42123e37f2aef287.pdf"}, "TLDR": {"value": "Reward shaping for reinforcement learning based on large language models"}, "_bibtex": {"value": "@inproceedings{\nxie2024textreward,\ntitle={Text2Reward: Dense Reward Generation with Language Models for Reinforcement Learning},\nauthor={Tianbao Xie and Siheng Zhao and Chen Henry Wu and Yitao Liu and Qian Luo and Victor Zhong and Yanchao Yang and Tao Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tUM39YTRxH}\n}"}, "paperhash": {"value": "xie|text2reward_reward_shaping_with_language_models_for_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5039/-/Revision", "ICLR.cc/2024/Conference/Submission5039/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5039/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925312, "version": 2}, {"id": "sMoifbuxjB", "forum": "sMoifbuxjB", "number": 4946, "cdate": 1695367801062, "tcdate": 1695367801062, "mdate": 1713101935713, "tmdate": 1713101935713, "signatures": ["ICLR.cc/2024/Conference/Submission4946/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4946/Authors"], "content": {"title": {"value": "Towards Meta-Pruning via Optimal Transport"}, "authors": {"value": ["Alexander Theus", "Olin Geimer", "Friedrich Wicke", "Thomas Hofmann", "Sotiris Anagnostidis", "Sidak Pal Singh"]}, "authorids": {"value": ["~Alexander_Theus1", "~Olin_Geimer1", "~Friedrich_Wicke1", "~Thomas_Hofmann1", "~Sotiris_Anagnostidis1", "~Sidak_Pal_Singh1"]}, "keywords": {"value": ["Pruning", "Fusion"]}, "TLDR": {"value": "Marrying Pruning and Fusion"}, "abstract": {"value": "Structural pruning of neural networks conventionally relies on identifying and discarding less important neurons, a practice often resulting in significant accuracy loss that necessitates subsequent fine-tuning efforts. This paper introduces a novel approach named Intra-Fusion, challenging this prevailing pruning paradigm.\nUnlike existing methods that focus on designing meaningful neuron importance metrics, Intra-Fusion redefines the overlying pruning procedure.\nThrough utilizing the concepts of model fusion and Optimal Transport, we leverage an agnostically given importance metric to arrive at a more effective sparse model representation.\nNotably, our approach achieves substantial accuracy recovery without the need for resource-intensive fine-tuning, making it an efficient and promising tool for neural network compression.\nAdditionally, we explore how fusion can be added to the pruning process to significantly decrease the training time while maintaining competitive performance. We benchmark our results for various networks on commonly used datasets such as CIFAR-10, CIFAR-100, and ImageNet. More broadly, we hope that the proposed Intra-Fusion approach invigorates exploration into a fresh alternative to the predominant compression approaches.\nOur code is available [here](https://github.com/alexandertheus/Intra-Fusion)."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/07560e42af2e42df14ac71025723b0b97a0924dd.pdf"}, "supplementary_material": {"value": "/attachment/f3880bade5a956d1464267f23a17af22bb840fb2.zip"}, "_bibtex": {"value": "@inproceedings{\ntheus2024towards,\ntitle={Towards Meta-Pruning via Optimal Transport},\nauthor={Alexander Theus and Olin Geimer and Friedrich Wicke and Thomas Hofmann and Sotiris Anagnostidis and Sidak Pal Singh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sMoifbuxjB}\n}"}, "paperhash": {"value": "theus|towards_metapruning_via_optimal_transport"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4946/-/Revision", "ICLR.cc/2024/Conference/Submission4946/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4946/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922671, "version": 2}, {"id": "MLBdiWu4Fw", "forum": "MLBdiWu4Fw", "number": 4917, "cdate": 1695367201861, "tcdate": 1695367201861, "mdate": 1713099671200, "tmdate": 1713099671200, "signatures": ["ICLR.cc/2024/Conference/Submission4917/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4917/Authors"], "content": {"title": {"value": "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation"}, "authors": {"value": ["Yi Wang", "Yinan He", "Yizhuo Li", "Kunchang Li", "Jiashuo Yu", "Xin Ma", "Xinhao Li", "Guo Chen", "Xinyuan Chen", "Yaohui Wang", "Ping Luo", "Ziwei Liu", "Yali Wang", "Limin Wang", "Yu Qiao"]}, "authorids": {"value": ["~Yi_Wang19", "~Yinan_He1", "~Yizhuo_Li1", "~Kunchang_Li1", "~Jiashuo_Yu1", "~Xin_Ma3", "~Xinhao_Li1", "~Guo_Chen2", "~Xinyuan_Chen1", "~Yaohui_Wang1", "~Ping_Luo2", "~Ziwei_Liu1", "~Yali_Wang1", "~Limin_Wang1", "~Yu_Qiao1"]}, "keywords": {"value": ["video-language dataset", "video understanding", "video generation", "multimodal understanding", "action recognition", "video retrieval"]}, "abstract": {"value": "This paper introduces InternVid, a large-scale video-centric multimodal dataset that enables learning powerful and transferable video-text representations for multimodal understanding and generation. InternVid contains over 7 million videos lasting nearly 760K hours, yielding 234M video clips accompanied by detailed descriptions of total 4.1B words. Our core contribution is to develop a scalable approach to autonomously build a high-quality video-text dataset with large language models (LLM), thereby showcasing its efficacy in learning video-language representation at scale. Specifically, we utilize a multi-scale approach to generate video-related descriptions. Furthermore, we introduce ViCLIP, a video-text representation learning model based on ViT-L. Learned on InternVid via contrastive learning, this model demonstrates leading zero-shot action recognition and competitive video retrieval performance. Beyond basic video understanding tasks like recognition and retrieval, our dataset and model have broad applications. They are particularly beneficial for generating interleaved video-text data for learning a video-centric dialogue system, advancing video-to-text and text-to-video generation research. These proposed resources provide a tool for researchers and practitioners interested in multimodal video understanding and generation."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "This paper introduces InternVid, a large-scale video-centric multimodal dataset that enables learning powerful and transferable video-text representations for multimodal understanding and generation."}, "pdf": {"value": "/pdf/5355ce2fec3ff26dca65a969b767fd7b1102bb05.pdf"}, "supplementary_material": {"value": "/attachment/ab6262d86bfdbdf3844255ccbd7ff6bdca41c17b.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024internvid,\ntitle={InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation},\nauthor={Yi Wang and Yinan He and Yizhuo Li and Kunchang Li and Jiashuo Yu and Xin Ma and Xinhao Li and Guo Chen and Xinyuan Chen and Yaohui Wang and Ping Luo and Ziwei Liu and Yali Wang and Limin Wang and Yu Qiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MLBdiWu4Fw}\n}"}, "paperhash": {"value": "wang|internvid_a_largescale_videotext_dataset_for_multimodal_understanding_and_generation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4917/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4917/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921840, "version": 2}, {"id": "Gg7cXo3S8l", "forum": "Gg7cXo3S8l", "number": 4912, "cdate": 1695367047828, "tcdate": 1695367047828, "mdate": 1710571003487, "tmdate": 1710571003487, "signatures": ["ICLR.cc/2024/Conference/Submission4912/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4912/Authors"], "content": {"title": {"value": "Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks"}, "authors": {"value": ["Suhwan Choi", "Myeongho Jeon", "Yeonjung Hwang", "Jeonglyul Oh", "Sungjun Lim", "Joonseok Lee", "Myungjoo Kang"]}, "authorids": {"value": ["~Suhwan_Choi1", "~Myeongho_Jeon1", "~Yeonjung_Hwang1", "~Jeonglyul_Oh1", "~Sungjun_Lim3", "~Joonseok_Lee1", "~Myungjoo_Kang1"]}, "keywords": {"value": ["Contrastive learning", "Forward learning", "Local learning", "Image classification", "Efficient learning"]}, "TLDR": {"value": "We propose a simple and efficient local contrastive learning objective that directly compares local features with label embeddings."}, "abstract": {"value": "While backpropagation (BP) has achieved widespread success in deep learning, it\nfaces two prominent challenges: computational inefficiency and biological implausibility.\nIn response to these challenges, local supervision, encompassing Local\nLearning (LL) and Forward Learning (FL), has emerged as a promising research\ndirection. LL employs module-wise BP to achieve competitive results yet relies on\nmodule-wise auxiliary networks, which increase memory and parameter demands.\nConversely, FL updates layer weights without BP and auxiliary networks but falls\nshort of BP\u2019s performance. This paper proposes a simple yet effective objective\nwithin a contrastive learning framework for local supervision without auxiliary\nnetworks. Given the insight that the existing contrastive learning framework for\nlocal supervision is susceptible to task-irrelevant information without auxiliary\nnetworks, we present DICTIONARY CONTRASTIVE LEARNING (DCL) that optimizes\nthe similarity between local features and label embeddings. Our method\nusing static label embeddings yields substantial performance improvements in the\nFL scenario, outperforming state-of-the-art FL approaches. Moreover, our method\nusing adaptive label embeddings closely approaches the performance achieved by\nLL while achieving superior memory and parameter efficiency."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f9734ebbb92e7bdafcdb35c2da50c63e5e5ad16d.pdf"}, "supplementary_material": {"value": "/attachment/4d7b65bb0cb5bc2c31aba5d42a1ed81262af681a.zip"}, "_bibtex": {"value": "@inproceedings{\nchoi2024dictionary,\ntitle={Dictionary Contrastive Forward Learning via Adaptive Label Embeddings},\nauthor={Suhwan Choi and Myeongho Jeon and Yeonjung Hwang and Jeonglyul Oh and Sungjun Lim and Joonseok Lee and Myungjoo Kang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Gg7cXo3S8l}\n}"}, "paperhash": {"value": "choi|dictionary_contrastive_learning_for_efficient_local_supervision_without_auxiliary_networks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4912/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4912/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/Submission4912/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921779, "version": 2}, {"id": "lmM4Ecm4HJ", "forum": "lmM4Ecm4HJ", "number": 4908, "cdate": 1695366897165, "tcdate": 1695366897165, "mdate": 1710944012393, "tmdate": 1710944012393, "signatures": ["ICLR.cc/2024/Conference/Submission4908/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4908/Authors"], "content": {"title": {"value": "Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments"}, "authors": {"value": ["Yang Yang", "Wenhai Wang", "Zhe Chen", "Jifeng Dai", "Liang Zheng"]}, "authorids": {"value": ["~Yang_Yang32", "~Wenhai_Wang2", "~Zhe_Chen10", "~Jifeng_Dai1", "~Liang_Zheng4"]}, "keywords": {"value": ["Object Detection", "Model Generalization"]}, "abstract": {"value": "Bounding boxes uniquely characterize object detection, where a good detector gives accurate bounding boxes of categories of interest. However, in the real-world where test ground truths are not provided, it is non-trivial to find out whether bounding boxes are accurate, thus preventing us from assessing the detector generalization ability. In this work, we find under feature map dropout, good detectors tend to output bounding boxes whose locations do not change much, while bounding boxes of poor detectors will undergo noticeable position changes. We compute the box stability score (BS score) to reflect this stability. Specifically, given an image, we compute a normal set of bounding boxes and a second set after feature map dropout. To obtain BS score, we use bipartite matching to find the corresponding boxes between the two sets and compute the average Intersection over Union (IoU) across the entire test set. We contribute to finding that BS score has a strong, positive correlation with detection accuracy measured by mean average precision (mAP) under various test environments. This relationship allows us to predict the accuracy of detectors on various real-world test sets without accessing test ground truths, verified on canonical detection tasks such as vehicle detection and pedestrian detection."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5510c4a1e453a12979e2d2a9f12b836fdc0436c8.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024bounding,\ntitle={Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments},\nauthor={Yang Yang and Wenhai Wang and Zhe Chen and Jifeng Dai and Liang Zheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lmM4Ecm4HJ}\n}"}, "TLDR": {"value": "Predict the accuracy of detectors on various real-world test sets without accessing test ground truths."}, "paperhash": {"value": "yang|bounding_box_stability_against_feature_dropout_reflects_detector_generalization_across_environments"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4908/-/Revision", "ICLR.cc/2024/Conference/Submission4908/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4908/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921613, "version": 2}, {"id": "PnR1MNen7u", "forum": "PnR1MNen7u", "number": 4904, "cdate": 1695366681071, "tcdate": 1695366681071, "mdate": 1710502786822, "tmdate": 1710502786822, "signatures": ["ICLR.cc/2024/Conference/Submission4904/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4904/Authors"], "content": {"title": {"value": "Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data"}, "authors": {"value": ["Ce Ju", "Reinmar J Kobler", "Liyao Tang", "Cuntai Guan", "Motoaki Kawanabe"]}, "authorids": {"value": ["~Ce_Ju1", "~Reinmar_J_Kobler1", "~Liyao_Tang1", "~Cuntai_Guan1", "~Motoaki_Kawanabe1"]}, "keywords": {"value": ["Geometric Deep Learning", "Self-Supervised Learning", "Brain-Computer Interfaces", "Neuroimaging", "Neuroscience"]}, "abstract": {"value": "In human neuroimaging, multi-modal imaging techniques are frequently combined to enhance our comprehension of whole-brain dynamics and improve diagnosis in clinical practice. Modalities like electroencephalography and functional magnetic resonance imaging provide distinct views to the brain dynamics due to diametral spatiotemporal sensitivities and underlying neurophysiological coupling mechanisms. These distinct views pose a considerable challenge to learning a shared representation space, especially when dealing with covariance-based data characterized by their geometric structure. To capitalize on the geometric structure, we introduce a measure called geodesic correlation which expands traditional correlation consistency to covariance-based data on the symmetric positive definite (SPD) manifold. This measure is derived from classical canonical correlation analysis and serves to evaluate the consistency of latent representations obtained from paired views. For multi-view, self-supervised learning where one or both latent views are SPD we propose an innovative geometric deep learning framework termed DeepGeoCCA. Its primary objective is to enhance the geodesic correlation of unlabeled, paired data, thereby generating novel representations while retaining the geometric structures. In simulations and experiments with multi-view and multi-modal human neuroimaging data, we find that DeepGeoCCA learns latent representations with high geodesic correlation for unseen data while retaining relevant information for downstream tasks."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4ccf9cac26244e14e3fd2742852e226018c0e4b8.pdf"}, "TLDR": {"value": "A geometric deep learning-based approach to learn the SPD matrix-valued latent representation for paired covariance-based neuroimaging modalities under the self-supervised learning framework."}, "_bibtex": {"value": "@inproceedings{\nju2024deep,\ntitle={Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data},\nauthor={Ce Ju and Reinmar J Kobler and Liyao Tang and Cuntai Guan and Motoaki Kawanabe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PnR1MNen7u}\n}"}, "paperhash": {"value": "ju|deep_geodesic_canonical_correlation_analysis_for_covariancebased_neuroimaging_data"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4904/-/Revision", "ICLR.cc/2024/Conference/Submission4904/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4904/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921397, "version": 2}, {"id": "tveiUXU2aa", "forum": "tveiUXU2aa", "number": 4897, "cdate": 1695366302606, "tcdate": 1695366302606, "mdate": 1709777715253, "tmdate": 1709777715253, "signatures": ["ICLR.cc/2024/Conference/Submission4897/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4897/Authors"], "content": {"title": {"value": "SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS"}, "authors": {"value": ["Yameng Peng", "Andy Song", "Haytham M. Fayek", "Vic Ciesielski", "Xiaojun Chang"]}, "authorids": {"value": ["~Yameng_Peng1", "~Andy_Song1", "~Haytham_M._Fayek1", "~Vic_Ciesielski1", "~Xiaojun_Chang4"]}, "keywords": {"value": ["Neural Architecture Search", "Network evaluation", "Training-free metric", "Deep neural networks"]}, "abstract": {"value": "Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid resource-intensive neural network training, especially in Neural Architecture Search (NAS). Recent studies show that existing training-free metrics have several limitations, such as limited correlation and poor generalisation across different search spaces and tasks. Hence, we propose Sample-Wise Activation Patterns and its derivative, SWAP-Score, a novel high-performance training-free metric. It measures the expressivity of networks over a batch of input samples. The SWAP-Score is strongly correlated with ground-truth performance across various search spaces and tasks, outperforming 15 existing training-free metrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be further enhanced by regularisation, which leads to even higher correlations in cell-based search space and enables model size control during the search. For example, Spearman\u2019s rank correlation coefficient between regularised SWAP-Score and CIFAR-100 validation accuracies on NAS-Bench-201 networks is 0.90, significantly higher than 0.80 from the second-best metric, NWOT. When integrated with an evolutionary algorithm for NAS, our SWAP-NAS achieves competitive performance on CIFAR-10 and ImageNet in approximately 6 minutes and 9 minutes of GPU time respectively."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/37b8588fc5e1d4701d0dd7f69b3af45b36b148e9.pdf"}, "_bibtex": {"value": "@inproceedings{\npeng2024swapnas,\ntitle={{SWAP}-{NAS}: Sample-Wise Activation Patterns for Ultra-fast {NAS}},\nauthor={Yameng Peng and Andy Song and Vic Ciesielski and Haytham M. Fayek and Xiaojun Chang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tveiUXU2aa}\n}"}, "paperhash": {"value": "peng|swapnas_samplewise_activation_patterns_for_ultrafast_nas"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4897/-/Revision", "ICLR.cc/2024/Conference/Submission4897/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4897/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921265, "version": 2}, {"id": "F1TKzG8LJO", "forum": "F1TKzG8LJO", "number": 4892, "cdate": 1695366043253, "tcdate": 1695366043253, "mdate": 1710524464737, "tmdate": 1710524464737, "signatures": ["ICLR.cc/2024/Conference/Submission4892/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4892/Authors"], "content": {"title": {"value": "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"}, "authors": {"value": ["Jiayuan Gu", "Sean Kirmani", "Paul Wohlhart", "Yao Lu", "Montserrat Gonzalez Arenas", "Kanishka Rao", "Wenhao Yu", "Chuyuan Fu", "Keerthana Gopalakrishnan", "Zhuo Xu", "Priya Sundaresan", "Peng Xu", "Hao Su", "Karol Hausman", "Chelsea Finn", "Quan Vuong", "Ted Xiao"]}, "authorids": {"value": ["~Jiayuan_Gu1", "~Sean_Kirmani1", "~Paul_Wohlhart1", "~Yao_Lu13", "~Montserrat_Gonzalez_Arenas1", "~Kanishka_Rao1", "~Wenhao_Yu1", "~Chuyuan_Fu1", "~Keerthana_Gopalakrishnan1", "~Zhuo_Xu1", "~Priya_Sundaresan1", "~Peng_Xu9", "~Hao_Su1", "~Karol_Hausman2", "~Chelsea_Finn1", "~Quan_Vuong2", "~Ted_Xiao1"]}, "keywords": {"value": ["robotics", "robot learning", "robot manipulation", "task representation", "behavior cloning", "multitask imitation learning", "goal conditioning"]}, "abstract": {"value": "Generalization remains one of the most important desiderata for robust robot learning systems. While recently proposed approaches show promise in generalization to novel objects, semantic concepts, or visual distribution shifts, generalization to new tasks remains challenging. For example, a language-conditioned policy trained on pick-and-place tasks will not be able to generalize to a folding task, even if the arm trajectory of folding is similar to pick-and-place. Our key insight is that this kind of generalization becomes feasible if we represent the task through rough trajectory sketches. We propose a policy conditioning method using such rough trajectory sketches, which we call RT-Trajectory, that is practical, easy to specify, and allows the policy to effectively perform new tasks that would otherwise be challenging to perform. We find that trajectory sketches strike a balance between being detailed enough to express low-level motion-centric guidance while being coarse enough to allow the learned policy to interpret the trajectory sketch in the context of situational visual observations. In addition, we show how trajectory sketches can provide a useful interface to communicate with robotic policies -- they can be specified through simple human inputs like drawings or videos, or through automated methods such as modern image-generating or waypoint-generating methods. We evaluate RT-Trajectory at scale on a variety of real-world robotic tasks, and find that RT-Trajectory is able to perform a wider range of tasks compared to language-conditioned and goal-conditioned policies, when provided the same training data."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/99c49fe414f0c5349b9a1f94d32198a847626df5.pdf"}, "supplementary_material": {"value": "/attachment/7b13ad7cc32db0ddb255c91a260ba8c4536f510a.zip"}, "_bibtex": {"value": "@inproceedings{\ngu2024robotic,\ntitle={Robotic Task Generalization via Hindsight Trajectory Sketches},\nauthor={Jiayuan Gu and Sean Kirmani and Paul Wohlhart and Yao Lu and Montserrat Gonzalez Arenas and Kanishka Rao and Wenhao Yu and Chuyuan Fu and Keerthana Gopalakrishnan and Zhuo Xu and Priya Sundaresan and Peng Xu and Hao Su and Karol Hausman and Chelsea Finn and Quan Vuong and Ted Xiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=F1TKzG8LJO}\n}"}, "paperhash": {"value": "gu|rttrajectory_robotic_task_generalization_via_hindsight_trajectory_sketches"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4892/-/Revision", "ICLR.cc/2024/Conference/Submission4892/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4892/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921083, "version": 2}, {"id": "Rc7dAwVL3v", "forum": "Rc7dAwVL3v", "number": 4886, "cdate": 1695365861371, "tcdate": 1695365861371, "mdate": 1709661514783, "tmdate": 1709661514783, "signatures": ["ICLR.cc/2024/Conference/Submission4886/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4886/Authors"], "content": {"title": {"value": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers"}, "authors": {"value": ["Kai Shen", "Zeqian Ju", "Xu Tan", "Eric Liu", "Yichong Leng", "Lei He", "Tao Qin", "sheng zhao", "Jiang Bian"]}, "authorids": {"value": ["~Kai_Shen2", "~Zeqian_Ju1", "~Xu_Tan1", "~Eric_Liu1", "~Yichong_Leng1", "~Lei_He6", "~Tao_Qin1", "~sheng_zhao1", "~Jiang_Bian1"]}, "keywords": {"value": ["text-to-speech", "large-scale corpus", "non-autoregressive", "diffusion"]}, "TLDR": {"value": "A large-scale text-to-speech and singing voice synthesis system with latent diffusion models."}, "abstract": {"value": "Scaling text-to-speech (TTS) to large-scale, multi-speaker, and in-the-wild datasets is important to capture the diversity in human speech such as speaker identities, prosodies, and styles (e.g., singing). Current large TTS systems usually quantize speech into discrete tokens and use language models to generate these tokens one by one, which suffer from unstable prosody, word skipping/repeating issue, and poor voice quality. In this paper, we develop NaturalSpeech 2, a TTS system that leverages a neural audio codec with residual vector quantizers to get the quantized latent vectors and uses a diffusion model to generate these latent vectors conditioned on text input. To enhance the zero-shot capability that is important to achieve diverse speech synthesis, we design a speech prompting mechanism to facilitate in-context learning in the diffusion model and the duration/pitch predictor. We scale NaturalSpeech 2 to large-scale datasets with 44K hours of speech and singing data and evaluate its voice quality on unseen speakers. NaturalSpeech 2 outperforms previous TTS systems by a large margin in terms of prosody/timbre similarity, robustness, and voice quality in a zero-shot setting, and performs novel zero-shot singing synthesis with only a speech prompt. Audio samples are available at https://naturalspeech2.github.io/."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 spotlight"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/509cda476b8eb36072d873b3fb7a5b5868bb7ce7.pdf"}, "_bibtex": {"value": "@inproceedings{\nshen2024naturalspeech,\ntitle={NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers},\nauthor={Kai Shen and Zeqian Ju and Xu Tan and Eric Liu and Yichong Leng and Lei He and Tao Qin and sheng zhao and Jiang Bian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Rc7dAwVL3v}\n}"}, "paperhash": {"value": "shen|naturalspeech_2_latent_diffusion_models_are_natural_and_zeroshot_speech_and_singing_synthesizers"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4886/-/Revision", "ICLR.cc/2024/Conference/Submission4886/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4886/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410920931, "version": 2}], "Poster": [{"id": "rhgIgTSSxW", "forum": "rhgIgTSSxW", "signatures": ["ICLR.cc/2024/Conference/Submission9502/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9502/Authors"], "content": {"title": {"value": "TabR: Tabular Deep Learning Meets Nearest Neighbors"}, "authors": {"value": ["Yury Gorishniy", "Ivan Rubachev", "Nikolay Kartashev", "Daniil Shlenskii", "Akim Kotelnikov", "Artem Babenko"]}, "authorids": {"value": ["~Yury_Gorishniy1", "~Ivan_Rubachev1", "~Nikolay_Kartashev1", "~Daniil_Shlenskii1", "~Akim_Kotelnikov1", "~Artem_Babenko1"]}, "keywords": {"value": ["tabular", "tabular data", "architecture", "deep learning", "neural networks"]}, "TLDR": {"value": "TabR is a new tabular DL model with a k-nearest-neighbors-like component and strong results on public benchmarks."}, "abstract": {"value": "Deep learning (DL) models for tabular data problems (e.g. classification, regression) are currently receiving increasingly more attention from researchers.\nHowever, despite the recent efforts, the non-DL algorithms based on gradient-boosted decision trees (GBDT) remain a strong go-to solution for these problems.\nOne of the research directions aimed at improving the position of tabular DL involves designing so-called retrieval-augmented models.\nFor a target object, such models retrieve other objects (e.g. the nearest neighbors) from the available training data and use their features and labels to make a better prediction.\n\nIn this work, we present TabR -- essentially, a feed-forward network with a custom k-Nearest-Neighbors-like component in the middle.\nOn a set of public benchmarks with datasets up to several million objects, TabR marks a big step forward for tabular DL: it demonstrates the best average performance among tabular DL models, becomes the new state-of-the-art on several datasets, and even outperforms GBDT models on the recently proposed \"GBDT-friendly\" benchmark (see Figure 1).\nAmong the important findings and technical details powering TabR, the main ones lie in the attention-like mechanism that is responsible for retrieving the nearest neighbors and extracting valuable signal from them.\nIn addition to the higher performance, TabR is simple and significantly more efficient compared to prior retrieval-based tabular DL models."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/178e173a880d7872c0a79d88e005426c20501329.pdf"}, "supplementary_material": {"value": "/attachment/1d89c5d545a0f9d97e06087ffe6cecd202365a40.zip"}, "_bibtex": {"value": "@inproceedings{\ngorishniy2024tabr,\ntitle={TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023},\nauthor={Yury Gorishniy and Ivan Rubachev and Nikolay Kartashev and Daniil Shlenskii and Akim Kotelnikov and Artem Babenko},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rhgIgTSSxW}\n}"}, "paperhash": {"value": "gorishniy|tabr_tabular_deep_learning_meets_nearest_neighbors"}}, "number": 9502, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9502/-/Revision", "ICLR.cc/2024/Conference/Submission9502/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9502/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695558732991, "cdate": 1695558732991, "tmdate": 1709661554947, "mdate": 1709661554947, "pdate": 1705411064826, "version": 2}, {"id": "qBL04XXex6", "forum": "qBL04XXex6", "signatures": ["ICLR.cc/2024/Conference/Submission9482/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9482/Authors"], "content": {"title": {"value": "Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models"}, "authors": {"value": ["Sijia Chen", "Baochun Li", "Di Niu"]}, "authorids": {"value": ["~Sijia_Chen2", "~Baochun_Li1", "~Di_Niu1"]}, "keywords": {"value": ["Large Language Models; Prompt Engineering; Boosting Mechanism;"]}, "abstract": {"value": "The reasoning performance of Large Language Models (LLMs) on a wide range of problems critically relies on chain-of-thought prompting, which involves providing a few chain of thought demonstrations as exemplars in prompts. Recent work, e.g., Tree of Thoughts, has pointed out the importance of exploration and self-evaluation in reasoning step selection for complex problem solving. In this paper, we present Boosting of Thoughts (BoT), an automated prompting framework for problem solving with LLMs by iteratively exploring and self-evaluating many trees of thoughts in order to acquire an ensemble of trial-and-error reasoning experiences, which will serve as a new form of prompting to solve the complex problem. Starting from a simple prompt without requiring examples, BoT iteratively explores and evaluates a large collection of reasoning steps, and more importantly, uses error analysis obtained from the LLM on them to explicitly revise prompting, which in turn enhances reasoning step generation, until a final answer is attained. Our experiments with GPT-4 and Llama2 across extensive complex mathematical problems demonstrate that BoT consistently achieves higher or comparable problem-solving rates than other advanced prompting approaches."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a30673a601700226be14c851d887cc7181f4c78f.pdf"}, "supplementary_material": {"value": "/attachment/b38e9414c83f49f066047870db6f2b8f7ea09f3b.zip"}, "_bibtex": {"value": "@inproceedings{\nchen2024boosting,\ntitle={Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models},\nauthor={Sijia Chen and Baochun Li and Di Niu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qBL04XXex6}\n}"}, "paperhash": {"value": "chen|boosting_of_thoughts_trialanderror_problem_solving_with_large_language_models"}}, "number": 9482, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9482/-/Revision", "ICLR.cc/2024/Conference/Submission9482/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9482/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695556700801, "cdate": 1695556700801, "tmdate": 1710551113404, "mdate": 1710551113404, "pdate": 1705411064647, "version": 2}, {"id": "i8PjQT3Uig", "forum": "i8PjQT3Uig", "signatures": ["ICLR.cc/2024/Conference/Submission9441/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9441/Authors"], "content": {"title": {"value": "Locality Sensitive Sparse Encoding for Learning World Models Online"}, "authors": {"value": ["Zichen Liu", "Chao Du", "Wee Sun Lee", "Min Lin"]}, "authorids": {"value": ["~Zichen_Liu1", "~Chao_Du1", "~Wee_Sun_Lee1", "~Min_Lin1"]}, "keywords": {"value": ["model-based rl", "online learning", "incremental learning", "catastrophic forgetting"]}, "abstract": {"value": "Acquiring an accurate world model $\\textit{online}$ for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features. We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift. We also show, in the Dyna MBRL setting, that our world models learned online using a $\\textit{single pass}$ of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/90736a4c9f9e6aaf79d27a63a0b9cd21b953821b.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024locality,\ntitle={Locality Sensitive Sparse Encoding for Learning World Models Online},\nauthor={Zichen Liu and Chao Du and Wee Sun Lee and Min Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=i8PjQT3Uig}\n}"}, "paperhash": {"value": "liu|locality_sensitive_sparse_encoding_for_learning_world_models_online"}}, "number": 9441, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9441/-/Revision", "ICLR.cc/2024/Conference/Submission9441/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9441/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695555355042, "cdate": 1695555355042, "tmdate": 1712556404390, "mdate": 1712556404390, "pdate": 1705411064053, "version": 2}, {"id": "eepoE7iLpL", "forum": "eepoE7iLpL", "signatures": ["ICLR.cc/2024/Conference/Submission9406/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9406/Authors"], "content": {"title": {"value": "Enhancing Neural Subset Selection: Integrating Background Information into Set Representations"}, "authors": {"value": ["Binghui Xie", "Yatao Bian", "Kaiwen Zhou", "Yongqiang Chen", "Peilin Zhao", "Bo Han", "Wei Meng", "James Cheng"]}, "authorids": {"value": ["~Binghui_Xie1", "~Yatao_Bian1", "~Kaiwen_Zhou2", "~Yongqiang_Chen1", "~Peilin_Zhao2", "~Bo_Han1", "~Wei_Meng1", "~James_Cheng2"]}, "keywords": {"value": ["Neural Set Function", "Hierarchical Structure", "Invariance", "Subset Selection"]}, "abstract": {"value": "Learning neural subset selection tasks, such as compound selection in AI-aided drug discovery, have become increasingly pivotal across diverse applications. The existing methodologies in the field primarily concentrate on constructing models that capture the relationship between utility function values and subsets within their respective supersets. However, these approaches tend to overlook the valuable information contained within the superset when utilizing neural networks to model set functions. In this work, we address this oversight by adopting a probabilistic perspective. Our theoretical findings demonstrate that when the target value is conditioned on both the input set and subset, it is essential to incorporate an invariant sufficient statistic of the superset into the subset of interest for effective learning. This ensures that the output value remains invariant to permutations of the subset and its corresponding superset, enabling identification of the specific superset from which the subset originated. Motivated by these insights, we propose a simple yet effective information aggregation module designed to merge the representations of subsets and supersets from a permutation invariance perspective. Comprehensive empirical evaluations across diverse tasks and datasets validate the enhanced efficacy of our approach over conventional methods, underscoring the practicality and potency of our proposed strategies in real-world contexts."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c23dcae9832d01a0cbe616d94729f6b4a7c8365c.pdf"}, "supplementary_material": {"value": "/attachment/e5184ac593e50c955d1cd16ad4b2c20b173c601e.zip"}, "_bibtex": {"value": "@inproceedings{\nxie2024enhancing,\ntitle={Enhancing Neural Subset Selection: Integrating Background Information into Set Representations},\nauthor={Binghui Xie and Yatao Bian and Kaiwen Zhou and Yongqiang Chen and Peilin Zhao and Bo Han and Wei Meng and James Cheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eepoE7iLpL}\n}"}, "paperhash": {"value": "xie|enhancing_neural_subset_selection_integrating_background_information_into_set_representations"}}, "number": 9406, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9406/-/Revision", "ICLR.cc/2024/Conference/Submission9406/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9406/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695554227885, "cdate": 1695554227885, "tmdate": 1709661554766, "mdate": 1709661554766, "pdate": 1705411063445, "version": 2}, {"id": "lK2V2E2MNv", "forum": "lK2V2E2MNv", "signatures": ["ICLR.cc/2024/Conference/Submission9396/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9396/Authors"], "content": {"title": {"value": "Bridging Vision and Language Spaces with Assignment Prediction"}, "authors": {"value": ["Jungin Park", "Jiyoung Lee", "Kwanghoon Sohn"]}, "authorids": {"value": ["~Jungin_Park1", "~Jiyoung_Lee2", "~Kwanghoon_Sohn2"]}, "keywords": {"value": ["Multimodal learning", "vision-language tasks", "frozen LLMs", "optimal transport", "assignment prediction"]}, "TLDR": {"value": "This paper presents to bridge frozen image encoders and large language models (LLMs) for grounding LLMs to images."}, "abstract": {"value": "While pretrained large language models (LLMs) excel in understanding linguistic contexts, it is still an open question: Can LLMs extend their capabilities beyond linguistic contexts to non-linguistic information? This paper introduces VLAP, a novel approach that bridges vision encoders and language models through assignment prediction. Since the LLMs interpret and reason linguistic information from correlations between word embeddings, we harness the well-established word embeddings to map visual representations into language space. Specifically, we simultaneously assign the visual and text representations to a set of word embeddings within LLMs. We propose a new training objective, optimal transport-based assignment prediction, to enforce the consistency of word assignments for paired multimodal data. This allows frozen LLMs to ground their word embedding space in visual data and use their robust semantic taxonomy visually. Moreover, VLAP is memory- and parameter-efficient in that it trains only a single linear layer, and works without extra embedding space (e.g. learnable prototypes) for the assignment prediction. Experimental results show that VLAP achieves substantial improvements over the previous linear transformation-based methods across a range of vision-language tasks, including image captioning, visual question answering, and cross-modal retrieval. We also demonstrate the learned visual representations hold a semantic taxonomy of LLMs, making visual semantic arithmetic possible."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e06b7bb229f7385bfa2782a5c7ecfdffc5b124ad.pdf"}, "_bibtex": {"value": "@inproceedings{\npark2024bridging,\ntitle={Bridging Vision and Language Spaces with Assignment Prediction},\nauthor={Jungin Park and Jiyoung Lee and Kwanghoon Sohn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lK2V2E2MNv}\n}"}, "paperhash": {"value": "park|bridging_vision_and_language_spaces_with_assignment_prediction"}}, "number": 9396, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9396/-/Revision", "ICLR.cc/2024/Conference/Submission9396/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9396/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695553760014, "cdate": 1695553760014, "tmdate": 1710604901062, "mdate": 1710604901062, "pdate": 1705411063316, "version": 2}, {"id": "gtkFw6sZGS", "forum": "gtkFw6sZGS", "signatures": ["ICLR.cc/2024/Conference/Submission9392/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9392/Authors"], "content": {"title": {"value": "Generative Judge for Evaluating Alignment"}, "authors": {"value": ["Junlong Li", "Shichao Sun", "Weizhe Yuan", "Run-Ze Fan", "hai zhao", "Pengfei Liu"]}, "authorids": {"value": ["~Junlong_Li1", "~Shichao_Sun1", "~Weizhe_Yuan1", "~Run-Ze_Fan1", "~hai_zhao1", "~Pengfei_Liu1"]}, "keywords": {"value": ["Generative", "Evaluation", "Alignment"]}, "abstract": {"value": "The rapid development of Large Language Models (LLMs) has substantially expanded the range of tasks they can address. In the field of Natural Language Processing (NLP), researchers have shifted their focus from conventional NLP tasks (e.g., sequence tagging and parsing) towards tasks that revolve around aligning with human needs (e.g., brainstorming and email writing). This shift in task distribution imposes new requirements on evaluating these aligned models regarding *generality* (i.e., assessing performance across diverse scenarios), *flexibility* (i.e., examining under different protocols), and *interpretability* (i.e., scrutinizing models with explanations). In this paper, we propose a generative judge with 13B parameters, **Auto-J**, designed to address these challenges. Our model is trained on user queries and LLM-generated responses under massive real-world scenarios and accommodates diverse evaluation protocols (e.g., pairwise response comparison and single-response evaluation) with well-structured natural language critiques. To demonstrate the efficacy of our approach, we construct a new testbed covering 58 different scenarios. Experimentally, **Auto-J** outperforms a series of strong competitors, including both open-source and closed-source models, by a large margin. We also provide detailed analysis and case studies to further reveal the potential of our method and make a variety of resources public at https://github.com/GAIR-NLP/auto-j."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7fe3087c6257d9121061bc6f3cb0571abebf9277.pdf"}, "TLDR": {"value": "We release Auto-J, a cutting-edge, flexible and interpretable judge with 13B parameters, to evaluate alignment in various real-world scenarios."}, "_bibtex": {"value": "@inproceedings{\nli2024generative,\ntitle={Generative Judge for Evaluating Alignment},\nauthor={Junlong Li and Shichao Sun and Weizhe Yuan and Run-Ze Fan and hai zhao and Pengfei Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gtkFw6sZGS}\n}"}, "paperhash": {"value": "li|generative_judge_for_evaluating_alignment"}}, "number": 9392, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9392/-/Revision", "ICLR.cc/2024/Conference/Submission9392/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9392/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695553656358, "cdate": 1695553656358, "tmdate": 1709661554684, "mdate": 1709661554684, "pdate": 1705411063204, "version": 2}, {"id": "7vVWiCrFnd", "forum": "7vVWiCrFnd", "signatures": ["ICLR.cc/2024/Conference/Submission9389/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9389/Authors"], "content": {"title": {"value": "Rethinking and Extending the Probabilistic Inference Capacity of GNNs"}, "authors": {"value": ["Tuo Xu", "Lei Zou"]}, "authorids": {"value": ["~Tuo_Xu1", "~Lei_Zou2"]}, "keywords": {"value": ["graph neural networks", "expressiveness", "approximate inference"]}, "TLDR": {"value": "Discuss and extend GNNs' expressive power for probabilistic inference."}, "abstract": {"value": "Designing expressive Graph Neural Networks (GNNs) is an important topic in graph machine learning fields. Despite the existence of numerous approaches proposed to enhance GNNs based on Weisfeiler-Lehman (WL) tests, what GNNs can and cannot learn still lacks a deeper understanding. This paper adopts a fundamentally different approach to examine the expressive power of GNNs from a probabilistic perspective. By establishing connections between GNNs' predictions and the central inference problems of probabilistic graphical models (PGMs), we can analyze previous GNN variants with a novel hierarchical framework and gain new insights into their node-level and link-level behaviors. Additionally, we introduce novel methods that can provably enhance GNNs' ability to capture complex dependencies and make complex predictions. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of our approaches."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2be9d877b45987042ba37d7f20e945fcbddc6df8.pdf"}, "supplementary_material": {"value": "/attachment/54841c69346bbc60258f7a6556c00bfbb49e79f7.zip"}, "_bibtex": {"value": "@inproceedings{\nxu2024rethinking,\ntitle={Rethinking and Extending the Probabilistic Inference Capacity of {GNN}s},\nauthor={Tuo Xu and Lei Zou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7vVWiCrFnd}\n}"}, "paperhash": {"value": "xu|rethinking_and_extending_the_probabilistic_inference_capacity_of_gnns"}}, "number": 9389, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9389/-/Revision", "ICLR.cc/2024/Conference/Submission9389/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9389/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695553568508, "cdate": 1695553568508, "tmdate": 1713010735902, "mdate": 1713010735902, "pdate": 1705411063170, "version": 2}, {"id": "bDWXhzZT40", "forum": "bDWXhzZT40", "signatures": ["ICLR.cc/2024/Conference/Submission9383/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9383/Authors"], "content": {"title": {"value": "Learning model uncertainty as variance-minimizing instance weights"}, "authors": {"value": ["Nishant Jain", "Karthikeyan Shanmugam", "Pradeep Shenoy"]}, "authorids": {"value": ["~Nishant_Jain2", "~Karthikeyan_Shanmugam1", "~Pradeep_Shenoy1"]}, "keywords": {"value": ["loss reweighting", "epistemic uncertainty", "bi-level optimization", "model calibration", "bayesian neural networks"]}, "abstract": {"value": "Predictive uncertainty--a model\u2019s self-awareness regarding its accuracy on an input--is key for both building robust models via training interventions and for test-time applications such as selective classification. We propose a novel instance-conditional reweighting approach that captures predictive uncertainty using an auxiliary network, and unifies these train- and test-time applications. The auxiliary network is trained using a meta-objective in a bilevel optimization framework. A key contribution of our proposal is the meta-objective of minimizing dropout variance, an approximation of Bayesian predictive uncertainty, We show in controlled experiments that we effectively capture diverse specific notions of uncertainty through this meta-objective, while previous approaches only capture certain aspects. These results translate to significant gains in real-world settings\u2013selective classification, label noise, domain adaptation, calibration\u2013and across datasets\u2013Imagenet, Cifar100, diabetic retinopathy, Camelyon, WILDs, Imagenet-C,-A,-R, Clothing-1.6M, etc. For Diabetic Retinopathy, we see upto 3.4\\%/3.3\\% accuracy & AUC gains over SOTA in selective classification. We also improve upon large-scale pretrained models such as PLEX."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ebdd64cc233d279eff550647eb57b1baf57fd9eb.pdf"}, "supplementary_material": {"value": "/attachment/eb1aeacdcf615805072a37900e3d5673cad9bd9f.pdf"}, "_bibtex": {"value": "@inproceedings{\njain2024learning,\ntitle={Learning model uncertainty as variance-minimizing instance weights},\nauthor={Nishant Jain and Karthikeyan Shanmugam and Pradeep Shenoy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bDWXhzZT40}\n}"}, "paperhash": {"value": "jain|learning_model_uncertainty_as_varianceminimizing_instance_weights"}}, "number": 9383, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9383/-/Revision", "ICLR.cc/2024/Conference/Submission9383/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9383/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695553402746, "cdate": 1695553402746, "tmdate": 1713163038132, "mdate": 1713163038132, "pdate": 1705411063088, "version": 2}, {"id": "My7lkRNnL9", "forum": "My7lkRNnL9", "signatures": ["ICLR.cc/2024/Conference/Submission9371/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9371/Authors"], "content": {"title": {"value": "Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization"}, "authors": {"value": ["Ravi Francesco Srinivasan", "Francesca Mignacco", "Martino Sorbaro", "Maria Refinetti", "Avi Cooper", "Gabriel Kreiman", "Giorgia Dellaferrera"]}, "authorids": {"value": ["~Ravi_Francesco_Srinivasan1", "~Francesca_Mignacco1", "~Martino_Sorbaro1", "~Maria_Refinetti1", "~Avi_Cooper1", "~Gabriel_Kreiman1", "~Giorgia_Dellaferrera1"]}, "keywords": {"value": ["Forward-only learning", "Biologically inspired learning", "Artificial neural networks", "Analytical characterization"]}, "TLDR": {"value": "We discuss \"forward-only\" algorithms, provide an analytical characterization and test strategies to improve their performance."}, "abstract": {"value": "\"Forward-only\" algorithms, which train neural networks while avoiding a backward pass, have recently gained attention as a way of solving the biologically unrealistic aspects of backpropagation. Here, we first address compelling challenges related to the \"forward-only\" rules, which include reducing the performance gap with backpropagation and providing an analytical understanding of their dynamics. To this end, we show that the forward-only algorithm with top-down feedback is well-approximated by an \"adaptive-feedback-alignment\" algorithm, and we analytically track its performance during learning in a prototype high-dimensional setting. Then, we compare different versions of forward-only algorithms, focusing on the Forward-Forward and PEPITA frameworks, and we show that they share the same learning principles. Overall, our work unveils the connections between three key neuro-inspired learning rules, providing a link between \"forward-only\" algorithms, i.e., Forward-Forward and PEPITA, and an approximation of backpropagation, i.e., Feedback Alignment."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d2749ae05700db2eaae75a159874c2e229ae8222.pdf"}, "supplementary_material": {"value": "/attachment/abae6fa98b6b5537144cb3e3d5c6a67165803088.pdf"}, "_bibtex": {"value": "@inproceedings{\nsrinivasan2024forward,\ntitle={Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization},\nauthor={Ravi Francesco Srinivasan and Francesca Mignacco and Martino Sorbaro and Maria Refinetti and Avi Cooper and Gabriel Kreiman and Giorgia Dellaferrera},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=My7lkRNnL9}\n}"}, "paperhash": {"value": "srinivasan|forward_learning_with_topdown_feedback_empirical_and_analytical_characterization"}}, "number": 9371, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9371/-/Revision", "ICLR.cc/2024/Conference/Submission9371/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9371/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695553023104, "cdate": 1695553023104, "tmdate": 1709661554509, "mdate": 1709661554509, "pdate": 1705411062967, "version": 2}, {"id": "AZGIwqCyYY", "forum": "AZGIwqCyYY", "signatures": ["ICLR.cc/2024/Conference/Submission9361/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9361/Authors"], "content": {"title": {"value": "Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning"}, "authors": {"value": ["Yeongwoo Song", "Hawoong Jeong"]}, "authorids": {"value": ["~Yeongwoo_Song1", "~Hawoong_Jeong1"]}, "keywords": {"value": ["hamiltonian dynamics", "cross domain generalization", "learning physics", "meta learning"]}, "abstract": {"value": "Recent advances in deep learning for physics have focused on discovering shared representations of target systems by incorporating physics priors or inductive biases into neural networks. While effective, these methods are limited to the system domain, where the type of system remains consistent and thus cannot ensure the adaptation to new, or unseen physical systems governed by different laws. For instance, a neural network trained on a mass-spring system cannot guarantee accurate predictions for the behavior of a two-body system or any other system with different physical laws.\nIn this work, we take a significant leap forward by targeting cross domain generalization within the field of Hamiltonian dynamics. \nWe model our system with a graph neural network (GNN) and employ a meta learning algorithm to enable the model to gain experience over a distribution of systems and make it adapt to new physics. Our approach aims to learn a unified Hamiltonian representation that is generalizable across multiple system domains, thereby overcoming the limitations of system-specific models. \nWe demonstrate that the meta-trained model captures the generalized Hamiltonian representation that is consistent across different physical domains.\nOverall, through the use of meta learning, we offer a framework that achieves cross domain generalization, providing a step towards a unified model for understanding a wide array of dynamical systems via deep learning."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b18ec7715410bb144074f86aecfa3acfa91b52d9.pdf"}, "supplementary_material": {"value": "/attachment/13c5178c183aa265ef6bcfdad34ad2fea13afaa0.zip"}, "TLDR": {"value": "We explore cross domain generalization across dynamical system of diverse functional form of Hamiltonian."}, "_bibtex": {"value": "@inproceedings{\nsong2024towards,\ntitle={Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning},\nauthor={Yeongwoo Song and Hawoong Jeong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AZGIwqCyYY}\n}"}, "paperhash": {"value": "song|towards_cross_domain_generalization_of_hamiltonian_representation_via_meta_learning"}}, "number": 9361, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9361/-/Revision", "ICLR.cc/2024/Conference/Submission9361/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9361/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695552644518, "cdate": 1695552644518, "tmdate": 1710581713869, "mdate": 1710581713869, "pdate": 1705411062755, "version": 2}, {"id": "BTKAeLqLMw", "forum": "BTKAeLqLMw", "signatures": ["ICLR.cc/2024/Conference/Submission9349/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9349/Authors"], "content": {"title": {"value": "What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"}, "authors": {"value": ["Wei Liu", "Weihao Zeng", "Keqing He", "Yong Jiang", "Junxian He"]}, "authorids": {"value": ["~Wei_Liu25", "~Weihao_Zeng2", "~Keqing_He1", "~Yong_Jiang1", "~Junxian_He1"]}, "keywords": {"value": ["data selection", "instruction tuning", "large language models"]}, "TLDR": {"value": "We perform a comprehensive study to understand the characteristics of data samples that are the most effective for alignment, and propose automatic data selection approaches that lead to data-efficient instruction tuning"}, "abstract": {"value": "Instruction tuning is a standard technique employed to align large language models to end tasks and user preferences after the initial pretraining phase. Recent research indicates the critical role of data engineering in instruction tuning -- when appropriately selected, only limited data is necessary to achieve superior performance. However, we still lack a principled understanding of what makes good instruction tuning data for alignment, and how we should select data automatically and effectively. In this work, we delve deeply into automatic data selection strategies for alignment. We start with controlled studies to measure data across three dimensions: complexity, quality, and diversity, along which we examine existing methods and introduce novel techniques for enhanced data measurement. Subsequently, we propose a simple strategy to select data samples based on the measurement. We present Deita (short for Data-Efficient Instruction Tuning for Alignment), a series of models fine-tuned from LLaMA models using data samples automatically selected with our proposed approach.  When assessed through both automatic metrics and human evaluation, Deita performs better or on par with the state-of-the-art open-source alignment models such as Vicuna and WizardLM with only 6K training data samples -- 10x less than the data used in the baselines. We anticipate this work to provide clear guidelines and tools on automatic data selection, aiding researchers and practitioners in achieving data-efficient alignment."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a617374cea846fefdd6511494d4f9722b000a237.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024what,\ntitle={What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning},\nauthor={Wei Liu and Weihao Zeng and Keqing He and Yong Jiang and Junxian He},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BTKAeLqLMw}\n}"}, "paperhash": {"value": "liu|what_makes_good_data_for_alignment_a_comprehensive_study_of_automatic_data_selection_in_instruction_tuning"}}, "number": 9349, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9349/-/Revision", "ICLR.cc/2024/Conference/Submission9349/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9349/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695552169713, "cdate": 1695552169713, "tmdate": 1713166048070, "mdate": 1713166048070, "pdate": 1705411062696, "version": 2}, {"id": "AJBkfwXh3u", "forum": "AJBkfwXh3u", "signatures": ["ICLR.cc/2024/Conference/Submission9348/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9348/Authors"], "content": {"title": {"value": "Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks"}, "authors": {"value": ["Kesen Zhao", "Liang Zhang"]}, "authorids": {"value": ["~Kesen_Zhao1", "~Liang_Zhang17"]}, "keywords": {"value": ["Dynamic Graph", "Graph Explanation", "Graph Neural Network", "Causal Inference"]}, "TLDR": {"value": "To the best of our knowledge, we are the first to explain dynamic graph neural networks."}, "abstract": {"value": "Dynamic Graph Neural Networks (DyGNNs) have gained significant popularity in the research of dynamic graphs, but are limited by the low transparency, such that human-understandable insights can hardly be drawn from their predictions. Although a number of existing research have been devoted to investigating the interpretability of graph neural networks (GNNs), achieving the interpretability of DyGNNs is pivotally challenging due to the complex spatial-temporal correlations in dynamic graphs. To this end, we propose an innovative causality-inspired generative model based on structural causal model (SCM), which explores the underlying philosophies of DyGNN predictions by identifying the trivial, static, and dynamic causal relationships. To reach this goal, two critical tasks need to be accomplished including (1) disentangling the complex causal relationships, and (2) fitting the spatial-temporal explanations of DyGNNs in the SCM architecture. To tackle these challenges, the proposed method incorporates a contrastive learning module to disentangle trivial and causal relationships, and a dynamic correlating module to disentangle dynamic and static causal relationships, respectively. A dynamic VGAE-based framework is further developed, which generates causal-and-dynamic masks for spatial interpretability, and recognizes dynamic relationships along the time horizon through causal invention for temporal interpretability. Comprehensive experiments have been conducted on both synthetic and real-world datasets, where our approach yields substantial improvements, thereby demonstrating significant superiority."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/da061144568aad672fd37e90edc5b87a39b91ba9.pdf"}, "supplementary_material": {"value": "/attachment/6961ddeb5ee2ee2596341db5f50262266b74bb58.zip"}, "_bibtex": {"value": "@inproceedings{\nzhao2024causalityinspired,\ntitle={Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks},\nauthor={Kesen Zhao and Liang Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AJBkfwXh3u}\n}"}, "paperhash": {"value": "zhao|causalityinspired_spatialtemporal_explanations_for_dynamic_graph_neural_networks"}}, "number": 9348, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9348/-/Revision", "ICLR.cc/2024/Conference/Submission9348/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9348/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695552059737, "cdate": 1695552059737, "tmdate": 1710491992975, "mdate": 1710491992975, "pdate": 1705411062634, "version": 2}, {"id": "tmsqb6WpLz", "forum": "tmsqb6WpLz", "signatures": ["ICLR.cc/2024/Conference/Submission9346/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9346/Authors"], "content": {"title": {"value": "Dissecting learning and forgetting in language model finetuning"}, "authors": {"value": ["Xiao Zhang", "Ji Wu"]}, "authorids": {"value": ["~Xiao_Zhang9", "~Ji_Wu3"]}, "keywords": {"value": ["language models", "domain adaptation", "catastrophic forgetting"]}, "abstract": {"value": "Finetuning language models on domain-specific corpus is a common approach to enhance their domain knowledge and capability. While improving performance on domain tasks, it often brings a side-effect of forgetting of the model's general abilities. In this study, we analyze the effects of finetuning on language models by dissecting its impacts on the modeling of topic, style, and factual knowledge in text. Our method uses instruction-following LLMs such as ChatGPT to auto-generate controlled-variable text examples which we use to probe the model. Our findings reveal that finetuning results in significant shifts in the language model's topic and style priors, while actual knowledge learning only contributes to a small fraction of the total probability change. Analysis shows that the adaptation of topic and style priors behave akin to learning simple features: they are learned rapidly and require little model capacity. They are also learned independently and primarily at the beginning of a text sequence. In contrast, factual knowledge is learned stably but slowly and requires significant model capacity to learn. The research offers insights and understanding into the finer dynamics of learning and forgetting in language models, and can potentially inform future research on improving domain adaptation and addressing the challenges of forgetting in continual learning of language models."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/11ec6e4f64662107e73511797d5b3135c9385ef5.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024dissecting,\ntitle={Dissecting learning and forgetting in language model finetuning},\nauthor={Xiao Zhang and Ji Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tmsqb6WpLz}\n}"}, "paperhash": {"value": "zhang|dissecting_learning_and_forgetting_in_language_model_finetuning"}}, "number": 9346, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9346/-/Revision", "ICLR.cc/2024/Conference/Submission9346/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9346/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695551935738, "cdate": 1695551935738, "tmdate": 1709661554293, "mdate": 1709661554293, "pdate": 1705411062620, "version": 2}, {"id": "TPZRq4FALB", "forum": "TPZRq4FALB", "signatures": ["ICLR.cc/2024/Conference/Submission9339/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9339/Authors"], "content": {"title": {"value": "Test-time Adaptation against Multi-modal Reliability Bias"}, "authors": {"value": ["Mouxing Yang", "Yunfan Li", "Changqing Zhang", "Peng Hu", "Xi Peng"]}, "authorids": {"value": ["~Mouxing_Yang1", "~Yunfan_Li1", "~Changqing_Zhang1", "~Peng_Hu2", "~Xi_Peng3"]}, "keywords": {"value": ["Test-time adaption", "Imbalanced multi-modal learning"]}, "TLDR": {"value": "Reveal a new problem named reliability bias for multi-modal TTA, and propose a new method to achieve reliable fusion and robust adaption."}, "abstract": {"value": "Test-time adaptation (TTA) has emerged as a new paradigm for reconciling distribution shifts across domains without accessing source data. However, existing TTA methods mainly concentrate on uni-modal tasks, overlooking the complexity of multi-modal scenarios.\nIn this paper, we delve into the multi-modal test-time adaptation and reveal a new challenge named reliability bias. Different from the definition of traditional distribution shifts, reliability bias refers to the information discrepancies across different modalities derived from intra-modal distribution shifts. To solve the challenge, we propose a novel method, dubbed REliable fusion and robust ADaptation (READ). On the one hand, unlike the existing TTA paradigm that mainly repurposes the normalization layers, READ employs a new paradigm that modulates the attention between modalities in a self-adaptive way, supporting reliable fusion against reliability bias. On the other hand, READ adopts a novel objective function for robust multi-modal adaptation, where the contributions of confident predictions could be amplified and the negative impacts of noisy predictions could be mitigated. Moreover, we introduce two new benchmarks to facilitate comprehensive evaluations of multi-modal TTA under reliability bias. Extensive experiments on the benchmarks verify the effectiveness of our method against multi-modal reliability bias. The code and benchmarks are available at https://github.com/XLearning-SCU/2024-ICLR-READ."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b4995bcc3ee4d649705147591c205b904f4a9d13.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024testtime,\ntitle={Test-time Adaption against Multi-modal Reliability Bias},\nauthor={Mouxing Yang and Yunfan Li and Changqing Zhang and Peng Hu and Xi Peng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TPZRq4FALB}\n}"}, "paperhash": {"value": "yang|testtime_adaptation_against_multimodal_reliability_bias"}}, "number": 9339, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9339/-/Revision", "ICLR.cc/2024/Conference/Submission9339/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9339/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695551524908, "cdate": 1695551524908, "tmdate": 1713169358566, "mdate": 1713169358566, "pdate": 1705411062507, "version": 2}, {"id": "78iGZdqxYY", "forum": "78iGZdqxYY", "signatures": ["ICLR.cc/2024/Conference/Submission9334/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9334/Authors"], "content": {"title": {"value": "Mirage: Model-agnostic Graph Distillation for Graph Classification"}, "authors": {"value": ["Mridul Gupta", "Sahil Manchanda", "HARIPRASAD KODAMANA", "Sayan Ranu"]}, "authorids": {"value": ["~Mridul_Gupta2", "~Sahil_Manchanda1", "~HARIPRASAD_KODAMANA1", "~Sayan_Ranu2"]}, "keywords": {"value": ["graph distillation", "graph classification", "frequent pattern mining"]}, "TLDR": {"value": "An unsupervised and model/hyper-parameter agnostic graph distillation algorithm for graph classification."}, "abstract": {"value": "GNNs, like other deep learning models, are data and computation hungry. There is a pressing need to scale training of GNNs on large datasets to enable their usage on low-resource environments. Graph distillation is an effort in that direction with the aim to construct a smaller synthetic training set from the original training data without significantly compromising model performance. While initial efforts are promising, this work is motivated by two key observations: (1) Existing graph distillation algorithms themselves rely on training with the full dataset, which undermines the very premise of graph distillation. (2) The distillation process is specific to the target GNN architecture and hyper-parameters and thus not robust to changes in the modeling pipeline. We circumvent these limitations by designing a distillation algorithm called MIRAGE for graph classification. MIRAGE is built on the insight that a message-passing GNN decomposes the input graph into a multiset of computation trees. Furthermore, the frequency distribution of computation trees is often skewed in nature, enabling us to condense this data into a concise distilled summary. By compressing the computation data itself, as opposed to emulating gradient flows on the original training set\u2014a prevalent approach to date\u2014MIRAGE transforms into an unsupervised and architecture-agnostic distillation algorithm. Extensive benchmarking on real-world datasets underscores MIRAGE\u2019s superiority, showcasing enhanced generalization accuracy, data compression, and distillation efficiency when compared to state-of-the-art baselines."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6734ad0e165c7017f3c6c0f400183a1bae684654.pdf"}, "_bibtex": {"value": "@inproceedings{\ngupta2024mirage,\ntitle={Mirage: Model-agnostic Graph Distillation for Graph Classification},\nauthor={Mridul Gupta and Sahil Manchanda and HARIPRASAD KODAMANA and Sayan Ranu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=78iGZdqxYY}\n}"}, "paperhash": {"value": "gupta|mirage_modelagnostic_graph_distillation_for_graph_classification"}}, "number": 9334, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9334/-/Revision", "ICLR.cc/2024/Conference/Submission9334/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9334/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695551265394, "cdate": 1695551265394, "tmdate": 1710056017506, "mdate": 1710056017506, "pdate": 1705411062331, "version": 2}, {"id": "9k0krNzvlV", "forum": "9k0krNzvlV", "signatures": ["ICLR.cc/2024/Conference/Submission9328/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9328/Authors"], "content": {"title": {"value": "On the Learnability of Watermarks for Language Models"}, "authors": {"value": ["Chenchen Gu", "Xiang Lisa Li", "Percy Liang", "Tatsunori Hashimoto"]}, "authorids": {"value": ["~Chenchen_Gu1", "~Xiang_Lisa_Li1", "~Percy_Liang1", "~Tatsunori_Hashimoto1"]}, "keywords": {"value": ["watermarking", "large language models", "distillation"]}, "abstract": {"value": "Watermarking of language model outputs enables statistical detection of model-generated text, which can mitigate harms and misuses of language models. Existing watermarking strategies operate by altering the decoder of an existing language model. In this paper, we ask whether language models can directly learn to generate watermarked text, which would have significant implications for the real-world deployment of watermarks. First, learned watermarks could be used to build open models that naturally generate watermarked text, enabling watermarking for open models, where users can control the decoding procedure. Second, if watermarking is used to determine the provenance of generated text, an adversary can hurt the reputation of a victim model by spoofing its watermark and generating damaging watermarked text. To investigate the learnability of watermarks, we propose watermark distillation, which trains a student model to behave like a teacher model that uses decoding-based watermarking. We test our approach on three decoding-based watermarking strategies and various hyperparameter settings, finding that models can learn to generate watermarked text with high detectability. We also find limitations to learnability, including the loss of watermarking capabilities under fine-tuning on normal text and high sample complexity when learning low-distortion watermarks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/218fcaae4d72e8c622881df1415344813b0aa3f0.pdf"}, "TLDR": {"value": "Language models can learn to naturally generate watermarked text, without using any special decoding algorithms."}, "_bibtex": {"value": "@inproceedings{\ngu2024on,\ntitle={On the Learnability of Watermarks for Language Models},\nauthor={Chenchen Gu and Xiang Lisa Li and Percy Liang and Tatsunori Hashimoto},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9k0krNzvlV}\n}"}, "paperhash": {"value": "gu|on_the_learnability_of_watermarks_for_language_models"}}, "number": 9328, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9328/-/Revision", "ICLR.cc/2024/Conference/Submission9328/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9328/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695550988485, "cdate": 1695550988485, "tmdate": 1713163997477, "mdate": 1713163997477, "pdate": 1705411062230, "version": 2}, {"id": "Iyve2ycvGZ", "forum": "Iyve2ycvGZ", "signatures": ["ICLR.cc/2024/Conference/Submission9312/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9312/Authors"], "content": {"title": {"value": "Bellman Optimal Stepsize Straightening of Flow-Matching Models"}, "authors": {"value": ["Bao Nguyen", "Binh Nguyen", "Viet Anh Nguyen"]}, "authorids": {"value": ["~Bao_Nguyen2", "~Binh_Nguyen2", "~Viet_Anh_Nguyen2"]}, "keywords": {"value": ["flow matching", "generative model", "efficient sampling", "distillation", "responsible ML"]}, "TLDR": {"value": "This paper introduces Bellman Optimal Step-size Straightening (BOSS) technique for distilling flow-matching generative models while adhering to a computational budget constraint."}, "abstract": {"value": "Flow matching is a powerful framework for generating high-quality samples in various applications, especially image synthesis. However, the intensive computational demands of these models, especially during the finetuning process and sampling processes, pose significant challenges for low-resource scenarios. This paper introduces Bellman Optimal Stepsize Straightening (BOSS) technique for distilling flow-matching generative models: it aims specifically for a few-step efficient image sampling while adhering to a computational budget constraint. First, this technique involves a dynamic programming algorithm that optimizes the stepsizes of the pretrained network. Then, it refines the velocity network to match the optimal step sizes, aiming to straighten the generation paths. Extensive experimental evaluations across image generation tasks demonstrate the efficacy of BOSS in terms of both resource utilization and image quality. Our results reveal that BOSS achieves substantial gains in efficiency while maintaining competitive sample quality, effectively bridging the gap between low-resource constraints and the demanding requirements of flow-matching generative models. Our paper also fortifies the responsible development of artificial intelligence, offering a more sustainable generative model that reduces computational costs and environmental footprints. Our code can be found at https://github.com/nguyenngocbaocmt02/BOSS."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/49149ffea0255c53a80d017478e79f91b0a6c402.pdf"}, "_bibtex": {"value": "@inproceedings{\nnguyen2024bellman,\ntitle={Bellman Optimal Step-size Straightening of Flow-Matching Models},\nauthor={Bao Nguyen and Binh Nguyen and Viet Anh Nguyen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Iyve2ycvGZ}\n}"}, "paperhash": {"value": "nguyen|bellman_optimal_stepsize_straightening_of_flowmatching_models"}}, "number": 9312, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9312/-/Revision", "ICLR.cc/2024/Conference/Submission9312/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9312/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695550155214, "cdate": 1695550155214, "tmdate": 1709661554075, "mdate": 1709661554075, "pdate": 1705411062097, "version": 2}, {"id": "6ARlSgun7J", "forum": "6ARlSgun7J", "signatures": ["ICLR.cc/2024/Conference/Submission9297/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9297/Authors"], "content": {"title": {"value": "Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction"}, "authors": {"value": ["Anirudh Buvanesh", "Rahul Chand", "Jatin Prakash", "Bhawna Paliwal", "Mudit Dhawan", "Neelabh Madan", "Deepesh Hada", "Vidit Jain", "SONU MEHTA", "Yashoteja Prabhu", "Manish Gupta", "Ramachandran Ramjee", "Manik Varma"]}, "authorids": {"value": ["~Anirudh_Buvanesh2", "~Rahul_Chand1", "~Jatin_Prakash2", "~Bhawna_Paliwal1", "~Mudit_Dhawan2", "~Neelabh_Madan2", "~Deepesh_Hada1", "~Vidit_Jain2", "~SONU_MEHTA1", "~Yashoteja_Prabhu1", "~Manish_Gupta4", "~Ramachandran_Ramjee1", "~Manik_Varma1"]}, "keywords": {"value": ["Extreme Classification", "Extreme Multi-Label Learning"]}, "abstract": {"value": "Extreme Classification (XC) architectures, which utilize a massive one-vs-all classifier layer at the output, have demonstrated remarkable performance on problems with large label sets. Nonetheless, these architectures falter on tail labels with few representative samples. This phenomenon has been attributed to factors such as classifier over-fitting and missing label bias, and solutions involving regularization and loss re-calibration have been developed. This paper explores the impact of label variance, a previously unexamined factor, on the tail performance in extreme classifiers. It also presents a method to systematically reduce label variance in XC by effectively utilizing the capabilities of an additional, tail-robust teacher model. For this purpose, it proposes a principled knowledge distillation framework, LEVER, which enhances the tail performance in extreme classifiers with formal guarantees on generalization. Comprehensive experiments are conducted on a diverse set of XC datasets, demonstrating that LEVER can enhance tail performance by around 5% and 6% points in PSP and coverage metrics, respectively, when integrated with leading extreme classifiers. Moreover, it establishes a new state-of-the-art when added to the top-performing Ren \u0301ee classifier. Extensive ablations and analyses substantiate the efficacy of our design choices. Another significant contribution is the release of two new XC datasets that are more challenging than the existing benchmark datasets and enable a more thorough algorithmic evaluation. Code for LEVER is available at: https://aka.ms/lever."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1de20e808c7983c2b0273fe454c9862ad14abedc.pdf"}, "supplementary_material": {"value": "/attachment/eaf12d040563a2e6c16ccf0eeae8aeb84a75d762.zip"}, "_bibtex": {"value": "@inproceedings{\nbuvanesh2024enhancing,\ntitle={Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction},\nauthor={Anirudh Buvanesh and Rahul Chand and Jatin Prakash and Bhawna Paliwal and Mudit Dhawan and Neelabh Madan and Deepesh Hada and Vidit Jain and SONU MEHTA and Yashoteja Prabhu and Manish Gupta and Ramachandran Ramjee and Manik Varma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6ARlSgun7J}\n}"}, "paperhash": {"value": "buvanesh|enhancing_tail_performance_in_extreme_classifiers_by_label_variance_reduction"}}, "number": 9297, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9297/-/Revision", "ICLR.cc/2024/Conference/Submission9297/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9297/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695549381615, "cdate": 1695549381615, "tmdate": 1710592523436, "mdate": 1710592523436, "pdate": 1705411061835, "version": 2}, {"id": "Ebt7JgMHv1", "forum": "Ebt7JgMHv1", "signatures": ["ICLR.cc/2024/Conference/Submission9274/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9274/Authors"], "content": {"title": {"value": "Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching"}, "authors": {"value": ["Aleksandar Makelov", "Georg Lange", "Atticus Geiger", "Neel Nanda"]}, "authorids": {"value": ["~Aleksandar_Makelov1", "~Georg_Lange1", "~Atticus_Geiger1", "~Neel_Nanda1"]}, "keywords": {"value": ["Mechanistic Interpretability", "Natural Language Processing", "Large Language Models"]}, "TLDR": {"value": "We show how activation patching can hallucinate meaningful subspaces in a language model by activating dormant pathways."}, "abstract": {"value": "Mechanistic interpretability aims to attribute high-level model behaviors to specific, interpretable learned features. It is hypothesized that these features manifest as directions or low-dimensional subspaces within activation space. Accordingly, recent studies have explored the identification and manipulation of such subspaces to reverse-engineer computations, employing methods such as activation patching. In this work, we demonstrate that na\u00efve approaches to subspace interventions can give rise to interpretability illusions.\n\nSpecifically, even if patching along a subspace has the intended end-to-end causal effect on model behavior, this effect may be achieved by activating \\emph{a dormant parallel pathway} using a component that is \\textit{causally disconnected} from the model output.\nWe demonstrate this in a mathematical example, realize the example empirically in two different settings (the Indirect Object Identification (IOI) task and factual recall), and argue that activating dormant pathways ought to be prevalent in practice.\nIn the context of factual recall, we further show that the illusion is related to rank-1 fact editing, providing a mechanistic explanation for previous work observing an inconsistency between fact editing performance and fact localisation.\n\nHowever, this does not imply that activation patching of subspaces is intrinsically unfit for interpretability.\nTo contextualize our findings, we also show what a success case looks like in a task (IOI) where prior manual circuit analysis allows an understanding of the location of the ground truth feature. We explore the additional evidence needed to argue that a patched subspace is faithful."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/69dc96e0fec6e0c34449ae8c80ecc0645bf5bbc5.pdf"}, "supplementary_material": {"value": "/attachment/e86712c084ae1d55827c06b9609e246f76c653d5.zip"}, "_bibtex": {"value": "@inproceedings{\nmakelov2024is,\ntitle={Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching},\nauthor={Aleksandar Makelov and Georg Lange and Atticus Geiger and Neel Nanda},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ebt7JgMHv1}\n}"}, "paperhash": {"value": "makelov|is_this_the_subspace_you_are_looking_for_an_interpretability_illusion_for_subspace_activation_patching"}}, "number": 9274, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9274/-/Revision", "ICLR.cc/2024/Conference/Submission9274/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9274/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695548531914, "cdate": 1695548531914, "tmdate": 1713123904608, "mdate": 1713123904608, "pdate": 1705411061486, "version": 2}, {"id": "lF2aip4Scn", "forum": "lF2aip4Scn", "signatures": ["ICLR.cc/2024/Conference/Submission9260/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9260/Authors"], "content": {"title": {"value": "Demonstration-Regularized RL"}, "authors": {"value": ["Daniil Tiapkin", "Denis Belomestny", "Daniele Calandriello", "Eric Moulines", "Alexey Naumov", "Pierre Perrault", "Michal Valko", "Pierre Menard"]}, "authorids": {"value": ["~Daniil_Tiapkin1", "~Denis_Belomestny1", "~Daniele_Calandriello1", "~Eric_Moulines1", "~Alexey_Naumov1", "~Pierre_Perrault1", "~Michal_Valko1", "~Pierre_Menard2"]}, "keywords": {"value": ["reinforcement learning", "regularization in reinforcement leaning", "learning with demonstrations", "reinforcemenet learning with human feedback"]}, "TLDR": {"value": "We showed a theoretically efficient way to inject expert demonstrations into RL agent and, moreover, into RLHF."}, "abstract": {"value": "Incorporating expert demonstrations has empirically helped to improve the sample efficiency of reinforcement learning (RL). This paper quantifies theoretically to what extent this extra information reduces RL's sample complexity. In particular, we study the demonstration-regularized reinforcement learning framework that leverages the expert demonstrations by $\\mathrm{KL}$-regularization for a policy learned by behavior cloning. Our findings reveal that using $N^{\\mathrm{E}}$ expert demonstrations enables the identification of an optimal policy at a sample complexity of order $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(S,A,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$ in finite and $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(d,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$ in linear Markov decision processes, where $\\varepsilon$is the target precision, $H$ the horizon, $A$ the number of action, $S$ the number of states in the finite case and $d$ the dimension of the feature space in the linear case. As a by-product, we provide tight convergence guarantees for the behavior cloning procedure under general assumptions on the policy classes. Additionally, we establish that demonstration-regularized methods are provably efficient for reinforcement learning from human feedback (RLHF). In this respect, we provide theoretical evidence showing the benefits of KL-regularization for RLHF  in tabular and linear MDPs. \nInterestingly, we avoid pessimism injection by employing computationally feasible regularization to handle reward estimation uncertainty, thus setting our approach apart from the prior works."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7f93971543d7b1a26e607380315994e7f7ad3051.pdf"}, "_bibtex": {"value": "@inproceedings{\ntiapkin2024demonstrationregularized,\ntitle={Demonstration-Regularized {RL}},\nauthor={Daniil Tiapkin and Denis Belomestny and Daniele Calandriello and Eric Moulines and Alexey Naumov and Pierre Perrault and Michal Valko and Pierre Menard},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lF2aip4Scn}\n}"}, "paperhash": {"value": "tiapkin|demonstrationregularized_rl"}}, "number": 9260, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9260/-/Revision", "ICLR.cc/2024/Conference/Submission9260/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9260/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695547931617, "cdate": 1695547931617, "tmdate": 1710702621893, "mdate": 1710702621893, "pdate": 1705411060991, "version": 2}, {"id": "vESNKdEMGp", "forum": "vESNKdEMGp", "signatures": ["ICLR.cc/2024/Conference/Submission9250/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9250/Authors"], "content": {"title": {"value": "Multilingual Jailbreak Challenges in Large Language Models"}, "authors": {"value": ["Yue Deng", "Wenxuan Zhang", "Sinno Jialin Pan", "Lidong Bing"]}, "authorids": {"value": ["~Yue_Deng3", "~Wenxuan_Zhang1", "~Sinno_Jialin_Pan1", "~Lidong_Bing2"]}, "keywords": {"value": ["multilingual", "safety", "large language models"]}, "abstract": {"value": "While large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, they pose potential safety concerns, such as the ``jailbreak'' problem, wherein malicious instructions can manipulate LLMs to exhibit undesirable behavior. Although several preventive measures have been developed to mitigate the potential risks associated with LLMs, they have primarily focused on English. In this study, we reveal the presence of multilingual jailbreak challenges within LLMs and consider two potential risky scenarios: unintentional and intentional. The unintentional scenario involves users querying LLMs using non-English prompts and inadvertently bypassing the safety mechanisms, while the intentional scenario concerns malicious users combining malicious instructions with multilingual prompts to deliberately attack LLMs. The experimental results reveal that in the unintentional scenario, the rate of unsafe content increases as the availability of languages decreases. Specifically, low-resource languages exhibit about three times the likelihood of encountering harmful content compared to high-resource languages, with both ChatGPT and GPT-4. In the intentional scenario, multilingual prompts can exacerbate the negative impact of malicious instructions, with astonishingly high rates of unsafe output: 80.92\\% for ChatGPT and 40.71\\% for GPT-4. To handle such a challenge in the multilingual context, we propose a novel \\textsc{Self-Defense} framework that automatically generates multilingual training data for safety fine-tuning. Experimental results show that ChatGPT fine-tuned with such data can achieve a substantial reduction in unsafe content generation.  Data is available at \\url{https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs}."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5755fd1159bae5a7cf71a490847938b7f047a0b3.pdf"}, "_bibtex": {"value": "@inproceedings{\ndeng2024multilingual,\ntitle={Multilingual Jailbreak Challenges in Large Language Models},\nauthor={Yue Deng and Wenxuan Zhang and Sinno Jialin Pan and Lidong Bing},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vESNKdEMGp}\n}"}, "TLDR": {"value": "We reveal the presence of multilingual jailbreak challenges within LLMs and propose the Self-Defense framework to mitigate the issue."}, "paperhash": {"value": "deng|multilingual_jailbreak_challenges_in_large_language_models"}}, "number": 9250, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9250/-/Revision", "ICLR.cc/2024/Conference/Submission9250/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9250/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695547633120, "cdate": 1695547633120, "tmdate": 1709661553854, "mdate": 1709661553854, "pdate": 1705411060691, "version": 2}, {"id": "RzNlECeoOB", "forum": "RzNlECeoOB", "signatures": ["ICLR.cc/2024/Conference/Submission9244/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9244/Authors"], "content": {"title": {"value": "$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence"}, "authors": {"value": ["Juno Kim", "Jaehyuk Kwon", "Mincheol Cho", "Hyunjong Lee", "Joong-Ho Won"]}, "authorids": {"value": ["~Juno_Kim1", "~Jaehyuk_Kwon1", "~Mincheol_Cho1", "~Hyunjong_Lee1", "~Joong-Ho_Won1"]}, "keywords": {"value": ["Variational autoencoder", "Information geometry", "Heavy-tail learning", "Generative model"]}, "abstract": {"value": "The variational autoencoder (VAE) typically employs a standard normal prior as a regularizer for the probabilistic latent encoder. However, the Gaussian tail often decays too quickly to effectively accommodate the encoded points, failing to preserve crucial structures hidden in the data. In this paper, we explore the use of heavy-tailed models to combat over-regularization. Drawing upon insights from information geometry, we propose $t^3$VAE, a modified VAE framework that incorporates Student's t-distributions for the prior, encoder, and decoder. This results in a joint model distribution of a power form which we argue can better fit real-world datasets. We derive a new objective by reformulating the evidence lower bound as joint optimization of KL divergence between two statistical manifolds and replacing with $\\gamma$-power divergence, a natural alternative for power families. $t^3$VAE demonstrates superior generation of low-density regions when trained on heavy-tailed synthetic data. Furthermore, we show that $t^3$VAE significantly outperforms other models on CelebA and imbalanced CIFAR-100 datasets."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/456160753ce7ca91fd5d14c5ba07b1183322d395.pdf"}, "supplementary_material": {"value": "/attachment/2c01181d799d3e99445d9421496d57688b8f55ba.zip"}, "_bibtex": {"value": "@inproceedings{\nkim2024tvariational,\ntitle={\\$t{\\textasciicircum}3\\$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence},\nauthor={Juno Kim and Jaehyuk Kwon and Mincheol Cho and Hyunjong Lee and Joong-Ho Won},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RzNlECeoOB}\n}"}, "paperhash": {"value": "kim|t^3variational_autoencoder_learning_heavytailed_data_with_students_t_and_power_divergence"}}, "number": 9244, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9244/-/Revision", "ICLR.cc/2024/Conference/Submission9244/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9244/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695547459740, "cdate": 1695547459740, "tmdate": 1710297798533, "mdate": 1710297798533, "pdate": 1705411060384, "version": 2}, {"id": "nTwb2vBLOV", "forum": "nTwb2vBLOV", "signatures": ["ICLR.cc/2024/Conference/Submission9229/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9229/Authors"], "content": {"title": {"value": "Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability"}, "authors": {"value": ["Zehao Dong", "Muhan Zhang", "Philip Payne", "Michael A Province", "Carlos Cruchaga", "Tianyu Zhao", "Fuhai Li", "Yixin Chen"]}, "authorids": {"value": ["~Zehao_Dong1", "~Muhan_Zhang1", "~Philip_Payne2", "~Michael_A_Province2", "~Carlos_Cruchaga1", "~Tianyu_Zhao4", "~Fuhai_Li1", "~Yixin_Chen1"]}, "keywords": {"value": ["Graph neural networks", "Graph canonization", "Stability"]}, "abstract": {"value": "The expressivity of Graph Neural Networks (GNNs) has been studied broadly in recent years to reveal the design principles for more powerful GNNs. Graph canonization is known as a typical approach to distinguish non-isomorphic graphs, yet rarely adopted when developing expressive GNNs. This paper proposes to maximize the expressivity of GNNs by graph canonization, then the power of such GNNs is studies from the perspective of model stability. A stable GNN will map similar graphs to close graph representations in the vectorial space, and the stability of GNNs is critical to generalize their performance to unseen graphs. We theoretically reveal the trade-off of expressivity and stability in graph-canonization-enhanced GNNs. Then we introduce a notion of universal graph canonization as the general solution to address the trade-off and characterize a widely applicable sufficient condition to solve the universal graph canonization. A comprehensive set of experiments demonstrates the effectiveness of the proposed method. In many popular graph benchmark datasets, graph canonization successfully enhances GNNs and provides highly competitive performance, indicating the capability and great potential of proposed method in general graph representation learning. In graph datasets where the sufficient condition holds, GNNs enhanced by universal graph canonization consistently outperform GNN baselines and successfully improve the SOTA performance up to $31$%, providing the optimal solution to numerous challenging real-world graph analytical tasks like gene network representation learning in bioinformatics."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cbad74b981d4d1bb7c06f5c746926121d2dc638f.pdf"}, "supplementary_material": {"value": "/attachment/39ae3370e9fa8e5c3ac0d89a48f15c56bf5f2f40.zip"}, "_bibtex": {"value": "@inproceedings{\ndong2024rethinking,\ntitle={Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability},\nauthor={Zehao Dong and Muhan Zhang and Philip Payne and Michael A Province and Carlos Cruchaga and Tianyu Zhao and Fuhai Li and Yixin Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nTwb2vBLOV}\n}"}, "paperhash": {"value": "dong|rethinking_the_power_of_graph_canonization_in_graph_representation_learning_with_stability"}}, "number": 9229, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9229/-/Revision", "ICLR.cc/2024/Conference/Submission9229/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9229/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695546910335, "cdate": 1695546910335, "tmdate": 1710541796686, "mdate": 1710541796686, "pdate": 1705411059937, "version": 2}, {"id": "FMMF1a9ifL", "forum": "FMMF1a9ifL", "signatures": ["ICLR.cc/2024/Conference/Submission9224/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9224/Authors"], "content": {"title": {"value": "Gradual Optimization Learning for Conformational Energy Minimization"}, "authors": {"value": ["Artem Tsypin", "Leonid Anatolievich Ugadiarov", "Kuzma Khrabrov", "Alexander Telepov", "Egor Rumiantsev", "Alexey Skrynnik", "Aleksandr Panov", "Dmitry P. Vetrov", "Elena Tutubalina", "Artur Kadurin"]}, "authorids": {"value": ["~Artem_Tsypin1", "~Leonid_Anatolievich_Ugadiarov1", "~Kuzma_Khrabrov1", "~Alexander_Telepov1", "~Egor_Rumiantsev1", "~Alexey_Skrynnik1", "~Aleksandr_Panov1", "~Dmitry_P._Vetrov1", "~Elena_Tutubalina1", "~Artur_Kadurin1"]}, "keywords": {"value": ["energy minimization", "conformational optimization", "geometry optimization"]}, "TLDR": {"value": "We propose a data-efficient framework for conformational energy minimization with neural networks"}, "abstract": {"value": "Molecular conformation optimization is crucial to computer-aided drug discovery and materials design.\nTraditional energy minimization techniques rely on iterative optimization methods that use molecular forces calculated by a physical simulator (oracle) as anti-gradients.\nHowever, this is a computationally expensive approach that requires many interactions with a physical simulator.\nOne way to accelerate this procedure is to replace the physical simulator with a neural network.\nDespite recent progress in neural networks for molecular conformation energy prediction, such models are prone to errors due to distribution shift, leading to inaccurate energy minimization.\nWe find that the quality of energy minimization with neural networks can be improved by providing optimization trajectories as additional training data.\nStill, obtaining complete optimization trajectories demands a lot of additional computations.\nTo reduce the required additional data, we present the Gradual Optimization Learning Framework (GOLF) for energy minimization with neural networks.\nThe framework consists of an efficient data-collecting scheme and an external optimizer.\nThe external optimizer utilizes gradients from the energy prediction model to generate optimization trajectories, and the data-collecting scheme selects additional training data to be processed by the physical simulator. \nOur results demonstrate that the neural network trained with GOLF performs \\textit{on par} with the oracle on a benchmark of diverse drug-like molecules using significantly less additional data."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/37b8c4267928b3f02b1f1f1c9df21956eb2c653c.pdf"}, "_bibtex": {"value": "@inproceedings{\ntsypin2024gradual,\ntitle={Gradual Optimization Learning for Conformational Energy Minimization},\nauthor={Artem Tsypin and Leonid Anatolievich Ugadiarov and Kuzma Khrabrov and Alexander Telepov and Egor Rumiantsev and Alexey Skrynnik and Aleksandr Panov and Dmitry P. Vetrov and Elena Tutubalina and Artur Kadurin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FMMF1a9ifL}\n}"}, "paperhash": {"value": "tsypin|gradual_optimization_learning_for_conformational_energy_minimization"}}, "number": 9224, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9224/-/Revision", "ICLR.cc/2024/Conference/Submission9224/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9224/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695546674929, "cdate": 1695546674929, "tmdate": 1710234268962, "mdate": 1710234268962, "pdate": 1705411059822, "version": 2}, {"id": "buC4E91xZE", "forum": "buC4E91xZE", "signatures": ["ICLR.cc/2024/Conference/Submission9222/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9222/Authors"], "content": {"title": {"value": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection"}, "authors": {"value": ["Qihang Zhou", "Guansong Pang", "Yu Tian", "Shibo He", "Jiming Chen"]}, "authorids": {"value": ["~Qihang_Zhou1", "~Guansong_Pang1", "~Yu_Tian8", "~Shibo_He1", "~Jiming_Chen1"]}, "keywords": {"value": ["Anomaly detection", "Zero-shot anomaly detection", "CLIP", "Industrial defect inspection"]}, "abstract": {"value": "Zero-shot anomaly detection (ZSAD) requires detection models trained using auxiliary\ndata to detect anomalies without any training sample in a target dataset. It\nis a crucial task when training data is not accessible due to various concerns, e.g.,\ndata privacy, yet it is challenging since the models need to generalize to anomalies\nacross different domains where the appearance of foreground objects, abnormal\nregions, and background features, such as defects/tumors on different products/\norgans, can vary significantly. Recently large pre-trained vision-language\nmodels (VLMs), such as CLIP, have demonstrated strong zero-shot recognition\nability in various vision tasks, including anomaly detection. However, their ZSAD\nperformance is weak since the VLMs focus more on modeling the class semantics\nof the foreground objects rather than the abnormality/normality in the images. In\nthis paper we introduce a novel approach, namely AnomalyCLIP, to adapt CLIP\nfor accurate ZSAD across different domains. The key insight of AnomalyCLIP\nis to learn object-agnostic text prompts that capture generic normality and abnormality\nin an image regardless of its foreground objects. This allows our model to\nfocus on the abnormal image regions rather than the object semantics, enabling\ngeneralized normality and abnormality recognition on diverse types of objects.\nLarge-scale experiments on 17 real-world anomaly detection datasets show that\nAnomalyCLIP achieves superior zero-shot performance of detecting and segmenting\nanomalies in datasets of highly diverse class semantics from various defect\ninspection and medical imaging domains. Code will be made available at https://github.com/zqhang/AnomalyCLIP."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c8c456c139a7b7f9cbf659ae062d7e3f9cba1aff.pdf"}, "TLDR": {"value": "We propose a novel approach, namely AnomalyCLIP, to adapt CLIP for accurate zero-shot anomaly detection."}, "_bibtex": {"value": "@inproceedings{\nzhou2024anomalyclip,\ntitle={Anomaly{CLIP}: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection},\nauthor={Qihang Zhou and Guansong Pang and Yu Tian and Shibo He and Jiming Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=buC4E91xZE}\n}"}, "paperhash": {"value": "zhou|anomalyclip_objectagnostic_prompt_learning_for_zeroshot_anomaly_detection"}}, "number": 9222, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9222/-/Revision", "ICLR.cc/2024/Conference/Submission9222/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9222/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695546661155, "cdate": 1695546661155, "tmdate": 1710768252186, "mdate": 1710768252186, "pdate": 1705411059776, "version": 2}, {"id": "uGtfk2OphU", "forum": "uGtfk2OphU", "signatures": ["ICLR.cc/2024/Conference/Submission9216/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9216/Authors"], "content": {"title": {"value": "Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery"}, "authors": {"value": ["Linan Yue", "Qi Liu", "Yichao Du", "Li Wang", "Weibo Gao", "Yanqing An"]}, "authorids": {"value": ["~Linan_Yue1", "~Qi_Liu3", "~Yichao_Du1", "~Li_Wang18", "~Weibo_Gao1", "~Yanqing_An1"]}, "keywords": {"value": ["Selective Rationalization", "Shortcut"]}, "abstract": {"value": "The remarkable success in neural networks provokes the selective rationalization. It explains the prediction results by identifying a small subset of the inputs sufficient to support them. Since existing methods still suffer from adopting the shortcuts in data to compose rationales and limited large-scale annotated rationales by human, in this paper, we propose a Shortcuts-fused Selective Rationalization (SSR) method, which boosts the rationalization by discovering and exploiting potential shortcuts. Specifically, SSR first designs a shortcuts discovery approach to detect several potential shortcuts. Then, by introducing the identified shortcuts, we propose two strategies to mitigate the problem of utilizing shortcuts to compose rationales. Finally, we develop two data augmentations methods to close the gap in the number of annotated rationales. Extensive experimental results on real-world datasets clearly validate the effectiveness of our proposed method."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c8c102f26cb7fc4cddf6ff889fe2a63454b563c9.pdf"}, "_bibtex": {"value": "@inproceedings{\nyue2024boosting,\ntitle={Boosting Selective Rationalization with Shortcuts Discovery},\nauthor={Linan Yue and Qi Liu and Yichao Du and Li Wang and Weibo Gao and Yanqing An},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uGtfk2OphU}\n}"}, "paperhash": {"value": "yue|towards_faithful_explanations_boosting_rationalization_with_shortcuts_discovery"}}, "number": 9216, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9216/-/Revision", "ICLR.cc/2024/Conference/Submission9216/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9216/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695546281340, "cdate": 1695546281340, "tmdate": 1712750181196, "mdate": 1712750181196, "pdate": 1705411059641, "version": 2}, {"id": "KTtEICH4TO", "forum": "KTtEICH4TO", "signatures": ["ICLR.cc/2024/Conference/Submission9206/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9206/Authors"], "content": {"title": {"value": "CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects"}, "authors": {"value": ["Yoonyoung Cho", "Junhyek Han", "Yoontae Cho", "Beomjoon Kim"]}, "authorids": {"value": ["~Yoonyoung_Cho1", "~Junhyek_Han1", "~Yoontae_Cho1", "~Beomjoon_Kim2"]}, "keywords": {"value": ["pretraining", "robotics", "manipulation", "object representation", "representation learning"]}, "TLDR": {"value": "contact-based representation learning for nonprehensile robotic manipulation on objects with general geometry, with zero-shot real-world transfer."}, "abstract": {"value": "Nonprehensile manipulation is essential for manipulating objects that are too thin, large, or otherwise ungraspable in the wild. To sidestep the difficulty of contact modeling in conventional modeling-based approaches, reinforcement learning (RL) has recently emerged as a promising alternative. However, previous RL approaches either lack the ability to generalize over diverse object shapes, or use simple action primitives that limit the diversity of robot motions. Furthermore, using RL over diverse object geometry is challenging due to the high cost of training a policy that takes in high-dimensional sensory inputs. We propose a novel contact-based object representation and pretraining pipeline to tackle this. To enable massively parallel training, we leverage a lightweight patch-based transformer architecture for our encoder that processes point clouds, thus scaling our training across thousands of environments. Compared to learning from scratch, or other shape representation baselines, our representation facilitates both time- and data-efficient learning. We validate the efficacy of our overall system by zero-shot transferring the trained policy to novel real-world objects. We highly recommend the video attached in the supplementary material. Code and videos are available at \\url{https://sites.google.com/view/contact-non-prehensile}."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/be6d29e6e7d18c8ea0250289f353011374d395b1.pdf"}, "supplementary_material": {"value": "/attachment/7b9d6b575b4cf1f40ee33003886bcdc8106880b7.zip"}, "_bibtex": {"value": "@inproceedings{\ncho2024corn,\ntitle={{CORN}: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects},\nauthor={Yoonyoung Cho and Junhyek Han and Yoontae Cho and Beomjoon Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KTtEICH4TO}\n}"}, "paperhash": {"value": "cho|corn_contactbased_object_representation_for_nonprehensile_manipulation_of_general_unseen_objects"}}, "number": 9206, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9206/-/Revision", "ICLR.cc/2024/Conference/Submission9206/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9206/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695545917493, "cdate": 1695545917493, "tmdate": 1710489237956, "mdate": 1710489237956, "pdate": 1705411059432, "version": 2}, {"id": "5JWAOLBxwp", "forum": "5JWAOLBxwp", "signatures": ["ICLR.cc/2024/Conference/Submission9205/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9205/Authors"], "content": {"title": {"value": "An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks"}, "authors": {"value": ["Dongwon Son", "Jaehyung Kim", "Sanghyeon Son", "Beomjoon Kim"]}, "authorids": {"value": ["~Dongwon_Son1", "~Jaehyung_Kim2", "~Sanghyeon_Son1", "~Beomjoon_Kim2"]}, "keywords": {"value": ["Equivariant networks", "SO(3) Equivariance", "Fourier features"]}, "abstract": {"value": "The usage of 3D vision algorithms, such as shape reconstruction, remains limited because they require inputs to be at a fixed canonical rotation. Recently, a simple equivariant network, Vector Neuron (VN) has been proposed that can be easily used with the state-of-the-art 3D neural network (NN) architectures. However, its performance is limited because it is designed to use only three-dimensional features, which is insufficient to capture the details present in 3D data. In this paper, we introduce an equivariant feature representation for mapping a 3D point to a high-dimensional feature space. Our feature can discern multiple frequencies present in 3D data, which, as shown by Tancik et al. (2020), is the key to designing an expressive feature for 3D vision tasks. Our representation can be used as an input to VNs, and the results demonstrate that with our feature representation, VN captures more details, overcoming the limitation raised in its original paper."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ae84b2b3de8b202f110cedf0a834de33c23e665d.pdf"}, "TLDR": {"value": "We propose a frequency-based rotation equivariant feature representation for 3D data."}, "_bibtex": {"value": "@inproceedings{\nson2024an,\ntitle={An Intuitive Multi-Frequency Feature Representation for {SO}(3)-Equivariant Networks},\nauthor={Dongwon Son and Jaehyung Kim and Sanghyeon Son and Beomjoon Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5JWAOLBxwp}\n}"}, "paperhash": {"value": "son|an_intuitive_multifrequency_feature_representation_for_so3equivariant_networks"}}, "number": 9205, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9205/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9205/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695545864891, "cdate": 1695545864891, "tmdate": 1710480520849, "mdate": 1710480520849, "pdate": 1705411059423, "version": 2}, {"id": "AqN23oqraW", "forum": "AqN23oqraW", "signatures": ["ICLR.cc/2024/Conference/Submission9199/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9199/Authors"], "content": {"title": {"value": "KoLA: Carefully Benchmarking World Knowledge of Large Language Models"}, "authors": {"value": ["Jifan Yu", "Xiaozhi Wang", "Shangqing Tu", "Shulin Cao", "Daniel Zhang-Li", "Xin Lv", "Hao Peng", "Zijun Yao", "Xiaohan Zhang", "Hanming Li", "Chunyang Li", "Zheyuan Zhang", "Yushi Bai", "Yantao Liu", "Amy Xin", "Kaifeng Yun", "Linlu GONG", "Nianyi Lin", "Jianhui Chen", "Zhili Wu", "Yunjia Qi", "Weikai Li", "Yong Guan", "Kaisheng Zeng", "Ji Qi", "Hailong Jin", "Jinxin Liu", "Yu Gu", "Yuan Yao", "Ning Ding", "Lei Hou", "Zhiyuan Liu", "Xu Bin", "Jie Tang", "Juanzi Li"]}, "authorids": {"value": ["~Jifan_Yu2", "~Xiaozhi_Wang1", "~Shangqing_Tu1", "~Shulin_Cao1", "~Daniel_Zhang-Li1", "~Xin_Lv1", "~Hao_Peng6", "~Zijun_Yao2", "~Xiaohan_Zhang6", "~Hanming_Li1", "~Chunyang_Li3", "~Zheyuan_Zhang3", "~Yushi_Bai1", "~Yantao_Liu1", "~Amy_Xin1", "~Kaifeng_Yun2", "~Linlu_GONG1", "~Nianyi_Lin2", "~Jianhui_Chen6", "~Zhili_Wu1", "~Yunjia_Qi1", "~Weikai_Li2", "~Yong_Guan2", "~Kaisheng_Zeng1", "~Ji_Qi2", "~Hailong_Jin2", "~Jinxin_Liu2", "~Yu_Gu5", "~Yuan_Yao12", "~Ning_Ding5", "~Lei_Hou2", "~Zhiyuan_Liu1", "~Xu_Bin1", "~Jie_Tang1", "~Juanzi_Li1"]}, "keywords": {"value": ["Large Language Model", "World Knowledge", "Evolving Benchmark"]}, "TLDR": {"value": "A carefully designed evolving benchmark for evaluating LLMs' world knowledge."}, "abstract": {"value": "The unprecedented performance of large language models (LLMs) necessitates improvements in evaluations. Rather than merely exploring the breadth of LLM abilities, we believe meticulous and thoughtful designs are essential to thorough, unbiased, and applicable evaluations. Given the importance of world knowledge to LLMs, we construct a Knowledge-oriented LLM Assessment benchmark (KoLA), in which we carefully design three crucial factors: (1) For ability modeling, we mimic human cognition to form a four-level taxonomy of knowledge-related abilities, covering 19 tasks. (2) For data, to ensure fair comparisons, we use both Wikipedia, a corpus prevalently pre-trained by LLMs, along with continuously collected emerging corpora, aiming to evaluate the capacity to handle unseen data and evolving knowledge. (3) For evaluation criteria, we adopt a contrastive system, including overall standard scores for better numerical comparability across tasks and models, and a unique self-contrast metric for automatically evaluating knowledge-creating ability. We evaluate 21 open-source and commercial LLMs and obtain some intriguing findings. The KoLA dataset will be updated every three months to provide timely references for developing LLMs and knowledge-related systems."}, "pdf": {"value": "/pdf/5b10764ea102a63e929b8b1179abdca8c1903c0a.pdf"}, "supplementary_material": {"value": "/attachment/15ddff071c61dc0e8abdc05e3574461847222dd9.zip"}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nyu2024kola,\ntitle={Ko{LA}: Carefully Benchmarking World Knowledge of Large Language Models},\nauthor={Jifan Yu and Xiaozhi Wang and Shangqing Tu and Shulin Cao and Daniel Zhang-Li and Xin Lv and Hao Peng and Zijun Yao and Xiaohan Zhang and Hanming Li and Chunyang Li and Zheyuan Zhang and Yushi Bai and Yantao Liu and Amy Xin and Kaifeng Yun and Linlu GONG and Nianyi Lin and Jianhui Chen and Zhili Wu and Yunjia Qi and Weikai Li and Yong Guan and Kaisheng Zeng and Ji Qi and Hailong Jin and Jinxin Liu and Yu Gu and Yuan Yao and Ning Ding and Lei Hou and Zhiyuan Liu and Xu Bin and Jie Tang and Juanzi Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AqN23oqraW}\n}"}, "paperhash": {"value": "yu|kola_carefully_benchmarking_world_knowledge_of_large_language_models"}}, "number": 9199, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9199/-/Revision", "ICLR.cc/2024/Conference/Submission9199/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9199/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695545711513, "cdate": 1695545711513, "tmdate": 1710475887703, "mdate": 1710475887703, "pdate": 1705411059294, "version": 2}, {"id": "hv3SklibkL", "forum": "hv3SklibkL", "signatures": ["ICLR.cc/2024/Conference/Submission9196/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9196/Authors"], "content": {"title": {"value": "Graph Parsing Networks"}, "authors": {"value": ["Yunchong Song", "Siyuan Huang", "Xinbing Wang", "Chenghu Zhou", "Zhouhan Lin"]}, "authorids": {"value": ["~Yunchong_Song1", "~Siyuan_Huang8", "~Xinbing_Wang1", "~Chenghu_Zhou3", "~Zhouhan_Lin1"]}, "keywords": {"value": ["GNN", "graph pooling", "parsing"]}, "TLDR": {"value": "In this paper, we propose an efficient parsing algorithm to infer the graph pooling structure and enable the model to learn personalized pooling structure for each individual graph."}, "abstract": {"value": "Graph pooling compresses graph information into a compact representation. State-of-the-art graph pooling methods follow a hierarchical approach, which reduces the graph size step-by-step. These methods must balance memory efficiency with preserving node information, depending on whether they use node dropping or node clustering. Additionally, fixed pooling ratios or numbers of pooling layers are predefined for all graphs, which prevents personalized pooling structures from being captured for each individual graph. In this work, inspired by bottom-up grammar induction, we propose an efficient graph parsing algorithm to infer the pooling structure, which then drives graph pooling. The resulting Graph Parsing Network (GPN) adaptively learns personalized pooling structure for each individual graph. GPN benefits from the discrete assignments generated by the graph parsing algorithm, allowing good memory efficiency while preserving node information intact. Experimental results on standard benchmarks demonstrate that GPN outperforms state-of-the-art graph pooling methods in graph classification tasks while being able to achieve competitive performance in node classification tasks. We also conduct a graph reconstruction task to show GPN's ability to preserve node information and measure both memory and time efficiency through relevant tests."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d9ce08bd60cb1e4ccd9fa59eade5645174e6c379.pdf"}, "_bibtex": {"value": "@inproceedings{\nsong2024graph,\ntitle={Graph Parsing Networks},\nauthor={Yunchong Song and Siyuan Huang and Xinbing Wang and Chenghu Zhou and Zhouhan Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hv3SklibkL}\n}"}, "paperhash": {"value": "song|graph_parsing_networks"}}, "number": 9196, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9196/-/Revision", "ICLR.cc/2024/Conference/Submission9196/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9196/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695545605651, "cdate": 1695545605651, "tmdate": 1709661553440, "mdate": 1709661553440, "pdate": 1705411059292, "version": 2}, {"id": "N0nTk5BSvO", "forum": "N0nTk5BSvO", "signatures": ["ICLR.cc/2024/Conference/Submission9189/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9189/Authors"], "content": {"title": {"value": "TESTAM: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of Experts"}, "authors": {"value": ["Hyunwook Lee", "Sungahn Ko"]}, "authorids": {"value": ["~Hyunwook_Lee1", "~Sungahn_Ko1"]}, "keywords": {"value": ["Traffic Prediction", "Deep Learning", "Spatio-Temporal data modeling"]}, "TLDR": {"value": "We propose a novel mixture-of-experts model named TESTAM that enables in-situ modeling of the traffic data"}, "abstract": {"value": "Accurate traffic forecasting is challenging due to the complex dependency on road networks, various types of roads, and the abrupt speed change due to the events. Recent works mainly focus on dynamic spatial modeling with adaptive graph embedding or graph attention having less consideration for temporal characteristics and in-situ modeling. In this paper, we propose a novel deep learning model named TESTAM, which individually models recurring and non-recurring traffic patterns by a mixture-of-experts model with three experts on temporal modeling, spatio-temporal modeling with static graph, and dynamic spatio-temporal dependency modeling with dynamic graph. By introducing different experts and properly routing them, TESTAM could better model various circumstances, including spatially isolated nodes, highly related nodes, and recurring and non-recurring events. For the proper routing, we reformulate a gating problem into a classification problem with pseudo labels. Experimental results on three public traffic network datasets, METR-LA, PEMS-BAY, and EXPY-TKY, demonstrate that TESTAM achieves a better indication and modeling of recurring and non-recurring traffic."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/75248a8c97bcbac15b26c02b68788bf7ddb56175.pdf"}, "supplementary_material": {"value": "/attachment/a88ef62f305fa4f6c3fd3f1825f09c9d128caeae.zip"}, "_bibtex": {"value": "@inproceedings{\nlee2024testam,\ntitle={{TESTAM}: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of Experts},\nauthor={Hyunwook Lee and Sungahn Ko},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=N0nTk5BSvO}\n}"}, "paperhash": {"value": "lee|testam_a_timeenhanced_spatiotemporal_attention_model_with_mixture_of_experts"}}, "number": 9189, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9189/-/Revision", "ICLR.cc/2024/Conference/Submission9189/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9189/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695545439600, "cdate": 1695545439600, "tmdate": 1709661553293, "mdate": 1709661553293, "pdate": 1705411059246, "version": 2}, {"id": "OsGUnYOzii", "forum": "OsGUnYOzii", "signatures": ["ICLR.cc/2024/Conference/Submission9185/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9185/Authors"], "content": {"title": {"value": "Learning From Simplicial Data Based on Random Walks and 1D Convolutions"}, "authors": {"value": ["Florian Frantzen", "Michael T Schaub"]}, "authorids": {"value": ["~Florian_Frantzen1", "~Michael_T_Schaub1"]}, "keywords": {"value": ["simplicial complex", "simplicial neural network", "random walks"]}, "abstract": {"value": "Triggered by limitations of graph-based deep learning methods in terms of computational expressivity and model flexibility, recent years have seen a surge of interest in computational models that operate on higher-order topological domains such as hypergraphs and simplicial complexes. While the increased expressivity of these models can indeed lead to a better classification performance and a more faithful representation of the underlying system, the computational cost of these higher-order models can increase dramatically. To this end, we here explore a simplicial complex neural network learning architecture based on random walks and fast 1D convolutions (SCRaWl), in which we can adjust the increase in computational cost by varying the length and number of random walks considered while accounting for higher-order relationships. Importantly, due to the random walk-based design, the expressivity of the proposed architecture is provably incomparable to that of existing message-passing simplicial neural networks. We empirically evaluate SCRaWl on real-world datasets and show that it outperforms other simplicial neural networks."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f7f8f6134614bab4c34752266fafd849070821c0.pdf"}, "supplementary_material": {"value": "/attachment/413a9f98abbdd8956b733946fb75fe351a423a1e.zip"}, "_bibtex": {"value": "@inproceedings{\nfrantzen2024learning,\ntitle={Learning From Simplicial Data Based on Random Walks and 1D Convolutions},\nauthor={Florian Frantzen and Michael T Schaub},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OsGUnYOzii}\n}"}, "paperhash": {"value": "frantzen|learning_from_simplicial_data_based_on_random_walks_and_1d_convolutions"}}, "number": 9185, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9185/-/Revision", "ICLR.cc/2024/Conference/Submission9185/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9185/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695545230835, "cdate": 1695545230835, "tmdate": 1712237333778, "mdate": 1712237333778, "pdate": 1705411059042, "version": 2}, {"id": "wkbeqr5XhC", "forum": "wkbeqr5XhC", "signatures": ["ICLR.cc/2024/Conference/Submission9181/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9181/Authors"], "content": {"title": {"value": "LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition"}, "authors": {"value": ["Lingfeng Liu", "Dong Ni", "Hangjie Yuan"]}, "authorids": {"value": ["~Lingfeng_Liu1", "~Dong_Ni3", "~Hangjie_Yuan1"]}, "keywords": {"value": ["hyperspectral imaging", "optical modulation", "real-time detection", "vision transformer", "pre-acquisition modulation", "learnable mask", "weight binarization"]}, "abstract": {"value": "Bandwidth constraints during signal acquisition frequently impede real-time detection applications. Hyperspectral data is a notable example, whose vast volume compromises real-time hyperspectral detection. To tackle this hurdle, we introduce a novel approach leveraging pre-acquisition modulation to reduce the acquisition volume. This modulation process is governed by a deep learning model, utilizing prior information. Central to our approach is LUM-ViT, a Vision Transformer variant. Uniquely, LUM-ViT incorporates a learnable under-sampling mask tailored for pre-acquisition modulation. To further optimize for optical calculations, we propose a kernel-level weight binarization technique and a three-stage fine-tuning strategy. Our evaluations reveal that, by sampling a mere 10\\% of the original image pixels, LUM-ViT maintains the accuracy loss within 1.8\\% on the ImageNet classification task. The method sustains near-original accuracy when implemented on real-world optical hardware, demonstrating its practicality. Code will be available at [https://github.com/MaxLLF/LUM-ViT](https://github.com/MaxLLF/LUM-ViT)."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e727a272852fd9b151a8c6fee5946d926aa8f97c.pdf"}, "supplementary_material": {"value": "/attachment/0ae6e93e622aea6445c707d0073d0562674fe857.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024lumvit,\ntitle={{LUM}-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition},\nauthor={Lingfeng Liu and Dong Ni and Hangjie Yuan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wkbeqr5XhC}\n}"}, "paperhash": {"value": "liu|lumvit_learnable_undersampling_mask_vision_transformer_for_bandwidth_limited_optical_signal_acquisition"}}, "number": 9181, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9181/-/Revision", "ICLR.cc/2024/Conference/Submission9181/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9181/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695544689958, "cdate": 1695544689958, "tmdate": 1709661553267, "mdate": 1709661553267, "pdate": 1705411058979, "version": 2}, {"id": "SQpnEfv9WH", "forum": "SQpnEfv9WH", "signatures": ["ICLR.cc/2024/Conference/Submission9161/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9161/Authors"], "content": {"title": {"value": "Social-Transmotion: Promptable Human Trajectory Prediction"}, "authors": {"value": ["Saeed Saadatnejad", "Yang Gao", "Kaouther Messaoud", "Alexandre Alahi"]}, "authorids": {"value": ["~Saeed_Saadatnejad1", "~Yang_Gao15", "~Kaouther_Messaoud1", "~Alexandre_Alahi3"]}, "keywords": {"value": ["human trajectory prediction", "robot navigation", "autonomous driving", "attention mechanism"]}, "abstract": {"value": "Accurate human trajectory prediction is crucial for applications such as autonomous vehicles, robotics, and surveillance systems. Yet, existing models often fail to fully leverage the non-verbal social cues human subconsciously communicate when navigating the space.\nTo address this, we introduce *Social-Transmotion*, a generic Transformer-based model that exploits diverse and numerous visual cues to predict human behavior. We translate the idea of a prompt from Natural Language Processing (NLP) to the task of human trajectory prediction, where a prompt can be a sequence of x-y coordinates on the ground, bounding boxes in the image plane, or body pose keypoints in either 2D or 3D.  This, in turn, augments trajectory data, leading to enhanced human trajectory prediction.\nUsing masking technique, our model exhibits flexibility and adaptability by capturing spatiotemporal interactions between agents based on the available visual cues.\nWe delve into the merits of using 2D versus 3D poses, and a limited set of poses. Additionally, we investigate the spatial and temporal attention map to identify which keypoints and time-steps in the sequence are vital for optimizing human trajectory prediction.\nOur approach is validated on multiple datasets, including JTA, JRDB, Pedestrians and Cyclists in Road Traffic, and ETH-UCY.\nThe code is publicly available: [https://github.com/vita-epfl/social-transmotion](https://github.com/vita-epfl/social-transmotion)."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5dcf47a66eb9a88f6cda4a59dfb2dd17df12bc68.pdf"}, "supplementary_material": {"value": "/attachment/ecb46a9e701c832c79affccf0380473888a8cf97.zip"}, "_bibtex": {"value": "@inproceedings{\nsaadatnejad2024socialtransmotion,\ntitle={Social-Transmotion: Promptable Human Trajectory Prediction},\nauthor={Saeed Saadatnejad and Yang Gao and Kaouther Messaoud and Alexandre Alahi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SQpnEfv9WH}\n}"}, "TLDR": {"value": "We propose a generic Transformer-based model that integrates diverse visual cues as prompts, powered by masking technique to enhance human trajectory prediction."}, "paperhash": {"value": "saadatnejad|socialtransmotion_promptable_human_trajectory_prediction"}}, "number": 9161, "odate": 1697213872796, "pdate": 1705411058679, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9161/-/Revision", "ICLR.cc/2024/Conference/Submission9161/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9161/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695543542128, "cdate": 1695543542128, "tmdate": 1713133004754, "mdate": 1713133004754, "version": 2}, {"id": "wfgZc3IMqo", "forum": "wfgZc3IMqo", "signatures": ["ICLR.cc/2024/Conference/Submission9158/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9158/Authors"], "content": {"title": {"value": "Robust Classification via Regression for Learning with Noisy Labels"}, "authors": {"value": ["Erik Englesson", "Hossein Azizpour"]}, "authorids": {"value": ["~Erik_Englesson1", "~Hossein_Azizpour2"]}, "keywords": {"value": ["label noise", "noisy labels", "robustness", "Gaussian noise", "classification", "log-ratio transform", "compositional data analysis"]}, "abstract": {"value": "Deep neural networks and large-scale datasets have revolutionized the field of machine learning. However, these large networks are susceptible to overfitting to label noise, resulting in reduced generalization. To address this challenge, two promising approaches have emerged: i) loss reweighting, which reduces the influence of noisy examples on the training loss, and ii) label correction that replaces noisy labels with estimated true labels. These directions have been pursued separately or combined as independent methods, lacking a unified approach. In this work, we present a unified method that seamlessly combines loss reweighting and label correction to enhance robustness against label noise in classification tasks. Specifically, by leveraging ideas from compositional data analysis in statistics, we frame the problem as a regression task, where loss reweighting and label correction can naturally be achieved with a shifted Gaussian label noise model. Our unified approach achieves strong performance compared to recent baselines on several noisy labelled datasets. We believe this work is a promising step towards robust deep learning in the presence of label noise. Our code is available at: https://github.com/ErikEnglesson/SGN."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dc6d5771bf99d6ea8d806a95a0283ab492a6448c.pdf"}, "_bibtex": {"value": "@inproceedings{\nenglesson2024robust,\ntitle={Robust Classification via Regression-Based Loss Reweighting and Label Correction},\nauthor={Erik Englesson and Hossein Azizpour},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wfgZc3IMqo}\n}"}, "paperhash": {"value": "englesson|robust_classification_via_regression_for_learning_with_noisy_labels"}}, "number": 9158, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9158/-/Revision", "ICLR.cc/2024/Conference/Submission9158/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9158/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695543511256, "cdate": 1695543511256, "tmdate": 1710751730579, "mdate": 1710751730579, "pdate": 1705411058606, "version": 2}, {"id": "dCHbFDsCZz", "forum": "dCHbFDsCZz", "signatures": ["ICLR.cc/2024/Conference/Submission9141/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9141/Authors"], "content": {"title": {"value": "Learning to Reject with a Fixed Predictor: Application to Decontextualization"}, "authors": {"value": ["Christopher Mohri", "Daniel Andor", "Eunsol Choi", "Michael Collins", "Anqi Mao", "Yutao Zhong"]}, "authorids": {"value": ["~Christopher_Mohri1", "~Daniel_Andor1", "~Eunsol_Choi1", "~Michael_Collins1", "~Anqi_Mao1", "~Yutao_Zhong1"]}, "keywords": {"value": ["Rejection", "abstention", "loss function", "consistency", "learning theory", "decontextualization", "natural language processing"]}, "TLDR": {"value": "We introduce a new loss function for learning a rejector with a fixed predictor, and focus on the decontextualization task."}, "abstract": {"value": "We study the problem of classification with a reject option for a fixed predictor, crucial to natural language processing. We introduce a new problem formulation for this scenario, and an algorithm minimizing a new surrogate loss function. We provide a complete theoretical analysis of the surrogate loss function with a strong $H$-consistency guarantee. For evaluation, we choose the \\textit{decontextualization} task, and provide a manually-labelled dataset of $2\\mathord,000$ examples. Our algorithm significantly outperforms the baselines considered, with a $\\sim 25$% improvement in coverage when halving the error rate, which is only $\\sim 3$% away from the theoretical limit."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/66caaecc6922bf5ef4e221d3e575e0c06e70075a.pdf"}, "supplementary_material": {"value": "/attachment/b5e011ebd8c2a5f5c5d93537b0805891513eaf57.pdf"}, "_bibtex": {"value": "@inproceedings{\nmohri2024learning,\ntitle={Learning to Reject with a Fixed Predictor: Application to Decontextualization},\nauthor={Christopher Mohri and Daniel Andor and Eunsol Choi and Michael Collins and Anqi Mao and Yutao Zhong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dCHbFDsCZz}\n}"}, "paperhash": {"value": "mohri|learning_to_reject_with_a_fixed_predictor_application_to_decontextualization"}}, "number": 9141, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9141/-/Revision", "ICLR.cc/2024/Conference/Submission9141/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9141/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695542547382, "cdate": 1695542547382, "tmdate": 1710557683180, "mdate": 1710557683180, "pdate": 1705411058377, "version": 2}, {"id": "jZPqf2G9Sw", "forum": "jZPqf2G9Sw", "signatures": ["ICLR.cc/2024/Conference/Submission9128/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9128/Authors"], "content": {"title": {"value": "Dynamics-Informed Protein Design with Structure Conditioning"}, "authors": {"value": ["Urszula Julia Komorowska", "Simon V Mathis", "Kieran Didi", "Francisco Vargas", "Pietro Lio", "Mateja Jamnik"]}, "authorids": {"value": ["~Urszula_Julia_Komorowska1", "~Simon_V_Mathis1", "~Kieran_Didi1", "~Francisco_Vargas1", "~Pietro_Lio1", "~Mateja_Jamnik1"]}, "keywords": {"value": ["Diffusion Models", "Generative Modeling", "Protein Design", "Normal Mode Analysis"]}, "abstract": {"value": "Current protein generative models are able to design novel backbones with desired shapes or functional motifs. However, despite the importance of a protein\u2019s dynamical properties for its function, conditioning on dynamical properties remains elusive. We present a new approach to protein generative modeling by leveraging Normal Mode Analysis that enables us to capture dynamical properties too. We introduce a method for conditioning the diffusion probabilistic models on protein dynamics, specifically on the lowest non-trivial normal mode of oscillation. Our method, similar to the classifier guidance conditioning, formulates the sampling process as being driven by conditional and unconditional terms. However, unlike previous works, we approximate the conditional term with a simple analytical function rather than an external neural network, thus making the eigenvector calculations approachable. We present the corresponding SDE theory as a formal justification of our approach. We extend our framework to conditioning on structure and dynamics at the same time, enabling scaffolding of the dynamical motifs. We demonstrate the empirical effectiveness of our method by turning the open-source unconditional protein diffusion model Genie into the conditional model with no retraining. Generated proteins exhibit the desired dynamical and structural properties while still being biologically plausible. Our work represents a first step towards incorporating dynamical behaviour in protein design and may open the door to designing more flexible and functional proteins in the future."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/be8ef14bc0fd6a695619eb7d8a048503515bbc20.pdf"}, "_bibtex": {"value": "@inproceedings{\nkomorowska2024dynamicsinformed,\ntitle={Dynamics-Informed Protein Design with Structure Conditioning},\nauthor={Urszula Julia Komorowska and Simon V Mathis and Kieran Didi and Francisco Vargas and Pietro Lio and Mateja Jamnik},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jZPqf2G9Sw}\n}"}, "paperhash": {"value": "komorowska|dynamicsinformed_protein_design_with_structure_conditioning"}}, "number": 9128, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9128/-/Revision", "ICLR.cc/2024/Conference/Submission9128/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9128/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695541695645, "cdate": 1695541695645, "tmdate": 1713095766373, "mdate": 1713095766373, "pdate": 1705411058091, "version": 2}, {"id": "tEgrUrUuwA", "forum": "tEgrUrUuwA", "signatures": ["ICLR.cc/2024/Conference/Submission9114/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9114/Authors"], "content": {"title": {"value": "Partitioning Message Passing for Graph Fraud Detection"}, "authors": {"value": ["Wei Zhuo", "Zemin Liu", "Bryan Hooi", "Bingsheng He", "Guang Tan", "Rizal Fathony", "Jia Chen"]}, "authorids": {"value": ["~Wei_Zhuo4", "~Zemin_Liu1", "~Bryan_Hooi1", "~Bingsheng_He1", "~Guang_Tan1", "~Rizal_Fathony1", "~Jia_Chen2"]}, "keywords": {"value": ["Graph Neural Networks", "Fraud Detection"]}, "TLDR": {"value": "Applyiing GNNs on fraud detection by distinguishing neighbors during message passing."}, "abstract": {"value": "Label imbalance and homophily-heterophily mixture are the fundamental problems encountered when applying Graph Neural Networks (GNNs) to Graph Fraud Detection (GFD) tasks. Existing GNN-based GFD models are designed to augment graph structure to accommodate the inductive bias of GNNs towards homophily, by excluding heterophilic neighbors during message passing. In our work, we argue that the key to applying GNNs for GFD is not to exclude but to {\\em distinguish} neighbors with different labels. Grounded in this perspective, we introduce Partitioning Message Passing (PMP), an intuitive yet effective message passing paradigm expressly crafted for GFD. Specifically, in the neighbor aggregation stage of PMP, neighbors with different classes are aggregated with distinct node-specific aggregation functions. By this means, the center node can adaptively adjust the information aggregated from its heterophilic and homophilic neighbors, thus avoiding the model gradient being dominated by benign nodes which occupy the majority of the population. We theoretically establish a connection between the spatial formulation of PMP and spectral analysis to characterize that PMP operates an adaptive node-specific spectral graph filter, which demonstrates the capability of PMP to handle heterophily-homophily mixed graphs. Extensive experimental results show that PMP can significantly boost the performance on GFD tasks."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7abe6053f04ef235ce8ddd5996dd27e266c6e058.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhuo2024partitioning,\ntitle={Partitioning Message Passing for Graph Fraud Detection},\nauthor={Wei Zhuo and Zemin Liu and Bryan Hooi and Bingsheng He and Guang Tan and Rizal Fathony and Jia Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tEgrUrUuwA}\n}"}, "paperhash": {"value": "zhuo|partitioning_message_passing_for_graph_fraud_detection"}}, "number": 9114, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9114/-/Revision", "ICLR.cc/2024/Conference/Submission9114/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9114/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695540898444, "cdate": 1695540898444, "tmdate": 1710734361749, "mdate": 1710734361749, "pdate": 1705411057865, "version": 2}, {"id": "EmQSOi1X2f", "forum": "EmQSOi1X2f", "signatures": ["ICLR.cc/2024/Conference/Submission9113/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9113/Authors"], "content": {"title": {"value": "Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"}, "authors": {"value": ["Niels M\u00fcndler", "Jingxuan He", "Slobodan Jenko", "Martin Vechev"]}, "authorids": {"value": ["~Niels_M\u00fcndler1", "~Jingxuan_He1", "~Slobodan_Jenko1", "~Martin_Vechev1"]}, "keywords": {"value": ["language model", "hallucination", "trustworthy artificial intelligence", "reasoning"]}, "TLDR": {"value": "We present a comprehensive analysis showing that state-of-the-art LLMs frequently produce self-contradictory hallucinations. We then design prompting methods that effectively detect and mitigate self-contradictions."}, "abstract": {"value": "Large language models (large LMs) are susceptible to producing text that contains hallucinated content. An important instance of this problem is self-contradiction, where the LM generates two contradictory sentences within the same context. In this work, we present a comprehensive investigation into self-contradiction for various instruction-tuned LMs, covering evaluation, detection, and mitigation. Our primary evaluation task is open-domain text generation, but we also demonstrate the applicability of our approach to shorter question answering. Our analysis reveals the prevalence of self-contradictions, e.g., in 17.7% of all sentences produced by ChatGPT. We then propose a novel prompting-based framework designed to effectively detect and mitigate self-contradictions. Our detector achieves high accuracy, e.g., around 80% F1 score when prompting ChatGPT. The mitigation algorithm iteratively refines the generated text to remove contradictory information while preserving text fluency and informativeness. Importantly, our entire framework is applicable to black-box LMs and does not require retrieval of external knowledge. Rather, our method complements retrieval-based methods, as a large portion of self-contradictions (e.g., 35.2% for ChatGPT) cannot be verified using online text. Our approach is practically effective and has been released as a push-button tool to benefit the public at https://chatprotect.ai/."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9087c7d18bb7707f5f8b47046499f922b5c47af3.pdf"}, "_bibtex": {"value": "@inproceedings{\nm{\\\"u}ndler2024selfcontradictory,\ntitle={Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation},\nauthor={Niels M{\\\"u}ndler and Jingxuan He and Slobodan Jenko and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EmQSOi1X2f}\n}"}, "paperhash": {"value": "m\u00fcndler|selfcontradictory_hallucinations_of_large_language_models_evaluation_detection_and_mitigation"}}, "number": 9113, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9113/-/Revision", "ICLR.cc/2024/Conference/Submission9113/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9113/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695540825331, "cdate": 1695540825331, "tmdate": 1710535780023, "mdate": 1710535780023, "pdate": 1705411057850, "version": 2}, {"id": "AyXIDfvYg8", "forum": "AyXIDfvYg8", "signatures": ["ICLR.cc/2024/Conference/Submission9066/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9066/Authors"], "content": {"title": {"value": "Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching"}, "authors": {"value": ["Ganesh Ramachandra Kini", "Vala Vakilian", "Tina Behnia", "Jaidev Gill", "Christos Thrampoulidis"]}, "authorids": {"value": ["~Ganesh_Ramachandra_Kini1", "~Vala_Vakilian2", "~Tina_Behnia1", "~Jaidev_Gill1", "~Christos_Thrampoulidis1"]}, "keywords": {"value": ["Supervised contrastive learning", "neural collapse", "implicit bias", "class imbalance"]}, "abstract": {"value": "Supervised contrastive loss (SCL) is a competitive and often superior alternative to the cross-entropy loss for classification. While prior studies have demonstrated that both losses yield symmetric training representations under balanced data, this symmetry breaks under class imbalances. This paper presents an intriguing discovery: the introduction of a ReLU activation at the final layer effectively restores the symmetry in SCL-learned representations. We arrive at this finding analytically, by establishing that the global minimizers of an unconstrained features model with SCL loss and entry-wise non-negativity constraints form an orthogonal frame. Extensive experiments conducted across various datasets, architectures, and imbalance scenarios corroborate our finding.  Importantly, our experiments reveal that the inclusion of the ReLU activation restores symmetry without compromising test accuracy. This constitutes the first geometry characterization of SCL under imbalances. Additionally, our analysis and experiments underscore the pivotal role of batch selection strategies in representation geometry. By proving necessary and sufficient conditions for mini-batch choices that ensure invariant symmetric representations, we introduce batch-binding as an efficient strategy that guarantees these conditions hold."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b40ab759531e71a4137172d4dca6019ea210d8d1.pdf"}, "supplementary_material": {"value": "/attachment/4ca8e27c93ca216bf6d3c929a8b4ff265f95c4a2.zip"}, "_bibtex": {"value": "@inproceedings{\nkini2024symmetric,\ntitle={Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of Re{LU} and Batching},\nauthor={Ganesh Ramachandra Kini and Vala Vakilian and Tina Behnia and Jaidev Gill and Christos Thrampoulidis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AyXIDfvYg8}\n}"}, "paperhash": {"value": "kini|symmetric_neuralcollapse_representations_with_supervised_contrastive_loss_the_impact_of_relu_and_batching"}}, "number": 9066, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9066/-/Revision", "ICLR.cc/2024/Conference/Submission9066/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9066/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695537740665, "cdate": 1695537740665, "tmdate": 1710588989275, "mdate": 1710588989275, "pdate": 1705411056940, "version": 2}, {"id": "ADDCErFzev", "forum": "ADDCErFzev", "signatures": ["ICLR.cc/2024/Conference/Submission9065/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9065/Authors"], "content": {"title": {"value": "Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems"}, "authors": {"value": ["Jacob S. Prince", "Gabriel Fajardo", "George A. Alvarez", "Talia Konkle"]}, "authorids": {"value": ["~Jacob_S._Prince1", "fajardgb@bc.edu", "~George_A._Alvarez2", "~Talia_Konkle1"]}, "keywords": {"value": ["Efficient coding", "object representation", "dropout", "robustness", "human fMRI", "occipitotemporal cortex", "cognitive neuroscience", "distributed coding"]}, "abstract": {"value": "According to the efficient coding hypothesis, neural populations encode information optimally when representations are high-dimensional and uncorrelated. However, such codes may carry a cost in terms of generalization and robustness. Past empirical studies of early visual cortex (V1) in rodents have suggested that this tradeoff indeed constrains sensory representations. However, it remains unclear whether these insights generalize across the hierarchy of the human visual system, and particularly to object representations in high-level occipitotemporal cortex (OTC). To gain new empirical clarity, here we develop a family of object recognition models with parametrically varying dropout proportion $p$, which induces systematically varying dimensionality of internal responses (while controlling all other inductive biases). We find that increasing dropout produces an increasingly smooth, low-dimensional representational space. Optimal robustness to lesioning is observed at around 70% dropout, after which both accuracy and robustness decline. Representational comparison to large-scale 7T fMRI data from occipitotemporal cortex in the Natural Scenes Dataset reveals that this optimal degree of dropout is also associated with maximal emergent neural predictivity. Finally, using new techniques for achieving denoised estimates of the eigenspectrum of human fMRI responses, we compare the rate of eigenspectrum decay between model and brain feature spaces. We observe that the match between model and brain representations is associated with a common balance between efficiency and robustness in the representational space. These results suggest that varying dropout may reveal an optimal point of balance between the efficiency of high-dimensional codes and the robustness of low dimensional codes in hierarchical vision systems."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7f10cc682acaa93ecdd9fa4c23e343be124115dd.pdf"}, "_bibtex": {"value": "@inproceedings{\nprince2024manipulating,\ntitle={Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems},\nauthor={Jacob S. Prince and Gabriel Fajardo and George A. Alvarez and Talia Konkle},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ADDCErFzev}\n}"}, "paperhash": {"value": "prince|manipulating_dropout_reveals_an_optimal_balance_of_efficiency_and_robustness_in_biological_and_machine_visual_systems"}}, "number": 9065, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9065/-/Revision", "ICLR.cc/2024/Conference/Submission9065/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9065/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695537702635, "cdate": 1695537702635, "tmdate": 1710576191493, "mdate": 1710576191493, "pdate": 1705411056816, "version": 2}, {"id": "327tbF3S65", "forum": "327tbF3S65", "signatures": ["ICLR.cc/2024/Conference/Submission9058/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9058/Authors"], "content": {"title": {"value": "DDMI: Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations"}, "authors": {"value": ["Dogyun Park", "Sihyeon Kim", "Sojin Lee", "Hyunwoo J. Kim"]}, "authorids": {"value": ["~Dogyun_Park2", "~Sihyeon_Kim1", "~Sojin_Lee1", "~Hyunwoo_J._Kim3"]}, "keywords": {"value": ["Implicit neural representation", "generative model", "domain agnostic", "diffusion model"]}, "abstract": {"value": "Recent studies have introduced a new class of generative models for synthesizing implicit neural representations (INRs) that capture arbitrary continuous signals in various domains. These models opened the door for domain-agnostic generative models, but they often fail to achieve high-quality generation. We observed that the existing methods generate the weights of neural networks to parameterize INRs and evaluate the network with fixed positional embeddings (PEs). Arguably, this architecture limits the expressive power of generative models and results in low-quality INR generation. To address this limitation, we propose Domain-agnostic Latent Diffusion Model for INRs (DDMI) that generates adaptive positional embeddings instead of neural networks' weights. Specifically, we develop a Discrete-to-continuous space Variational AutoEncoder (D2C-VAE) that seamlessly connects discrete data and continuous signal functions in the shared latent space. Additionally, we introduce a novel conditioning mechanism for evaluating INRs with the hierarchically decomposed PEs to further enhance expressive power. Extensive experiments across four modalities, \\eg, 2D images, 3D shapes, Neural Radiance Fields, and videos, with seven benchmark datasets, demonstrate the versatility of DDMI and its superior performance compared to the existing INR generative models. Code is available at \\href{https://github.com/mlvlab/DDMI}{https://github.com/mlvlab/DDMI}."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/716a67cdede3543daa6309c204a066e517decc41.pdf"}, "_bibtex": {"value": "@inproceedings{\npark2024domainagnostic,\ntitle={Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations},\nauthor={Dogyun Park and Sihyeon Kim and Sojin Lee and Hyunwoo J. Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=327tbF3S65}\n}"}, "TLDR": {"value": "We propose a latent diffusion model that generates hierarchically decomposed positional embeddings of Implicit neural representations, enabling high-quality generation on various data domains."}, "paperhash": {"value": "park|ddmi_domainagnostic_latent_diffusion_models_for_synthesizing_highquality_implicit_neural_representations"}}, "number": 9058, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9058/-/Revision", "ICLR.cc/2024/Conference/Submission9058/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9058/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695537079601, "cdate": 1695537079601, "tmdate": 1710561373174, "mdate": 1710561373174, "pdate": 1705411056639, "version": 2}, {"id": "uz7d2N2zul", "forum": "uz7d2N2zul", "signatures": ["ICLR.cc/2024/Conference/Submission9034/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9034/Authors"], "content": {"title": {"value": "Bayesian Coreset Optimization for Personalized Federated Learning"}, "authors": {"value": ["Prateek Chanda", "Shrey Modi", "Ganesh Ramakrishnan"]}, "authorids": {"value": ["~Prateek_Chanda2", "~Shrey_Modi1", "~Ganesh_Ramakrishnan1"]}, "keywords": {"value": ["federated learning", "personalized federated learning", "bayesian coreset", "submodularity", "variational inference", "coresets", "optimization"]}, "TLDR": {"value": "The paper deals with utilizing a bayesian coreset on individual client's data in a federated learning setting that takes into account personalization at each client's side."}, "abstract": {"value": "In a distributed machine learning setting like Federated Learning where there are multiple clients involved which update their individual weights to a single central server, often training on the entire individual client's dataset for each client becomes cumbersome. To address this issue we propose CORESET-PFEDBAYES : a personalized coreset weighted federated learning setup where the training updates for each individual clients are forwarded to the central server based on only individual client coreset based representative data points instead of the entire client data. Through theoretical analysis we present how the average generalization error is minimax optimal up to logarithm bounds (upper bounded by $\\mathcal{O}(n_k^{-\\frac{2 \\beta}{2 \\beta+\\boldsymbol{\\Lambda}}} \\log ^{2 \\delta^{\\prime}}(n_k))$) and lower bounds of $\\mathcal{O}(n_k^{-\\frac{2 \\beta}{2 \\beta+\\boldsymbol{\\Lambda}}})$, and how the overall generalization error on the data likelihood differs from a vanilla Federated Learning setup as a closed form function ${\\boldsymbol{\\Im}}(\\boldsymbol{w}, n_k)$ of the coreset weights $\\boldsymbol{w}$ and coreset sample size $n_k$. \nOur experiments on different benchmark datasets based on a variety of recent personalized federated learning architectures show significant gains as compared to random sampling on the training data followed by federated learning, thereby indicating how intelligently selecting such training samples can help in performance. Additionally, through experiments on medical datasets our proposed method showcases some gains as compared to  other submodular optimization based approaches used for subset selection on client's data."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f9f99855efeefee1e15f22a4c54ff218b314f9c5.pdf"}, "supplementary_material": {"value": "/attachment/39bfb2549481f4842e78d7fdcfc9ba1b90653362.pdf"}, "_bibtex": {"value": "@inproceedings{\nchanda2024bayesian,\ntitle={Bayesian Coreset Optimization for Personalized Federated Learning},\nauthor={Prateek Chanda and Shrey Modi and Ganesh Ramakrishnan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uz7d2N2zul}\n}"}, "paperhash": {"value": "chanda|bayesian_coreset_optimization_for_personalized_federated_learning"}}, "number": 9034, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9034/-/Revision", "ICLR.cc/2024/Conference/Submission9034/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9034/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695535707402, "cdate": 1695535707402, "tmdate": 1713098460942, "mdate": 1713098460942, "pdate": 1705411056101, "version": 2}, {"id": "uREj4ZuGJE", "forum": "uREj4ZuGJE", "signatures": ["ICLR.cc/2024/Conference/Submission9031/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9031/Authors"], "content": {"title": {"value": "In-context Autoencoder for Context Compression in a Large Language Model"}, "authors": {"value": ["Tao Ge", "Hu Jing", "Lei Wang", "Xun Wang", "Si-Qing Chen", "Furu Wei"]}, "authorids": {"value": ["~Tao_Ge1", "~Hu_Jing1", "2362769214@qq.com", "~Xun_Wang5", "~Si-Qing_Chen1", "~Furu_Wei1"]}, "keywords": {"value": ["large language model", "context compression", "in-context autoencoder", "pretraining", "fine-tuning", "Llama", "GPT", "memorization"]}, "TLDR": {"value": "A paper proposing a novel approach called In-context Autoencoder (ICAE) for LLM context compression"}, "abstract": {"value": "We propose the In-context Autoencoder (ICAE), leveraging the power of a large language model (LLM) to compress a long context into short compact memory slots that can be directly conditioned on by the LLM for various purposes. ICAE is first pretrained using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context. Then, it is fine-tuned on instruction data for producing desirable responses to various prompts. Experiments demonstrate that our lightweight ICAE, introducing about 1% additional parameters, effectively achieves $4\\times$ context compression based on Llama, offering advantages in both improved latency and GPU memory cost during inference, and showing an interesting insight in memorization as well as potential for scalability. These promising results imply a novel perspective on the connection between working memory in cognitive science and representation learning in LLMs, revealing ICAE's significant implications in addressing the long context problem and suggesting further research in LLM context management. Our data, code and models are available at https://github.com/getao/icae."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0cb80bedd6a43e1383e8fe4642b39105d27be261.pdf"}, "_bibtex": {"value": "@inproceedings{\nge2024incontext,\ntitle={In-context Autoencoder for Context Compression in a Large Language Model},\nauthor={Tao Ge and Hu Jing and Lei Wang and Xun Wang and Si-Qing Chen and Furu Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uREj4ZuGJE}\n}"}, "paperhash": {"value": "ge|incontext_autoencoder_for_context_compression_in_a_large_language_model"}}, "number": 9031, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9031/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9031/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695535623476, "cdate": 1695535623476, "tmdate": 1713059336016, "mdate": 1713059336016, "pdate": 1705411056052, "version": 2}, {"id": "J44HfH4JCg", "forum": "J44HfH4JCg", "signatures": ["ICLR.cc/2024/Conference/Submission9027/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9027/Authors"], "content": {"title": {"value": "Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"}, "authors": {"value": ["Fuxiao Liu", "Kevin Lin", "Linjie Li", "Jianfeng Wang", "Yaser Yacoob", "Lijuan Wang"]}, "authorids": {"value": ["~Fuxiao_Liu1", "~Kevin_Lin3", "~Linjie_Li1", "~Jianfeng_Wang4", "~Yaser_Yacoob1", "~Lijuan_Wang1"]}, "keywords": {"value": ["instruction tuning", "multimodal large language model", "hallucination", "datasets"]}, "abstract": {"value": "Despite the promising progress in multi-modal tasks, current large multi-modal models (LMMs) are prone to hallucinating inconsistent descriptions with respect to the associated image and human instructions. This paper addresses this issue by introducing the first large and diverse visual instruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction. Our dataset comprises 400k visual\ninstructions generated by GPT4, covering 16 vision-and-language tasks with open-ended instructions and answers. Unlike existing studies that primarily focus on positive instruction samples, we design LRV-Instruction to include both positive and negative instructions for more robust visual instruction tuning. Our negative instructions are designed at three semantic levels: (i) Nonexistent Object Manipulation, (ii) Existent Object Manipulation and (iii) Knowledge Manipulation. To efficiently measure the hallucination generated by LMMs, we propose GPT4-Assisted Visual Instruction Evaluation (GAVIE), a stable approach to evaluate visual instruction tuning like human experts. GAVIE does not require human-annotated groundtruth answers and can adapt to diverse instruction formats. We conduct comprehensive experiments to investigate the hallucination of LMMs. Our results demonstrate existing LMMs exhibit significant hallucinations when presented with our negative instructions, particularly Existent Object and Knowledge Manipulation instructions. Moreover, we successfully mitigate hallucination by finetuning MiniGPT4 and mPLUG-Owl on LRV-Instruction while improving performance on several public\ndatasets compared to state-of-the-art methods. Additionally, we observed that a balanced ratio of positive and negative instances in the training data leads to a more robust model. Code and data will be released upon publication."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a7dc45dbafdb5c8be70b9ae7f987f44a08b62885.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024mitigating,\ntitle={Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning},\nauthor={Fuxiao Liu and Kevin Lin and Linjie Li and Jianfeng Wang and Yaser Yacoob and Lijuan Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=J44HfH4JCg}\n}"}, "paperhash": {"value": "liu|mitigating_hallucination_in_large_multimodal_models_via_robust_instruction_tuning"}}, "number": 9027, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9027/-/Revision", "ICLR.cc/2024/Conference/Submission9027/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9027/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695535205464, "cdate": 1695535205464, "tmdate": 1710001956065, "mdate": 1710001956065, "pdate": 1705411055933, "version": 2}, {"id": "FHqAzWl2wE", "forum": "FHqAzWl2wE", "signatures": ["ICLR.cc/2024/Conference/Submission9021/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9021/Authors"], "content": {"title": {"value": "Multimarginal Generative Modeling with Stochastic Interpolants"}, "authors": {"value": ["Michael Samuel Albergo", "Nicholas Matthew Boffi", "Michael Lindsey", "Eric Vanden-Eijnden"]}, "authorids": {"value": ["~Michael_Samuel_Albergo1", "~Nicholas_Matthew_Boffi1", "~Michael_Lindsey1", "~Eric_Vanden-Eijnden1"]}, "keywords": {"value": ["multi-marginal", "unsupervised learning", "generative modeling", "measure transport", "optimal transport"]}, "TLDR": {"value": "We introduce a method to generalize flow-based and diffusion based generative models to map between K distributions instead of two, revealing multiway-correspondences between densities."}, "abstract": {"value": "Given a set of $K$ probability densities, we consider the multimarginal generative modeling problem of learning a joint distribution that recovers these densities as marginals. The structure of this joint distribution should identify multi-way correspondences among the prescribed marginals. We formalize an approach to this task within a generalization of the stochastic interpolant framework, leading to efficient learning algorithms built upon dynamical transport of measure. Our generative models are defined by velocity and score fields that can be characterized as the minimizers of simple quadratic objectives, and they are defined on a simplex that generalizes the time variable in the usual dynamical transport framework. The resulting transport on the simplex is influenced by all marginals, and we show that multi-way correspondences can be extracted. The identification of such correspondences has applications to style transfer, algorithmic fairness, and data decorruption.  In addition, the multimarginal perspective enables an efficient algorithm for optimizing the dynamical transport cost in the ordinary two-marginal setting. We demonstrate these capacities with several numerical examples."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ffbe0129551a2886a81d49db461b05400f637dee.pdf"}, "_bibtex": {"value": "@inproceedings{\nalbergo2024multimarginal,\ntitle={Multimarginal Generative Modeling with Stochastic Interpolants},\nauthor={Michael Samuel Albergo and Nicholas Matthew Boffi and Michael Lindsey and Eric Vanden-Eijnden},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FHqAzWl2wE}\n}"}, "paperhash": {"value": "albergo|multimarginal_generative_modeling_with_stochastic_interpolants"}}, "number": 9021, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9021/-/Revision", "ICLR.cc/2024/Conference/Submission9021/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9021/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695534912877, "cdate": 1695534912877, "tmdate": 1710865809587, "mdate": 1710865809587, "pdate": 1705411055908, "version": 2}, {"id": "JiTVtCUOpS", "forum": "JiTVtCUOpS", "signatures": ["ICLR.cc/2024/Conference/Submission9003/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9003/Authors"], "content": {"title": {"value": "Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators"}, "authors": {"value": ["Lifan Zhao", "Yanyan Shen"]}, "authorids": {"value": ["~Lifan_Zhao3", "~Yanyan_Shen1"]}, "keywords": {"value": ["Multivariate time series forecasting", "channel dependence", "lead-lag relationships", "distribution shift"]}, "TLDR": {"value": "We rethink the distribution shift in multivariate time series, where channel dependence varies over time. We propose LIFT to dynamically select and leverage leading indicators, which emprically improves SOTA forecasting methods by 5.5% in average."}, "abstract": {"value": "Recently, channel-independent methods have achieved state-of-the-art performance in multivariate time series (MTS) forecasting. Despite reducing overfitting risks, these methods miss potential opportunities in utilizing channel dependence for accurate predictions. We argue that there exist locally stationary lead-lag relationships between variates, i.e., some lagged variates may follow the leading indicators within a short time period. Exploiting such channel dependence is beneficial since leading indicators offer advance information that can be used to reduce the forecasting difficulty of the lagged variates. In this paper, we propose a new method named LIFT that first efficiently estimates leading indicators and their leading steps at each time step and then judiciously allows the lagged variates to utilize the advance information from leading indicators. LIFT plays as a plugin that can be seamlessly collaborated with arbitrary time series forecasting methods. Extensive experiments on six real-world datasets demonstrate that LIFT improves the state-of-the-art methods by 5.4% in average forecasting performance. Our code is available at https://github.com/SJTU-Quant/LIFT."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1c5cada650477665ffdbf06176f1a13087806e36.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhao2024rethinking,\ntitle={Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators},\nauthor={Lifan Zhao and Yanyan Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JiTVtCUOpS}\n}"}, "paperhash": {"value": "zhao|rethinking_channel_dependence_for_multivariate_time_series_forecasting_learning_from_leading_indicators"}}, "number": 9003, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9003/-/Revision", "ICLR.cc/2024/Conference/Submission9003/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9003/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695533471068, "cdate": 1695533471068, "tmdate": 1712982376423, "mdate": 1712982376423, "pdate": 1705411055494, "version": 2}, {"id": "GN921JHCRw", "forum": "GN921JHCRw", "signatures": ["ICLR.cc/2024/Conference/Submission8997/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8997/Authors"], "content": {"title": {"value": "RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"}, "authors": {"value": ["Parth Sarthi", "Salman Abdullah", "Aditi Tuli", "Shubh Khanna", "Anna Goldie", "Christopher D Manning"]}, "authorids": {"value": ["~Parth_Sarthi1", "~Salman_Abdullah1", "~Aditi_Tuli1", "~Shubh_Khanna1", "~Anna_Goldie2", "~Christopher_D_Manning1"]}, "keywords": {"value": ["Retrieval Augmented Language Models", "Information Retrieval", "summarization", "QA"]}, "abstract": {"value": "Retrieval-augmented language models can better adapt to changes in world state and incorporate long-tail knowledge.  However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, limiting holistic understanding of the overall document context. We introduce the novel approach of recursively embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization from the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across lengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive summaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example, by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by 20\\% in absolute accuracy."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1414c23eb8af2e30daa25a4f53471f69091f48d9.pdf"}, "supplementary_material": {"value": "/attachment/d08bad0d7976e4e81370c62a8f20de5efd38236a.zip"}, "TLDR": {"value": "RAPTOR improves LLM QA performance by constructing a hierarchical summarization tree for information retrieval, outperforming existing retrieval methods across various metrics and datasets."}, "_bibtex": {"value": "@inproceedings{\nsarthi2024raptor,\ntitle={{RAPTOR}: Recursive Abstractive Processing for Tree-Organized Retrieval},\nauthor={Parth Sarthi and Salman Abdullah and Aditi Tuli and Shubh Khanna and Anna Goldie and Christopher D Manning},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GN921JHCRw}\n}"}, "paperhash": {"value": "sarthi|raptor_recursive_abstractive_processing_for_treeorganized_retrieval"}}, "number": 8997, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8997/-/Revision", "ICLR.cc/2024/Conference/Submission8997/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8997/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695533163316, "cdate": 1695533163316, "tmdate": 1713056310238, "mdate": 1713056310238, "pdate": 1705411055378, "version": 2}, {"id": "sLQb8q0sUi", "forum": "sLQb8q0sUi", "signatures": ["ICLR.cc/2024/Conference/Submission8996/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8996/Authors"], "content": {"title": {"value": "Fair and Efficient Contribution Valuation for Vertical Federated Learning"}, "authors": {"value": ["Zhenan Fan", "Huang Fang", "Xinglu Wang", "Zirui Zhou", "Jian Pei", "Michael Friedlander", "Yong Zhang"]}, "authorids": {"value": ["~Zhenan_Fan1", "~Huang_Fang1", "~Xinglu_Wang1", "~Zirui_Zhou2", "~Jian_Pei1", "~Michael_Friedlander1", "~Yong_Zhang2"]}, "keywords": {"value": ["Vertical federated learning", "Contribution valuation", "Fairness"]}, "abstract": {"value": "Federated learning is an emerging technology for training machine learning models across decentralized data sources without sharing data. Vertical federated learning, also known as feature-based federated learning, applies to scenarios where data sources have the same sample IDs but different feature sets. To ensure fairness among data owners, it is critical to objectively assess the contributions from different data sources and compensate the corresponding data owners accordingly. The Shapley value is a provably fair contribution valuation metric originating from cooperative game theory. However, its straight-forward computation requires extensively retraining a model on each potential combination of data sources, leading to prohibitively high communication and computation overheads due to multiple rounds of federated learning. To tackle this challenge, we propose a contribution valuation metric called vertical federated Shapley value (VerFedSV) based on the classic Shapley value. We show that VerFedSV not only satisfies many desirable properties of fairness but is also efficient to compute. Moreover, VerFedSV can be adapted to both synchronous and asynchronous vertical federated learning algorithms. Both theoretical analysis and extensive experimental results demonstrate the fairness, efficiency, adaptability, and effectiveness of VerFedSV."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6a7f95c7baec41005e195a24ebc51afc7ef5acbf.pdf"}, "supplementary_material": {"value": "/attachment/2b3bee69555f755c5252df51d9e8dffc6ad5d620.zip"}, "_bibtex": {"value": "@inproceedings{\nfan2024fair,\ntitle={Fair and Efficient Contribution Valuation for Vertical Federated Learning},\nauthor={Zhenan Fan and Huang Fang and Xinglu Wang and Zirui Zhou and Jian Pei and Michael Friedlander and Yong Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sLQb8q0sUi}\n}"}, "paperhash": {"value": "fan|fair_and_efficient_contribution_valuation_for_vertical_federated_learning"}}, "number": 8996, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8996/-/Revision", "ICLR.cc/2024/Conference/Submission8996/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8996/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695533124346, "cdate": 1695533124346, "tmdate": 1709661552490, "mdate": 1709661552490, "pdate": 1705411055375, "version": 2}, {"id": "HX5ujdsSon", "forum": "HX5ujdsSon", "signatures": ["ICLR.cc/2024/Conference/Submission8985/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8985/Authors"], "content": {"title": {"value": "In-Context Learning through the Bayesian Prism"}, "authors": {"value": ["Madhur Panwar", "Kabir Ahuja", "Navin Goyal"]}, "authorids": {"value": ["~Madhur_Panwar1", "~Kabir_Ahuja1", "~Navin_Goyal1"]}, "keywords": {"value": ["In-context Learning", "Transformers", "Inductive Biases", "Meta Learning", "Language Modelling", "Bayesian Inference"]}, "abstract": {"value": "In-context learning (ICL) is one of the surprising and useful features of large language models and subject of intense research. Recently, stylized meta-learning-like ICL setups have been devised that train transformers on sequences of input-output pairs $(x, f(x))$. The function $f$ comes from a function class and generalization is checked by evaluating on sequences generated from unseen functions from the same class. One of the main discoveries in this line of research has been that for several function classes, such as linear regression, transformers successfully generalize to new functions in the class. However, the inductive biases of these models resulting in this behavior are not clearly understood. A model with unlimited training data and compute is a Bayesian predictor: it learns the pretraining distribution.\nIn this paper we empirically examine how far this Bayesian perspective can help us understand ICL. To this end, we generalize the previous meta-ICL setup to hierarchical meta-ICL setup which involve unions of multiple task families. We instantiate this setup on a diverse range of linear and nonlinear function families and find that transformers can do ICL in this setting as well. Where Bayesian inference is tractable, we find evidence that high-capacity transformers mimic the Bayesian predictor. The Bayesian perspective provides insights into the inductive bias of ICL and how transformers perform a particular task when they are trained on multiple tasks. We also find that transformers can learn to generalize to new function classes that were not seen during pretraining. This involves deviation from the Bayesian predictor. We examine these deviations in more depth offering new insights and hypotheses."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fc9aa29ea37339217577f61679622246ebfce078.pdf"}, "_bibtex": {"value": "@inproceedings{\npanwar2024incontext,\ntitle={In-Context Learning through the Bayesian Prism},\nauthor={Madhur Panwar and Kabir Ahuja and Navin Goyal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HX5ujdsSon}\n}"}, "paperhash": {"value": "panwar|incontext_learning_through_the_bayesian_prism"}}, "number": 8985, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8985/-/Revision", "ICLR.cc/2024/Conference/Submission8985/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8985/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695532605311, "cdate": 1695532605311, "tmdate": 1713058427229, "mdate": 1713058427229, "pdate": 1705411055183, "version": 2}, {"id": "WsRHpHH4s0", "forum": "WsRHpHH4s0", "signatures": ["ICLR.cc/2024/Conference/Submission8983/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8983/Authors"], "content": {"title": {"value": "RingAttention with Blockwise Transformers for Near-Infinite Context"}, "authors": {"value": ["Hao Liu", "Matei Zaharia", "Pieter Abbeel"]}, "authorids": {"value": ["~Hao_Liu1", "~Matei_Zaharia1", "~Pieter_Abbeel2"]}, "keywords": {"value": ["Language Model", "Large Context", "Transformers", "Long Context Model", "Memory Efficiency"]}, "abstract": {"value": "Transformers have emerged as the architecture of choice for many state-of-the-art AI models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands imposed by Transformers limit their ability to handle long sequences, thereby posing challenges in utilizing videos, actions, and other long-form sequences and modalities in complex environments. We present a novel approach, Blockwise RingAttention, which leverages blockwise computation of self-attention and feedforward to distribute long sequences across multiple devices while fully overlapping the communication of key-value blocks with the computation of blockwise attention. Our approach enables training and inference of sequences that are up to device count times longer than those achievable by prior memory-efficient Transformers, without resorting to approximations or incurring additional communication and computation overheads. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of our approach in allowing millions of tokens context size and improving performance."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/46002918e58387fc0091aa342ec23ebe66fd93e4.pdf"}, "TLDR": {"value": "We present an efficient method of computing the standard transformer architecture, enabling effective processing of long contextual information."}, "_bibtex": {"value": "@inproceedings{\nliu2024harnessing,\ntitle={Harnessing Overlap in Blockwise Transformers for Near-Infinite Context},\nauthor={Hao Liu and Matei Zaharia and Pieter Abbeel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WsRHpHH4s0}\n}"}, "paperhash": {"value": "liu|ringattention_with_blockwise_transformers_for_nearinfinite_context"}}, "number": 8983, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8983/-/Revision", "ICLR.cc/2024/Conference/Submission8983/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8983/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695532532578, "cdate": 1695532532578, "tmdate": 1709932991893, "mdate": 1709932991893, "pdate": 1705411055094, "version": 2}, {"id": "6xfe4IVcOu", "forum": "6xfe4IVcOu", "signatures": ["ICLR.cc/2024/Conference/Submission8976/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8976/Authors"], "content": {"title": {"value": "Chain of Hindsight aligns Language Models with Feedback"}, "authors": {"value": ["Hao Liu", "Carmelo Sferrazza", "Pieter Abbeel"]}, "authorids": {"value": ["~Hao_Liu1", "~Carmelo_Sferrazza1", "~Pieter_Abbeel2"]}, "keywords": {"value": ["Reinforcement Learning", "Reinforcement Learning from Human Feedback", "RLHF"]}, "abstract": {"value": "Learning from human preferences is important for language models to match human needs and to align with human and social values. \nPrior works have achieved remarkable successes by learning from human feedback to understand and follow instructions. Nonetheless, these methods are either founded on hand-picked model generations that are favored by human annotators, rendering them inefficient in terms of data utilization and challenging to apply in general, or they depend on reinforcement learning, which often suffers from imperfect reward functions and relies on extremely challenging optimizations. In this work, we propose a novel technique, Chain of Hindsight, that is easy to optimize and can learn from any form of feedback, regardless of its polarity. Our idea is inspired by how humans learn from extensive feedback presented in the form of languages. We convert all types of feedback into sequences of sentences, which are then used to fine-tune the model, allowing us to take advantage of the language comprehension capabilities of language models.\nWe condition the model on a sequence of model generations paired with feedback. By doing so, the model is trained to generate outputs based on feedback, while learning to identify and correct negative attributes or errors.  Applying our method to large language models, we observed that Chain of Hindsight significantly surpasses previous methods in aligning language models with human preferences. We report significant improvements on summarization and dialogue benchmarks, with our approach markedly preferred in human evaluations."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4f8d82888dd23100ef54c554d89583f33ab3b66e.pdf"}, "supplementary_material": {"value": "/attachment/db2a0718e6995981e24187ef60a5d65b25d77f54.pdf"}, "TLDR": {"value": "We present a method for learning from human feedback that's simpler than RLHF"}, "_bibtex": {"value": "@inproceedings{\nliu2024chain,\ntitle={Chain of Hindsight aligns Language Models with Feedback},\nauthor={Hao Liu and Carmelo Sferrazza and Pieter Abbeel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6xfe4IVcOu}\n}"}, "paperhash": {"value": "liu|chain_of_hindsight_aligns_language_models_with_feedback"}}, "number": 8976, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8976/-/Revision", "ICLR.cc/2024/Conference/Submission8976/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695532275254, "cdate": 1695532275254, "tmdate": 1707625651455, "mdate": 1707625651455, "pdate": 1705411054999, "version": 2}, {"id": "IjMUGuUmBI", "forum": "IjMUGuUmBI", "signatures": ["ICLR.cc/2024/Conference/Submission8971/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8971/Authors"], "content": {"title": {"value": "GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks"}, "authors": {"value": ["Peter M\u00fcller", "Lukas Faber", "Karolis Martinkus", "Roger Wattenhofer"]}, "authorids": {"value": ["~Peter_M\u00fcller2", "~Lukas_Faber1", "~Karolis_Martinkus1", "~Roger_Wattenhofer1"]}, "keywords": {"value": ["Graph Neural Networks", "GNN", "Explainability", "Decision Trees"]}, "TLDR": {"value": "GraphChef integrate Decision Trees into Graph Neural Networks to allow explaining the full decision process."}, "abstract": {"value": "We propose a new self-explainable Graph Neural Network (GNN) model: GraphChef. GraphChef integrates decision trees into the GNN message passing framework. Given a dataset, GraphChef returns a set of rules (a recipe) that explains each class in the dataset unlike existing GNNs and explanation methods that reason on individual graphs. Thanks to the decision trees, GraphChef  recipes are human understandable.  We also present a new pruning method to produce small and easy to digest trees. Experiments demonstrate that GraphChef reaches comparable accuracy to not self-explainable GNNs and produced decision trees are indeed small. We further validate the correctness of the discovered recipes on datasets where explanation ground truth is available: Reddit-Binary, MUTAG, BA-2Motifs, BA-Shapes, Tree-Cycle, and Tree-Grid."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0e5d8259f045fd1291bc9817e8008716c5c83cb3.pdf"}, "supplementary_material": {"value": "/attachment/f54bec525dfcaccee5a198f22d9775be87a286ca.zip"}, "_bibtex": {"value": "@inproceedings{\nm{\\\"u}ller2024graphchef,\ntitle={GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks},\nauthor={Peter M{\\\"u}ller and Lukas Faber and Karolis Martinkus and Roger Wattenhofer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IjMUGuUmBI}\n}"}, "paperhash": {"value": "m\u00fcller|graphchef_decisiontree_recipes_to_explain_graph_neural_networks"}}, "number": 8971, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8971/-/Revision", "ICLR.cc/2024/Conference/Submission8971/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8971/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695532036838, "cdate": 1695532036838, "tmdate": 1710346798454, "mdate": 1710346798454, "pdate": 1705411054966, "version": 2}, {"id": "yarUvgEXq3", "forum": "yarUvgEXq3", "signatures": ["ICLR.cc/2024/Conference/Submission8970/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8970/Authors"], "content": {"title": {"value": "Safe Collaborative Filtering"}, "authors": {"value": ["Riku Togashi", "Tatsushi Oka", "Naoto Ohsaka", "Tetsuro Morimura"]}, "authorids": {"value": ["~Riku_Togashi3", "~Tatsushi_Oka1", "~Naoto_Ohsaka2", "~Tetsuro_Morimura1"]}, "keywords": {"value": ["recommender systems", "collaborative filtering", "scalability"]}, "abstract": {"value": "Excellent tail performance is crucial for modern machine learning tasks, such as algorithmic fairness, class imbalance, and risk-sensitive decision making, as it ensures the effective handling of challenging samples within a dataset. Tail performance is also a vital determinant of success for personalized recommender systems to reduce the risk of losing users with low satisfaction. This study introduces a \"safe\" collaborative filtering method that prioritizes recommendation quality for less-satisfied users rather than focusing on the average performance. Our approach minimizes the conditional value at risk (CVaR), which represents the average risk over the tails of users' loss. To overcome computational challenges for web-scale recommender systems, we develop a robust yet practical algorithm that extends the most scalable method, implicit alternating least squares (iALS). Empirical evaluation on real-world datasets demonstrates the excellent tail performance of our approach while maintaining competitive computational efficiency."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/51efd839f7a6eb9312e011822450ded36a856126.pdf"}, "_bibtex": {"value": "@inproceedings{\ntogashi2024safe,\ntitle={Safe Collaborative Filtering},\nauthor={Riku Togashi and Tatsushi Oka and Naoto Ohsaka and Tetsuro Morimura},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yarUvgEXq3}\n}"}, "paperhash": {"value": "togashi|safe_collaborative_filtering"}}, "number": 8970, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8970/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8970/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695532021291, "cdate": 1695532021291, "tmdate": 1710583941307, "mdate": 1710583941307, "pdate": 1705411054875, "version": 2}, {"id": "3K3s9qxSn7", "forum": "3K3s9qxSn7", "signatures": ["ICLR.cc/2024/Conference/Submission8968/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8968/Authors"], "content": {"title": {"value": "On Representation Complexity of Model-based and Model-free Reinforcement Learning"}, "authors": {"value": ["Hanlin Zhu", "Baihe Huang", "Stuart Russell"]}, "authorids": {"value": ["~Hanlin_Zhu2", "~Baihe_Huang1", "~Stuart_Russell1"]}, "keywords": {"value": ["model-based and model-free RL", "representation complexity", "circuit complexity", "approximation error"]}, "TLDR": {"value": "We study representation complexity of model-based and model-free RL through circuit complexity to provide unique insights into sample efficiency of model-based RL."}, "abstract": {"value": "We study the representation complexity of model-based and model-free reinforcement learning (RL) in the context of circuit complexity. We prove theoretically that there exists a broad class of MDPs such that their underlying transition and reward functions can be represented by constant depth circuits with polynomial size, while the optimal $Q$-function suffers an exponential circuit complexity in constant-depth circuits. By drawing attention to the approximation errors and building connections to complexity theory, our theory provides unique insights into why model-based algorithms usually enjoy better sample complexity than model-free algorithms from a novel representation complexity perspective: in some cases, the ground-truth rule (model) of the environment is simple to represent, while other quantities, such as $Q$-function, appear complex. We empirically corroborate our theory by comparing the approximation error of the transition kernel, reward function, and optimal $Q$-function in various Mujoco environments, which demonstrates that the approximation errors of the transition kernel and reward function are consistently lower than those of the optimal $Q$-function. To the best of our knowledge, this work is the first to study the circuit complexity of RL, which also provides a rigorous framework for future research."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/94c3b9655119f9778dfab41fe3cb7661151ae6a3.pdf"}, "supplementary_material": {"value": "/attachment/636c407cfdbdbea5f6bf0356c85553601435ca7d.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhu2024on,\ntitle={On Representation Complexity of Model-based and Model-free Reinforcement Learning},\nauthor={Hanlin Zhu and Baihe Huang and Stuart Russell},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3K3s9qxSn7}\n}"}, "paperhash": {"value": "zhu|on_representation_complexity_of_modelbased_and_modelfree_reinforcement_learning"}}, "number": 8968, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8968/-/Revision", "ICLR.cc/2024/Conference/Submission8968/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8968/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695531846898, "cdate": 1695531846898, "tmdate": 1710126827147, "mdate": 1710126827147, "pdate": 1705411054818, "version": 2}, {"id": "sKPzAXoylB", "forum": "sKPzAXoylB", "signatures": ["ICLR.cc/2024/Conference/Submission8965/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8965/Authors"], "content": {"title": {"value": "Addressing Loss of Plasticity and Catastrophic Forgetting in Continual Learning"}, "authors": {"value": ["Mohamed Elsayed", "A. Rupam Mahmood"]}, "authorids": {"value": ["~Mohamed_Elsayed2", "~A._Rupam_Mahmood1"]}, "keywords": {"value": ["catastrophic forgetting", "loss of plasticity", "plasticity", "stability", "continual learning", "streaming learning", "online learning", "incremental learning"]}, "abstract": {"value": "Deep representation learning methods struggle with continual learning, suffering from both catastrophic forgetting of useful units and loss of plasticity, often due to rigid and unuseful units. While many methods address these two issues separately, only a few currently deal with both simultaneously. In this paper, we introduce Utility-based Perturbed Gradient Descent (UPGD) as a novel approach for the continual learning of representations. UPGD combines gradient updates with perturbations, where it applies smaller modifications to more useful units, protecting them from forgetting, and larger modifications to less useful units, rejuvenating their plasticity. We use a challenging streaming learning setup where continual learning problems have hundreds of non-stationarities and unknown task boundaries. We show that many existing methods suffer from at least one of the issues, predominantly manifested by their decreasing accuracy over tasks. On the other hand, UPGD continues to improve performance and surpasses or is competitive with all methods in all problems. Finally, in extended reinforcement learning experiments with PPO, we show that while Adam exhibits a performance drop after initial learning, UPGD avoids it by addressing both continual learning issues."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7eb81f1c1c4fea7fa434ebe26bbf3145d56b032f.pdf"}, "_bibtex": {"value": "@inproceedings{\nelsayed2024addressing,\ntitle={Addressing Catastrophic Forgetting and Loss of Plasticity in Neural Networks},\nauthor={Mohamed Elsayed and A. Rupam Mahmood},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sKPzAXoylB}\n}"}, "paperhash": {"value": "elsayed|addressing_loss_of_plasticity_and_catastrophic_forgetting_in_continual_learning"}}, "number": 8965, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8965/-/Revision", "ICLR.cc/2024/Conference/Submission8965/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8965/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695531697040, "cdate": 1695531697040, "tmdate": 1711912812045, "mdate": 1711912812045, "pdate": 1705411054762, "version": 2}, {"id": "Ixi4j6LtdX", "forum": "Ixi4j6LtdX", "signatures": ["ICLR.cc/2024/Conference/Submission8958/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8958/Authors"], "content": {"title": {"value": "A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation"}, "authors": {"value": ["Ayan Sengupta", "Shantanu Dixit", "Md Shad Akhtar", "Tanmoy Chakraborty"]}, "authorids": {"value": ["~Ayan_Sengupta1", "shantanu20118@iiitd.ac.in", "~Md_Shad_Akhtar1", "~Tanmoy_Chakraborty2"]}, "keywords": {"value": ["Knowledge Distillation", "Meta-Knowledge Distillation", "Policy-driven Knowledge Distillation", "Large Language Models"]}, "abstract": {"value": "Knowledge distillation (KD) is a technique used to transfer knowledge from a larger ''teacher'' model into a smaller ''student'' model. Recent advancements in meta-learning-based knowledge distillation (MetaKD) emphasize that the fine-tuning of teacher models should be aware of the student's need to achieve better knowledge distillation. However, existing MetaKD methods often lack incentives for the teacher model to improve itself. In this study, we introduce MPDistil, a meta-policy distillation technique, that utilizes novel optimization strategies to foster both *collaboration* and *competition* during the fine-tuning of the teacher model in the meta-learning step. Additionally, we propose a curriculum learning framework for the student model in a competitive setup, in which the student model aims to outperform the teacher model by self-training on various tasks. Exhaustive experiments on SuperGLUE and GLUE benchmarks demonstrate the efficacy of MPDistil compared to $20$ conventional KD and advanced MetaKD baselines, showing significant performance enhancements in the student model -- e.g., a distilled 6-layer BERT model outperforms a 12-layer BERT model on five out of six SuperGLUE tasks. Furthermore, MPDistil, while applied to a large language teacher model (DeBERTa-v2-xxlarge), significantly narrows the performance gap of its smaller student counterpart (DeBERTa-12) by just $4.6$% on SuperGLUE. We further demonstrate how higher rewards and customized training curricula strengthen the student model and enhance generalizability."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/79548908914d91f19b250084cc53384846d7ddbb.pdf"}, "supplementary_material": {"value": "/attachment/89d35f257c8862d94521847e8bfb07e2c664f074.zip"}, "TLDR": {"value": "The paper introduces collaborative joint loss and curriculum learning for meta-teacher knowledge distillation"}, "_bibtex": {"value": "@inproceedings{\nsengupta2024a,\ntitle={A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation},\nauthor={Ayan Sengupta and Shantanu Dixit and Md Shad Akhtar and Tanmoy Chakraborty},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ixi4j6LtdX}\n}"}, "paperhash": {"value": "sengupta|a_good_learner_can_teach_better_teacherstudent_collaborative_knowledge_distillation"}}, "number": 8958, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8958/-/Revision", "ICLR.cc/2024/Conference/Submission8958/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8958/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695531428276, "cdate": 1695531428276, "tmdate": 1710341657084, "mdate": 1710341657084, "pdate": 1705411054518, "version": 2}, {"id": "k581sTMyPt", "forum": "k581sTMyPt", "signatures": ["ICLR.cc/2024/Conference/Submission8956/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8956/Authors"], "content": {"title": {"value": "Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making"}, "authors": {"value": ["Aliyah R. Hsu", "Yeshwanth Cherapanamjeri", "Briton Park", "Tristan Naumann", "Anobel Odisho", "Bin Yu"]}, "authorids": {"value": ["~Aliyah_R._Hsu1", "~Yeshwanth_Cherapanamjeri1", "~Briton_Park1", "~Tristan_Naumann1", "~Anobel_Odisho1", "~Bin_Yu5"]}, "keywords": {"value": ["fine-tuning", "transformer-based language models", "feature analysis", "interpretation", "clinical classification"]}, "abstract": {"value": "Pre-trained transformers are often fine-tuned to aid clinical decision-making using limited clinical notes. Model interpretability is crucial, especially in high-stakes domains like medicine, to establish trust and ensure safety, which requires human engagement. We introduce SUFO, a systematic framework that enhances interpretability of fine-tuned transformer feature spaces. SUFO utilizes a range of analytic and visualization techniques, including Supervised probing, Unsupervised similarity analysis, Feature dynamics, and Outlier analysis to address key questions about model trust and interpretability (e.g. model suitability for a task, feature space evolution during fine-tuning, and interpretation of fine-tuned features and failure modes). We conduct a case study investigating the impact of pre-training data where we focus on real-world pathology classification tasks, and validate our findings on MedNLI. We evaluate five 110M-sized pre-trained transformer models, categorized into general-domain (BERT, TNLR), mixed-domain (BioBERT, Clinical BioBERT), and domain-specific (PubMedBERT) groups. Our SUFO analyses reveal that: (1) while PubMedBERT, the domain-specific model, contains valuable information for fine-tuning, it can overfit to minority classes when class imbalances exist. In contrast, mixed-domain models exhibit greater resistance to overfitting, suggesting potential improvements in domain-specific model robustness; (2) in-domain pre-training accelerates feature disambiguation during fine-tuning; and (3) feature spaces undergo significant sparsification during this process, enabling clinicians to identify common outlier modes among fine-tuned models as demonstrated in this paper. These findings showcase the utility of SUFO in enhancing trust and safety when using transformers in medicine, and we believe SUFO can aid practitioners in evaluating fine-tuned language models (LMs) for other applications in medicine and in more critical domains."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4396dc3858433d144c7809bad60e3be5f5a5ebae.pdf"}, "supplementary_material": {"value": "/attachment/1e9924da9b21fd688057ec1c1fc8d155cdfa2e4f.pdf"}, "_bibtex": {"value": "@inproceedings{\nhsu2024diagnosing,\ntitle={Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making},\nauthor={Aliyah R. Hsu and Yeshwanth Cherapanamjeri and Briton Park and Tristan Naumann and Anobel Odisho and Bin Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=k581sTMyPt}\n}"}, "paperhash": {"value": "hsu|diagnosing_transformers_illuminating_feature_spaces_for_clinical_decisionmaking"}}, "number": 8956, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8956/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8956/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695531351560, "cdate": 1695531351560, "tmdate": 1709661552153, "mdate": 1709661552153, "pdate": 1705411054400, "version": 2}, {"id": "A0HKeKl4Nl", "forum": "A0HKeKl4Nl", "signatures": ["ICLR.cc/2024/Conference/Submission8951/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8951/Authors"], "content": {"title": {"value": "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks"}, "authors": {"value": ["Samyak Jain", "Robert Kirk", "Ekdeep Singh Lubana", "Robert P. Dick", "Hidenori Tanaka", "Tim Rockt\u00e4schel", "Edward Grefenstette", "David Krueger"]}, "authorids": {"value": ["~Samyak_Jain1", "~Robert_Kirk1", "~Ekdeep_Singh_Lubana1", "~Robert_P._Dick1", "~Hidenori_Tanaka1", "~Tim_Rockt\u00e4schel1", "~Edward_Grefenstette1", "~David_Krueger1"]}, "keywords": {"value": ["Fine-Tuning", "Interpretability", "Mechanisms"]}, "TLDR": {"value": "We demonstrate that fine-tuning models rarely alters their underlying capabilities."}, "abstract": {"value": "Fine-tuning large pre-trained models has become the de facto strategy for developing both task-specific and general-purpose machine learning systems, including developing models that are safe to deploy. Despite its clear importance, there has been minimal work that explains how fine-tuning alters the underlying capabilities learned by a model during pretraining: does fine-tuning yield entirely novel capabilities or does it just modulate existing ones? We address this question empirically in synthetic, controlled settings where we can use mechanistic interpretability tools (e.g., network pruning and probing) to understand how the model's underlying capabilities are changing. We perform an extensive analysis of the effects of fine-tuning in these settings, and show that: (i) fine-tuning rarely alters the underlying model capabilities; (ii) a minimal transformation, which we call a `wrapper', is typically learned on top of the underlying model capabilities, creating the illusion that they have been modified; and (iii) further fine-tuning on a task where such ``wrapped capabilities'' are relevant leads to sample-efficient revival of the capability, i.e., the model begins reusing these capabilities after only a few gradient steps. This indicates that practitioners can unintentionally remove a model's safety wrapper merely by fine-tuning it on a, e.g., superficially unrelated, downstream task. We additionally perform analysis on language models trained on the TinyStories dataset to support our claims in a more realistic setup."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b46dce52717c9ba5bb6dc047b34dd04064101c1d.pdf"}, "_bibtex": {"value": "@inproceedings{\njain2024what,\ntitle={What happens when you fine-tuning your model? Mechanistic analysis of procedurally generated tasks.},\nauthor={Samyak Jain and Robert Kirk and Ekdeep Singh Lubana and Robert P. Dick and Hidenori Tanaka and Tim Rockt{\\\"a}schel and Edward Grefenstette and David Krueger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=A0HKeKl4Nl}\n}"}, "paperhash": {"value": "jain|mechanistically_analyzing_the_effects_of_finetuning_on_procedurally_defined_tasks"}}, "number": 8951, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8951/-/Revision", "ICLR.cc/2024/Conference/Submission8951/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8951/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695531175182, "cdate": 1695531175182, "tmdate": 1712663378244, "mdate": 1712663378244, "pdate": 1705411054382, "version": 2}, {"id": "pPjZIOuQuF", "forum": "pPjZIOuQuF", "signatures": ["ICLR.cc/2024/Conference/Submission8936/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8936/Authors"], "content": {"title": {"value": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems"}, "authors": {"value": ["Tianyang Liu", "Canwen Xu", "Julian McAuley"]}, "authorids": {"value": ["~Tianyang_Liu2", "~Canwen_Xu1", "~Julian_McAuley1"]}, "keywords": {"value": ["large language model", "code completion", "benchmark"]}, "TLDR": {"value": "We introduce RepoBench, a comprehensive benchmark for evaluating repository-level code auto-completion systems"}, "abstract": {"value": "Large Language Models (LLMs) have greatly advanced code auto-completion systems, with a potential for substantial productivity enhancements for developers. However, current benchmarks mainly focus on single-file tasks, leaving an assessment gap for more complex, real-world, multi-file programming scenarios. To fill this gap, we introduce RepoBench, a new benchmark specifically designed for evaluating repository-level code auto-completion systems. RepoBench consists of three interconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P (Pipeline). Each task respectively measures the system's ability to retrieve the most relevant code snippets from other files as cross-file context, predict the next line of code with cross-file and in-file context, and handle complex tasks that require a combination of both retrieval and next-line prediction. RepoBench aims to facilitate a more complete comparison of performance and encouraging continuous improvement in auto-completion systems. RepoBench is actively maintained with the latest code, serving as a live benchmark publicly available at https://github.com/Leolty/repobench."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/904b94b516d638671ae5c0877f71de8c576853cb.pdf"}, "supplementary_material": {"value": "/attachment/0c04077347314304d2d79620f47e5fa662b2d861.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024repobench,\ntitle={RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems},\nauthor={Tianyang Liu and Canwen Xu and Julian McAuley},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pPjZIOuQuF}\n}"}, "paperhash": {"value": "liu|repobench_benchmarking_repositorylevel_code_autocompletion_systems"}}, "number": 8936, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8936/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8936/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695530275561, "cdate": 1695530275561, "tmdate": 1710317684224, "mdate": 1710317684224, "pdate": 1705411054163, "version": 2}, {"id": "mIEHIcHGOo", "forum": "mIEHIcHGOo", "signatures": ["ICLR.cc/2024/Conference/Submission8932/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8932/Authors"], "content": {"title": {"value": "Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective"}, "authors": {"value": ["Ming Zhong", "Chenxin An", "Weizhu Chen", "Jiawei Han", "Pengcheng He"]}, "authorids": {"value": ["~Ming_Zhong2", "~Chenxin_An1", "~Weizhu_Chen1", "~Jiawei_Han1", "~Pengcheng_He2"]}, "keywords": {"value": ["Parametric Knowledge Transfer", "Large Language Model"]}, "TLDR": {"value": "In this paper, we provide empirical evidence that parametric knowledge are transferable between large language models accross varying scales."}, "abstract": {"value": "Large Language Models (LLMs) inherently encode a wealth of knowledge within their parameters through pre-training on extensive corpora. While prior research has delved into operations on these parameters to manipulate the underlying implicit knowledge\u2014encompassing detection, editing, and merging\u2014there remains an ambiguous understanding regarding their transferability across models with varying scales. In this paper, we seek to empirically investigate knowledge transfer from larger to smaller models through a parametric perspective. To achieve this, we employ sensitivity-based techniques to extract and align knowledge-specific parameters between different LLMs. Moreover, the LoRA module is used as the intermediary mechanism for injecting the extracted knowledge into smaller models. Evaluations across four benchmarks validate the efficacy of our proposed method. Our findings highlight the critical factors contributing to the process of parametric knowledge transfer, underscoring the transferability of model parameters across LLMs of different scales."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4e51eb2022d258cd812ca62d5fa86a00a2da606f.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhong2024seeking,\ntitle={Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective},\nauthor={Ming Zhong and Chenxin An and Weizhu Chen and Jiawei Han and Pengcheng He},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mIEHIcHGOo}\n}"}, "paperhash": {"value": "zhong|seeking_neural_nuggets_knowledge_transfer_in_large_language_models_from_a_parametric_perspective"}}, "number": 8932, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8932/-/Revision", "ICLR.cc/2024/Conference/Submission8932/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695530065988, "cdate": 1695530065988, "tmdate": 1707625651086, "mdate": 1707625651086, "pdate": 1705411054108, "version": 2}, {"id": "RXFVcynVe1", "forum": "RXFVcynVe1", "signatures": ["ICLR.cc/2024/Conference/Submission8930/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8930/Authors"], "content": {"title": {"value": "Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"}, "authors": {"value": ["Xiaoxin He", "Xavier Bresson", "Thomas Laurent", "Adam Perold", "Yann LeCun", "Bryan Hooi"]}, "authorids": {"value": ["~Xiaoxin_He1", "~Xavier_Bresson6", "~Thomas_Laurent1", "~Adam_Perold1", "~Yann_LeCun1", "~Bryan_Hooi1"]}, "keywords": {"value": ["large language models (LLM)", "feature learning", "text attributed graphs (TAG)", "graph neural networks (GNN)"]}, "TLDR": {"value": "We propose the first framework that leverages LLMs to enhance representation learning on text-attributed graphs, achieving SOTA results on four benchmark datasets."}, "abstract": {"value": "Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Initial graph neural network (GNN) pipelines handled these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models (LMs), which typically demand intricate designs and substantial computational resources. With the advent of powerful large language models (LLMs) such as GPT or Llama2, which demonstrate an ability to reason and to utilize general knowledge, there is a growing need for techniques which combine the textual modelling abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN performance on downstream tasks. A key innovation is our use of \\emph{explanations as features}: we prompt an LLM to perform zero-shot classification, request textual explanations for its decision-making process, and design an \\emph{LLM-to-LM interpreter} to translate these explanations into informative features for downstream GNNs. Our experiments demonstrate that our method achieves state-of-the-art results on well-established TAG datasets, including \\texttt{Cora}, \\texttt{PubMed}, \\texttt{ogbn-arxiv}, as well as our newly introduced dataset, \\texttt{tape-arxiv23}. Furthermore, our method significantly speeds up training, achieving a 2.88 times improvement over the closest baseline on \\texttt{ogbn-arxiv}. Lastly, we believe the versatility of the proposed method extends beyond TAGs and holds the potential to enhance other tasks involving graph-text data~\\footnote{Our codes and datasets are available at: \\url{https://github.com/XiaoxinHe/TAPE}}."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0db04867c257dc081f5a8f03268da344deb07417.pdf"}, "_bibtex": {"value": "@inproceedings{\nhe2024harnessing,\ntitle={Harnessing Explanations: {LLM}-to-{LM} Interpreter for Enhanced Text-Attributed Graph Representation Learning},\nauthor={Xiaoxin He and Xavier Bresson and Thomas Laurent and Adam Perold and Yann LeCun and Bryan Hooi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RXFVcynVe1}\n}"}, "paperhash": {"value": "he|harnessing_explanations_llmtolm_interpreter_for_enhanced_textattributed_graph_representation_learning"}}, "number": 8930, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8930/-/Revision", "ICLR.cc/2024/Conference/Submission8930/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8930/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695530036004, "cdate": 1695530036004, "tmdate": 1709779237698, "mdate": 1709779237698, "pdate": 1705411054050, "version": 2}, {"id": "w4DW6qkRmt", "forum": "w4DW6qkRmt", "signatures": ["ICLR.cc/2024/Conference/Submission8921/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8921/Authors"], "content": {"title": {"value": "SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs"}, "authors": {"value": ["Jaehyung Kim", "Jaehyun Nam", "Sangwoo Mo", "Jongjin Park", "Sang-Woo Lee", "Minjoon Seo", "Jung-Woo Ha", "Jinwoo Shin"]}, "authorids": {"value": ["~Jaehyung_Kim1", "~Jaehyun_Nam2", "~Sangwoo_Mo1", "~Jongjin_Park1", "~Sang-Woo_Lee1", "~Minjoon_Seo1", "~Jung-Woo_Ha1", "~Jinwoo_Shin1"]}, "keywords": {"value": ["question answering", "large language model", "retrieval"]}, "abstract": {"value": "Large language models (LLMs) have made significant advancements in various natural language processing tasks, including question answering (QA) tasks. While incorporating new information with the retrieval of relevant passages is a promising way to improve QA with LLMs, the existing methods often require additional fine-tuning which becomes infeasible with recent LLMs. Augmenting retrieved passages via prompting has the potential to address this limitation, but this direction has been limitedly explored. To this end, we design a simple yet effective framework to enhance open-domain QA (ODQA) with LLMs, based on the summarized retrieval (SuRe). SuRe helps LLMs predict more accurate answers for a given question, which are well-supported by the summarized retrieval that could be viewed as an explicit rationale extracted from the retrieved passages. Specifically, SuRe first constructs summaries of the retrieved passages for each of the multiple answer candidates. Then, SuRe confirms the most plausible answer from the candidate set by evaluating the validity and ranking of the generated summaries. Experimental results on diverse ODQA benchmarks demonstrate the superiority of SuRe, with improvements of up to 4.6\\% in exact match (EM) and 4.0\\% in F1 score over standard prompting approaches. SuRe also can be integrated with a broad range of retrieval methods and LLMs. Finally, the generated summaries from SuRe show additional advantages to measure the importance of retrieved passages and serve as more preferred rationales by models and humans."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9192639fe8e3dbb64d5431c85984894b9e1b089d.pdf"}, "TLDR": {"value": "We propose a simple framework to improve ODQA accuracy of LLM, by generating conditional summarizations of retrieval and evaluating them with carefully desinged prompts."}, "_bibtex": {"value": "@inproceedings{\nkim2024sure,\ntitle={SuRe: Improving Open-domain Question Answering of {LLM}s via Summarized Retrieval},\nauthor={Jaehyung Kim and Jaehyun Nam and Sangwoo Mo and Jongjin Park and Sang-Woo Lee and Minjoon Seo and Jung-Woo Ha and Jinwoo Shin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w4DW6qkRmt}\n}"}, "paperhash": {"value": "kim|sure_summarizing_retrievals_using_answer_candidates_for_opendomain_qa_of_llms"}}, "number": 8921, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8921/-/Revision", "ICLR.cc/2024/Conference/Submission8921/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8921/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695529572514, "cdate": 1695529572514, "tmdate": 1710508704643, "mdate": 1710508704643, "pdate": 1705411053855, "version": 2}, {"id": "xw5nxFWMlo", "forum": "xw5nxFWMlo", "signatures": ["ICLR.cc/2024/Conference/Submission8917/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8917/Authors"], "content": {"title": {"value": "Retrieval meets Long Context Large Language Models"}, "authors": {"value": ["Peng Xu", "Wei Ping", "Xianchao Wu", "Lawrence McAfee", "Chen Zhu", "Zihan Liu", "Sandeep Subramanian", "Evelina Bakhturina", "Mohammad Shoeybi", "Bryan Catanzaro"]}, "authorids": {"value": ["~Peng_Xu7", "~Wei_Ping1", "~Xianchao_Wu1", "~Lawrence_McAfee1", "~Chen_Zhu2", "~Zihan_Liu2", "~Sandeep_Subramanian1", "~Evelina_Bakhturina1", "~Mohammad_Shoeybi1", "~Bryan_Catanzaro1"]}, "keywords": {"value": ["Large Language Models", "Long Context Window", "Retrieval"]}, "abstract": {"value": "Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented Llama2-70B with 32K context window, outperforms GPT-3.5-turbo-16k and Davinci003 in terms of average score on nine long context tasks including question answering, query-based summarization, and in-context few-shot learning tasks. It also outperforms its non-retrieval Llama2-70B-32k baseline by a margin, while being much faster at generation. Our study provides general insights on the choice of retrieval-augmentation versus long context extension of LLM for practitioners."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4cd5150fe82d2f05e1ac91ccde87cca2e5f6d8e2.pdf"}, "supplementary_material": {"value": "/attachment/6b51f19be02b2b956eae4a50b0b71d03696242a4.pdf"}, "_bibtex": {"value": "@inproceedings{\nxu2024retrieval,\ntitle={Retrieval meets Long Context Large Language Models},\nauthor={Peng Xu and Wei Ping and Xianchao Wu and Lawrence McAfee and Chen Zhu and Zihan Liu and Sandeep Subramanian and Evelina Bakhturina and Mohammad Shoeybi and Bryan Catanzaro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xw5nxFWMlo}\n}"}, "paperhash": {"value": "xu|retrieval_meets_long_context_large_language_models"}}, "number": 8917, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8917/-/Revision", "ICLR.cc/2024/Conference/Submission8917/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8917/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695529436967, "cdate": 1695529436967, "tmdate": 1709661551840, "mdate": 1709661551840, "pdate": 1705411053720, "version": 2}, {"id": "2DbVeuoa6a", "forum": "2DbVeuoa6a", "signatures": ["ICLR.cc/2024/Conference/Submission8910/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8910/Authors"], "content": {"title": {"value": "Neural Spectral Methods: Self-supervised learning in the spectral domain"}, "authors": {"value": ["Yiheng Du", "Nithin Chalapathi", "Aditi S. Krishnapriyan"]}, "authorids": {"value": ["~Yiheng_Du1", "~Nithin_Chalapathi1", "~Aditi_S._Krishnapriyan1"]}, "keywords": {"value": ["Machine learning for PDEs", "spectral methods", "neural network differentiation", "spectral loss", "PDEs", "neural operators"]}, "TLDR": {"value": "We present Neural Spectral Methods to solve parametric PDEs in the spectral domain."}, "abstract": {"value": "We present Neural Spectral Methods, a technique to solve parametric Partial Differential Equations (PDEs), grounded in classical spectral methods. Our method uses orthogonal bases to learn PDE solutions as mappings between spectral coefficients, instantiating a spectral-based neural operator. In contrast to current machine learning approaches which enforce PDE constraints by minimizing the numerical quadrature of the residuals in the spatiotemporal domain, we leverage Parseval's identity and introduce a new training strategy through a spectral loss. Our spectral loss enables more efficient differentiation through the neural network, and substantially reduces training complexity. At inference time, the computational cost of our method remains constant, regardless of the spatiotemporal resolution of the domain.  Our experimental results demonstrate that our method significantly outperforms previous machine learning approaches in terms of speed and accuracy by one to two orders of magnitude on multiple different problems, including reaction-diffusion, and forced and unforced Navier-Stokes equations. When compared to numerical solvers of the same accuracy, our method demonstrates a $10\\times$ increase in performance speed. Our source code is publicly available at https://github.com/ASK-Berkeley/Neural-Spectral-Methods."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9aa74e5bf7d501d1a636aee71ec751a621b15eee.pdf"}, "_bibtex": {"value": "@inproceedings{\ndu2024neural,\ntitle={Neural Spectral Methods},\nauthor={Yiheng Du and Nithin Chalapathi and Aditi S. Krishnapriyan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2DbVeuoa6a}\n}"}, "paperhash": {"value": "du|neural_spectral_methods_selfsupervised_learning_in_the_spectral_domain"}}, "number": 8910, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8910/-/Revision", "ICLR.cc/2024/Conference/Submission8910/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8910/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695529220502, "cdate": 1695529220502, "tmdate": 1710255580189, "mdate": 1710255580189, "pdate": 1705411053465, "version": 2}, {"id": "he6mX9LTyE", "forum": "he6mX9LTyE", "signatures": ["ICLR.cc/2024/Conference/Submission8897/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8897/Authors"], "content": {"title": {"value": "Kosmos-G: Generating Images in Context with Multimodal Large Language Models"}, "authors": {"value": ["Xichen Pan", "Li Dong", "Shaohan Huang", "Zhiliang Peng", "Wenhu Chen", "Furu Wei"]}, "authorids": {"value": ["~Xichen_Pan1", "~Li_Dong1", "~Shaohan_Huang1", "~Zhiliang_Peng1", "~Wenhu_Chen3", "~Furu_Wei1"]}, "keywords": {"value": ["Diffusion Models", "Vision-Language", "Multimodal Large Language Model", "Image Generation", "Subject-Driven Generation"]}, "abstract": {"value": "Recent advancements in subject-driven image generation have made significant strides. However, current methods still fall short in diverse application scenarios, as they require test-time tuning and cannot accept interleaved multi-image and text input. These limitations keep them far from the ultimate goal of \"image as a foreign language in image generation.\" This paper presents Kosmos-G, a model that leverages the advanced multimodal perception capabilities of Multimodal Large Language Models (MLLMs) to tackle the aforementioned challenge. Our approach aligns the output space of MLLM with CLIP using the textual modality as an anchor and performs compositional instruction tuning on curated data. Kosmos-G demonstrates an impressive capability of zero-shot subject-driven generation with interleaved multi-image and text input. Notably, the score distillation instruction tuning requires no modifications to the image decoder. This allows for a seamless substitution of CLIP and effortless integration with a myriad of U-Net techniques ranging from fine-grained controls to personalized image decoder variants. We posit Kosmos-G as an initial attempt towards the goal of \"image as a foreign language in image generation.\""}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8ffe0cc3c3fb4e1f945894b836d9a97b0dbaf9b5.pdf"}, "TLDR": {"value": "Kosmos-G leverages Multimodal Large Language Models for subject-driven image generation"}, "_bibtex": {"value": "@inproceedings{\npan2024generating,\ntitle={Generating Images in Context with Multimodal Large Language Models},\nauthor={Xichen Pan and Li Dong and Shaohan Huang and Zhiliang Peng and Wenhu Chen and Furu Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=he6mX9LTyE}\n}"}, "paperhash": {"value": "pan|kosmosg_generating_images_in_context_with_multimodal_large_language_models"}}, "number": 8897, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8897/-/Revision", "ICLR.cc/2024/Conference/Submission8897/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8897/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695528799406, "cdate": 1695528799406, "tmdate": 1710476093783, "mdate": 1710476093783, "pdate": 1705411053284, "version": 2}, {"id": "lAhQCHuANV", "forum": "lAhQCHuANV", "signatures": ["ICLR.cc/2024/Conference/Submission8889/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8889/Authors"], "content": {"title": {"value": "Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition"}, "authors": {"value": ["Jean-R\u00e9my Conti", "Stephan Cl\u00e9men\u00e7on"]}, "authorids": {"value": ["~Jean-R\u00e9my_Conti1", "~Stephan_Cl\u00e9men\u00e7on1"]}, "keywords": {"value": ["Uncertainty", "Face", "Recognition", "Performance", "ROC", "Fairness", "Bootstrap"]}, "TLDR": {"value": "This paper provides a valid bootstrap method for quantifying the uncertainty of ROC-based metrics of a similarity scoring function, such as performance and fairness metrics in Face Recognition."}, "abstract": {"value": "The ROC curve is the major tool for assessing not only the performance but also the fairness properties of a similarity scoring function. In order to draw reliable conclusions based on empirical ROC analysis, accurately evaluating the uncertainty level related to statistical versions of the ROC curves of interest is absolutely necessary, especially for applications with considerable societal impact such as Face Recognition.  In this article, we prove asymptotic guarantees for empirical ROC curves of similarity functions as well as for by-product metrics useful to assess fairness. We also explain that, because the false acceptance/rejection rates are of the form of U-statistics in the case of similarity scoring, the naive bootstrap approach may jeopardize the assessment procedure. A dedicated recentering technique must be used instead. Beyond the theoretical analysis carried out, various experiments using real face image datasets provide strong empirical evidence of the practical relevance of the methods promoted here, when applied to several ROC-based measures such as popular fairness metrics."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2aa88e74521ae92488dd1b2c23c8c9f5996dc778.pdf"}, "supplementary_material": {"value": "/attachment/239227429c3d2becfcf601e294b5477f223faddc.pdf"}, "_bibtex": {"value": "@inproceedings{\nconti2024assessing,\ntitle={Assessing Uncertainty in Similarity Scoring: Performance \\& Fairness in Face Recognition},\nauthor={Jean-R{\\'e}my Conti and Stephan Cl{\\'e}men{\\c{c}}on},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lAhQCHuANV}\n}"}, "paperhash": {"value": "conti|assessing_uncertainty_in_similarity_scoring_performance_fairness_in_face_recognition"}}, "number": 8889, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8889/-/Revision", "ICLR.cc/2024/Conference/Submission8889/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8889/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695528406695, "cdate": 1695528406695, "tmdate": 1709661551733, "mdate": 1709661551733, "pdate": 1705411052948, "version": 2}, {"id": "jH67LHVOIO", "forum": "jH67LHVOIO", "signatures": ["ICLR.cc/2024/Conference/Submission8885/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8885/Authors"], "content": {"title": {"value": "LitCab: Lightweight Language Model Calibration over Short- and Long-form Responses"}, "authors": {"value": ["Xin Liu", "Muhammad Khalifa", "Lu Wang"]}, "authorids": {"value": ["~Xin_Liu18", "~Muhammad_Khalifa2", "~Lu_Wang9"]}, "keywords": {"value": ["calibration", "hallucination", "large language model"]}, "abstract": {"value": "A model is considered well-calibrated when its probability estimate aligns with the actual likelihood of the output being correct. Calibrating language models (LMs) is crucial, as it plays a vital role in detecting and mitigating hallucinations of LMs as well as building more trustworthy models. However, standard calibration techniques may not be suited for LM calibration. For instance, post-processing methods such as temperature scaling do not reorder the candidate generations. On the other hand, training-based methods require fine-tuning the entire model, which is impractical for LMs of large scale. We present LitCab, a lightweight calibration mechanism consisting of a single linear layer that takes the input text representation and predicts a bias term, which is then added to the LM output logits. LitCab improves model calibration by only adding < 2% of the original model parameters. For evaluation, we construct CaT, a benchmark consisting of eight text generation tasks, covering responses ranging from short phrases to paragraphs. We test LitCab with Llama2-7B, where it improves calibration across all tasks, reducing the average ECE score by as large as 30%. We further conduct a comprehensive evaluation with multiple popular open-sourced LMs from GPT and LLaMA families, yielding the following key findings: (i) Larger models within the same family exhibit better calibration on tasks with short generation tasks, but not necessarily for longer ones. (ii) GPT-family models show superior calibration compared to LLaMA, Llama2, and Vicuna models, despite having much fewer parameters. (iii) Fine-tuning pretrained model (e.g., LLaMA) with samples of limited purpose (e.g., conversations) may lead to worse calibration, highlighting the importance of fine-tuning setups for calibrating LMs."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/060aede7175d70a3fe37974ccb7cb976fcfa6486.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024lightweight,\ntitle={Lightweight Language Model Calibration for Open-ended Question Answering with Varied Answer Lengths},\nauthor={Xin Liu and Muhammad Khalifa and Lu Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jH67LHVOIO}\n}"}, "paperhash": {"value": "liu|litcab_lightweight_language_model_calibration_over_short_and_longform_responses"}}, "number": 8885, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8885/-/Revision", "ICLR.cc/2024/Conference/Submission8885/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8885/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695528117888, "cdate": 1695528117888, "tmdate": 1710306851025, "mdate": 1710306851025, "pdate": 1705411052926, "version": 2}, {"id": "cPgh4gWZlz", "forum": "cPgh4gWZlz", "signatures": ["ICLR.cc/2024/Conference/Submission8874/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8874/Authors"], "content": {"title": {"value": "Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"}, "authors": {"value": ["Xingxuan Li", "Ruochen Zhao", "Yew Ken Chia", "Bosheng Ding", "Shafiq Joty", "Soujanya Poria", "Lidong Bing"]}, "authorids": {"value": ["~Xingxuan_Li1", "~Ruochen_Zhao1", "~Yew_Ken_Chia1", "~Bosheng_Ding1", "~Shafiq_Joty1", "~Soujanya_Poria1", "~Lidong_Bing2"]}, "keywords": {"value": ["large language model", "knowledge grounding"]}, "TLDR": {"value": "We present chain-of-knowledge, a novel framework that augments large language models dynamically by incorporating grounding information from heterogeneous sources."}, "abstract": {"value": "We present chain-of-knowledge (CoK), a novel framework that augments large language models (LLMs) by dynamically incorporating grounding information from heterogeneous sources. It results in more factual rationales and reduced hallucination in generation. \nSpecifically, CoK consists of three stages: reasoning preparation, dynamic knowledge adapting, and answer consolidation. \nGiven a knowledge-intensive question, CoK first prepares several preliminary rationales and answers while identifying the relevant knowledge domains.\nIf there is no majority consensus among the answers from samples, CoK corrects the rationales step by step by adapting knowledge from the identified domains.\nThese corrected rationales can plausibly serve as a better foundation for the final answer consolidation.\nUnlike prior studies that primarily use unstructured data, CoK also leverages structured knowledge sources such as Wikidata and tables that provide more reliable factual information.\nTo access both unstructured and structured knowledge sources in the dynamic knowledge adapting stage, we propose an adaptive query generator that allows the generation of queries for various types of query languages, including SPARQL, SQL, and natural sentences. Moreover, to minimize error propagation between rationales, CoK corrects the rationales progressively using preceding corrected rationales to generate and correct subsequent rationales.\nExtensive experiments show that CoK consistently improves the performance of LLMs on knowledge-intensive tasks across different domains."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/99bf7907ce66cffb067fbb21e933967471cbfdb7.pdf"}, "supplementary_material": {"value": "/attachment/b2a4e035eb65c0eb2a9d0a598dfc2637c02d190f.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024chainofknowledge,\ntitle={Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources},\nauthor={Xingxuan Li and Ruochen Zhao and Yew Ken Chia and Bosheng Ding and Shafiq Joty and Soujanya Poria and Lidong Bing},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cPgh4gWZlz}\n}"}, "paperhash": {"value": "li|chainofknowledge_grounding_large_language_models_via_dynamic_knowledge_adapting_over_heterogeneous_sources"}}, "number": 8874, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8874/-/Revision", "ICLR.cc/2024/Conference/Submission8874/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8874/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695527756488, "cdate": 1695527756488, "tmdate": 1709661551571, "mdate": 1709661551571, "pdate": 1705411052622, "version": 2}, {"id": "m3xVPaZp6Z", "forum": "m3xVPaZp6Z", "signatures": ["ICLR.cc/2024/Conference/Submission8871/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8871/Authors"], "content": {"title": {"value": "Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning"}, "authors": {"value": ["Chengxing Jia", "Chenxiao Gao", "Hao Yin", "Fuxiang Zhang", "Xiong-Hui Chen", "Tian Xu", "Lei Yuan", "Zongzhang Zhang", "Zhi-Hua Zhou", "Yang Yu"]}, "authorids": {"value": ["~Chengxing_Jia1", "~Chenxiao_Gao1", "~Hao_Yin3", "~Fuxiang_Zhang1", "~Xiong-Hui_Chen1", "~Tian_Xu2", "~Lei_Yuan2", "~Zongzhang_Zhang1", "~Zhi-Hua_Zhou2", "~Yang_Yu5"]}, "keywords": {"value": ["Reinforcement Learning", "Model-based Reinforcement Learning", "Offline Reinforcement Learning"]}, "TLDR": {"value": "We introduce the idea of rehearsal into reinforcement learning in scenarios where both online and offline experiences are expensive and limited."}, "abstract": {"value": "Human beings can make adaptive decisions in a preparatory manner, i.e., by making preparations in advance, which offers significant advantages in scenarios where both online and offline experiences are expensive and limited. Meanwhile, current reinforcement learning methods commonly rely on numerous environment interactions but hardly obtain generalizable policies. In this paper, we introduce the idea of \\textit{rehearsal} into policy optimization, where the agent plans for all possible outcomes in mind and acts adaptively according to actual responses from the environment. To effectively rehearse, we propose ReDM, an algorithm that generates a diverse and eligible set of dynamics models and then rehearse the policy via adaptive training on the generated model set. Rehearsal enables the policy to make decision plans for various hypothetical dynamics and to naturally generalize to previously unseen environments. Our experimental results demonstrate that ReDM is capable of learning a valid policy solely through rehearsal, even with \\emph{zero} interaction data. We further extend ReDM to scenarios where limited or mismatched interaction data is available, and our experimental results reveal that ReDM produces high-performing policies compared to other offline RL baselines."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b983c88da15dde7d91c48aee3b97aa22087d7cc0.pdf"}, "supplementary_material": {"value": "/attachment/60060d3cb210a5ee5a27e73d89d9c10b6fdf84b3.zip"}, "_bibtex": {"value": "@inproceedings{\njia2024policy,\ntitle={Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning},\nauthor={Chengxing Jia and Chenxiao Gao and Hao Yin and Fuxiang Zhang and Xiong-Hui Chen and Tian Xu and Lei Yuan and Zongzhang Zhang and Yang Yu and Zhi-Hua Zhou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=m3xVPaZp6Z}\n}"}, "paperhash": {"value": "jia|policy_rehearsing_training_generalizable_policies_for_reinforcement_learning"}}, "number": 8871, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8871/-/Revision", "ICLR.cc/2024/Conference/Submission8871/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8871/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695527592497, "cdate": 1695527592497, "tmdate": 1710585523493, "mdate": 1710585523493, "pdate": 1705411052517, "version": 2}, {"id": "CHGcP6lVWd", "forum": "CHGcP6lVWd", "signatures": ["ICLR.cc/2024/Conference/Submission8869/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8869/Authors"], "content": {"title": {"value": "Energy-based Automated Model Evaluation"}, "authors": {"value": ["Ru Peng", "Heming Zou", "Haobo Wang", "Yawen Zeng", "Zenan Huang", "Junbo Zhao"]}, "authorids": {"value": ["~Ru_Peng1", "~Heming_Zou1", "~Haobo_Wang1", "~Yawen_Zeng1", "~Zenan_Huang1", "~Junbo_Zhao1"]}, "keywords": {"value": ["Automated Model Evalutaion", "Energy", "Meta-distribution", "Distribution shift"]}, "TLDR": {"value": "We introduce a simple yet effective method (Meta-Distribution Energy) in predicting a model's generalization to previously unseen, unlabeled datasets with theoretical guarantees and achieves state-of-the-art performance."}, "abstract": {"value": "The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real-world applications.\nThe Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels.\nDespite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost.\nIn that regard, we propose a novel measure --- Meta-Distribution Energy (MDE) that allows the AutoEval framework to be both more efficient and effective.\nThe core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning.\nWe further provide our theoretical insights by connecting the MDE with the classification loss.\nWe provide extensive experiments across modalities, datasets and different architectural backbones to validate MDE's validity, together with its superiority compared with prior approaches.\nWe also prove MDE's versatility by showing its seamless integration with large-scale models, and easy adaption to learning scenarios with noisy- or imbalanced- labels."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b67cd952981636bb89569bc035666d70b30d02bc.pdf"}, "supplementary_material": {"value": "/attachment/7d161eccc0fece1a1390613109e1d1f41a4003b5.zip"}, "_bibtex": {"value": "@inproceedings{\npeng2024energybased,\ntitle={Energy-based Automated Model Evaluation},\nauthor={Ru Peng and Heming Zou and Haobo Wang and Yawen Zeng and Zenan Huang and Junbo Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CHGcP6lVWd}\n}"}, "paperhash": {"value": "peng|energybased_automated_model_evaluation"}}, "number": 8869, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8869/-/Revision", "ICLR.cc/2024/Conference/Submission8869/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8869/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695527435613, "cdate": 1695527435613, "tmdate": 1710484901140, "mdate": 1710484901140, "pdate": 1705411052380, "version": 2}, {"id": "iS5ADHNg2A", "forum": "iS5ADHNg2A", "signatures": ["ICLR.cc/2024/Conference/Submission8867/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8867/Authors"], "content": {"title": {"value": "Deceptive Fairness Attacks on Graphs via Meta Learning"}, "authors": {"value": ["Jian Kang", "Yinglong Xia", "Ross Maciejewski", "Jiebo Luo", "Hanghang Tong"]}, "authorids": {"value": ["~Jian_Kang1", "~Yinglong_Xia1", "~Ross_Maciejewski1", "~Jiebo_Luo1", "~Hanghang_Tong3"]}, "keywords": {"value": ["graph learning", "fairness", "adversarial attacks"]}, "TLDR": {"value": "We develop a meta learning-based poisoning attack strategy to exacerbate unfairness of graph learning models, while preserving the utility in downstream tasks."}, "abstract": {"value": "We study deceptive fairness attacks on graphs to answer the following question: How can we achieve poisoning attacks on a graph learning model to exacerbate the bias deceptively? We answer this question via a bi-level optimization problem and propose a meta learning-based framework named FATE. FATE is broadly applicable with respect to various fairness definitions and graph learning models, as well as arbitrary choices of manipulation operations. We further instantiate FATE to attack statistical parity or individual fairness on graph neural networks. We conduct extensive experimental evaluations on real-world datasets in the task of semi-supervised node classification. The experimental results demonstrate that FATE could amplify the bias of graph neural networks with or without fairness consideration while maintaining the utility on the downstream task. We hope this paper provides insights into the adversarial robustness of fair graph learning and can shed light on designing robust and fair graph learning in future studies."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ec8c9c4fa87c072aa9815fe7601e5b37a8b938b2.pdf"}, "_bibtex": {"value": "@inproceedings{\nkang2024deceptive,\ntitle={Deceptive Fairness Attacks on Graphs via Meta Learning},\nauthor={Jian Kang and Yinglong Xia and Ross Maciejewski and Jiebo Luo and Hanghang Tong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iS5ADHNg2A}\n}"}, "supplementary_material": {"value": "/attachment/d9919c5a8f3e8af21303186e780c0261eeaa9a08.pdf"}, "paperhash": {"value": "kang|deceptive_fairness_attacks_on_graphs_via_meta_learning"}}, "number": 8867, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8867/-/Revision", "ICLR.cc/2024/Conference/Submission8867/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8867/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695527305669, "cdate": 1695527305669, "tmdate": 1710391204682, "mdate": 1710391204682, "pdate": 1706844956098, "version": 2}, {"id": "CTlUHIKF71", "forum": "CTlUHIKF71", "signatures": ["ICLR.cc/2024/Conference/Submission8866/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8866/Authors"], "content": {"title": {"value": "What Matters to You? Towards Visual Representation Alignment for Robot Learning"}, "authors": {"value": ["Thomas Tian", "Chenfeng Xu", "Masayoshi Tomizuka", "Jitendra Malik", "Andrea Bajcsy"]}, "authorids": {"value": ["~Thomas_Tian1", "~Chenfeng_Xu1", "~Masayoshi_Tomizuka2", "~Jitendra_Malik2", "~Andrea_Bajcsy1"]}, "keywords": {"value": ["Robot learning", "Preference learning", "Visual reward learning", "Representation alignment"]}, "abstract": {"value": "When operating in service of people, robots need to optimize rewards aligned with end-user preferences. Since robots will rely on raw perceptual inputs, their rewards will inevitably use visual representations. Recently there has been excitement in using representations from pre-trained visual models, but key to making these work in robotics is fine-tuning, which is typically done via proxy tasks like dynamics prediction or enforcing temporal cycle-consistency. However, all these proxy tasks bypass the human\u2019s input on what matters to them, exacerbating spurious correlations and ultimately leading to behaviors that are misaligned with user preferences. In this work, we propose that robots should leverage human feedback to align their visual representations with the end-user and disentangle what matters for the task. We propose Representation-Aligned Preference-based Learning (RAPL), a method for solving the visual representation alignment problem and visual reward learning problem through the lens of preference-based learning and optimal transport. Across experiments in X MAGICAL and in robotic manipulation, we find that RAPL\u2019s reward consistently generates preferred robot behaviors with high sample efficiency, and shows strong zero-shot generalization when the visual representation is learned from a different embodiment than the robot\u2019s."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b089a2d0ee33f551f8ee252854a9a7630830fe59.pdf"}, "supplementary_material": {"value": "/attachment/77faf5f630a4bdb20c92744b30a196eb0f268ffd.zip"}, "_bibtex": {"value": "@inproceedings{\ntian2024what,\ntitle={What Matters to You? Towards Visual Representation Alignment for Robot Learning},\nauthor={Thomas Tian and Chenfeng Xu and Masayoshi Tomizuka and Jitendra Malik and Andrea Bajcsy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CTlUHIKF71}\n}"}, "paperhash": {"value": "tian|what_matters_to_you_towards_visual_representation_alignment_for_robot_learning"}}, "number": 8866, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8866/-/Revision", "ICLR.cc/2024/Conference/Submission8866/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8866/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695527267031, "cdate": 1695527267031, "tmdate": 1710493746959, "mdate": 1710493746959, "pdate": 1705411052278, "version": 2}, {"id": "kjn99xFUF3", "forum": "kjn99xFUF3", "signatures": ["ICLR.cc/2024/Conference/Submission8857/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8857/Authors"], "content": {"title": {"value": "FedDA: Faster Adaptive Gradient Methods for Federated Constrained Optimization"}, "authors": {"value": ["Junyi Li", "Feihu Huang", "Heng Huang"]}, "authorids": {"value": ["~Junyi_Li1", "~Feihu_Huang1", "~Heng_Huang1"]}, "keywords": {"value": ["Federated Learning", "Adaptive Gradient Methods"]}, "abstract": {"value": "Federated learning (FL) is an emerging learning paradigm where a set of distributed clients learns a task under the coordination of a server. The FedAvg algorithm is one of the most widely used methods in FL. In FedAvg, the learning rate is a constant rather than changing adaptively. Adaptive gradient methods have demonstrated superior performance over the constant learning rate schedules in non-distributed settings, and they have recently been adapted to FL. However, the majority of these methods are designed for unconstrained settings. Meanwhile, many crucial FL applications, like disease diagnosis and biomarker identification, often rely on constrained formulations such as Lasso and group Lasso. It remains an open question as to whether adaptive gradient methods can be effectively applied to FL problems with constrains. In this work, we introduce \\textbf{FedDA}, a novel adaptive gradient framework for FL. This framework utilizes a restarted dual averaging technique and is compatible with a range of gradient estimation methods and adaptive learning rate schedules.  Specifically, an instantiation of our framework FedDA-MVR achieves sample complexity $\\tilde{O}(K^{-1}\\epsilon^{-1.5})$ and communication complexity $\\tilde{O}(K^{-0.25}\\epsilon^{-1.25})$ for finding a stationary point $\\epsilon$ in the constrained setting with $K$ be the number of clients. We conduct experiments over both constrained and unconstrained tasks to confirm the effectiveness of our approach."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/db0f03c6b9016274933d2407dddcaef05789c2f2.pdf"}, "supplementary_material": {"value": "/attachment/884bf90414917ca43dba0f26309eb759b7e56d76.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024fedda,\ntitle={Fed{DA}: Faster Adaptive Gradient Methods for Federated Constrained Optimization},\nauthor={Junyi Li and Feihu Huang and Heng Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kjn99xFUF3}\n}"}, "paperhash": {"value": "li|fedda_faster_adaptive_gradient_methods_for_federated_constrained_optimization"}}, "number": 8857, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8857/-/Revision", "ICLR.cc/2024/Conference/Submission8857/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8857/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695526999386, "cdate": 1695526999386, "tmdate": 1710217397909, "mdate": 1710217397909, "pdate": 1705411051966, "version": 2}, {"id": "qT7DXUmX7j", "forum": "qT7DXUmX7j", "signatures": ["ICLR.cc/2024/Conference/Submission8845/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8845/Authors"], "content": {"title": {"value": "Extending Power of Nature from Binary to Real-Valued Graph Learning in Real World"}, "authors": {"value": ["Chunshu Wu", "Ruibing Song", "Chuan Liu", "Yunan Yang", "Ang Li", "Michael Huang", "Tong Geng"]}, "authorids": {"value": ["~Chunshu_Wu1", "rsong10@ur.rochester.edu", "cliu81@ur.rochester.edu", "yunan.yang@cornell.edu", "~Ang_Li11", "~Michael_Huang1", "~Tong_Geng1"]}, "keywords": {"value": ["graph learning", "nature-powered computing", "dynamic physical system"]}, "TLDR": {"value": "We upgrade a binary Ising Machine and its associated model to support real values in solving real-world problems, achieving orders of magnitude of speedup and energy efficiency in Graph Learning compared to baseline GNNs"}, "abstract": {"value": "Nature performs complex computations constantly at clearly lower cost and higher performance than digital computers. It is crucial to understand how to harness the unique computational power of nature in Machine Learning (ML). In the past decade, besides the development of Neural Networks (NNs), the community has also relentlessly explored nature-powered ML paradigms. Although most of them are still predominantly theoretical, a new practical paradigm enabled by the recent advent of CMOS-compatible room-temperature nature-based computers has emerged. By harnessing a dynamical system's intrinsic behavior of chasing the lowest energy state, this paradigm can solve some simple binary problems delivering considerable speedup and energy savings compared with NNs, while maintaining comparable accuracy. Regrettably, its values to the real world are highly constrained by its binary nature. A clear pathway to its extension to real-valued problems remains elusive. This paper aims to unleash this pathway by proposing a novel end-to-end Nature-Powered Graph Learning (NP-GL) framework. Specifically, through a three-dimensional co-design, NP-GL can leverage the spontaneous energy decrease in nature to efficiently solve real-valued graph learning problems. Experimental results across 4 real-world applications with 6 datasets demonstrate that NP-GL delivers, on average, $6.97\\times 10^3$ speedup and $10^5$ energy consumption reduction with comparable or even higher accuracy than Graph Neural Networks (GNNs)."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c3a5eccec09e9fea31f8e2a25c42986e31463191.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024npgl,\ntitle={{NP}-{GL}: Extending Power of Nature from Binary Problems to Real-World Graph Learning},\nauthor={Chunshu Wu and Ruibing Song and Chuan Liu and Yunan Yang and Ang Li and Michael Huang and Tong Geng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qT7DXUmX7j}\n}"}, "paperhash": {"value": "wu|extending_power_of_nature_from_binary_to_realvalued_graph_learning_in_real_world"}}, "number": 8845, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8845/-/Revision", "ICLR.cc/2024/Conference/Submission8845/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8845/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695526505810, "cdate": 1695526505810, "tmdate": 1712076211023, "mdate": 1712076211023, "pdate": 1705411051587, "version": 2}, {"id": "ElykcDu5YK", "forum": "ElykcDu5YK", "signatures": ["ICLR.cc/2024/Conference/Submission8829/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8829/Authors"], "content": {"title": {"value": "Meta-VBO: Utilizing Prior Tasks in Optimizing Risk Measures with Gaussian Processes"}, "authors": {"value": ["Quoc Phong Nguyen", "Bryan Kian Hsiang Low", "Patrick Jaillet"]}, "authorids": {"value": ["~Quoc_Phong_Nguyen2", "~Bryan_Kian_Hsiang_Low1", "~Patrick_Jaillet1"]}, "keywords": {"value": ["meta-learning", "Bayesian optimization", "risk measure", "value-at-risk", "conditional value-at-risk"]}, "abstract": {"value": "Research on optimizing the risk measure of a blackbox function using Gaussian processes, especially Bayesian optimization (BO) of risk measures, has become increasingly important due to the inevitable presence of uncontrollable variables in real-world applications. Nevertheless, existing works on BO of risk measures start the optimization from scratch for every new task without considering the results of prior tasks. In contrast, its vanilla BO counterpart has received a thorough investigation on utilizing prior tasks to speed up the current task through the body of works on meta-BO which, however, have not considered risk measures. To bridge this gap, this paper presents the first algorithm for meta-BO of risk measures (i.e., value-at-risk (VaR) and the conditional VaR), namely meta-VBO, by introducing a novel adjustment to the upper confidence bound acquisition function. Our proposed algorithm exhibits two desirable properties: (i) invariance to scaling and vertical shifting of the blackbox function and (ii) robustness to prior harmful tasks. We provide a theoretical performance guarantee for our algorithm and empirically demonstrate its performance using several synthetic function benchmarks and real-world objective functions."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/438a0598bfd4e1457d158d87209039d77cfd4c53.pdf"}, "supplementary_material": {"value": "/attachment/248599a968ef378272c140aa14e640c90dc01efa.pdf"}, "_bibtex": {"value": "@inproceedings{\nnguyen2024leveraging,\ntitle={Leveraging Previous Tasks in Optimizing Risk Measures with Gaussian Processes},\nauthor={Quoc Phong Nguyen and Bryan Kian Hsiang Low and Patrick Jaillet},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ElykcDu5YK}\n}"}, "paperhash": {"value": "nguyen|metavbo_utilizing_prior_tasks_in_optimizing_risk_measures_with_gaussian_processes"}}, "number": 8829, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8829/-/Revision", "ICLR.cc/2024/Conference/Submission8829/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8829/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525750696, "cdate": 1695525750696, "tmdate": 1711455099762, "mdate": 1711455099762, "pdate": 1705411051021, "version": 2}, {"id": "qxGXjWxabq", "forum": "qxGXjWxabq", "signatures": ["ICLR.cc/2024/Conference/Submission8826/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8826/Authors"], "content": {"title": {"value": "Data Debugging with Shapley Importance over Machine Learning Pipelines"}, "authors": {"value": ["Bojan Karla\u0161", "David Dao", "Matteo Interlandi", "Sebastian Schelter", "Wentao Wu", "Ce Zhang"]}, "authorids": {"value": ["~Bojan_Karla\u01611", "~David_Dao1", "~Matteo_Interlandi1", "~Sebastian_Schelter1", "~Wentao_Wu1", "~Ce_Zhang1"]}, "keywords": {"value": ["data debugging", "data valuation", "shapley value", "machine learning pipelines"]}, "TLDR": {"value": "Efficiently computing the Shapley value of training data examples over machine learning pipelines."}, "abstract": {"value": "When a machine learning (ML) model exhibits poor quality (e.g., poor accuracy or fairness), the problem can often be traced back to errors in the training data. Being able to discover the data examples that are the most likely culprits is a fundamental concern that has received a lot of attention recently. One prominent way to measure \"data importance\" with respect to model quality is the Shapley value. Unfortunately, existing methods only focus on the ML model in isolation, without considering the broader ML pipeline for data preparation and feature extraction, which appears in the majority of real-world ML code. This presents a major limitation to applying existing methods in practical settings. In this paper, we propose Datascope, a method for efficiently computing Shapley-based data importance over ML pipelines. We introduce several approximations that lead to dramatic improvements in terms of computational speed. Finally, our experimental evaluation demonstrates that our methods are capable of data error discovery that is as effective as existing Monte Carlo baselines, and in some cases even outperform them. We release our code as an open-source data debugging library available at https://github.com/easeml/datascope."}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4db53cc6069dd0fa85463531bc0168416e7590da.pdf"}, "_bibtex": {"value": "@inproceedings{\nkarla{\\v{s}}2024canonpipe,\ntitle={Canonpipe: Data Debugging with Shapley Importance over Machine Learning Pipelines},\nauthor={Bojan Karla{\\v{s}} and David Dao and Matteo Interlandi and Sebastian Schelter and Wentao Wu and Ce Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qxGXjWxabq}\n}"}, "paperhash": {"value": "karla|data_debugging_with_shapley_importance_over_machine_learning_pipelines"}}, "number": 8826, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8826/-/Revision", "ICLR.cc/2024/Conference/Submission8826/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8826/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525636026, "cdate": 1695525636026, "tmdate": 1710565081187, "mdate": 1710565081187, "pdate": 1705411050873, "version": 2}, {"id": "4kLVvIh8cp", "forum": "4kLVvIh8cp", "signatures": ["ICLR.cc/2024/Conference/Submission8813/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8813/Authors"], "content": {"title": {"value": "Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning"}, "authors": {"value": ["Qiwei Di", "Heyang Zhao", "Jiafan He", "Quanquan Gu"]}, "authorids": {"value": ["~Qiwei_Di1", "~Heyang_Zhao1", "~Jiafan_He1", "~Quanquan_Gu1"]}, "keywords": {"value": ["Offline reinforcement learning", "instance-dependent", "least-squares value iteration"]}, "TLDR": {"value": "In this paper, we present Pessimistic Nonlinear Least-Square Value Iteration (PNLSVI), an oracle-efficient algorithm for offline RL with non-linear function approximation."}, "abstract": {"value": "Offline reinforcement learning (RL), where the agent aims to learn the optimal policy based on the data collected by a behavior policy, has attracted increasing attention in recent years. While offline RL with linear function approximation has been extensively studied with optimal results achieved under certain assumptions, many works shift their interest to offline RL with non-linear function approximation.\nHowever, limited works on offline RL with non-linear function approximation have instance-dependent regret guarantees.\n    In this paper, we propose an oracle-efficient algorithm, dubbed Pessimistic Nonlinear Least-Square Value Iteration (PNLSVI), for offline RL with non-linear function approximation. Our algorithmic design comprises three innovative components: (1) a variance-based weighted regression scheme that can be applied to a wide range of function classes, (2) a subroutine for variance estimation, and (3) a planning phase that utilizes a pessimistic value iteration approach. Our algorithm enjoys a regret bound that has a tight dependency on the function class complexity and achieves minimax optimal instance-dependent regret when specialized to linear function approximation. Our work extends the previous instance-dependent results within simpler function classes, such as linear and differentiable function to a more general framework. To the best of our knowledge, this is the first statistically optimal algorithm for nonlinear offline RL."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/eccb6a13ad39f4a83f32bd2e74f2359e20086e81.pdf"}, "_bibtex": {"value": "@inproceedings{\ndi2024pessimistic,\ntitle={Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning},\nauthor={Qiwei Di and Heyang Zhao and Jiafan He and Quanquan Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4kLVvIh8cp}\n}"}, "paperhash": {"value": "di|pessimistic_nonlinear_leastsquares_value_iteration_for_offline_reinforcement_learning"}}, "number": 8813, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8813/-/Revision", "ICLR.cc/2024/Conference/Submission8813/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8813/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525286533, "cdate": 1695525286533, "tmdate": 1710562941386, "mdate": 1710562941386, "pdate": 1705411050741, "version": 2}, {"id": "Jf5gplvglq", "forum": "Jf5gplvglq", "signatures": ["ICLR.cc/2024/Conference/Submission8809/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8809/Authors"], "content": {"title": {"value": "SKILL-MIX: a Flexible and Expandable Family of Evaluations for AI Models"}, "authors": {"value": ["Dingli Yu", "Simran Kaur", "Arushi Gupta", "Jonah Brown-Cohen", "Anirudh Goyal", "Sanjeev Arora"]}, "authorids": {"value": ["~Dingli_Yu1", "~Simran_Kaur1", "~Arushi_Gupta1", "~Jonah_Brown-Cohen1", "~Anirudh_Goyal1", "~Sanjeev_Arora1"]}, "keywords": {"value": ["Large language model", "skill evaluation", "LLM benchmark", "emergence"]}, "abstract": {"value": "With LLMs shifting their role from statistical modeling of language to serving as general-purpose AI agents, how should LLM evaluations change? Arguably, a key ability of an AI agent is to flexibly combine, as needed, the basic skills it has learned. The capability to combine skills plays an important role in (human) pedagogy and also in a paper on emergence phenomena (Arora & Goyal, 2023).\n\nThis work introduces SKILL-MIX, a new evaluation to measure ability to combine skills. Using a list of $N$  skills the evaluator repeatedly picks random subsets of $k$ skills and asks the LLM to produce text combining that subset of skills. Since the number of subsets grows like $N^k$, for even modest $k$ this evaluation will, with high probability, require the LLM to produce text significantly different from any text in the training set. \nThe paper develops a methodology for (a) designing and administering such an evaluation, and (b) automatic grading (plus spot-checking by humans) of the results using GPT-4 as well as the open LLaMA-2 70B model. \n\nAdministering a version of SKILL-MIX to popular chatbots gave results that,  while generally in line with prior expectations, contained surprises. Sizeable differences exist among model capabilities that are not captured by their ranking on popular LLM leaderboards (\"cramming for the leaderboard\"). Furthermore, simple probability calculations indicate that GPT-4's reasonable performance on $k=5$ is suggestive of going beyond \"stochastic parrot\" behavior (Bender et al., 2021), i.e., it combines skills in ways that it had not seen during training.\n\nWe sketch how the methodology can lead to a SKILL-MIX based eco-system of open evaluations for AI capabilities of future models. We maintain a leaderboard of SKILL-MIX at [https://skill-mix.github.io](https://skill-mix.github.io)."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2f6d42f9e2ebcdc95ea494a075e5cd3fc7e5e119.pdf"}, "supplementary_material": {"value": "/attachment/fb987782e509bfc4845c7c8dbb9a173851e4a061.zip"}, "_bibtex": {"value": "@inproceedings{\nyu2024skillmix,\ntitle={Skill-Mix: a Flexible and Expandable Family of Evaluations for {AI} Models},\nauthor={Dingli Yu and Simran Kaur and Arushi Gupta and Jonah Brown-Cohen and Anirudh Goyal and Sanjeev Arora},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Jf5gplvglq}\n}"}, "paperhash": {"value": "yu|skillmix_a_flexible_and_expandable_family_of_evaluations_for_ai_models"}}, "number": 8809, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8809/-/Revision", "ICLR.cc/2024/Conference/Submission8809/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8809/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525228849, "cdate": 1695525228849, "tmdate": 1710534273987, "mdate": 1710534273987, "pdate": 1705411050632, "version": 2}, {"id": "yroyhkhWS6", "forum": "yroyhkhWS6", "signatures": ["ICLR.cc/2024/Conference/Submission8805/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8805/Authors"], "content": {"title": {"value": "A Quadratic Synchronization Rule for Distributed Deep Learning"}, "authors": {"value": ["Xinran Gu", "Kaifeng Lyu", "Sanjeev Arora", "Jingzhao Zhang", "Longbo Huang"]}, "authorids": {"value": ["~Xinran_Gu2", "~Kaifeng_Lyu2", "~Sanjeev_Arora1", "~Jingzhao_Zhang2", "~Longbo_Huang2"]}, "keywords": {"value": ["distributed training", "Local SGD", "local gradient methods", "generalization", "implicit bias", "sharpness"]}, "TLDR": {"value": "We propose Quadratic Synchronization Rule (QSR) to dynamically set the synchronization period in local gradient methods based on the learning rate, reducing wall-clock training time and improving test accuracy of ResNet and ViT on ImageNet."}, "abstract": {"value": "In distributed deep learning with data parallelism, synchronizing gradients at each training step can cause a huge communication overhead, especially when many nodes work together to train large models.\n  Local gradient methods, such as Local SGD, address this issue by allowing workers to compute locally for $H$ steps without synchronizing with others, hence reducing communication frequency.\n  While $H$ has been viewed as a hyperparameter to trade optimization efficiency for communication cost, recent research indicates that setting a proper  $H$ value can lead to generalization improvement. Yet, selecting a proper $H$ is elusive. This work proposes a theory-grounded method for determining $H$, named the Quadratic Synchronization Rule (QSR), which recommends dynamically setting $H$ in proportion to $\\frac{1}{\\eta^2}$ as the learning rate $\\eta$ decays over time.\n  Extensive ImageNet experiments on ResNet and ViT show that local gradient methods with QSR consistently improve the test accuracy over other synchronization strategies. Compared to the standard data parallel training, QSR enables Local AdamW to cut the training time on 16 or 64 GPUs down from 26.7 to 20.2 hours or from 8.6 to 5.5 hours and, at the same time, achieves 1.16% or 0.84% higher top-1 validation accuracy."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d7d0725ff6973ff72e22785c8490bab873333e1c.pdf"}, "_bibtex": {"value": "@inproceedings{\ngu2024a,\ntitle={A Quadratic Synchronization Rule for Distributed Deep Learning},\nauthor={Xinran Gu and Kaifeng Lyu and Sanjeev Arora and Jingzhao Zhang and Longbo Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yroyhkhWS6}\n}"}, "paperhash": {"value": "gu|a_quadratic_synchronization_rule_for_distributed_deep_learning"}}, "number": 8805, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8805/-/Revision", "ICLR.cc/2024/Conference/Submission8805/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8805/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525170850, "cdate": 1695525170850, "tmdate": 1710482917385, "mdate": 1710482917385, "pdate": 1705411050610, "version": 2}, {"id": "e2YOVTenU9", "forum": "e2YOVTenU9", "signatures": ["ICLR.cc/2024/Conference/Submission8804/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8804/Authors"], "content": {"title": {"value": "ArchLock: Locking DNN Transferability at the Architecture Level with a Zero-Cost Binary Predictor"}, "authors": {"value": ["Tong Zhou", "Shaolei Ren", "Xiaolin Xu"]}, "authorids": {"value": ["~Tong_Zhou3", "~Shaolei_Ren1", "~Xiaolin_Xu3"]}, "keywords": {"value": ["Defense; DNN Transferability; Neural Architecture Search"]}, "abstract": {"value": "Deep neural network (DNN) models, despite their impressive performance, are vulnerable to exploitation by attackers who attempt to transfer them to other tasks for their own benefit. Current defense strategies mainly address this vulnerability at the model parameter level, leaving the potential of architectural-level defense largely unexplored. This paper, for the first time, addresses the issue of model protection by reducing transferability at the architecture level. Specifically, we present a novel neural architecture search (NAS)-enabled algorithm that employs zero-cost proxies and evolutionary search, to explore model architectures with low transferability. Our method, namely ArchLock, aims to achieve high performance on the source task, while degrading the performance on potential target tasks, i.e., locking the transferability of a DNN model. To achieve efficient cross-task search without accurately knowing the training data owned by the attackers, we utilize zero-cost proxies to speed up architecture evaluation and simulate potential target task embeddings to assist cross-task search with a binary performance predictor. Extensive experiments on NAS-Bench-201 and TransNAS-Bench-101 demonstrate that ArchLock reduces transferability by up to 30% and 50%, respectively, with negligible performance degradation on source tasks (<2%). The code is available at https://github.com/Tongzhou0101/ArchLock."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f966042936a5ada1446d82fe31a36969f9d3e87a.pdf"}, "supplementary_material": {"value": "/attachment/6e6d3d437cdbf0e4a1d4012b98edbb26062b93fe.zip"}, "_bibtex": {"value": "@inproceedings{\nzhou2024archlock,\ntitle={ArchLock: Locking {DNN} Transferability at the Architecture Level with a Zero-Cost Binary Predictor},\nauthor={Tong Zhou and Shaolei Ren and Xiaolin Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=e2YOVTenU9}\n}"}, "paperhash": {"value": "zhou|archlock_locking_dnn_transferability_at_the_architecture_level_with_a_zerocost_binary_predictor"}}, "number": 8804, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8804/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8804/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695525154769, "cdate": 1695525154769, "tmdate": 1709661551116, "mdate": 1709661551116, "pdate": 1705411050570, "version": 2}, {"id": "ZDGKPbF0VQ", "forum": "ZDGKPbF0VQ", "signatures": ["ICLR.cc/2024/Conference/Submission8769/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8769/Authors"], "content": {"title": {"value": "Leftover-Lunch: Advantage-based Offline Reinforcement Learning for Language Models"}, "authors": {"value": ["Ashutosh Baheti", "Ximing Lu", "Faeze Brahman", "Ronan Le Bras", "Maarten Sap", "Mark Riedl"]}, "authorids": {"value": ["~Ashutosh_Baheti1", "~Ximing_Lu1", "~Faeze_Brahman1", "~Ronan_Le_Bras1", "~Maarten_Sap1", "~Mark_Riedl1"]}, "keywords": {"value": ["Reinforcement Learning", "Natural Language Generation", "Offline Policy Gradients"]}, "TLDR": {"value": "Advantage Leftover Lunch RL (A-LoL), a simple training algorithm that uses offline policy gradients for learning language generation tasks as a single action RL game."}, "abstract": {"value": "Reinforcement Learning with Human Feedback (RLHF) is the most prominent method for Language Model (LM) alignment. However, RLHF is an unstable and data-hungry process that continually requires new high-quality LM-generated data for finetuning. We introduce Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data. By assuming the entire LM output sequence as a single action, A-LoL allows incorporating sequence-level classifiers or human-designed scoring functions as\nrewards. Subsequently, by using LM\u2019s value estimate, A-LoL only trains on positive advantage (leftover) data points, making it resilient to noise. Overall, A-LoL is an easy-to-implement, sample-efficient, and stable LM training recipe.\n\nWe demonstrate the effectiveness of A-LoL and its variants with a set of four different language generation tasks. We compare against both online RL (PPO) and recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL baselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant (HHA), LMs trained with A-LoL methods achieve the highest diversity while also being rated more safe and helpful than the baselines according to humans. Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7ffde304b42276b91b5e97f80fd6dd024d35e9bd.pdf"}, "_bibtex": {"value": "@inproceedings{\nbaheti2024improving,\ntitle={Improving Language Models with Advantage-based Offline Policy Gradients},\nauthor={Ashutosh Baheti and Ximing Lu and Faeze Brahman and Ronan Le Bras and Maarten Sap and Mark Riedl},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZDGKPbF0VQ}\n}"}, "paperhash": {"value": "baheti|leftoverlunch_advantagebased_offline_reinforcement_learning_for_language_models"}}, "number": 8769, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8769/-/Revision", "ICLR.cc/2024/Conference/Submission8769/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8769/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523880919, "cdate": 1695523880919, "tmdate": 1710097953429, "mdate": 1710097953429, "pdate": 1705411049622, "version": 2}, {"id": "mlJLVigNHp", "forum": "mlJLVigNHp", "signatures": ["ICLR.cc/2024/Conference/Submission8767/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8767/Authors"], "content": {"title": {"value": "RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation"}, "authors": {"value": ["Fangyuan Xu", "Weijia Shi", "Eunsol Choi"]}, "authorids": {"value": ["~Fangyuan_Xu1", "~Weijia_Shi1", "~Eunsol_Choi1"]}, "keywords": {"value": ["retrieval augmented language model", "language modeling", "question answering", "summarization", "distillation"]}, "TLDR": {"value": "We train compressor models to shorten retrieved documents passed to language models."}, "abstract": {"value": "Retrieval-augmented language models improve language models (LMs) by retrieving documents and prepending them in-context.\nHowever, these documents, often spanning hundreds of words, make inference substantially less efficient. We propose compressing the retrieved documents into textual summaries prior to in-context integration. This not only reduces the computational costs but also relieve the burden of LMs to identify relevant information in long retrieved documents. We present two compressors -- an extractive compressor which selects useful sentences from retrieved documents  and an abstractive compressor which generates summary by synthesizing information from multiple documents. Both are trained to achieve performance gain in LMs when we prepend the generated summary from the compressor to LMs' input, while minimizing the summary length. When retrieved documents are irrelevant to the input or offer no additional information to LM, our compressors output an empty string, enabling selective augmentation. We evaluate our approach on the language modeling task and open domain question answering task. We achieve a compression rate of as low as 6% with minimal loss in performance for both tasks, significantly outperforming the off-the-shelf summarization models. We show that our compressors trained for one LM can transfer to other LMs on the language modeling task and provide a summary largely faithful to the retrieved documents."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/43938c98697c89512480fceb61ff554001727889.pdf"}, "_bibtex": {"value": "@inproceedings{\nxu2024recomp,\ntitle={{RECOMP}: Improving Retrieval-Augmented {LM}s with Context Compression and Selective Augmentation},\nauthor={Fangyuan Xu and Weijia Shi and Eunsol Choi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mlJLVigNHp}\n}"}, "paperhash": {"value": "xu|recomp_improving_retrievalaugmented_lms_with_context_compression_and_selective_augmentation"}}, "number": 8767, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8767/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8767/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523812255, "cdate": 1695523812255, "tmdate": 1710516408013, "mdate": 1710516408013, "pdate": 1705411049500, "version": 2}, {"id": "rkplYfqUr0", "forum": "rkplYfqUr0", "signatures": ["ICLR.cc/2024/Conference/Submission8763/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8763/Authors"], "content": {"title": {"value": "Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions"}, "authors": {"value": ["Sachin Kumar", "Chan Young Park", "Yulia Tsvetkov"]}, "authorids": {"value": ["~Sachin_Kumar1", "~Chan_Young_Park1", "~Yulia_Tsvetkov1"]}, "keywords": {"value": ["zero-shot classification", "prompting", "generative classification", "label descriptions"]}, "TLDR": {"value": "We present a zero-shot prompting framework that outperforms or closely matches in-context learning for a variety of text classification tasks."}, "abstract": {"value": "Language model (LM) prompting\u2014a popular paradigm for solving NLP tasks\u2014has been shown to be susceptible to miscalibration and brittleness to slight prompt variations, caused by its discriminative prompting approach, i.e., predicting the label given the input. To address these issues, we propose Gen-Z\u2014a generative prompting framework for zero-shot text classification. GEN-Z is generative, as it measures the LM likelihood of input text, conditioned on natural language descriptions of labels. The framework is multivariate, as label descriptions allow us to seamlessly integrate additional contextual information about the labels to improve task performance. On various standard classification benchmarks, with six open-source LM families, we show that zero-shot classification with simple contextualization of the data source of the evaluation set consistently outperforms both zero-shot and few-shot baselines while improving robustness to prompt variations. Further, our approach enables personalizing classification in a zero-shot manner by incorporating author, subject, or reader information in the label descriptions."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2e1ad3678931fd5cd531d53c3e1468838077a6de.pdf"}, "supplementary_material": {"value": "/attachment/3aa6d9adf1244d4e9b4c6e9b287bff738107aadb.zip"}, "_bibtex": {"value": "@inproceedings{\nkumar2024genz,\ntitle={Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions},\nauthor={Sachin Kumar and Chan Young Park and Yulia Tsvetkov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rkplYfqUr0}\n}"}, "paperhash": {"value": "kumar|genz_generative_zeroshot_text_classification_with_contextualized_label_descriptions"}}, "number": 8763, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8763/-/Revision", "ICLR.cc/2024/Conference/Submission8763/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523761562, "cdate": 1695523761562, "tmdate": 1707625649948, "mdate": 1707625649948, "pdate": 1705411049363, "version": 2}, {"id": "62K7mALO2q", "forum": "62K7mALO2q", "signatures": ["ICLR.cc/2024/Conference/Submission8758/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8758/Authors"], "content": {"title": {"value": "In-Context Learning Dynamics with Random Binary Sequences"}, "authors": {"value": ["Eric J Bigelow", "Ekdeep Singh Lubana", "Robert P. Dick", "Hidenori Tanaka", "Tomer Ullman"]}, "authorids": {"value": ["~Eric_J_Bigelow1", "~Ekdeep_Singh_Lubana1", "~Robert_P._Dick1", "~Hidenori_Tanaka1", "~Tomer_Ullman1"]}, "keywords": {"value": ["In-Context Learning", "Large Language Models", "Interpretability", "Computational Cognitive Science"]}, "abstract": {"value": "Large language models (LLMs) trained on huge text datasets demonstrate intriguing capabilities, achieving state-of-the-art performance on tasks they were not explicitly trained for. The precise nature of LLM capabilities is often mysterious, and different prompts can elicit different capabilities through in-context learning. We propose a framework that enables us to analyze in-context learning dynamics to understand latent concepts underlying LLMs\u2019 behavioral patterns. This provides a more nuanced understanding than success-or-failure evaluation benchmarks, but does not require observing internal activations as a mechanistic interpretation of circuits would. Inspired by the cognitive science of human randomness perception, we use random binary sequences as context and study dynamics of in-context learning by manipulating properties of context data, such as sequence length. In the latest GPT-3.5+ models, we find emergent abilities to generate seemingly random numbers and learn basic formal languages, with striking in-context learning dynamics where model outputs transition sharply from seemingly random behaviors to deterministic repetition."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b3b2da0b2a8f41b25ce90b041f1fad321dd98835.pdf"}, "_bibtex": {"value": "@inproceedings{\nbigelow2024incontext,\ntitle={In-Context Learning Dynamics with Random Binary Sequences},\nauthor={Eric J Bigelow and Ekdeep Singh Lubana and Robert P. Dick and Hidenori Tanaka and Tomer Ullman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=62K7mALO2q}\n}"}, "paperhash": {"value": "bigelow|incontext_learning_dynamics_with_random_binary_sequences"}}, "number": 8758, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8758/-/Revision", "ICLR.cc/2024/Conference/Submission8758/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8758/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523564712, "cdate": 1695523564712, "tmdate": 1712774529974, "mdate": 1712774529974, "pdate": 1705411049328, "version": 2}, {"id": "XsHqr9dEGH", "forum": "XsHqr9dEGH", "signatures": ["ICLR.cc/2024/Conference/Submission8756/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8756/Authors"], "content": {"title": {"value": "Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking"}, "authors": {"value": ["Kaifeng Lyu", "Jikai Jin", "Zhiyuan Li", "Simon Shaolei Du", "Jason D. Lee", "Wei Hu"]}, "authorids": {"value": ["~Kaifeng_Lyu2", "~Jikai_Jin1", "~Zhiyuan_Li2", "~Simon_Shaolei_Du1", "~Jason_D._Lee1", "~Wei_Hu1"]}, "keywords": {"value": ["grokking", "implicit bias", "margin", "kernel", "training dynamics", "generalization"]}, "TLDR": {"value": "Due to a dichotomy of early and late phase implicit biases, training homogeneous neural nets with large initialization and small weight decay provably induces grokking."}, "abstract": {"value": "Recent work by Power et al. (2022) highlighted a surprising \"grokking\" phenomenon in learning arithmetic tasks: a neural net first \"memorizes\" the training set, resulting in perfect training accuracy but near-random test accuracy, and after training for sufficiently longer, it suddenly transitions to perfect test accuracy. This paper studies the grokking phenomenon in theoretical setups and shows that it can be induced by a dichotomy of early and late phase implicit biases. Specifically, when training homogeneous neural nets with large initialization and small weight decay on both classification and regression tasks, we prove that the training process gets trapped at a solution corresponding to a kernel predictor for a long time, and then a very sharp transition to min-norm/max-margin predictors occurs, leading to a dramatic change in test accuracy. Even in the absence of weight decay, we show that grokking can still happen when the late phase implicit bias is driven by other regularization mechanisms, such as implicit margin maximization or sharpness reduction."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a44b7ffbd53a80fbd4d969f2e39aa59edf5c8012.pdf"}, "supplementary_material": {"value": "/attachment/81eef69dc6b3b9296ea1ddebec8950f6006ef5a7.zip"}, "_bibtex": {"value": "@inproceedings{\nlyu2024dichotomy,\ntitle={Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking},\nauthor={Kaifeng Lyu and Jikai Jin and Zhiyuan Li and Simon Shaolei Du and Jason D. Lee and Wei Hu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XsHqr9dEGH}\n}"}, "paperhash": {"value": "lyu|dichotomy_of_early_and_late_phase_implicit_biases_can_provably_induce_grokking"}}, "number": 8756, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8756/-/Revision", "ICLR.cc/2024/Conference/Submission8756/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8756/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523542028, "cdate": 1695523542028, "tmdate": 1710600554328, "mdate": 1710600554328, "pdate": 1705411049232, "version": 2}, {"id": "52fz5sUAy2", "forum": "52fz5sUAy2", "signatures": ["ICLR.cc/2024/Conference/Submission8755/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8755/Authors"], "content": {"title": {"value": "Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation"}, "authors": {"value": ["Haoxuan Li", "Chunyuan Zheng", "Sihao Ding", "Peng Wu", "Zhi Geng", "Fuli Feng", "Xiangnan He"]}, "authorids": {"value": ["~Haoxuan_Li6", "~Chunyuan_Zheng1", "~Sihao_Ding2", "~Peng_Wu5", "~Zhi_Geng1", "~Fuli_Feng1", "~Xiangnan_He1"]}, "keywords": {"value": ["Recommender system", "Selection Bias", "Neighborhood effect"]}, "abstract": {"value": "The interaction between users and recommender systems is not only affected by selection bias but also the neighborhood effect, i.e., the interaction between a user and an item is affected by the interactions between other users and other items, or between the same user and other items, or between other users and the same item. Many previous studies have focused on addressing selection bias to achieve unbiased learning of the prediction model, but the lack of consideration of neighborhood effects can lead to biased estimates and suboptimal performance of the prediction model. In this paper, we formally formulate the neighborhood effect as an interference problem from the perspective of causal inference and introduce a treatment representation to capture the neighborhood effect. On this basis, we propose a novel ideal loss that can be used to deal with selection bias in the presence of neighborhood effects. In addition, we further develop two novel estimators for the ideal loss. We theoretically establish the connection between the proposed methods and previous methods ignoring the neighborhood effect and show that the proposed methods achieve unbiased learning when both selection bias and neighborhood effects are present, while the existing methods are biased. Extensive semi-synthetic and real-world experiments are conducted to demonstrate the effectiveness of the proposed methods."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/11a3fa3315793d582e62120d653769157d8978e3.pdf"}, "supplementary_material": {"value": "/attachment/5014e0cba90f6221438dd251299bc49f828c5ec9.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024be,\ntitle={Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation},\nauthor={Haoxuan Li and Chunyuan Zheng and Sihao Ding and Fuli Feng and Xiangnan He and Zhi Geng and Peng Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=52fz5sUAy2}\n}"}, "paperhash": {"value": "li|be_aware_of_the_neighborhood_effect_modeling_selection_bias_under_interference_for_recommendation"}}, "number": 8755, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8755/-/Revision", "ICLR.cc/2024/Conference/Submission8755/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8755/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523533774, "cdate": 1695523533774, "tmdate": 1709661550905, "mdate": 1709661550905, "pdate": 1705411049153, "version": 2}, {"id": "22pyNMuIoa", "forum": "22pyNMuIoa", "signatures": ["ICLR.cc/2024/Conference/Submission8751/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8751/Authors"], "content": {"title": {"value": "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization"}, "authors": {"value": ["Xinyuan Wang", "Chenxi Li", "Zhen Wang", "Fan Bai", "Haotian Luo", "Jiayou Zhang", "Nebojsa Jojic", "Eric Xing", "Zhiting Hu"]}, "authorids": {"value": ["xiw136@ucsd.edu", "chl078@ucsd.edu", "~Zhen_Wang6", "~Fan_Bai5", "1203616626@sjtu.edu.cn", "~Jiayou_Zhang1", "~Nebojsa_Jojic1", "~Eric_Xing1", "~Zhiting_Hu3"]}, "keywords": {"value": ["Large Language Models", "Expert-level Prompt Optimization", "Strategic Planning"]}, "abstract": {"value": "Expert-level prompts, carefully engineered by human experts who have a deep understanding of both large language models (LLMs) and domain knowledge, are the future of prompting and pivotal to harnessing the full power of advanced LLMs. Discovering such prompts with an automated process remains a sought-after and unresolved challenge. Existing prompt optimization techniques, though automated through iterative sampling, often fall short in injecting domain knowledge and exploring the vast prompt space for complex expert-level prompts efficiently. To address this pressing need and achieve expert-level prompting, we introduce PromptAgent, which autonomously discovers prompts equivalent in quality to those handcrafted by experts. At its core, PromptAgent views prompt optimization as a strategic planning problem and employs a principled planning algorithm (rooted in Monte Carlo Tree Search) to strategically explore the vast expert-level prompt space. PromptAgent interacts with the LLM in a human-like trial-and-error manner during the planning, and injects expert-level knowledge by reflecting on model errors and generating insightful error feedback. This novel formulation allows it to iteratively evaluate intermediate prompts, refine them based on errors, simulate future rewards, and search for high-reward paths leading to expert-level prompts. We apply PromptAgent to 12 tasks spanning three practical domains: BIG-Bench Hard (BBH), domain-expert, and general NLU tasks, showing PromptAgent consistently outperforms strong prompting and prompt optimization baselines by great margins. Our qualitative analysis further emphasizes PromptAgent's capability to distill insightful errors into expert-level prompts."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a7d56d7e4539c2a15e9198310b462bd9020c5c98.pdf"}, "TLDR": {"value": "PromptAgent introduces a strategic planning approach to autonomously generate expert-level prompts for advanced LLMs outperforming existing methods across diverse tasks by strategically exploring the prompt space and leveraging error insights."}, "_bibtex": {"value": "@inproceedings{\nwang2024promptagent,\ntitle={PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization},\nauthor={Xinyuan Wang and Chenxi Li and Zhen Wang and Fan Bai and Haotian Luo and Jiayou Zhang and Nebojsa Jojic and Eric Xing and Zhiting Hu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=22pyNMuIoa}\n}"}, "paperhash": {"value": "wang|promptagent_strategic_planning_with_language_models_enables_expertlevel_prompt_optimization"}}, "number": 8751, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8751/-/Revision", "ICLR.cc/2024/Conference/Submission8751/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523490224, "cdate": 1695523490224, "tmdate": 1707625649799, "mdate": 1707625649799, "pdate": 1705411049017, "version": 2}, {"id": "JnRStoIuTe", "forum": "JnRStoIuTe", "signatures": ["ICLR.cc/2024/Conference/Submission8746/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8746/Authors"], "content": {"title": {"value": "Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning"}, "authors": {"value": ["Patrik Okanovic", "Roger Waleffe", "Vasilis Mageirakos", "Konstantinos Nikolakakis", "Amin Karbasi", "Dionysios Kalogerias", "Nezihe Merve G\u00fcrel", "Theodoros Rekatsinas"]}, "authorids": {"value": ["~Patrik_Okanovic1", "~Roger_Waleffe1", "~Vasilis_Mageirakos1", "~Konstantinos_Nikolakakis1", "~Amin_Karbasi3", "~Dionysios_Kalogerias1", "~Nezihe_Merve_G\u00fcrel2", "~Theodoros_Rekatsinas2"]}, "keywords": {"value": ["data pruning", "dataset distillation", "random sampling", "corset selection", "data-efficient learning"]}, "abstract": {"value": "Methods for carefully selecting or generating a small set of training data to learn from, i.e., data pruning, coreset selection, and dataset distillation, have been shown to be effective in reducing the ever-increasing cost of training neural networks. Behind this success are rigorously designed, yet expensive, strategies for identifying the most informative training examples out of large datasets. In this work, we revisit these methods to understand if the additional computational costs associated with such strategies are justified from the perspective of time-to-accuracy, which has become a critical efficiency measure of deep neural network training over large datasets. Surprisingly, we find that many of the recently proposed methods underperform what we call Repeated Sampling of Random Subsets (RSRS or RS2), a powerful yet overlooked extension of the standard random baseline that learns from repeatedly sampled data throughout training instead of a fixed random subset. We test RS2 against thirty-two state-of-the-art data pruning and distillation methods across four datasets including ImageNet. Our results demonstrate that RS2 significantly reduces time-to-accuracy, particularly in practical regimes where accuracy, but not runtime, is similar to that of training on full dataset. For example, when training ResNet-18 on ImageNet, with 10\\% of the dataset each epoch RS2 reaches an accuracy of 66\\% versus 69\\% when training with the full dataset. The best competing method achieves only 55\\% while training 1.6$\\times$ slower than RS2. Beyond the above meta-study, we discuss the theoretical properties of RS2 such as its convergence rate and generalization error. Our primary goal is to highlight that future works that aim to minimize total training cost by using subset selection, need to consider 1) the total computation cost (including preparing the subset) and 2) should aim to outperform a simple extension of random sampling (i.e., RS2)."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d7e4c9daefbd1d5624c0875538fb1fb95b9a2ce9.pdf"}, "supplementary_material": {"value": "/attachment/9e7370d52abba95188410f1bf221f307a636adaf.zip"}, "_bibtex": {"value": "@inproceedings{\nokanovic2024repeated,\ntitle={Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning},\nauthor={Patrik Okanovic and Roger Waleffe and Vasilis Mageirakos and Konstantinos Nikolakakis and Amin Karbasi and Dionysios Kalogerias and Nezihe Merve G{\\\"u}rel and Theodoros Rekatsinas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JnRStoIuTe}\n}"}, "paperhash": {"value": "okanovic|repeated_random_sampling_for_minimizing_the_timetoaccuracy_of_learning"}}, "number": 8746, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8746/-/Revision", "ICLR.cc/2024/Conference/Submission8746/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8746/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523401520, "cdate": 1695523401520, "tmdate": 1713014620866, "mdate": 1713014620866, "pdate": 1705411048891, "version": 2}, {"id": "kGteeZ18Ir", "forum": "kGteeZ18Ir", "signatures": ["ICLR.cc/2024/Conference/Submission8745/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8745/Authors"], "content": {"title": {"value": "Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"}, "authors": {"value": ["Shashank Gupta", "Vaishnavi Shrivastava", "Ameet Deshpande", "Ashwin Kalyan", "Peter Clark", "Ashish Sabharwal", "Tushar Khot"]}, "authorids": {"value": ["~Shashank_Gupta3", "~Vaishnavi_Shrivastava1", "~Ameet_Deshpande1", "~Ashwin_Kalyan6", "~Peter_Clark1", "~Ashish_Sabharwal1", "~Tushar_Khot1"]}, "keywords": {"value": ["Bias", "Fairness", "LLM", "Reasoning", "Persona", "Safety"]}, "TLDR": {"value": "Assigning personas to LLMs can bring their deep-rooted biases to the surface, significantly diminishing their reasoning ability across domains."}, "abstract": {"value": "Recent works have showcased the ability of large-scale language models (LLMs) to embody diverse personas in their responses, exemplified by prompts like \u2018_You are Yoda. Explain the Theory of Relativity._\u2019 While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs\u2019 capabilities remains unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs to perform _basic reasoning tasks_. Our study covers 24 reasoning datasets (spanning mathematics, law, medicine, morals, and more), 4 LLMs (2 versions of ChatGPT-3.5, GPT-4-Turbo, and Llama-2-70b-chat), and 19 diverse personas (e.g., \u2018an Asian person\u2019) spanning 5 socio-demographic groups: race, gender, religion, disability, and political affiliation. Our experiments unveil that LLMs harbor deep rooted bias against various socio-demographics underneath a veneer of fairness. While they overtly reject stereotypes when explicitly asked (\u2018_Are Black people less skilled at mathematics?_\u2019), they manifest stereotypical and often erroneous presumptions when prompted to answer questions while adopting a persona. These can be observed as abstentions in the model\u2019s response, e.g., \u2018_As a Black person, I am unable to answer this question as it requires math knowledge_\u2019, and generally result in a substantial drop in performance on reasoning tasks. Our experiments with ChatGPT-3.5 show that this bias is _ubiquitous_&mdash;80% of our personas demonstrate bias; it is _significant_&mdash;some datasets show performance drops of 70%+; and can be especially _harmful for certain groups_&mdash;some personas suffer statistically significant drops on 80%+ of the datasets. Overall, all four LLMs exhibit persona-induced bias to varying extents, with GPT-4-Turbo showing the least but still a problematic amount of bias (evident in 42% of the personas). Further analysis shows that these persona-induced errors can be hard-to-discern as they do not always manifest as explicit abstentions, and can also be hard-to-avoid&mdash;we find de-biasing prompts to have minimal to no effect. Our findings serve as a cautionary tale that the practice of assigning personas to LLMs&mdash;a trend on the rise&mdash;can surface their deep-rooted biases and have unforeseeable and detrimental side-effects."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/80ad8992d5c1096ee5f775cfb3ce54c4de41a376.pdf"}, "_bibtex": {"value": "@inproceedings{\ngupta2024bias,\ntitle={Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned {LLM}s},\nauthor={Shashank Gupta and Vaishnavi Shrivastava and Ameet Deshpande and Ashwin Kalyan and Peter Clark and Ashish Sabharwal and Tushar Khot},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kGteeZ18Ir}\n}"}, "paperhash": {"value": "gupta|bias_runs_deep_implicit_reasoning_biases_in_personaassigned_llms"}}, "number": 8745, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8745/-/Revision", "ICLR.cc/2024/Conference/Submission8745/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8745/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523385751, "cdate": 1695523385751, "tmdate": 1712558537582, "mdate": 1712558537582, "pdate": 1705411048864, "version": 2}, {"id": "AZW3qlCGTe", "forum": "AZW3qlCGTe", "signatures": ["ICLR.cc/2024/Conference/Submission8741/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8741/Authors"], "content": {"title": {"value": "Enhancing Instance-Level Image Classification with Set-Level Labels"}, "authors": {"value": ["Renyu Zhang", "Aly A Khan", "Yuxin Chen", "Robert L. Grossman"]}, "authorids": {"value": ["~Renyu_Zhang2", "~Aly_A_Khan1", "~Yuxin_Chen1", "~Robert_L._Grossman2"]}, "keywords": {"value": ["set-level labels", "fast excess risk rate", "representation learning", "few-shot learning"]}, "TLDR": {"value": "We present a novel approach to enhance instance-level image classification by leveraging set-level labels."}, "abstract": {"value": "Instance-level image classification tasks have traditionally relied on single-instance labels to train models, e.g., few-shot learning and transfer learning. However, set-level coarse-grained labels that capture relationships among instances can provide richer information in real-world scenarios. In this paper, we present a novel approach to enhance instance-level image classification by leveraging set-level labels. We provide a theoretical analysis of the proposed method, including recognition conditions for fast excess risk rate, shedding light on the theoretical foundations of our approach. We conducted experiments on two distinct categories of datasets: natural image datasets and histopathology image datasets. Our experimental results demonstrate the effectiveness of our approach, showcasing improved classification performance compared to traditional single-instance label-based methods. Notably, our algorithm achieves 13\\% improvement in classification accuracy compared to the strongest baseline on the histopathology image classification benchmarks. Importantly, our experimental findings align with the theoretical analysis, reinforcing the robustness and reliability of our proposed method. This work bridges the gap between instance-level and set-level image classification, offering a promising avenue for advancing the capabilities of image classification models with set-level coarse-grained labels."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c61a439433658edb2a1f929a97ec263da9c31fea.pdf"}, "supplementary_material": {"value": "/attachment/6da5ddfffa12a56a47e07353ad6df009d1936ab5.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024enhancing,\ntitle={Enhancing Instance-Level Image Classification with Set-Level Labels},\nauthor={Renyu Zhang and Aly A Khan and Yuxin Chen and Robert L. Grossman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AZW3qlCGTe}\n}"}, "paperhash": {"value": "zhang|enhancing_instancelevel_image_classification_with_setlevel_labels"}}, "number": 8741, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8741/-/Revision", "ICLR.cc/2024/Conference/Submission8741/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8741/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523256198, "cdate": 1695523256198, "tmdate": 1710537100677, "mdate": 1710537100677, "pdate": 1705411048737, "version": 2}, {"id": "jTSKkcbEsj", "forum": "jTSKkcbEsj", "signatures": ["ICLR.cc/2024/Conference/Submission8736/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8736/Authors"], "content": {"title": {"value": "Pushing Boundaries: Mixup's Influence on Neural Collapse"}, "authors": {"value": ["Quinn LeBlanc Fisher", "Haoming Meng", "Vardan Papyan"]}, "authorids": {"value": ["~Quinn_LeBlanc_Fisher1", "~Haoming_Meng1", "~Vardan_Papyan1"]}, "keywords": {"value": ["mixup", "neural collapse", "unconstrained features model"]}, "TLDR": {"value": "Mixup induces a rigid geometric configuration in last-layer features richer than that of Neural Collapse."}, "abstract": {"value": "Mixup is a data augmentation strategy that employs convex combinations of training instances and their respective labels to improve the robustness and calibration of deep neural networks. Despite its widespread adoption, the nuanced mechanisms that underpin its success are not entirely understood. The observed phenomenon of Neural Collapse, where the last-layer activations and classifier of deep networks converge to a simplex equiangular tight frame (ETF), provides a compelling motivation to explore whether mixup induces alternative geometric configurations and whether those could explain its success. In this study, we delve into the last-layer activations of training data for deep networks subjected to mixup, aiming to uncover insights into its operational efficacy. Our investigation, spanning various architectures and dataset pairs, reveals that mixup's last-layer activations predominantly converge to a distinctive configuration different than one might expect. In this configuration, activations from mixed-up examples of identical classes align with the classifier, while those from different classes delineate channels along the decision boundary. These findings are unexpected, as mixed-up features are not simple convex combinations of feature class means (as one might get, for example, by training mixup with the mean squared error loss). By analyzing this distinctive geometric configuration, we elucidate the mechanisms by which mixup enhances model calibration. To further validate our empirical observations, we conduct a theoretical analysis under the assumption of an unconstrained features model, utilizing the mixup loss. Through this, we characterize and derive the optimal last-layer features under the assumption that the classifier forms a simplex ETF."}, "pdf": {"value": "/pdf/fc3d9e6d2cf3f29c440ba403f9ad95a4ef697601.pdf"}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nfisher2024pushing,\ntitle={Pushing Boundaries: Mixup's Influence on Neural Collapse},\nauthor={Quinn LeBlanc Fisher and Haoming Meng and Vardan Papyan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jTSKkcbEsj}\n}"}, "paperhash": {"value": "fisher|pushing_boundaries_mixups_influence_on_neural_collapse"}}, "number": 8736, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8736/-/Revision", "ICLR.cc/2024/Conference/Submission8736/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8736/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523101246, "cdate": 1695523101246, "tmdate": 1710539623719, "mdate": 1710539623719, "pdate": 1705411048532, "version": 2}, {"id": "2XBBumBGeP", "forum": "2XBBumBGeP", "signatures": ["ICLR.cc/2024/Conference/Submission8735/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8735/Authors"], "content": {"title": {"value": "sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows"}, "authors": {"value": ["Dongjin Kim", "Donggoo Jung", "Sungyong Baik", "Tae Hyun Kim"]}, "authorids": {"value": ["~Dongjin_Kim3", "~Donggoo_Jung1", "~Sungyong_Baik1", "~Tae_Hyun_Kim2"]}, "keywords": {"value": ["sRGB real noise modeling", "Normalizing flow", "Low-level vision"]}, "abstract": {"value": "Noise poses a widespread challenge in signal processing, particularly when it comes to denoising images. Although convolutional neural networks (CNNs) have exhibited remarkable success in this field, they are predicated upon the belief that noise follows established distributions, which restricts their practicality when dealing with real-world noise. To overcome this limitation, several efforts have been taken to collect noisy image datasets from the real world. Generative methods, employing techniques such as generative adversarial networks (GANs) and normalizing flows (NFs), have emerged as a solution for generating realistic noisy images. Recent works model noise using camera metadata, however requiring metadata even for sampling phase. In contrast, in this work, we aim to estimate the underlying camera settings, enabling us to improve noise modeling and generate diverse noise distributions. To this end, we introduce a new NF framework that allows us to both classify noise based on camera settings and generate various noisy images. Through experimental results, our model demonstrates exceptional noise quality and leads in denoising performance on benchmark datasets."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4e4c68a8b09ae4ef7e4d0ff1f101a225642f3723.pdf"}, "_bibtex": {"value": "@inproceedings{\nkim2024srgb,\ntitle={s{RGB} Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows},\nauthor={Dongjin Kim and Donggoo Jung and Sungyong Baik and Tae Hyun Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2XBBumBGeP}\n}"}, "paperhash": {"value": "kim|srgb_real_noise_modeling_via_noiseaware_sampling_with_normalizing_flows"}}, "number": 8735, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8735/-/Revision", "ICLR.cc/2024/Conference/Submission8735/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8735/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695523083977, "cdate": 1695523083977, "tmdate": 1711503426000, "mdate": 1711503426000, "pdate": 1705411048524, "version": 2}, {"id": "8dN7gApKm3", "forum": "8dN7gApKm3", "signatures": ["ICLR.cc/2024/Conference/Submission8730/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8730/Authors"], "content": {"title": {"value": "Uncertainty-aware Graph-based Hyperspectral Image Classification"}, "authors": {"value": ["Linlin Yu", "Yifei Lou", "Feng Chen"]}, "authorids": {"value": ["~Linlin_Yu1", "~Yifei_Lou2", "~Feng_Chen7"]}, "keywords": {"value": ["Uncertainty Quantification", "Graph", "Hyperspectral Image Classification"]}, "abstract": {"value": "Hyperspectral imaging (HSI) technology captures spectral information across a broad wavelength range, providing richer pixel features compared to traditional color images with only three channels. Although pixel classification in HSI  has been extensively studied, especially using graph convolution neural networks (GCNs), quantifying epistemic and aleatoric uncertainties associated with the HSI classification (HSIC) results remains an unexplored area. These two uncertainties are effective for out-of-distribution (OOD) and misclassification detection, respectively. In this paper, we adapt two advanced uncertainty quantification models, evidential GCNs (EGCN) and graph posterior networks (GPN), designed for node classifications in graphs, into the realm of HSIC. We first reveal theoretically that a popular uncertainty cross-entropy (UCE) loss function is insufficient to produce good epistemic uncertainty when learning EGCNs. To mitigate the limitations, we propose two regularization terms. One leverages the inherent property of HSI data where each feature vector is a linear combination of the spectra signatures of the confounding materials, while the other is the total variation (TV) regularization to enforce the spatial smoothness of the evidence with edge-preserving. We demonstrate the effectiveness of the proposed regularization terms on both EGCN and GPN on three real-world HSIC datasets for OOD and misclassification detection tasks. The code is available at GitHub."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5cb7dbbaad37d6d8ad2e4be0826caf667a69732a.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024uncertaintyaware,\ntitle={Uncertainty-aware Graph-based Hyperspectral Image Classification},\nauthor={Linlin Yu and Yifei Lou and Feng Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8dN7gApKm3}\n}"}, "paperhash": {"value": "yu|uncertaintyaware_graphbased_hyperspectral_image_classification"}}, "number": 8730, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8730/-/Revision", "ICLR.cc/2024/Conference/Submission8730/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8730/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695522748814, "cdate": 1695522748814, "tmdate": 1710542189639, "mdate": 1710542189639, "pdate": 1705411048218, "version": 2}, {"id": "TlyiaPXaVN", "forum": "TlyiaPXaVN", "signatures": ["ICLR.cc/2024/Conference/Submission8725/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8725/Authors"], "content": {"title": {"value": "Generative Adversarial Equilibrium Solvers"}, "authors": {"value": ["Denizalp Goktas", "David C. Parkes", "Ian Gemp", "Luke Marris", "Georgios Piliouras", "Romuald Elie", "Guy Lever", "Andrea Tacchetti"]}, "authorids": {"value": ["~Denizalp_Goktas1", "~David_C._Parkes1", "~Ian_Gemp1", "~Luke_Marris2", "~Georgios_Piliouras1", "~Romuald_Elie3", "~Guy_Lever1", "~Andrea_Tacchetti1"]}, "keywords": {"value": ["Game Theory", "Amortized Optimization", "Generalized Nash equilibrium", "Economics"]}, "TLDR": {"value": "We reformulate the problem of computing generalized Nash equilibrium in pseudo-games (and competitive equilibrium in Arrow-Debreu competitive economies) as a learning problem for a generative adversarial network."}, "abstract": {"value": "We introduce the use of generative adversarial learning to compute equilibria in general game-theoretic settings, specifically the generalized Nash equilibrium (GNE) in pseudo-games, and its specific instantiation as the competitive equilibrium (CE) in Arrow-Debreu competitive economies. Pseudo-games are a generalization of games in which players' actions affect not only the payoffs of other players but also their feasible action spaces. Although the computation of GNE and CE is intractable in the worst-case, i.e., PPAD-hard, in practice, many applications only require solutions with high accuracy in expectation over a distribution of problem instances. We introduce Generative Adversarial Equilibrium Solvers (GAES): a family of generative adversarial neural networks that can learn GNE and CE from only a sample of problem instances. We provide computational and sample complexity bounds for Lipschitz-smooth function approximators in a large class of concave pseudo-games, and apply the framework to finding Nash equilibria in normal-form games, CE in Arrow-Debreu competitive economies, and GNE in an environmental economic model of the Kyoto mechanism."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8d39d3937cb54ffcccfa5539247a3ff0d23a008d.pdf"}, "supplementary_material": {"value": "/attachment/03cbae5a1b5de09667246a5314b1568814981f47.pdf"}, "_bibtex": {"value": "@inproceedings{\ngoktas2024generative,\ntitle={Generative Adversarial Equilibrium Solvers},\nauthor={Denizalp Goktas and David C. Parkes and Ian Gemp and Luke Marris and Georgios Piliouras and Romuald Elie and Guy Lever and Andrea Tacchetti},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TlyiaPXaVN}\n}"}, "paperhash": {"value": "goktas|generative_adversarial_equilibrium_solvers"}}, "number": 8725, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8725/-/Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695522706732, "cdate": 1695522706732, "tmdate": 1707625649534, "mdate": 1707625649534, "pdate": 1705411047978, "version": 2}, {"id": "pe0Vdv7rsL", "forum": "pe0Vdv7rsL", "signatures": ["ICLR.cc/2024/Conference/Submission8705/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8705/Authors"], "content": {"title": {"value": "Graph Transformers on EHRs: Better Representation Improves Downstream Performance"}, "authors": {"value": ["Raphael Poulain", "Rahmatollah Beheshti"]}, "authorids": {"value": ["~Raphael_Poulain1", "~Rahmatollah_Beheshti2"]}, "keywords": {"value": ["transformers", "graph neural networks", "electronic health records"]}, "abstract": {"value": "Following the success of transformer-based methods across various machine learning applications, their adoption for healthcare predictive tasks using electronic health records (EHRs)  has also expanded extensively. Similarly, graph-based methods have been shown to be very effective in capturing inherent graph-type relationships in EHRs, leading to improved downstream performance. Although integrating these two families of approaches seems like a natural next step, in practice, creating such a design is challenging and has not been done. This is partly due to known EHR problems, such as high sparsity, making extracting meaningful temporal representations of medical visits challenging. In this study, we propose GT-BEHRT, a new approach that leverages temporal visit embeddings extracted from a graph transformer and uses a BERT-based model to obtain more robust patient representations, especially on longer EHR sequences. The graph-based approach allows GT-BEHRT to implicitly capture the intrinsic graphical relationships between medical observations, while the BERT model extracts the temporal relationships between visits, loosely mimicking the clinicians' decision-making process. As part of our method, we also present a two-step pre-training strategy for learning better graphical and temporal representations. Our proposed method achieves state-of-the-art performance in a variety of standard medical predictive tasks, demonstrating the versatility of our approach."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cc3e4cf0f1122fe0c256b5e62246f05026012d2a.pdf"}, "_bibtex": {"value": "@inproceedings{\npoulain2024graph,\ntitle={Graph Transformers on {EHR}s: Better Representation Improves Downstream Performance},\nauthor={Raphael Poulain and Rahmatollah Beheshti},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pe0Vdv7rsL}\n}"}, "paperhash": {"value": "poulain|graph_transformers_on_ehrs_better_representation_improves_downstream_performance"}}, "number": 8705, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8705/-/Revision", "ICLR.cc/2024/Conference/Submission8705/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8705/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521971169, "cdate": 1695521971169, "tmdate": 1712855245329, "mdate": 1712855245329, "pdate": 1705411047217, "version": 2}, {"id": "dwzLn78jq7", "forum": "dwzLn78jq7", "signatures": ["ICLR.cc/2024/Conference/Submission8702/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8702/Authors"], "content": {"title": {"value": "On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks"}, "authors": {"value": ["Zi Wang", "Bin Hu", "Aaron J Havens", "Alexandre Araujo", "Yang Zheng", "Yudong Chen", "Somesh Jha"]}, "authorids": {"value": ["~Zi_Wang3", "~Bin_Hu2", "~Aaron_J_Havens1", "~Alexandre_Araujo3", "~Yang_Zheng4", "~Yudong_Chen1", "~Somesh_Jha1"]}, "keywords": {"value": ["Semidefinite programming", "Lipschitz constant", "Deep learning"]}, "abstract": {"value": "Lipschitz constant estimation plays an important role in understanding generalization, robustness, and fairness in deep learning. Unlike naive bounds based on the network weight norm product, semidefinite programs (SDPs) have shown great promise in providing less conservative Lipschitz bounds with polynomial-time complexity guarantees. However, due to the memory consumption and running speed, standard SDP algorithms cannot scale to modern neural network architectures. In this paper, we transform the SDPs for Lipschitz constant estimation into an eigenvalue optimization problem, which aligns with the modern large-scale optimization paradigms based on first-order methods. This is amenable to autodiff frameworks such as PyTorch and TensorFlow, requiring significantly less memory than standard SDP algorithms. The transformation also allows us to leverage various existing numerical techniques for eigenvalue optimization, opening the way for further memory improvement and computational speedup. The essential technique of our eigenvalue-problem transformation is to introduce redundant quadratic constraints and then utilize both Lagrangian and Shor's SDP relaxations under a certain trace constraint.  Notably, our numerical study successfully scales the SDP-based Lipschitz constant estimation to address large neural networks on ImageNet. Our numerical examples on CIFAR10 and ImageNet demonstrate that our technique is more scalable than existing approaches. Our code is available at https://github.com/z1w/LipDiff."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/333a8145de80d282eac48f6722bab292ed03b563.pdf"}, "TLDR": {"value": "We scale the SDP for Lipschitz constant estimation to practical CIFAR10/ImageNet networks."}, "_bibtex": {"value": "@inproceedings{\nwang2024on,\ntitle={On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks},\nauthor={Zi Wang and Aaron J Havens and Alexandre Araujo and Yang Zheng and Bin Hu and Yudong Chen and Somesh Jha},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dwzLn78jq7}\n}"}, "paperhash": {"value": "wang|on_the_scalability_and_memory_efficiency_of_semidefinite_programs_for_lipschitz_constant_estimation_of_neural_networks"}}, "number": 8702, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8702/-/Revision", "ICLR.cc/2024/Conference/Submission8702/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8702/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521949303, "cdate": 1695521949303, "tmdate": 1713069319009, "mdate": 1713069319009, "pdate": 1705411047105, "version": 2}, {"id": "kZEXgtMNNo", "forum": "kZEXgtMNNo", "signatures": ["ICLR.cc/2024/Conference/Submission8696/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8696/Authors"], "content": {"title": {"value": "Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models"}, "authors": {"value": ["Yuanfeng Ji", "Chongjian GE", "Weikai Kong", "Enze Xie", "Zhengying Liu", "Zhenguo Li", "Ping Luo"]}, "authorids": {"value": ["~Yuanfeng_Ji1", "~Chongjian_GE1", "~Weikai_Kong1", "~Enze_Xie1", "~Zhengying_Liu2", "~Zhenguo_Li1", "~Ping_Luo2"]}, "keywords": {"value": ["LLMs", "VLMs", "Benchmark"]}, "abstract": {"value": "With the advancements in Large Language Models (LLMs), Vision-Language Models (VLMs) have reached a new level of sophistication, showing notable competence in executing intricate cognition and reasoning tasks. However, existing evaluation benchmarks, primarily relying on rigid, hand-crafted datasets to measure task-specific performance, face significant limitations in assessing the alignment of these increasingly anthropomorphic models with human intelligence. In this work, we address the limitations via Auto-Bench, which delves into exploring LLMs as proficient aligners, measuring the alignment between VLMs and human intelligence and value through automatic data curation and assessment. Specifically, for data curation, Auto-Bench utilizes LLMs (e.g., GPT-4) to automatically generate a vast set of question-answer-reasoning triplets via prompting on visual symbolic representations (e.g., captions, object locations, instance relationships, and etc. The curated data closely matches human intent, owing to the extensive world knowledge embedded in LLMs. Through this pipeline, a total of 28.5K human-verified and 3,504K unfiltered question-answer-reasoning triplets have been curated, covering 4 primary abilities and 16 sub-abilities. We subsequently engage LLMs like GPT-3.5 to serve as judges, implementing the quantitative and qualitative automated assessments to facilitate a comprehensive evaluation of VLMs. Our validation results reveal that LLMs are proficient in both evaluation data curation and model assessment, achieving an average agreement rate of 85%. We envision Auto-Bench as a flexible, scalable, and comprehensive benchmark for evaluating the evolving sophisticated VLMs."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fec2f0e416c0a90d47240e5522b34b70940223f4.pdf"}, "_bibtex": {"value": "@inproceedings{\nji2024large,\ntitle={Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models},\nauthor={Yuanfeng Ji and Chongjian GE and Weikai Kong and Enze Xie and Zhengying Liu and Zhenguo Li and Ping Luo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kZEXgtMNNo}\n}"}, "paperhash": {"value": "ji|large_language_models_as_automated_aligners_for_benchmarking_visionlanguage_models"}}, "number": 8696, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8696/-/Revision", "ICLR.cc/2024/Conference/Submission8696/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8696/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521713473, "cdate": 1695521713473, "tmdate": 1710826520088, "mdate": 1710826520088, "pdate": 1705411046968, "version": 2}, {"id": "ofzeypWosV", "forum": "ofzeypWosV", "signatures": ["ICLR.cc/2024/Conference/Submission8692/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8692/Authors"], "content": {"title": {"value": "CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech"}, "authors": {"value": ["Jaehyeon Kim", "Keon Lee", "Seungjun Chung", "Jaewoong Cho"]}, "authorids": {"value": ["~Jaehyeon_Kim1", "~Keon_Lee1", "~Seungjun_Chung1", "~Jaewoong_Cho1"]}, "keywords": {"value": ["text-to-speech", "speech synthesis", "neural audio codec"]}, "abstract": {"value": "With the emergence of neural audio codecs, which encode multiple streams of discrete tokens from audio, large language models have recently gained attention as a promising approach for zero-shot Text-to-Speech (TTS) synthesis. Despite the ongoing rush towards scaling paradigms, audio tokenization ironically amplifies the scalability challenge, stemming from its long sequence length and the complexity of modelling the multiple sequences. To mitigate these issues, we present CLaM-TTS that employs a probabilistic residual vector quantization to (1) achieve superior compression in the token length, and (2) allow a language model to generate multiple tokens at once, thereby eliminating the need for cascaded modeling to handle the number of token streams. Our experimental results demonstrate that CLaM-TTS is better than or comparable to state-of-the-art neural codec-based TTS models regarding naturalness, intelligibility, speaker similarity, and inference speed. In addition, we examine the impact of the pretraining extent of the language models and their text tokenization strategies on performances."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4aa68c6552ace824647a0f32a7f3b5ff97a6cd58.pdf"}, "_bibtex": {"value": "@inproceedings{\nkim2024clamtts,\ntitle={{CL}aM-{TTS}: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech},\nauthor={Jaehyeon Kim and Keon Lee and Seungjun Chung and Jaewoong Cho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ofzeypWosV}\n}"}, "paperhash": {"value": "kim|clamtts_improving_neural_codec_language_model_for_zeroshot_texttospeech"}}, "number": 8692, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8692/-/Revision", "ICLR.cc/2024/Conference/Submission8692/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8692/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521636069, "cdate": 1695521636069, "tmdate": 1712155604196, "mdate": 1712155604196, "pdate": 1705411046925, "version": 2}, {"id": "4VgBjsOC8k", "forum": "4VgBjsOC8k", "signatures": ["ICLR.cc/2024/Conference/Submission8688/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8688/Authors"], "content": {"title": {"value": "Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels"}, "authors": {"value": ["Zahra Babaiee", "Peyman Kiasari", "Daniela Rus", "Radu Grosu"]}, "authorids": {"value": ["~Zahra_Babaiee1", "~Peyman_Kiasari1", "~Daniela_Rus1", "~Radu_Grosu1"]}, "keywords": {"value": ["Depthwise Convolutions", "Explainability", "Neuroscience", "Computer Vision", "ConvNext"]}, "TLDR": {"value": "This paper reveals that discernible patterns resembling biological vision models consistently emerge in the trained kernels of depthwise convolutional neural networks."}, "abstract": {"value": "Recent advances in depthwise-separable convolutional neural networks (DS-CNNs) have led to novel architectures, that surpass the performance of classical CNNs, by a considerable scalability and accuracy margin. This paper reveals another striking property of DS-CNN architectures: discernible and explainable patterns emerge in their trained depthwise convolutional kernels in all layers. Through an extensive analysis of millions of trained filters, with different sizes and from various models, we employed unsupervised clustering with autoencoders, to categorize these filters. Astonishingly, the patterns converged into a few main clusters, each resembling the difference of Gaussian (DoG) functions, and their first and second-order derivatives. Notably, we classify over 95\\% and 90\\% of the filters from state-of-the-art ConvNeXtV2 and ConvNeXt models, respectively. This finding is not merely a technological curiosity; it echoes the foundational models neuroscientists have long proposed for the vision systems of mammals. Our results thus deepen our understanding of the emergent properties of trained DS-CNNs and provide a bridge between artificial and biological visual processing systems. More broadly, they pave the way for more interpretable and biologically-inspired neural network designs in the future."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3c890643bdfe86705d7ed24e33e7edf242f989d7.pdf"}, "_bibtex": {"value": "@inproceedings{\nbabaiee2024unveiling,\ntitle={Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels},\nauthor={Zahra Babaiee and Peyman Kiasari and Daniela Rus and Radu Grosu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4VgBjsOC8k}\n}"}, "paperhash": {"value": "babaiee|unveiling_the_unseen_identifiable_clusters_in_trained_depthwise_convolutional_kernels"}}, "number": 8688, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8688/-/Revision", "ICLR.cc/2024/Conference/Submission8688/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8688/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521493968, "cdate": 1695521493968, "tmdate": 1712072990887, "mdate": 1712072990887, "pdate": 1705411046845, "version": 2}, {"id": "0j9ZDzMPqr", "forum": "0j9ZDzMPqr", "signatures": ["ICLR.cc/2024/Conference/Submission8687/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8687/Authors"], "content": {"title": {"value": "UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models"}, "authors": {"value": ["Hyunju Kang", "Geonhee Han", "Hogun Park"]}, "authorids": {"value": ["~Hyunju_Kang1", "~Geonhee_Han1", "~Hogun_Park2"]}, "keywords": {"value": ["XAI", "Unsupervised node representation learning", "Counterfactual Explanations"]}, "TLDR": {"value": "UNR-Explainer aims to provide counterfactual explanations for a single target node in unsupervised node representation models."}, "abstract": {"value": "Node representation learning, such as Graph Neural Networks (GNNs), has become one of the important learning methods in machine learning, and the demand for reliable explanation generation is growing. Despite extensive research on explanation generation for supervised node representation learning, explaining unsupervised models has been less explored. To address this gap, we propose a method for generating counterfactual (CF) explanations in unsupervised node representation learning, aiming to identify the most important subgraphs that cause a significant change in the $k$-nearest neighbors of a node of interest in the learned embedding space upon perturbation. The $k$-nearest neighbor-based CF explanation method provides simple, yet pivotal, information for understanding unsupervised downstream tasks, such as top-$k$ link prediction and clustering. Furthermore, we introduce a Monte Carlo Tree Search (MCTS)-based explainability method for generating expressive CF explanations for **U**nsupervised **N**ode **R**epresentation learning methods, which we call **UNR-Explainer**. The proposed method demonstrates improved performance on six datasets for both unsupervised GraphSAGE and DGI."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/10b9fd3acfd02641ed30cb17e2a56438f96d6673.pdf"}, "_bibtex": {"value": "@inproceedings{\nkang2024unrexplainer,\ntitle={{UNR}-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models},\nauthor={Hyunju Kang and Geonhee Han and Hogun Park},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0j9ZDzMPqr}\n}"}, "paperhash": {"value": "kang|unrexplainer_counterfactual_explanations_for_unsupervised_node_representation_learning_models"}}, "number": 8687, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8687/-/Revision", "ICLR.cc/2024/Conference/Submission8687/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8687/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521428100, "cdate": 1695521428100, "tmdate": 1713159794236, "mdate": 1713159794236, "pdate": 1705411046804, "version": 2}, {"id": "x8VNtpCu1I", "forum": "x8VNtpCu1I", "signatures": ["ICLR.cc/2024/Conference/Submission8680/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8680/Authors"], "content": {"title": {"value": "Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations"}, "authors": {"value": ["yisheng xiao", "Juntao Li", "Zechen Sun", "Zechang Li", "Qingrong Xia", "Xinyu Duan", "Zhefeng Wang", "Min Zhang"]}, "authorids": {"value": ["~yisheng_xiao1", "~Juntao_Li2", "~Zechen_Sun1", "~Zechang_Li1", "~Qingrong_Xia1", "~Xinyu_Duan1", "~Zhefeng_Wang1", "~Min_Zhang9"]}, "keywords": {"value": ["Instruction tuning", "Large language models", "BERT family", "Natural language generation"]}, "abstract": {"value": "Language modeling at scale has proven very effective and brought unprecedented success to natural language models. Many typical representatives, especially decoder-only models, e.g., BLOOM and LLaMA, and encoder-decoder models, e.g., Flan-T5 and AlexaTM, have exhibited incredible instruction-following capabilities while keeping strong task completion ability. These large language models can achieve superior performance in various tasks and even yield emergent capabilities, e.g., reasoning and universal generalization. Though the above two paradigms are mainstream and well explored, the potential of the BERT family, which are encoder-only based models and have ever been one of the most representative pre-trained models, also deserves attention, at least should be discussed. In this work, we adopt XML-R to explore the effectiveness of the BERT family for instruction following and zero-shot learning. We first design a simple yet effective strategy to utilize the encoder-only models for generation tasks and then conduct multi-task instruction tuning.  Experimental results demonstrate that our fine-tuned model, Instruct-XMLR, outperforms Bloomz on all evaluation tasks and achieves comparable performance with mT0 on most tasks. Surprisingly, Instruct-XMLR also possesses strong task and language generalization abilities, indicating that Instruct-XMLR can also serve as a good instruction follower and zero-shot learner. Besides, Instruct-XMLR can accelerate decoding due to its non-autoregressive generation manner, achieving around 3 times speedup compared with current autoregressive large language models. Although we also witnessed several limitations through our experiments, such as the performance decline in long-generation tasks and the shortcoming of length prediction, Instruct-XMLR can still become a good member of the family of current large language models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e58804ca5c30798461a4aa73b0cc89f9836c6880.pdf"}, "_bibtex": {"value": "@inproceedings{\nxiao2024are,\ntitle={Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations},\nauthor={yisheng xiao and Zechen Sun and Juntao Li and Min Zhang and Zechang Li and Qingrong Xia and Xinyu Duan and Zhefeng Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=x8VNtpCu1I}\n}"}, "paperhash": {"value": "xiao|are_bert_family_good_instruction_followers_a_study_on_their_potential_and_limitations"}}, "number": 8680, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8680/-/Revision", "ICLR.cc/2024/Conference/Submission8680/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8680/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695521064585, "cdate": 1695521064585, "tmdate": 1712669690907, "mdate": 1712669690907, "pdate": 1705411046592, "version": 2}, {"id": "V2cBKtdC3a", "forum": "V2cBKtdC3a", "signatures": ["ICLR.cc/2024/Conference/Submission8675/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8675/Authors"], "content": {"title": {"value": "Exploring the Promise and Limits of Real-Time Recurrent Learning"}, "authors": {"value": ["Kazuki Irie", "Anand Gopalakrishnan", "J\u00fcrgen Schmidhuber"]}, "authorids": {"value": ["~Kazuki_Irie1", "~Anand_Gopalakrishnan1", "~J\u00fcrgen_Schmidhuber1"]}, "keywords": {"value": ["recurrent neural networks", "real-time recurrent learning", "online recurrent learning", "reinforcement learning", "actor-critic", "policy gradients"]}, "TLDR": {"value": "We evaluate RTRL without approximation using element-wise recurrent networks on many standard RL tasks, and highlight challenges of RTRL rarely discussed in prior work."}, "abstract": {"value": "Real-time recurrent learning (RTRL) for sequence-processing recurrent neural networks (RNNs) offers certain conceptual advantages over backpropagation through time (BPTT). RTRL requires neither caching past activations nor truncating context, and enables online learning. However, RTRL's time and space complexity make it impractical. To overcome this problem, most recent work on RTRL focuses on approximation theories, while experiments are often limited to diagnostic settings. Here we explore the practical promise of RTRL in more realistic settings. We study actor-critic methods that combine RTRL and policy gradients, and test them in several subsets of DMLab-30, ProcGen, and Atari-2600 environments. On DMLab memory tasks, our system trained on fewer than 1.2B environmental frames is competitive with or outperforms well-known IMPALA and R2D2 baselines trained on 10B frames. To scale to such challenging tasks, we focus on certain well-known neural architectures with element-wise recurrence, allowing for tractable RTRL without approximation. Importantly, we also discuss rarely addressed limitations of RTRL in real-world applications, such as its complexity in the multi-layer case."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9107e97b85399a8a37e9379bb2cdb2ef3e226b56.pdf"}, "supplementary_material": {"value": "/attachment/22ffdb149060b0ae0f77ca98eab1204f1fb8beea.zip"}, "_bibtex": {"value": "@inproceedings{\nirie2024exploring,\ntitle={Exploring the Promise and Limits of Real-Time Recurrent Learning},\nauthor={Kazuki Irie and Anand Gopalakrishnan and J{\\\"u}rgen Schmidhuber},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=V2cBKtdC3a}\n}"}, "paperhash": {"value": "irie|exploring_the_promise_and_limits_of_realtime_recurrent_learning"}}, "number": 8675, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8675/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8675/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520956457, "cdate": 1695520956457, "tmdate": 1709661550206, "mdate": 1709661550206, "pdate": 1705411046467, "version": 2}, {"id": "YH5w12OUuU", "forum": "YH5w12OUuU", "signatures": ["ICLR.cc/2024/Conference/Submission8670/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8670/Authors"], "content": {"title": {"value": "TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"}, "authors": {"value": ["Defu Cao", "Furong Jia", "Sercan O Arik", "Tomas Pfister", "Yixiang Zheng", "Wen Ye", "Yan Liu"]}, "authorids": {"value": ["~Defu_Cao1", "~Furong_Jia1", "~Sercan_O_Arik1", "~Tomas_Pfister1", "~Yixiang_Zheng1", "~Wen_Ye2", "~Yan_Liu1"]}, "keywords": {"value": ["Forecasting; Time Series; Large Language Model"]}, "abstract": {"value": "The past decade has witnessed significant advances in time series modeling with deep learning. While achieving state-of-the-art results, the best-performing architectures vary highly across applications and domains. Meanwhile, for natural language processing, the Generative Pre-trained Transformer (GPT) has demonstrated impressive performance via training one general-purpose model across various textual datasets. It is intriguing to explore whether GPT-type architectures can be effective for time series, capturing the intrinsic dynamic attributes and leading to significant accuracy improvements. In this paper, we propose a novel framework, TEMPO, that can effectively learn time series representations. We focus on utilizing two essential inductive biases of the time series task for pre-trained models: (i) decomposition of the complex interaction between trend, seasonal and residual components; and (ii) introducing the design of prompts to facilitate distribution adaptation in different types of time series. TEMPO expands the capability for dynamically modeling real-world temporal phenomena from data within diverse domains. Our experiments demonstrate the superior performance of TEMPO over state-of-the-art methods on zero shot setting for a number of time series benchmark datasets. This performance gain is observed not only in scenarios involving previously unseen datasets but also in scenarios with multi-modal inputs. This compelling finding highlights TEMPO's potential to constitute a foundational model-building framework."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/aa8beab0b2913d71a83f4ec71411d87d5c2409b4.pdf"}, "TLDR": {"value": "This work propose a generative pre-trained transformer (GPT) for time series forecasting."}, "_bibtex": {"value": "@inproceedings{\ncao2024tempo,\ntitle={{TEMPO}: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting},\nauthor={Defu Cao and Furong Jia and Sercan O Arik and Tomas Pfister and Yixiang Zheng and Wen Ye and Yan Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YH5w12OUuU}\n}"}, "paperhash": {"value": "cao|tempo_promptbased_generative_pretrained_transformer_for_time_series_forecasting"}}, "number": 8670, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8670/-/Revision", "ICLR.cc/2024/Conference/Submission8670/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8670/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520825744, "cdate": 1695520825744, "tmdate": 1712162817704, "mdate": 1712162817704, "pdate": 1705411046352, "version": 2}, {"id": "u3dX2CEIZb", "forum": "u3dX2CEIZb", "signatures": ["ICLR.cc/2024/Conference/Submission8669/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8669/Authors"], "content": {"title": {"value": "Scaling physics-informed hard constraints with mixture-of-experts"}, "authors": {"value": ["Nithin Chalapathi", "Yiheng Du", "Aditi S. Krishnapriyan"]}, "authorids": {"value": ["~Nithin_Chalapathi1", "~Yiheng_Du1", "~Aditi_S._Krishnapriyan1"]}, "keywords": {"value": ["Physics-Informed Machine Learning", "PDEs", "differentiable optimization", "differentiable physics", "neural networks", "mixture of experts", "constrained optimization", "neural operators"]}, "abstract": {"value": "Imposing known physical constraints, such as conservation laws, during neural network training introduces an inductive bias that can improve accuracy, reliability, convergence, and data efficiency for modeling physical dynamics. While such constraints can be softly imposed via loss function penalties, recent advancements in differentiable physics and optimization improve performance by incorporating PDE-constrained optimization as individual layers in neural networks. This enables a stricter adherence to physical constraints. However, imposing hard constraints significantly increases computational and memory costs, especially for complex dynamical systems. This is because it requires solving an optimization problem over a large number of points in a mesh, representing spatial and temporal discretizations, which greatly increases the complexity of the constraint. To address this challenge, we develop a scalable approach to enforce hard physical constraints using Mixture-of-Experts (MoE), which can be used with any neural network architecture. Our approach imposes the constraint over smaller decomposed domains, each of which is solved by an ``expert'' through differentiable optimization. During training, each expert independently performs a localized backpropagation step by leveraging the implicit function theorem; the independence of each expert allows for parallelization across multiple GPUs. Compared to standard differentiable optimization, our scalable approach achieves greater accuracy in the neural PDE solver setting for predicting the dynamics of challenging non-linear systems. We also improve training stability and require significantly less computation time during both training and inference stages."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0dbb1a4e1eb20fc5d0e7c94834773579d30e5b4b.pdf"}, "_bibtex": {"value": "@inproceedings{\nchalapathi2024scaling,\ntitle={Scaling physics-informed hard constraints with mixture-of-experts},\nauthor={Nithin Chalapathi and Yiheng Du and Aditi S. Krishnapriyan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=u3dX2CEIZb}\n}"}, "TLDR": {"value": "We scale incorporating differentiable PDE-constrained optimization (physics-informed hard constraints) as individual layers in a neural network through a mixture-of-experts formulation."}, "paperhash": {"value": "chalapathi|scaling_physicsinformed_hard_constraints_with_mixtureofexperts"}}, "number": 8669, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8669/-/Revision", "ICLR.cc/2024/Conference/Submission8669/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8669/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520790211, "cdate": 1695520790211, "tmdate": 1709661550077, "mdate": 1709661550077, "pdate": 1705411046311, "version": 2}, {"id": "bvjcMvMn7B", "forum": "bvjcMvMn7B", "signatures": ["ICLR.cc/2024/Conference/Submission8658/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8658/Authors"], "content": {"title": {"value": "Structural Fairness-aware Active Learning for Graph Neural Networks"}, "authors": {"value": ["Haoyu Han", "Xiaorui Liu", "Li Ma", "MohamadAli Torkamani", "Hui Liu", "Jiliang Tang", "Makoto Yamada"]}, "authorids": {"value": ["~Haoyu_Han1", "~Xiaorui_Liu1", "~Li_Ma9", "~MohamadAli_Torkamani1", "~Hui_Liu8", "~Jiliang_Tang1", "~Makoto_Yamada3"]}, "keywords": {"value": ["Active Learning", "Graph Neural Networks", "Structural Fairness"]}, "abstract": {"value": "Graph Neural Networks (GNNs) have seen significant achievements in semi-supervised node classification. Yet, their efficacy often hinges on access to high-quality labeled node samples, which may not always be available in real-world scenarios. While active learning is commonly employed across various domains to pinpoint and label high-quality samples based on data features, graph data present unique challenges due to their intrinsic structures that render nodes non-i.i.d. Furthermore, biases emerge from the positioning of labeled nodes; for instance, nodes closer to the labeled counterparts often yield better performance. To better leverage graph structure and mitigate structural bias in active learning, we present a unified optimization framework (SCARCE), which is also easily incorporated with node features.  Extensive experiments demonstrate that the proposed method not only improves the GNNs performance but also paves the way for more fair results."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1e818b0f851160468dacdfb012e8de08fabf1511.pdf"}, "_bibtex": {"value": "@inproceedings{\nhan2024structural,\ntitle={Structural Fairness-aware Active Learning for Graph Neural Networks},\nauthor={Haoyu Han and Xiaorui Liu and Li Ma and MohamadAli Torkamani and Hui Liu and Jiliang Tang and Makoto Yamada},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bvjcMvMn7B}\n}"}, "paperhash": {"value": "han|structural_fairnessaware_active_learning_for_graph_neural_networks"}}, "number": 8658, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8658/-/Revision", "ICLR.cc/2024/Conference/Submission8658/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8658/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520268147, "cdate": 1695520268147, "tmdate": 1712850669121, "mdate": 1712850669121, "pdate": 1705411045991, "version": 2}, {"id": "FWJAmwE0xH", "forum": "FWJAmwE0xH", "signatures": ["ICLR.cc/2024/Conference/Submission8657/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8657/Authors"], "content": {"title": {"value": "Neural-Symbolic Recursive Machine for Systematic Generalization"}, "authors": {"value": ["Qing Li", "Yixin Zhu", "Yitao Liang", "Ying Nian Wu", "Song-Chun Zhu", "Siyuan Huang"]}, "authorids": {"value": ["~Qing_Li1", "~Yixin_Zhu1", "~Yitao_Liang1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1", "~Siyuan_Huang2"]}, "keywords": {"value": ["Neuro-symbolic AI", "Systematic Generalization", "Compositional Generalization"]}, "abstract": {"value": "Current learning models often struggle with human-like systematic generalization, particularly in learning compositional rules from limited data and extrapolating them to novel combinations. We introduce the Neural-Symbolic Recursive Ma- chine ( NSR), whose core is a Grounded Symbol System ( GSS), allowing for the emergence of combinatorial syntax and semantics directly from training data. The NSR employs a modular design that integrates neural perception, syntactic parsing, and semantic reasoning. These components are synergistically trained through a novel deduction-abduction algorithm. Our findings demonstrate that NSR\u2019s design, imbued with the inductive biases of equivariance and compositionality, grants it the expressiveness to adeptly handle diverse sequence-to-sequence tasks and achieve unparalleled systematic generalization. We evaluate NSR\u2019s efficacy across four challenging benchmarks designed to probe systematic generalization capabilities: SCAN for semantic parsing, PCFG for string manipulation, HINT for arithmetic reasoning, and a compositional machine translation task. The results affirm NSR \u2019s superiority over contemporary neural and hybrid models in terms of generalization and transferability."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/440caa44d54237dd2cb02bb7f536e9fdfceadfba.pdf"}, "supplementary_material": {"value": "/attachment/53b47e622163d9c5441cd1a32768c5f57e6f67e8.zip"}, "TLDR": {"value": "We present Neural-Symbolic Recursive Machine for systematic generalization, which achieves state-of-the-art performance on SCAN, PCFG, and HINT."}, "_bibtex": {"value": "@inproceedings{\nli2024neuralsymbolic,\ntitle={Neural-Symbolic Recursive Machine for Systematic Generalization},\nauthor={Qing Li and Yixin Zhu and Yitao Liang and Ying Nian Wu and Song-Chun Zhu and Siyuan Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FWJAmwE0xH}\n}"}, "paperhash": {"value": "li|neuralsymbolic_recursive_machine_for_systematic_generalization"}}, "number": 8657, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8657/-/Revision", "ICLR.cc/2024/Conference/Submission8657/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8657/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520265058, "cdate": 1695520265058, "tmdate": 1710211566691, "mdate": 1710211566691, "pdate": 1705411045964, "version": 2}, {"id": "ITq4ZRUT4a", "forum": "ITq4ZRUT4a", "signatures": ["ICLR.cc/2024/Conference/Submission8654/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8654/Authors"], "content": {"title": {"value": "Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"}, "authors": {"value": ["Jaemin Cho", "Yushi Hu", "Jason Michael Baldridge", "Roopal Garg", "Peter Anderson", "Ranjay Krishna", "Mohit Bansal", "Jordi Pont-Tuset", "Su Wang"]}, "authorids": {"value": ["~Jaemin_Cho1", "~Yushi_Hu1", "~Jason_Michael_Baldridge1", "roopalgarg@google.com", "~Peter_Anderson1", "~Ranjay_Krishna1", "~Mohit_Bansal2", "~Jordi_Pont-Tuset2", "~Su_Wang4"]}, "keywords": {"value": ["text-to-image generation", "text-to-image evaluation", "Davidsonian semantics", "large language models", "scene graphs", "visual question answering", "question generation", "benchmark"]}, "abstract": {"value": "Evaluating text-to-image models is notoriously difficult. A strong recent approach for assessing text-image faithfulness is based on QG/A (question generation and answering), which uses pre-trained foundational models to automatically generate a set of questions and answers from the prompt, and output images are scored based on whether these answers extracted with a visual question answering model are consistent with the prompt-based answers. This kind of evaluation is naturally dependent on the quality of the underlying QG and VQA models. We identify and address several reliability challenges in existing QG/A work: (a) QG questions should respect the prompt (avoiding hallucinations, duplications, and omissions) and (b) VQA answers should be consistent (not asserting that there is no motorcycle in an image while also claiming the motorcycle is blue). We address these issues with Davidsonian Scene Graph (DSG), an empirically grounded evaluation framework inspired by formal semantics, which is adaptable to any QG/A frameworks. DSG produces atomic and unique questions organized in dependency graphs, which (i) ensure appropriate semantic coverage and (ii) sidestep inconsistent answers. With extensive experimentation and human evaluation on a range of model configurations (LLM, VQA, and T2I), we empirically demonstrate that DSG addresses the challenges noted above. Finally, we present DSG-1k, an open-sourced evaluation benchmark that includes 1,060 prompts, covering a wide range of fine-grained semantic categories with a balanced distribution. We release the DSG-1k prompts and the corresponding DSG questions."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/713250bdf458c9b54444d2bf78bfd594a06adead.pdf"}, "_bibtex": {"value": "@inproceedings{\ncho2024davidsonian,\ntitle={Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation},\nauthor={Jaemin Cho and Yushi Hu and Jason Michael Baldridge and Roopal Garg and Peter Anderson and Ranjay Krishna and Mohit Bansal and Jordi Pont-Tuset and Su Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ITq4ZRUT4a}\n}"}, "paperhash": {"value": "cho|davidsonian_scene_graph_improving_reliability_in_finegrained_evaluation_for_texttoimage_generation"}}, "number": 8654, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8654/-/Revision", "ICLR.cc/2024/Conference/Submission8654/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8654/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520234963, "cdate": 1695520234963, "tmdate": 1710366733345, "mdate": 1710366733345, "pdate": 1705411045887, "version": 2}, {"id": "3EWTEy9MTM", "forum": "3EWTEy9MTM", "signatures": ["ICLR.cc/2024/Conference/Submission8645/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8645/Authors"], "content": {"title": {"value": "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems"}, "authors": {"value": ["Zhiyuan Li", "Hong Liu", "Denny Zhou", "Tengyu Ma"]}, "authorids": {"value": ["~Zhiyuan_Li2", "~Hong_Liu5", "~Denny_Zhou1", "~Tengyu_Ma1"]}, "keywords": {"value": ["Chain of thought", "language modeling", "circuit complexity", "deep learning theory"]}, "abstract": {"value": "Generating a sequence of intermediate steps, \\emph{a.k.a.}, a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. \nThis work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length $n$, previous works have constant-depth transformers with finite precision $\\mathsf{poly}(n)$ embedding size can only solve problems in $\\mathsf{TC}^0$ without CoT. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in $\\mathsf{AC}^0$, a proper subset of $ \\mathsf{TC}^0$. However, with $T$ steps of CoT, constant-depth transformers using constant-bit precision and $O(\\log n)$ embedding size can solve any problem solvable by boolean circuits of size $T$. Empirically, enabling CoT dramatically improves the accuracy for tasks that are hard for parallel computation, including the composition of permutation groups, iterated squaring, and circuit value problems, especially for low-depth transformers."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2c3e913d1014164603f487f70dace6570bb0a1d0.pdf"}, "TLDR": {"value": "We show both theoretically and empirically transformers with polynomial steps of CoT can simulate polysize circuits and thus are strictly more expressive than transformers without CoT."}, "_bibtex": {"value": "@inproceedings{\nli2024chain,\ntitle={Chain of Thought Empowers Transformers to Solve Inherently Serial Problems},\nauthor={Zhiyuan Li and Hong Liu and Denny Zhou and Tengyu Ma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3EWTEy9MTM}\n}"}, "paperhash": {"value": "li|chain_of_thought_empowers_transformers_to_solve_inherently_serial_problems"}}, "number": 8645, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8645/-/Revision", "ICLR.cc/2024/Conference/Submission8645/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8645/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695519700217, "cdate": 1695519700217, "tmdate": 1712197427018, "mdate": 1712197427018, "pdate": 1705411045600, "version": 2}, {"id": "pmweVpJ229", "forum": "pmweVpJ229", "signatures": ["ICLR.cc/2024/Conference/Submission8643/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8643/Authors"], "content": {"title": {"value": "Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy"}, "authors": {"value": ["Yingyu Lin", "Yian Ma", "Yu-Xiang Wang", "Rachel Emily Redberg", "Zhiqi Bu"]}, "authorids": {"value": ["~Yingyu_Lin1", "~Yian_Ma1", "~Yu-Xiang_Wang1", "~Rachel_Emily_Redberg1", "~Zhiqi_Bu1"]}, "keywords": {"value": ["Pure Differential Privacy", "Monte Carlo sampling", "Gaussian Differential Privacy", "Exponential Mechanism"]}, "TLDR": {"value": "We propose an approximate Monte Carlo sampling method to achieve pure and Gaussian differential privacy."}, "abstract": {"value": "Posterior sampling, i.e., exponential mechanism to sample from the posterior distribution, provides $\\varepsilon$-pure differential privacy (DP) guarantees and does not suffer from potentially unbounded privacy breach introduced by $(\\varepsilon,\\delta)$-approximate DP. In practice, however, one needs to apply approximate sampling methods such as Markov chain Monte Carlo (MCMC), thus re-introducing the unappealing $\\delta$-approximation error into the privacy guarantees. To bridge this gap, we propose the Approximate SAample Perturbation (abbr. ASAP) algorithm which perturbs an MCMC sample with noise proportional to its Wasserstein-infinity ($W_\\infty$) distance from a reference distribution that satisfies pure DP or pure Gaussian DP (i.e., $\\delta=0$). We then leverage a Metropolis-Hastings algorithm to generate the sample and prove that the algorithm converges in W$_\\infty$ distance. We show that by combining our new techniques with a localization step, we obtain the first nearly linear-time algorithm that achieves the optimal rates in the DP-ERM problem with strongly convex and smooth losses."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/98377763ad27f9f0dab3a807c831a7d2b1e123ef.pdf"}, "_bibtex": {"value": "@inproceedings{\nlin2024tractable,\ntitle={Tractable {MCMC} for Private Learning with Pure and Gaussian Differential Privacy},\nauthor={Yingyu Lin and Yian Ma and Yu-Xiang Wang and Rachel Emily Redberg and Zhiqi Bu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pmweVpJ229}\n}"}, "paperhash": {"value": "lin|tractable_mcmc_for_private_learning_with_pure_and_gaussian_differential_privacy"}}, "number": 8643, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8643/-/Revision", "ICLR.cc/2024/Conference/Submission8643/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8643/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695519568614, "cdate": 1695519568614, "tmdate": 1713171946403, "mdate": 1713171946403, "pdate": 1705411045571, "version": 2}, {"id": "RsJwmWvE6Q", "forum": "RsJwmWvE6Q", "signatures": ["ICLR.cc/2024/Conference/Submission8639/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8639/Authors"], "content": {"title": {"value": "Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms"}, "authors": {"value": ["Yi Li", "Honghao Lin", "David Woodruff"]}, "authorids": {"value": ["~Yi_Li8", "~Honghao_Lin1", "~David_Woodruff1"]}, "keywords": {"value": ["Sketching", "Residual error", "Low-rank approximation", "sparse recovery"]}, "abstract": {"value": "We study the problem of residual error estimation for matrix and vector norms using a linear sketch. Such estimates can be used, for example, to quickly assess how useful a more expensive low-rank approximation computation will be. The matrix case concerns the Frobenius norm and the task is to approximate the $k$-residual $\\|A - A_k\\|_F$ of the input matrix $A$ within a $(1+\\epsilon)$-factor, where $A_k$ is the optimal rank-$k$ approximation. We provide a tight bound of $\\Theta(k^2/\\epsilon^4)$ on the size of bilinear sketches, which have the form of a matrix product $SAT$. This improves the previous $O(k^2/\\epsilon^6)$ upper bound in (Andoni et al. SODA 2013) and gives the first non-trivial lower bound, to the best of our knowledge. \nIn our algorithm, our sketching matrices $S$ and $T$ can both be sparse matrices, allowing for a very fast update time. \nWe demonstrate that this gives a substantial advantage empirically, for roughly the same sketch size and accuracy as in previous work. \n\nFor the vector case, we consider the $\\ell_p$-norm for $p>2$, where the task is to approximate the $k$-residual $\\|x - x_k\\|_p$ up to a constant factor, where $x_k$ is the optimal $k$-sparse approximation to $x$. Such vector norms are frequently studied in the data stream literature and are useful for finding frequent items or so-called heavy hitters. We establish an upper bound of $O(k^{2/p}n^{1-2/p}\\operatorname{poly}(\\log n))$ for constant $\\epsilon$ on the dimension of a linear sketch for this problem. Our algorithm can be extended to the $\\ell_p$ sparse recovery problem with the same sketching dimension, which seems to be the first such bound for $p > 2$. We also show an $\\Omega(k^{2/p}n^{1-2/p})$ lower bound for the sparse recovery problem, which is tight up to a $\\mathrm{poly}(\\log n)$ factor."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7f94d35697799a150e50b5657014861583975c50.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024optimal,\ntitle={Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms},\nauthor={Yi Li and Honghao Lin and David Woodruff},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RsJwmWvE6Q}\n}"}, "paperhash": {"value": "li|optimal_sketching_for_residual_error_estimation_for_matrix_and_vector_norms"}}, "number": 8639, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8639/-/Revision", "ICLR.cc/2024/Conference/Submission8639/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8639/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695519288128, "cdate": 1695519288128, "tmdate": 1710564900315, "mdate": 1710564900315, "pdate": 1705411045463, "version": 2}, {"id": "kIPEyMSdFV", "forum": "kIPEyMSdFV", "signatures": ["ICLR.cc/2024/Conference/Submission8638/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8638/Authors"], "content": {"title": {"value": "Reverse Diffusion Monte Carlo"}, "authors": {"value": ["Xunpeng Huang", "Hanze Dong", "Yifan HAO", "Yian Ma", "Tong Zhang"]}, "authorids": {"value": ["~Xunpeng_Huang2", "~Hanze_Dong1", "~Yifan_HAO2", "~Yian_Ma1", "~Tong_Zhang2"]}, "keywords": {"value": ["posterior Sampling", "multi-modal sampling", "diffusion process"]}, "abstract": {"value": "We propose a Monte Carlo sampler from the reverse diffusion process. Unlike the practice of diffusion models, where the intermediary updates---the score functions---are learned with a neural network, we transform the score matching problem into a mean estimation one.\nBy estimating the means of the regularized posterior distributions, we derive a novel Monte Carlo sampling algorithm called reverse diffusion Monte Carlo (rdMC), which is distinct from the Markov chain Monte Carlo (MCMC) methods. We determine the sample size from the error tolerance and the properties of the posterior distribution to yield an algorithm that can approximately sample the target distribution with any desired accuracy. Additionally, we demonstrate and prove under suitable conditions that sampling with rdMC can be significantly faster than that with MCMC.  For multi-modal target distributions such as those in Gaussian mixture models, rdMC greatly improves over the Langevin-style MCMC sampling methods both theoretically and in practice. The proposed rdMC method offers a new perspective and solution beyond classical MCMC algorithms for the challenging complex distributions."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5e05dd8867eb805ba66920ee894e0234bbfd718d.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024reverse,\ntitle={Reverse Diffusion Monte Carlo},\nauthor={Xunpeng Huang and Hanze Dong and Yifan HAO and Yian Ma and Tong Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kIPEyMSdFV}\n}"}, "paperhash": {"value": "huang|reverse_diffusion_monte_carlo"}}, "number": 8638, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8638/-/Revision", "ICLR.cc/2024/Conference/Submission8638/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8638/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695519252515, "cdate": 1695519252515, "tmdate": 1709661549792, "mdate": 1709661549792, "pdate": 1705411045426, "version": 2}, {"id": "qaJxPhkYtD", "forum": "qaJxPhkYtD", "signatures": ["ICLR.cc/2024/Conference/Submission8631/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8631/Authors"], "content": {"title": {"value": "Counting Graph Substructures with Graph Neural Networks"}, "authors": {"value": ["Charilaos Kanatsoulis", "Alejandro Ribeiro"]}, "authorids": {"value": ["~Charilaos_Kanatsoulis1", "~Alejandro_Ribeiro1"]}, "keywords": {"value": ["graph neural networks", "expressive power", "representation learning", "subgraph isomorphism", "cliques", "cycles", "motifs", "substructures", "count", "message-passing"]}, "TLDR": {"value": "This paper studies the ability of message-passing graph neural networks to count graph substructures."}, "abstract": {"value": "Graph Neural Networks (GNNs) are powerful representation learning tools that have achieved remarkable performance in various downstream tasks. However, there are still open questions regarding their ability to count and list substructures, which play a crucial role in biological and social networks. In this work, we fill this gap and characterize the representation {and generalization} power of GNNs in terms of their ability to produce powerful representations that count substructures. In particular, we study the message-passing operations of GNNs with random node input in a novel fashion, and show how they can produce equivariant representations that are associated with high-order statistical moments. Using these representations, we prove that GNNs can learn how to count cycles, {cliques}, quasi-cliques, and the number of connected components in a graph. We also provide new insights into the generalization capacity of GNNs. Our analysis is constructive and enables the design of a generic GNN architecture that shows remarkable performance in four distinct tasks: cycle detection, cycle counting, graph classification, and molecular property prediction."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e67f6c96c22a1385e79288f9c495a280f91cb6f7.pdf"}, "_bibtex": {"value": "@inproceedings{\nkanatsoulis2024counting,\ntitle={Counting Graph Substructures with Graph Neural Networks},\nauthor={Charilaos Kanatsoulis and Alejandro Ribeiro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qaJxPhkYtD}\n}"}, "paperhash": {"value": "kanatsoulis|counting_graph_substructures_with_graph_neural_networks"}}, "number": 8631, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8631/-/Revision", "ICLR.cc/2024/Conference/Submission8631/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8631/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695518830353, "cdate": 1695518830353, "tmdate": 1713070733863, "mdate": 1713070733863, "pdate": 1705411045231, "version": 2}, {"id": "w1JanwReU6", "forum": "w1JanwReU6", "signatures": ["ICLR.cc/2024/Conference/Submission8612/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8612/Authors"], "content": {"title": {"value": "Are Models Biased on Text without Gender-related Language?"}, "authors": {"value": ["Catarina G Bel\u00e9m", "Preethi Seshadri", "Yasaman Razeghi", "Sameer Singh"]}, "authorids": {"value": ["~Catarina_G_Bel\u00e9m1", "~Preethi_Seshadri2", "~Yasaman_Razeghi1", "~Sameer_Singh1"]}, "keywords": {"value": ["Large language models", "bias evaluation", "gender bias", "gender co-occurring words", "gender-invariant", "pretraining data statistics"]}, "TLDR": {"value": "\"Do large language models still favor one gender over the other in non-stereotypical settings? We study this question in the gender pronoun setting and show that, surprisingly, 20 popular LLMs still exhibit gender bias in 50-90% of the examples\""}, "abstract": {"value": "Gender bias research has been pivotal in revealing undesirable behaviors in large language models, exposing serious gender stereotypes associated with occupations, and emotions. A key assumption in prior works is that models reinforce stereotypes in the training data by picking up on gendered correlations. In this paper, we challenge this assumption and instead address the question: *Do language models still exhibit gender bias in non-stereotypical settings?* To do so, we introduce *UnStereoEval* (USE), a novel framework tailored for investigating gender bias in stereotype-free scenarios. USE defines a sentence-level score based on pretraining data statistics to determine if the sentence contain minimal word-gender associations. To systematically benchmark the fairness of popular language models in stereotype-free scenarios, we utilize USE to automatically generate benchmarks without any gender-related language.  By leveraging USE's sentence-level score, we also repurpose prior gender bias benchmarks (Winobias and Winogender) for non-stereotypical evaluation. Surprisingly, we find low fairness across all 28 tested models.  Concretely, models demonstrate fair behavior in only 9%-41% of stereotype-free sentences, suggesting that bias does not solely stem from the presence of gender-related words. These results raise important questions about where underlying model biases come from and highlight the need for more systematic and comprehensive bias evaluation. We release the full dataset and code on [github](https://github.com/ucinlp/unstereo-eval)."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a3245021ca7646cb39a3b3ccde88411a2af7ab65.pdf"}, "_bibtex": {"value": "@inproceedings{\nbel{\\'e}m2024are,\ntitle={Are Models Biased on Text without Gender-related Language?},\nauthor={Catarina G Bel{\\'e}m and Preethi Seshadri and Yasaman Razeghi and Sameer Singh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w1JanwReU6}\n}"}, "paperhash": {"value": "bel\u00e9m|are_models_biased_on_text_without_genderrelated_language"}}, "number": 8612, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8612/-/Revision", "ICLR.cc/2024/Conference/Submission8612/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8612/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695517935031, "cdate": 1695517935031, "tmdate": 1713165591189, "mdate": 1713165591189, "pdate": 1705411044785, "version": 2}, {"id": "dFcXJgnrGB", "forum": "dFcXJgnrGB", "signatures": ["ICLR.cc/2024/Conference/Submission8605/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8605/Authors"], "content": {"title": {"value": "PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning"}, "authors": {"value": ["Faeze Brahman", "Chandra Bhagavatula", "Valentina Pyatkin", "Jena D. Hwang", "Xiang Lorraine Li", "Hirona Jacqueline Arai", "Soumya Sanyal", "Keisuke Sakaguchi", "Xiang Ren", "Yejin Choi"]}, "authorids": {"value": ["~Faeze_Brahman1", "~Chandra_Bhagavatula1", "~Valentina_Pyatkin1", "~Jena_D._Hwang1", "~Xiang_Lorraine_Li1", "~Hirona_Jacqueline_Arai1", "~Soumya_Sanyal1", "~Keisuke_Sakaguchi2", "~Xiang_Ren1", "~Yejin_Choi1"]}, "keywords": {"value": ["language-based planning", "procedural/script knowledge", "distillation", "large language models", "decoding-time algorithm"]}, "TLDR": {"value": "We propose a novel two-pronged approach to endow small language models with procedural knowledge and (constrained) language-based planning capabilities through knowledge distillation and an inference-time algorithm."}, "abstract": {"value": "Procedural planning, which entails decomposing a high-level goal into a sequence of temporally ordered steps, is an important yet intricate task for machines. It involves integrating common-sense knowledge to reason about complex and often contextualized situations, e.g. ``scheduling a doctor's appointment without a phone''. While current approaches show encouraging results using large language models (LLMs), they are hindered by drawbacks such as costly API calls and reproducibility issues. In this paper, we advocate planning using smaller language models. We present PlaSma, a novel two-pronged approach to endow small language models with procedural knowledge and (constrained) language-based planning capabilities. More concretely, we develop *symbolic procedural knowledge distillation* to enhance the commonsense knowledge in small language models and an *inference-time algorithm* to facilitate more structured and accurate reasoning. In addition, we introduce a new related task, *Replanning*, that requires a revision of a plan to cope with a constrained situation. In both the planning and replanning settings, we show that orders-of-magnitude smaller models (770M-11B parameters) can compete and often surpass their larger teacher models' capabilities. Finally, we showcase successful application of PlaSma in an embodied environment, VirtualHome."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b88eaa0cc84120348881ebfc5dd4fe00210337df.pdf"}, "_bibtex": {"value": "@inproceedings{\nbrahman2024plasma,\ntitle={PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning},\nauthor={Faeze Brahman and Chandra Bhagavatula and Valentina Pyatkin and Jena D. Hwang and Xiang Lorraine Li and Hirona Jacqueline Arai and Soumya Sanyal and Keisuke Sakaguchi and Xiang Ren and Yejin Choi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dFcXJgnrGB}\n}"}, "paperhash": {"value": "brahman|plasma_procedural_knowledge_models_for_languagebased_planning_and_replanning"}}, "number": 8605, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8605/-/Revision", "ICLR.cc/2024/Conference/Submission8605/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8605/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695517527541, "cdate": 1695517527541, "tmdate": 1710551144641, "mdate": 1710551144641, "pdate": 1705411044652, "version": 2}, {"id": "PfPnugdxup", "forum": "PfPnugdxup", "signatures": ["ICLR.cc/2024/Conference/Submission8604/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8604/Authors"], "content": {"title": {"value": "From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction"}, "authors": {"value": ["Nima Shoghi", "Adeesh Kolluru", "John R. Kitchin", "Zachary Ward Ulissi", "C. Lawrence Zitnick", "Brandon M Wood"]}, "authorids": {"value": ["~Nima_Shoghi1", "~Adeesh_Kolluru1", "~John_R._Kitchin1", "~Zachary_Ward_Ulissi1", "~C._Lawrence_Zitnick2", "~Brandon_M_Wood1"]}, "keywords": {"value": ["atomic property prediction", "pre-training", "3D atomic pre-training", "graph neural networks", "multi-task learning", "molecules", "materials"]}, "TLDR": {"value": "We pre-train a large model on multiple chemical datasets in a multi-task learning framework to generate transferable atomic representations that can be fine-tuned for SOTA results across various tasks."}, "abstract": {"value": "Foundation models have been transformational in machine learning fields such as natural language processing and computer vision. Similar success in atomic property prediction has been limited due to the challenges of training effective models across multiple chemical domains. To address this, we introduce Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that simultaneously trains on multiple datasets from different chemical domains, treating each dataset as a unique pre-training task within a multi-task framework. Our combined training dataset consists of $\\sim$120M systems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and generalization by fine-tuning over a diverse set of downstream tasks and datasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP demonstrates an average improvement of 59% over training from scratch and matches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the potential of pre-training strategies that utilize diverse data to advance property prediction across chemical domains, especially for low-data tasks."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7ae9e4f5f396605dfda891057be51e0ec4e42fdc.pdf"}, "_bibtex": {"value": "@inproceedings{\nshoghi2024from,\ntitle={From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction},\nauthor={Nima Shoghi and Adeesh Kolluru and John R. Kitchin and Zachary Ward Ulissi and C. Lawrence Zitnick and Brandon M Wood},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PfPnugdxup}\n}"}, "paperhash": {"value": "shoghi|from_molecules_to_materials_pretraining_large_generalizable_models_for_atomic_property_prediction"}}, "number": 8604, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8604/-/Revision", "ICLR.cc/2024/Conference/Submission8604/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8604/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695517516805, "cdate": 1695517516805, "tmdate": 1713135263243, "mdate": 1713135263243, "pdate": 1705411044637, "version": 2}, {"id": "Zc2aIcucwc", "forum": "Zc2aIcucwc", "signatures": ["ICLR.cc/2024/Conference/Submission8594/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8594/Authors"], "content": {"title": {"value": "Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"}, "authors": {"value": ["Dominique Beaini", "Shenyang Huang", "Joao Alex Cunha", "Zhiyi Li", "Gabriela Moisescu-Pareja", "Oleksandr Dymov", "Samuel Maddrell-Mander", "Callum McLean", "Frederik Wenkel", "Luis M\u00fcller", "Jama Hussein Mohamud", "Ali Parviz", "Michael Craig", "Micha\u0142 Koziarski", "Jiarui Lu", "Zhaocheng Zhu", "Cristian Gabellini", "Kerstin Klaser", "Josef Dean", "Cas Wognum", "Maciej Sypetkowski", "Guillaume Rabusseau", "Reihaneh Rabbany", "Jian Tang", "Christopher Morris", "Mirco Ravanelli", "Guy Wolf", "Prudencio Tossou", "Hadrien Mary", "Therence Bois", "Andrew William Fitzgibbon", "Blazej Banaszewski", "Chad Martin", "Dominic Masters"]}, "authorids": {"value": ["~Dominique_Beaini1", "~Shenyang_Huang1", "~Joao_Alex_Cunha1", "~Zhiyi_Li1", "~Gabriela_Moisescu-Pareja1", "~Oleksandr_Dymov1", "~Samuel_Maddrell-Mander1", "~Callum_McLean1", "~Frederik_Wenkel1", "~Luis_M\u00fcller1", "~Jama_Hussein_Mohamud1", "~Ali_Parviz1", "~Michael_Craig1", "~Micha\u0142_Koziarski1", "~Jiarui_Lu2", "~Zhaocheng_Zhu1", "~Cristian_Gabellini1", "~Kerstin_Klaser1", "~Josef_Dean1", "~Cas_Wognum1", "~Maciej_Sypetkowski1", "~Guillaume_Rabusseau1", "~Reihaneh_Rabbany1", "~Jian_Tang1", "~Christopher_Morris1", "~Mirco_Ravanelli1", "~Guy_Wolf1", "~Prudencio_Tossou1", "~Hadrien_Mary1", "~Therence_Bois1", "~Andrew_William_Fitzgibbon1", "~Blazej_Banaszewski1", "~Chad_Martin1", "~Dominic_Masters1"]}, "keywords": {"value": ["graph neural networks", "Datasets", "molecules", "molecular graphs", "Quantum", "Multi-task", "foundation model"]}, "TLDR": {"value": "By far the largest datasets for 2D molecular graphs, both in terms of number of unique molecules and number of tasks, and a new library for multi-task GNNs."}, "abstract": {"value": "Recently, pre-trained foundation models have enabled significant advancements in multiple fields. In molecular machine learning, however, where datasets are often hand-curated, and hence typically small, the lack of datasets with labeled features, and codebases to manage those datasets, has hindered the development of foundation models. In this work, we present seven novel datasets categorized by size into three distinct categories: ToyMix, LargeMix and UltraLarge. These datasets push the boundaries in both the scale and the diversity of supervised labels for molecular learning. They cover nearly 100 million molecules and over 3000 sparsely defined tasks, totaling more than 13 billion individual labels of both quantum and biological nature. In comparison, our datasets contain 300 times more data points than the widely used OGB-LSC PCQM4Mv2 dataset, and 13 times more than the quantum-only QM1B dataset. In addition, to support the development of foundational models based on our proposed datasets, we present the Graphium graph machine learning library which simplifies the process of building and training molecular machine learning models for multi-task and multi-level molecular datasets. Finally, we present a range of baseline results as a starting point of multi-task and multi-level training on these datasets. Empirically, we observe that performance on low-resource biological datasets show improvement by also training on large amounts of quantum data. This indicates that there may be potential in multi-task and multi-level training of a foundation model and fine-tuning it to resource-constrained downstream tasks. The Graphium library is publicly available on Github and the dataset links are available in Part 1 and Part 2."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/070fcd7e5f031fc5d671ef14723f848bdc7a540b.pdf"}, "_bibtex": {"value": "@inproceedings{\nbeaini2024towards,\ntitle={Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets},\nauthor={Dominique Beaini and Shenyang Huang and Joao Alex Cunha and Zhiyi Li and Gabriela Moisescu-Pareja and Oleksandr Dymov and Samuel Maddrell-Mander and Callum McLean and Frederik Wenkel and Luis M{\\\"u}ller and Jama Hussein Mohamud and Ali Parviz and Michael Craig and Micha{\\l} Koziarski and Jiarui Lu and Zhaocheng Zhu and Cristian Gabellini and Kerstin Klaser and Josef Dean and Cas Wognum and Maciej Sypetkowski and Guillaume Rabusseau and Reihaneh Rabbany and Jian Tang and Christopher Morris and Mirco Ravanelli and Guy Wolf and Prudencio Tossou and Hadrien Mary and Therence Bois and Andrew William Fitzgibbon and Blazej Banaszewski and Chad Martin and Dominic Masters},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Zc2aIcucwc}\n}"}, "paperhash": {"value": "beaini|towards_foundational_models_for_molecular_learning_on_largescale_multitask_datasets"}}, "number": 8594, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8594/-/Revision", "ICLR.cc/2024/Conference/Submission8594/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8594/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695517008517, "cdate": 1695517008517, "tmdate": 1710253758941, "mdate": 1710253758941, "pdate": 1705411044326, "version": 2}, {"id": "w50MQ9Vfty", "forum": "w50MQ9Vfty", "signatures": ["ICLR.cc/2024/Conference/Submission8589/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8589/Authors"], "content": {"title": {"value": "Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference"}, "authors": {"value": ["Chencheng Cai", "Xu Zhang", "Edoardo Airoldi"]}, "authorids": {"value": ["~Chencheng_Cai1", "~Xu_Zhang25", "~Edoardo_Airoldi1"]}, "keywords": {"value": ["Causal inference", "Design of experiments", "Interference", "Random graph", "Spillover effects", "Treatment effects", "Potential outcomes"]}, "TLDR": {"value": "We propose a novel design of experiments for estimating treatment and spillover effects under network interference."}, "abstract": {"value": "Interference is ubiquitous when conducting causal experiments over networks. Except for certain network structures, causal inference on the network in the presence of interference is difficult due to the entanglement between the treatment assignments and the interference levels. In this article, we conduct causal inference under interference on an observed, sparse, but connected network, and we propose a novel design of experiments based on an independent set. Compared to conventional designs, the independent-set design focuses on an independent subset of data and controls their interference exposures through the assignments to the rest (auxiliary set). We provide a lower bound on the size of the independent set from a greedy algorithm and justify the theoretical performance of estimators under the proposed design. Our approach is capable of estimating both spillover effects and treatment effects. We justify its superiority over conventional methods and illustrate the empirical performance through simulations."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4a5c46e185cf5147131948b3a81949edc248583b.pdf"}, "_bibtex": {"value": "@inproceedings{\ncai2024independentset,\ntitle={Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference},\nauthor={Chencheng Cai and Xu Zhang and Edoardo Airoldi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w50MQ9Vfty}\n}"}, "paperhash": {"value": "cai|independentset_design_of_experiments_for_estimating_treatment_and_spillover_effects_under_network_interference"}}, "number": 8589, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8589/-/Revision", "ICLR.cc/2024/Conference/Submission8589/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8589/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695516851987, "cdate": 1695516851987, "tmdate": 1710540877938, "mdate": 1710540877938, "pdate": 1705411044325, "version": 2}, {"id": "gPKTTAfYBp", "forum": "gPKTTAfYBp", "signatures": ["ICLR.cc/2024/Conference/Submission8584/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8584/Authors"], "content": {"title": {"value": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"}, "authors": {"value": ["Daniel Y Fu", "Hermann Kumbong", "Eric Nguyen", "Christopher Re"]}, "authorids": {"value": ["~Daniel_Y_Fu1", "~Hermann_Kumbong1", "~Eric_Nguyen1", "~Christopher_Re1"]}, "keywords": {"value": ["convolutions", "GPUs", "hardware-efficient algorithms", "long context", "fast fourier transform", "I/O awareness"]}, "TLDR": {"value": "We propose FlashFFTConv, a new system that optimizes the FFT convolution algorithm to speed up long convolutions and enable long-sequence applications."}, "abstract": {"value": "Convolution models with long filters have demonstrated state-of-the-art reasoning abilities in many long-sequence tasks but lag behind the most optimized Transformers in wall-clock time.\nA major bottleneck is the Fast Fourier Transform (FFT)---which allows long convolutions to run in $O(N\\log N)$ time in sequence length $N$ but has poor hardware utilization.\nIn this paper, we study how to optimize the FFT convolution.\nWe find two key bottlenecks: the FFT does not effectively use specialized matrix multiply units, and it incurs expensive I/O between layers of the memory hierarchy.\nIn response, we propose FlashFFTConv.\nFlashFFTConv uses a matrix decomposition that computes the FFT using matrix multiply units and enables kernel fusion for long sequences, reducing I/O.\nWe also present two sparse convolution algorithms---1) partial convolutions and 2) frequency-sparse convolutions---which can be implemented simply by skipping blocks in the matrix decomposition, enabling further opportunities for memory and compute savings.\nFlashFFTConv speeds up exact FFT convolutions by up to 8.7$\\times$ over PyTorch and achieves up to 4.4$\\times$ speedup end-to-end.\nGiven the same compute budget, FlashFFTConv allows Hyena-GPT-s to achieve 2.3 points better perplexity and M2-BERT-base to achieve 3.3 points higher GLUE score---matching models with twice the parameter count.\nFlashFFTConv also achieves 96.1% accuracy on Path-512, a high-resolution vision task where no model had previously achieved better than 50%.\nFurthermore, partial convolutions enable longer-sequence models---yielding the first DNA model that can process the longest human genes (2.3M base pairs)---and frequency-sparse convolutions speed up pretrained models while maintaining or improving model quality."}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c77f3c8f339aae3682e72c37d33ce5bf90cd1134.pdf"}, "supplementary_material": {"value": "/attachment/0c489cf1f8c688a2f44e0e20004fe4a153e4b0f4.zip"}, "_bibtex": {"value": "@inproceedings{\nfu2024flashfftconv,\ntitle={Flash{FFTC}onv: Efficient Convolutions for Long Sequences with Tensor Cores},\nauthor={Daniel Y Fu and Hermann Kumbong and Eric Nguyen and Christopher Re},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gPKTTAfYBp}\n}"}, "paperhash": {"value": "fu|flashfftconv_efficient_convolutions_for_long_sequences_with_tensor_cores"}}, "number": 8584, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8584/-/Revision", "ICLR.cc/2024/Conference/Submission8584/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8584/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695516529598, "cdate": 1695516529598, "tmdate": 1710643622792, "mdate": 1710643622792, "pdate": 1705411044209, "version": 2}, {"id": "oDdzXQzP2F", "forum": "oDdzXQzP2F", "signatures": ["ICLR.cc/2024/Conference/Submission8575/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8575/Authors"], "content": {"title": {"value": "Transformer-VQ: Linear-Time Transformers via Vector Quantization"}, "authors": {"value": ["Lucas Dax Lingle"]}, "authorids": {"value": ["~Lucas_Dax_Lingle1"]}, "keywords": {"value": ["Transformer", "Transformer Decoder", "Decoder-Only Transformer", "Natural Language Processing", "NLP", "Vector Quantization", "VQ", "K-Means", "Clustering", "Causal Attention", "Autoregressive Attention", "Efficient Attention", "Linear-Time Attention", "Autoregressive Modeling", "Generative Modeling", "Gated Attention", "Compressive Attention", "Kernelized Attention", "Kernelizable Attention", "Hierarchical Attention", "Segment-Level Recurrent Attention", "Long-Context Modeling", "Long-Range Modeling", "Long-Range Dependencies", "Long-Term Dependencies", "Cached Attention", "Shift-Equivariant Attention"]}, "TLDR": {"value": "Simple, efficient, and stable decoder-only attention via vector quantization"}, "abstract": {"value": "We introduce Transformer-VQ, a decoder-only transformer computing softmax-based dense self-attention in linear time.  Transformer-VQ's efficient attention is enabled by vector-quantized keys and a novel caching mechanism. \nIn our large-scale experiments, Transformer-VQ is shown highly competitive in quality, obtaining 0.99 bpb on Enwik8, 26.6 ppl on PG-19, and 3.16 bpb on ImageNet64. In addition, the optimized implementation of Transformer-VQ is over 3x faster than a comparable quadratic-time transformer at sequence length 8k, is over 12x faster at 32k, and can scale to 131k with similar throughput. Code available: \\url{https://github.com/transformer-vq/transformer_vq}"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9dfab016ded80c8754b4868d9dc2a054a8f347b6.pdf"}, "_bibtex": {"value": "@inproceedings{\nlingle2024transformervq,\ntitle={Transformer-{VQ}: Linear-Time Transformers via Vector Quantization},\nauthor={Lucas Dax Lingle},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oDdzXQzP2F}\n}"}, "paperhash": {"value": "lingle|transformervq_lineartime_transformers_via_vector_quantization"}}, "number": 8575, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8575/-/Revision", "ICLR.cc/2024/Conference/Submission8575/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8575/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695516047186, "cdate": 1695516047186, "tmdate": 1709661549403, "mdate": 1709661549403, "pdate": 1705411044106, "version": 2}, {"id": "4g02l2N2Nx", "forum": "4g02l2N2Nx", "signatures": ["ICLR.cc/2024/Conference/Submission8562/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8562/Authors"], "content": {"title": {"value": "The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry"}, "authors": {"value": ["Michael Zhang", "Kush Bhatia", "Hermann Kumbong", "Christopher Re"]}, "authorids": {"value": ["~Michael_Zhang4", "~Kush_Bhatia3", "~Hermann_Kumbong1", "~Christopher_Re1"]}, "keywords": {"value": ["linear attention", "transformers"]}, "abstract": {"value": "Linear attentions have shown promise for improving Transformer efficiency, reducing attention's quadratic complexity to linear in sequence length. This holds exciting promise for (1) training linear Transformers from scratch, (2) `inetuned-conversion of task-specific Transformers into linear versions that recover task performance, and (3) pretrained-conversion of Transformers, such as language models, into linear versions readily finetunable on downstream tasks. However, linear attentions often underperform compared to standard softmax attention. To close this performance gap, we study the behaviors of softmax and linear attentions in various train-from-scratch and finetuned-conversion settings. We find prior linear attentions lack key properties of softmax attention tied to good performance: low-entropy (or spiky) weights and dot-product monotonicity. We further observe surprisingly simple feature maps that retain these properties match softmax performance, but are inefficient to compute in linear attention. We thus propose Hedgehog, a learnable linear attention that retains the spiky and monotonic properties of softmax attention while maintaining linear complexity. Hedgehog uses simple, trainable MLPs to produce attention weights mimicking softmax attention. Experiments show Hedgehog recovers over 99\\% of standard Transformer performance in train-from-scratch and finetuned-conversion settings, outperforming prior linear attentions by up to 6 perplexity points on WikiText-103 when training causal GPT models from scratch, and up to 8.7 GLUE score points when converting finetuned bidirectional BERT models. Hedgehog also enables pretrained-conversion. Converting a pretrained GPT-2 into a linear attention variant achieves state-of-the-art 16.7 perplexity on WikiText-103 for 125M subquadratic decoder models. We finally turn a pretrained Llama-2 7B into a viable linear attention Llama. With low-rank adaptation, Hedgehog-Llama-2 7B achieves 28.1 higher ROUGE-1 points over the base standard attention model, where prior linear attentions lead to 16.5 point drops."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/253a4c0c2132cbb269cad956934997223cc2c5c0.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024the,\ntitle={The Hedgehog \\& the Porcupine: Expressive Linear Attentions with Softmax Mimicry},\nauthor={Michael Zhang and Kush Bhatia and Hermann Kumbong and Christopher Re},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4g02l2N2Nx}\n}"}, "paperhash": {"value": "zhang|the_hedgehog_the_porcupine_expressive_linear_attentions_with_softmax_mimicry"}}, "number": 8562, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8562/-/Revision", "ICLR.cc/2024/Conference/Submission8562/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8562/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695515621460, "cdate": 1695515621460, "tmdate": 1710713947666, "mdate": 1710713947666, "pdate": 1705411043806, "version": 2}, {"id": "XNa6r6ZjoB", "forum": "XNa6r6ZjoB", "signatures": ["ICLR.cc/2024/Conference/Submission8558/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8558/Authors"], "content": {"title": {"value": "Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers"}, "authors": {"value": ["Awni Altabaa", "Taylor Whittington Webb", "Jonathan D. Cohen", "John Lafferty"]}, "authorids": {"value": ["~Awni_Altabaa1", "~Taylor_Whittington_Webb1", "~Jonathan_D._Cohen1", "~John_Lafferty2"]}, "keywords": {"value": ["relational representation learning", "attention", "transformers", "sequence models", "abstract representations"]}, "abstract": {"value": "An extension of Transformers is proposed that enables explicit relational reasoning through a novel module called the *Abstractor*. At the core of the Abstractor is a variant of attention called *relational cross-attention*. The approach is motivated by an architectural inductive bias for relational learning that disentangles relational information from object-level features. This enables explicit relational reasoning, supporting abstraction and generalization from limited data. The Abstractor is first evaluated on simple discriminative relational tasks and compared to existing relational architectures. Next, the Abstractor is evaluated on purely relational sequence-to-sequence tasks, where dramatic improvements are seen in sample efficiency compared to standard Transformers. Finally, Abstractors are evaluated on a collection of tasks based on mathematical problem solving, where consistent improvements in performance and sample efficiency are observed."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/24529d393a107ced3db4542a44c29da2edba8d83.pdf"}, "supplementary_material": {"value": "/attachment/dfc553de22a91c9b71ab86263ed22b284a12ad13.zip"}, "TLDR": {"value": "An extension of Transformers is proposed for explicit representation of relational information."}, "_bibtex": {"value": "@inproceedings{\naltabaa2024abstractors,\ntitle={Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers},\nauthor={Awni Altabaa and Taylor Whittington Webb and Jonathan D. Cohen and John Lafferty},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XNa6r6ZjoB}\n}"}, "paperhash": {"value": "altabaa|abstractors_and_relational_crossattention_an_inductive_bias_for_explicit_relational_reasoning_in_transformers"}}, "number": 8558, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8558/-/Revision", "ICLR.cc/2024/Conference/Submission8558/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8558/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695515486447, "cdate": 1695515486447, "tmdate": 1712958898030, "mdate": 1712958898030, "pdate": 1705411043679, "version": 2}, {"id": "OF5x1dzWSS", "forum": "OF5x1dzWSS", "signatures": ["ICLR.cc/2024/Conference/Submission8556/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8556/Authors"], "content": {"title": {"value": "Doubly Robust Instance-Reweighted Adversarial Training"}, "authors": {"value": ["Daouda Sow", "Sen Lin", "Zhangyang Wang", "Yingbin Liang"]}, "authorids": {"value": ["~Daouda_Sow1", "~Sen_Lin1", "~Zhangyang_Wang1", "~Yingbin_Liang1"]}, "keywords": {"value": ["adversarial training", "distributionally robust optimization", "bilevel optimization", "instance reweighting"]}, "TLDR": {"value": "We propose a novel doubly robust instance reweighted adversarial training framework based on DRO"}, "abstract": {"value": "Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained by optimizing the KL-divergence regularized loss function, which allows us to devise new algorithms with a theoretical convergence guarantee. \nExperiments on standard classification datasets demonstrate that our proposed approach outperforms related state-of-the-art baseline methods in terms of average robust performance, and at the same time improves the robustness against attacks on the weakest data points. Codes can be found in the Supplement."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c8cb1e0f5f66335caae7b2b8cebef4a72602b4ad.pdf"}, "supplementary_material": {"value": "/attachment/6aaa5bbfc956ee25f2b4d88cbc92830cfb78f891.zip"}, "_bibtex": {"value": "@inproceedings{\nsow2024doubly,\ntitle={Doubly Robust Instance-Reweighted Adversarial Training},\nauthor={Daouda Sow and Sen Lin and Zhangyang Wang and Yingbin Liang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OF5x1dzWSS}\n}"}, "paperhash": {"value": "sow|doubly_robust_instancereweighted_adversarial_training"}}, "number": 8556, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8556/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8556/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695515450261, "cdate": 1695515450261, "tmdate": 1710490074413, "mdate": 1710490074413, "pdate": 1705411043677, "version": 2}, {"id": "YCWjhGrJFD", "forum": "YCWjhGrJFD", "signatures": ["ICLR.cc/2024/Conference/Submission8548/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8548/Authors"], "content": {"title": {"value": "Training Diffusion Models with Reinforcement Learning"}, "authors": {"value": ["Kevin Black", "Michael Janner", "Yilun Du", "Ilya Kostrikov", "Sergey Levine"]}, "authorids": {"value": ["~Kevin_Black2", "~Michael_Janner1", "~Yilun_Du1", "~Ilya_Kostrikov1", "~Sergey_Levine1"]}, "keywords": {"value": ["reinforcement learning", "RLHF", "diffusion models"]}, "abstract": {"value": "Diffusion models are a class of flexible generative models trained with an approximation to the log-likelihood objective. However, most use cases of diffusion models are not concerned with likelihoods, but instead with downstream objectives such as human-perceived image quality or drug effectiveness. In this paper, we investigate reinforcement learning methods for directly optimizing diffusion models for such objectives. We describe how posing denoising as a multi-step decision-making problem enables a class of policy gradient algorithms, which we refer to as denoising diffusion policy optimization ( DDPO), that are more effective than alternative reward-weighted likelihood approaches. Empirically, DDPO can adapt text-to-image diffusion models to objectives that are difficult to express via prompting, such as image compressibility, and those derived from human feedback, such as aesthetic quality. Finally, we show that DDPO can improve prompt-image alignment using feedback from a vision-language model without the need for additional data collection or human annotation. The project\u2019s website can be found at http://rl-diffusion.github.io."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/39611b93653580f659f3d4d491f00250c4874376.pdf"}, "_bibtex": {"value": "@inproceedings{\nblack2024training,\ntitle={Training Diffusion Models with Reinforcement Learning},\nauthor={Kevin Black and Michael Janner and Yilun Du and Ilya Kostrikov and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YCWjhGrJFD}\n}"}, "paperhash": {"value": "black|training_diffusion_models_with_reinforcement_learning"}}, "number": 8548, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8548/-/Revision", "ICLR.cc/2024/Conference/Submission8548/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8548/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695514938705, "cdate": 1695514938705, "tmdate": 1712697859746, "mdate": 1712697859746, "pdate": 1705411043513, "version": 2}, {"id": "D2eOVqPX9g", "forum": "D2eOVqPX9g", "signatures": ["ICLR.cc/2024/Conference/Submission8544/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8544/Authors"], "content": {"title": {"value": "Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning"}, "authors": {"value": ["Chenyu Zhang", "Han Wang", "Aritra Mitra", "James Anderson"]}, "authorids": {"value": ["~Chenyu_Zhang2", "~Han_Wang14", "~Aritra_Mitra1", "~James_Anderson6"]}, "keywords": {"value": ["reinforcement learning", "federated learning", "temporal difference learning"]}, "abstract": {"value": "Federated reinforcement learning (FRL) has emerged as a promising paradigm for reducing the sample complexity of reinforcement learning tasks by exploiting information from different agents. However, when each agent interacts with a potentially different environment, little to nothing is known theoretically about the non-asymptotic performance of FRL algorithms. The lack of such results can be attributed to various technical challenges and their intricate interplay: Markovian sampling, linear function approximation, multiple local updates to save communication, heterogeneity in the reward functions and transition kernels of the agents' MDPs, and continuous state-action spaces.  Moreover, in the on-policy setting, the behavior policies vary with time, further complicating the analysis. In response, we introduce FedSARSA, a novel federated on-policy reinforcement learning scheme, equipped with linear function approximation, to address these challenges and provide a comprehensive finite-time error analysis. Notably, we establish that FedSARSA converges to a policy that is near-optimal for all agents, with the extent of near-optimality proportional to the level of heterogeneity. Furthermore, we prove that FedSARSA leverages agent collaboration to enable linear speedups as the number of agents increases, which holds for both fixed and adaptive step-size configurations."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f97ca95cc9cf273902a1eba91646203707a42223.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024finitetime,\ntitle={Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning},\nauthor={Chenyu Zhang and Han Wang and Aritra Mitra and James Anderson},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=D2eOVqPX9g}\n}"}, "paperhash": {"value": "zhang|finitetime_analysis_of_onpolicy_heterogeneous_federated_reinforcement_learning"}}, "number": 8544, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8544/-/Revision", "ICLR.cc/2024/Conference/Submission8544/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8544/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695514737716, "cdate": 1695514737716, "tmdate": 1712985907677, "mdate": 1712985907677, "pdate": 1705411043385, "version": 2}, {"id": "fe6ANBxcKM", "forum": "fe6ANBxcKM", "signatures": ["ICLR.cc/2024/Conference/Submission8542/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8542/Authors"], "content": {"title": {"value": "Federated Q-Learning: Linear Regret Speedup with Low Communication Cost"}, "authors": {"value": ["Zhong Zheng", "Fengyu Gao", "Lingzhou Xue", "Jing Yang"]}, "authorids": {"value": ["~Zhong_Zheng3", "~Fengyu_Gao1", "~Lingzhou_Xue1", "~Jing_Yang3"]}, "keywords": {"value": ["Federated Learning", "Reinforcement Learning", "Q-Learning", "Regret", "Communication Cost"]}, "abstract": {"value": "In this paper, we consider federated reinforcement learning for tabular episodic Markov Decision Processes (MDP) where, under the coordination of a central server, multiple agents collaboratively explore the environment and learn an optimal policy without sharing their raw data.  While linear speedup in the number of agents has been achieved for some metrics, such as convergence rate and sample complexity, in similar settings, it is unclear whether it is possible to design a *model-free* algorithm to achieve linear *regret* speedup with low communication cost. We propose two federated Q-Learning algorithms termed as FedQ-Hoeffding and FedQ-Bernstein, respectively, and show that the corresponding total regrets achieve a linear speedup compared with their single-agent counterparts, while the communication cost scales logarithmically in the total number of time steps $T$. Those results rely on an event-triggered synchronization mechanism between the agents and the server, a novel step size selection when the server aggregates the local estimates of the state-action values to form the global estimates, and a set of new concentration inequalities to bound the sum of non-martingale differences. This is the first work showing that linear regret speedup and logarithmic communication cost can be achieved by model-free algorithms in federated reinforcement learning."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "This paper proposes two model-free federated reinforcement learning algorithms that achieve linear regret speedup with logarithmic communication cost."}, "pdf": {"value": "/pdf/6ae0807140d8835f40da63717a9baa1749faec87.pdf"}, "supplementary_material": {"value": "/attachment/acb9e5927deec72d055d68ff6f2245d46d46c0c6.zip"}, "_bibtex": {"value": "@inproceedings{\nzheng2024federated,\ntitle={Federated Q-Learning: Linear Regret Speedup with Low Communication Cost},\nauthor={Zhong Zheng and Fengyu Gao and Lingzhou Xue and Jing Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fe6ANBxcKM}\n}"}, "paperhash": {"value": "zheng|federated_qlearning_linear_regret_speedup_with_low_communication_cost"}}, "number": 8542, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8542/-/Revision", "ICLR.cc/2024/Conference/Submission8542/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8542/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695514650730, "cdate": 1695514650730, "tmdate": 1710526099590, "mdate": 1710526099590, "pdate": 1705411043296, "version": 2}, {"id": "MeHmwCDifc", "forum": "MeHmwCDifc", "signatures": ["ICLR.cc/2024/Conference/Submission8541/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8541/Authors"], "content": {"title": {"value": "The Trickle-down Impact of Reward Inconsistency on RLHF"}, "authors": {"value": ["Lingfeng Shen", "Sihao Chen", "Linfeng Song", "Lifeng Jin", "Baolin Peng", "Haitao Mi", "Daniel Khashabi", "Dong Yu"]}, "authorids": {"value": ["~Lingfeng_Shen1", "~Sihao_Chen1", "~Linfeng_Song1", "~Lifeng_Jin1", "~Baolin_Peng2", "~Haitao_Mi1", "~Daniel_Khashabi2", "~Dong_Yu2"]}, "keywords": {"value": ["Large language model", "reward model", "RLHF", "consistency"]}, "abstract": {"value": "Standard practice within Reinforcement Learning from Human Feedback (RLHF) involves optimizing against a Reward Model (RM), which itself is trained to reflect human preferences for desirable generations. A notable subject that is understudied is the (in-)consistency of RMs --- whether they can recognize the semantic changes to different prompts and \nappropriately adapt their reward assignments\n\n--- and their impact on the downstream RLHF model.\n\nIn this paper, we visit a series of research questions relevant to RM inconsistency:\n(1) How can we measure the consistency of reward models? \n(2) How consistent are the existing RMs and how can we improve them? \n(3) In what ways does reward inconsistency influence the chatbots resulting from the RLHF model training?\n\n\nWe propose **Contrast Instruction** -- a benchmarking strategy for the consistency of RM.  \nEach example in **Contrast Instruction** features a pair of lexically similar instructions with different ground truth responses. A consistent RM is expected to rank the corresponding instruction and response higher than other combinations. We observe that current RMs trained with the standard ranking objective fail miserably on \\contrast{} compared to average humans. To show that RM consistency can be improved efficiently without using extra training budget, we propose two techniques **ConvexDA** and **RewardFusion**, which enhance reward consistency \nthrough extrapolation during the RM training and inference stage, respectively.\nWe show that RLHF models trained with a more consistent RM yield more useful responses, suggesting that reward inconsistency exhibits a trickle-down effect on the downstream RLHF process."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a8dad7978440d43316bc0727f7c324cbffe5e4c0.pdf"}, "supplementary_material": {"value": "/attachment/7d396953ca1c5b08cec84c2768187a79c87fee9b.zip"}, "_bibtex": {"value": "@inproceedings{\nshen2024the,\ntitle={The Trickle-down Impact of Reward Inconsistency on {RLHF}},\nauthor={Lingfeng Shen and Sihao Chen and Linfeng Song and Lifeng Jin and Baolin Peng and Haitao Mi and Daniel Khashabi and Dong Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MeHmwCDifc}\n}"}, "paperhash": {"value": "shen|the_trickledown_impact_of_reward_inconsistency_on_rlhf"}}, "number": 8541, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8541/-/Revision", "ICLR.cc/2024/Conference/Submission8541/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8541/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695514558820, "cdate": 1695514558820, "tmdate": 1711839021847, "mdate": 1711839021847, "pdate": 1705411043268, "version": 2}, {"id": "ip5LHJs6QX", "forum": "ip5LHJs6QX", "signatures": ["ICLR.cc/2024/Conference/Submission8518/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8518/Authors"], "content": {"title": {"value": "Efficient Modulation for Vision Networks"}, "authors": {"value": ["Xu Ma", "Xiyang Dai", "Jianwei Yang", "Bin Xiao", "Yinpeng Chen", "Yun Fu", "Lu Yuan"]}, "authorids": {"value": ["~Xu_Ma2", "~Xiyang_Dai4", "~Jianwei_Yang1", "~Bin_Xiao2", "~Yinpeng_Chen1", "~Yun_Fu1", "~Lu_Yuan1"]}, "keywords": {"value": ["EfficientMod", "Efficient Networks"]}, "TLDR": {"value": "In this study, we introduce Efficient Modulation (EfficientMod), a novel design for efficient networks that oupforms other methods in terms of both results and latency."}, "abstract": {"value": "In this work, we present efficient modulation, a novel design for efficient vision networks. We revisit the modulation mechanism, which operates input through convolutional context modeling and feature projection layers, and fuses features via element-wise multiplication and an MLP block. We demonstrate that the abstracted modulation mechanism is particularly well suited for efficient networks and further tailor the modulation design by proposing the efficient modulation (EfficientMod) block, which is considered the essential building block for our networks. Bene- fiting from the prominent representational ability of modulation mechanism and the efficiency of efficient modulation design, our network can accomplish better accuracy-efficiency trade-offs and set new state-of-the-art performance for efficient networks. When integrating EfficientMod block with the vanilla self-attention block, we obtain the hybrid architecture and further improve the performance without sacrificing the efficiency. We carry out comprehensive experiments to verify EfficientMod\u2019s performance. With fewer parameters, our EfficientMod-s performs 0.6 top-1 accuracy better than the prior state-of-the-art approach EfficientFormerV2-s2 without any training tricks and is 25% faster on GPU. Additionally, our method presents a notable improvement in downstream tasks, outperforming EfficientFormerV2-s by 3.6 mIoU on the ADE20K benchmark. Code and checkpoints are available at https://github.com/ma-xu/EfficientMod."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/60b84aa807789b9bf4b5e8f2ff637e481c3cd2c8.pdf"}, "supplementary_material": {"value": "/attachment/0e5f09bffd5c54486d66de87adc232e7585c974d.zip"}, "_bibtex": {"value": "@inproceedings{\nma2024efficient,\ntitle={Efficient Modulation for Vision Networks},\nauthor={Xu Ma and Xiyang Dai and Jianwei Yang and Bin Xiao and Yinpeng Chen and Yun Fu and Lu Yuan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ip5LHJs6QX}\n}"}, "paperhash": {"value": "ma|efficient_modulation_for_vision_networks"}}, "number": 8518, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8518/-/Revision", "ICLR.cc/2024/Conference/Submission8518/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8518/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513613181, "cdate": 1695513613181, "tmdate": 1710477017318, "mdate": 1710477017318, "pdate": 1705411042604, "version": 2}, {"id": "fB1iiH9xo7", "forum": "fB1iiH9xo7", "signatures": ["ICLR.cc/2024/Conference/Submission8517/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8517/Authors"], "content": {"title": {"value": "Pre-training LiDAR-based 3D Object Detectors through Colorization"}, "authors": {"value": ["Tai-Yu Pan", "Chenyang Ma", "Tianle Chen", "Cheng Perng Phoo", "Katie Z Luo", "Yurong You", "Mark Campbell", "Kilian Q Weinberger", "Bharath Hariharan", "Wei-Lun Chao"]}, "authorids": {"value": ["~Tai-Yu_Pan1", "~Chenyang_Ma2", "~Tianle_Chen2", "~Cheng_Perng_Phoo1", "~Katie_Z_Luo1", "~Yurong_You1", "~Mark_Campbell1", "~Kilian_Q_Weinberger1", "~Bharath_Hariharan3", "~Wei-Lun_Chao1"]}, "keywords": {"value": ["3D object detection", "LiDAR point cloud", "pre-training", "autonomous driving", "self-supervised learning"]}, "abstract": {"value": "Accurate 3D object detection and understanding for self-driving cars heavily relies on LiDAR point clouds, necessitating large amounts of labeled data to train. In this work, we introduce an innovative pre-training approach, Grounded Point Colorization (GPC), to bridge the gap between data and labels by teaching the model to colorize LiDAR point clouds, equipping it with valuable semantic cues. To tackle challenges arising from color variations and selection bias, we incorporate color as \"context\" by providing ground-truth colors as hints during colorization.\nExperimental results on the KITTI and Waymo datasets demonstrate GPC's remarkable effectiveness. Even with limited labeled data, GPC significantly improves fine-tuning performance; notably, on just 20% of the KITTI dataset, GPC outperforms training from scratch with the entire dataset. \nIn sum, we introduce a fresh perspective on pre-training for 3D object detection, aligning the objective with the model's intended role and ultimately advancing the accuracy and efficiency of 3D object detection for autonomous vehicles."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bcbf057d60c81f10beb0dc381109a0616f19d030.pdf"}, "_bibtex": {"value": "@inproceedings{\npan2024pretraining,\ntitle={Pre-training Li{DAR}-based 3D Object Detectors through Colorization},\nauthor={Tai-Yu Pan and Chenyang Ma and Tianle Chen and Cheng Perng Phoo and Katie Z Luo and Yurong You and Mark Campbell and Kilian Q Weinberger and Bharath Hariharan and Wei-Lun Chao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fB1iiH9xo7}\n}"}, "supplementary_material": {"value": "/attachment/ffab97ee157dbc5fff2c8d7fcc0463ffe257338d.pdf"}, "paperhash": {"value": "pan|pretraining_lidarbased_3d_object_detectors_through_colorization"}}, "number": 8517, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8517/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8517/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513609840, "cdate": 1695513609840, "tmdate": 1710408612886, "mdate": 1710408612886, "pdate": 1705411042542, "version": 2}, {"id": "Eo7kv0sllr", "forum": "Eo7kv0sllr", "signatures": ["ICLR.cc/2024/Conference/Submission8516/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8516/Authors"], "content": {"title": {"value": "An Emulator for Fine-tuning Large Language Models using Small Language Models"}, "authors": {"value": ["Eric Mitchell", "Rafael Rafailov", "Archit Sharma", "Chelsea Finn", "Christopher D Manning"]}, "authorids": {"value": ["~Eric_Mitchell1", "~Rafael_Rafailov1", "~Archit_Sharma1", "~Chelsea_Finn1", "~Christopher_D_Manning1"]}, "keywords": {"value": ["pre-training", "fine-tuning", "decouple", "scale", "reward", "alignment"]}, "TLDR": {"value": "We show a principled, hyperparameter-free approach to decoupling the knowledge gained from pre-training and fine-tuning, enabling study of the source of model capabilities and showing benefits in factuality and helpfulness"}, "abstract": {"value": "Widely used language models (LMs) are typically built by scaling up a two-stage training pipeline: a pre-training stage that uses a very large, diverse dataset of text and a fine-tuning (sometimes, 'alignment') stage that uses targeted examples or other specifications of desired behaviors. While it has been hypothesized that knowledge and skills come from pre-training, and fine-tuning mostly filters this knowledge and skillset, this intuition has not been extensively tested. To aid in doing so, we introduce a novel technique for decoupling the knowledge and skills gained in these two stages, enabling a direct answer to the question, *What would happen if we combined the knowledge learned by a large model during pre-training with the knowledge learned by a small model during fine-tuning (or vice versa)?* Using an RL-based framework derived from recent developments in learning from human preferences, we introduce *emulated fine-tuning (EFT)*, a principled and practical method for sampling from a distribution that approximates (or 'emulates') the result of pre-training and fine-tuning at different scales. Our experiments with EFT show that scaling up fine-tuning tends to improve helpfulness, while scaling up pre-training tends to improve factuality. Beyond decoupling scale, we show that EFT enables test-time adjustment of competing behavioral traits like helpfulness and harmlessness without additional training. Finally, a special case of emulated fine-tuning, which we call LM *up-scaling*, avoids resource-intensive fine-tuning of large pre-trained models by ensembling them with small fine-tuned models, essentially emulating the result of fine-tuning the large pre-trained model. Up-scaling consistently improves helpfulness and factuality of instruction-following models in the Llama, Llama-2, and Falcon families, without additional hyperparameters or training. For reference implementation, see [https://github.com/eric-mitchell/emulated-fine-tuning](https://github.com/eric-mitchell/emulated-fine-tuning)."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b0342e1462535a7e1a40bac079cefdfd493a9912.pdf"}, "_bibtex": {"value": "@inproceedings{\nmitchell2024an,\ntitle={An Emulator for Fine-tuning Large Language Models using Small Language Models},\nauthor={Eric Mitchell and Rafael Rafailov and Archit Sharma and Chelsea Finn and Christopher D Manning},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Eo7kv0sllr}\n}"}, "paperhash": {"value": "mitchell|an_emulator_for_finetuning_large_language_models_using_small_language_models"}}, "number": 8516, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8516/-/Revision", "ICLR.cc/2024/Conference/Submission8516/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8516/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513487328, "cdate": 1695513487328, "tmdate": 1713135518088, "mdate": 1713135518088, "pdate": 1705411042527, "version": 2}, {"id": "wsWGcw6qKD", "forum": "wsWGcw6qKD", "signatures": ["ICLR.cc/2024/Conference/Submission8515/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8515/Authors"], "content": {"title": {"value": "Toward Student-oriented Teacher Network Training for Knowledge Distillation"}, "authors": {"value": ["Chengyu Dong", "Liyuan Liu", "Jingbo Shang"]}, "authorids": {"value": ["~Chengyu_Dong1", "~Liyuan_Liu3", "~Jingbo_Shang2"]}, "keywords": {"value": ["Knowledge distillation", "Teacher-student training", "Empirical risk minimization"]}, "abstract": {"value": "How to conduct teacher training for knowledge distillation is still an open problem. It has been widely observed that a best-performing teacher does not necessarily yield the best-performing student, suggesting a fundamental discrepancy between the current teacher training practice and the ideal teacher training strategy. To fill this gap, we explore the feasibility of training a teacher that is oriented toward student performance with empirical risk minimization (ERM). Our analyses are inspired by the recent findings that the effectiveness of knowledge distillation hinges on the teacher\u2019s capability to approximate the true label distribution of training inputs. We theoretically establish that ERM minimizer can approximate the true label distribution of training data as long as the feature extractor of the learner network is Lipschitz continuous and is robust to feature transformations. In light of our theory, we propose a teacher training method SoTeacher which incorporates Lipschitz regularization and consistency regularization into ERM. Experiments on benchmark datasets using various knowledge distillation algorithms and teacher-student pairs confirm that SoTeacher can improve student accuracy consistently."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/78287861759246a621e90ed0b27c2dd79390afec.pdf"}, "_bibtex": {"value": "@inproceedings{\ndong2024toward,\ntitle={Toward Student-oriented Teacher Network Training for Knowledge Distillation},\nauthor={Chengyu Dong and Liyuan Liu and Jingbo Shang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wsWGcw6qKD}\n}"}, "paperhash": {"value": "dong|toward_studentoriented_teacher_network_training_for_knowledge_distillation"}}, "number": 8515, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8515/-/Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513485950, "cdate": 1695513485950, "tmdate": 1707625648014, "mdate": 1707625648014, "pdate": 1705411042453, "version": 2}, {"id": "jE8xbmvFin", "forum": "jE8xbmvFin", "signatures": ["ICLR.cc/2024/Conference/Submission8514/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8514/Authors"], "content": {"title": {"value": "Language Models Represent Space and Time"}, "authors": {"value": ["Wes Gurnee", "Max Tegmark"]}, "authorids": {"value": ["~Wes_Gurnee1", "~Max_Tegmark1"]}, "keywords": {"value": ["Interpretability", "world models", "probing"]}, "TLDR": {"value": "Probing for spatial and temporal features in Llama-2 models."}, "abstract": {"value": "The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual \"space neurons\" and \"time neurons\" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c50ebbefe4d77434016a143c31d247f30948dd6c.pdf"}, "_bibtex": {"value": "@inproceedings{\ngurnee2024language,\ntitle={Language Models Represent Space and Time},\nauthor={Wes Gurnee and Max Tegmark},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jE8xbmvFin}\n}"}, "paperhash": {"value": "gurnee|language_models_represent_space_and_time"}}, "number": 8514, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8514/-/Revision", "ICLR.cc/2024/Conference/Submission8514/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8514/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513418084, "cdate": 1695513418084, "tmdate": 1709661548940, "mdate": 1709661548940, "pdate": 1705411042410, "version": 2}, {"id": "pAoqRlTBtY", "forum": "pAoqRlTBtY", "signatures": ["ICLR.cc/2024/Conference/Submission8513/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8513/Authors"], "content": {"title": {"value": "Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning"}, "authors": {"value": ["Ahmed Abdulaal", "adamos hadjivasiliou", "Nina Montana-Brown", "Tiantian He", "Ayodeji Ijishakin", "Ivana Drobnjak", "Daniel C. Castro", "Daniel C. Alexander"]}, "authorids": {"value": ["~Ahmed_Abdulaal1", "~adamos_hadjivasiliou1", "~Nina_Montana-Brown1", "tiantian.he.20@ucl.ac.uk", "~Ayodeji_Ijishakin1", "~Ivana_Drobnjak2", "~Daniel_C._Castro1", "~Daniel_C._Alexander1"]}, "keywords": {"value": ["Causal Reasoning", "Causal Discovery", "Structural Causal Models", "Large Language Models"]}, "abstract": {"value": "Scientific discovery hinges on the effective integration of metadata, which refers to a set of 'cognitive' operations such as determining what information is relevant for inquiry, and data, which encompasses physical operations such as observation and experimentation. This paper introduces the Causal Modelling Agent (CMA), a novel framework that synergizes the metadata-based reasoning capabilities of Large Language Models (LLMs) with the data-driven modelling of Deep Structural Causal Models (DSCMs) for the task of causal discovery. We evaluate the CMA's performance on a number of benchmarks, as well as on the real-world task of modelling the clinical and radiological phenotype of Alzheimer's Disease (AD). Our experimental results indicate that the CMA can outperform previous data-driven or metadata-driven approaches to causal discovery. In our real-world application, we use the CMA to derive new insights into the causal relationships among biomarkers of AD."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/62fc3766e10c6f5fa2f2a9b44b46098519f89596.pdf"}, "_bibtex": {"value": "@inproceedings{\nabdulaal2024causal,\ntitle={Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning},\nauthor={Ahmed Abdulaal and adamos hadjivasiliou and Nina Montana-Brown and Tiantian He and Ayodeji Ijishakin and Ivana Drobnjak and Daniel C. Castro and Daniel C. Alexander},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pAoqRlTBtY}\n}"}, "paperhash": {"value": "abdulaal|causal_modelling_agents_causal_graph_discovery_through_synergising_metadata_and_datadriven_reasoning"}}, "number": 8513, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8513/-/Revision", "ICLR.cc/2024/Conference/Submission8513/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8513/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513408950, "cdate": 1695513408950, "tmdate": 1709827690076, "mdate": 1709827690076, "pdate": 1705411042385, "version": 2}, {"id": "8OBuqbLb8h", "forum": "8OBuqbLb8h", "signatures": ["ICLR.cc/2024/Conference/Submission8511/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8511/Authors"], "content": {"title": {"value": "Fast-ELECTRA for Efficient Pre-training"}, "authors": {"value": ["Chengyu Dong", "Liyuan Liu", "Hao Cheng", "Jingbo Shang", "Jianfeng Gao", "Xiaodong Liu"]}, "authorids": {"value": ["~Chengyu_Dong1", "~Liyuan_Liu3", "~Hao_Cheng4", "~Jingbo_Shang2", "~Jianfeng_Gao1", "~Xiaodong_Liu1"]}, "keywords": {"value": ["Language model Pre-training", "ELECTRA", "Efficiency"]}, "abstract": {"value": "ELECTRA pre-trains language models by detecting tokens in a sequence that have been replaced by an auxiliary model. Although ELECTRA offers a significant boost in efficiency, its potential is constrained by the training cost brought by the auxiliary model. Notably, this model, which is jointly trained with the main model, only serves to assist the training of the main model and is discarded post-training. This results in a substantial amount of training cost being expended in vain. To mitigate this issue, we propose Fast-ELECTRA, which leverages an existing language model as the auxiliary model. To construct a learning curriculum for the main model, we smooth its output distribution via temperature scaling following a descending schedule. Our approach rivals the performance of state-of-the-art ELECTRA-style pre-training methods, while significantly eliminating the computation and memory cost brought by the joint training of the auxiliary model. Our method also reduces the sensitivity to hyper-parameters and enhances the pre-training stability."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ec83017cab49946fb5f76c893123986b79e319ea.pdf"}, "_bibtex": {"value": "@inproceedings{\ndong2024fastelectra,\ntitle={Fast-{ELECTRA} for Efficient Pre-training},\nauthor={Chengyu Dong and Liyuan Liu and Hao Cheng and Jingbo Shang and Jianfeng Gao and Xiaodong Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8OBuqbLb8h}\n}"}, "paperhash": {"value": "dong|fastelectra_for_efficient_pretraining"}}, "number": 8511, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8511/-/Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513316541, "cdate": 1695513316541, "tmdate": 1707625647932, "mdate": 1707625647932, "pdate": 1705411042287, "version": 2}, {"id": "kNpSUN0uCc", "forum": "kNpSUN0uCc", "signatures": ["ICLR.cc/2024/Conference/Submission8509/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8509/Authors"], "content": {"title": {"value": "Maximum Entropy Model Correction in Reinforcement Learning"}, "authors": {"value": ["Amin Rakhsha", "Mete Kemertas", "Mohammad Ghavamzadeh", "Amir-massoud Farahmand"]}, "authorids": {"value": ["~Amin_Rakhsha1", "~Mete_Kemertas1", "~Mohammad_Ghavamzadeh2", "~Amir-massoud_Farahmand1"]}, "keywords": {"value": ["reinforcement learning", "model-based reinforcement learning", "maximum entropy", "planning"]}, "TLDR": {"value": "Planning algorithm that corrects the model"}, "abstract": {"value": "We propose and theoretically analyze an approach for planning with an approximate model in reinforcement learning that can reduce the adverse impact of model error. If the model is accurate enough, it accelerates the convergence to the true value function too. One of its key components is the MaxEnt Model Correction (MoCo) procedure that corrects the model\u2019s next-state distributions based on a Maximum Entropy density estimation formulation. Based on MoCo, we introduce the Model Correcting Value Iteration (MoCoVI) algorithm, and its sampled-based variant MoCoDyna. We show that MoCoVI and MoCoDyna\u2019s convergence can be much faster than the conventional model-free algorithms. Unlike traditional model-based algorithms, MoCoVI and MoCoDyna effectively utilize an approximate model and still converge to the correct value function."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f91adc5c8d10f07321994671b62ab5b8ced10cb.pdf"}, "_bibtex": {"value": "@inproceedings{\nrakhsha2024maximum,\ntitle={Maximum Entropy Model Correction in Reinforcement Learning},\nauthor={Amin Rakhsha and Mete Kemertas and Mohammad Ghavamzadeh and Amir-massoud Farahmand},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kNpSUN0uCc}\n}"}, "paperhash": {"value": "rakhsha|maximum_entropy_model_correction_in_reinforcement_learning"}}, "number": 8509, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8509/-/Revision", "ICLR.cc/2024/Conference/Submission8509/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8509/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695513167911, "cdate": 1695513167911, "tmdate": 1713143205179, "mdate": 1713143205179, "pdate": 1705411042272, "version": 2}, {"id": "D9rJdtmIG6", "forum": "D9rJdtmIG6", "signatures": ["ICLR.cc/2024/Conference/Submission8502/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8502/Authors"], "content": {"title": {"value": "SpaCE: The Spatial Confounding Environment"}, "authors": {"value": ["Mauricio Tec", "Ana Trisovic", "Michelle Audirac", "Sophie Mirabai Woodward", "Jie Kate Hu", "Naeem Khoshnevis", "Francesca Dominici"]}, "authorids": {"value": ["~Mauricio_Tec1", "~Ana_Trisovic1", "~Michelle_Audirac1", "~Sophie_Mirabai_Woodward1", "~Jie_Kate_Hu1", "~Naeem_Khoshnevis1", "~Francesca_Dominici2"]}, "keywords": {"value": ["causal inference", "datasets", "benchmarks", "spatial confounding", "public health"]}, "TLDR": {"value": "We introduce SpaCE, the first comprehensive toolkit providing realistic benchmark datasets and tools for evaluating causal inference methods in spatial confounding scenarios."}, "abstract": {"value": "Spatial confounding poses a significant challenge in scientific studies involving spatial data, where unobserved spatial variables can influence both treatment and outcome, possibly leading to spurious associations. To address this problem, we introduce SpaCE: The Spatial Confounding Environment, the first toolkit to provide realistic benchmark datasets and tools for systematically evaluating causal inference methods designed to alleviate spatial confounding. Each dataset includes training data, true counterfactuals, a spatial graph with coordinates, and smoothness and confounding scores characterizing the effect of a missing spatial confounder. It also includes realistic semi-synthetic outcomes and counterfactuals, generated using state-of-the-art machine learning ensembles, following best practices for causal inference benchmarks. The datasets cover real treatment and covariates from diverse domains, including climate, health and social sciences. SpaCE facilitates an automated end-to-end pipeline, simplifying data loading, experimental setup, and evaluating machine learning and causal inference models. The SpaCE project provides several dozens of datasets of diverse sizes and spatial complexity. It is publicly available as a Python package, encouraging community feedback and contributions."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dc32f6d87ea1b68ffdd0236aabb8169cb1a765a9.pdf"}, "_bibtex": {"value": "@inproceedings{\ntec2024space,\ntitle={Spa{CE}: The Spatial Confounding Environment},\nauthor={Mauricio Tec and Ana Trisovic and Michelle Audirac and Sophie Mirabai Woodward and Jie Kate Hu and Naeem Khoshnevis and Francesca Dominici},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=D9rJdtmIG6}\n}"}, "paperhash": {"value": "tec|space_the_spatial_confounding_environment"}}, "number": 8502, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8502/-/Revision", "ICLR.cc/2024/Conference/Submission8502/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695512844915, "cdate": 1695512844915, "tmdate": 1707625647764, "mdate": 1707625647764, "pdate": 1705411042056, "version": 2}, {"id": "4eJDMjYZZG", "forum": "4eJDMjYZZG", "signatures": ["ICLR.cc/2024/Conference/Submission8488/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8488/Authors"], "content": {"title": {"value": "Language Model Detectors Are Easily Optimized Against"}, "authors": {"value": ["Charlotte Nicks", "Eric Mitchell", "Rafael Rafailov", "Archit Sharma", "Christopher D Manning", "Chelsea Finn", "Stefano Ermon"]}, "authorids": {"value": ["cnicks13@stanford.edu", "~Eric_Mitchell1", "~Rafael_Rafailov1", "~Archit_Sharma1", "~Christopher_D_Manning1", "~Chelsea_Finn1", "~Stefano_Ermon1"]}, "keywords": {"value": ["detector", "language model", "learning from preferences"]}, "TLDR": {"value": "We show that existing open source and commercial LLM detectors can be used as reward functions to produce much more difficult-to-detect language models."}, "abstract": {"value": "The fluency and general applicability of large language models (LLMs) has motivated significant interest in detecting whether a piece of text was written by a language model. While both academic and commercial detectors have been deployed in some settings, particularly education, other research has highlighted the fragility of these systems. In this paper, we demonstrate a data-efficient attack that fine-tunes language models to confuse existing detectors, leveraging recent developments in reinforcement learning of language models. We use the 'human-ness' score (often just a log probability) of various open-source and commercial detectors as a reward function for reinforcement learning, subject to a KL-divergence constraint that the resulting model does not differ significantly from the original. For a 7B parameter Llama-2 model, fine-tuning for under a day reduces the AUROC of the OpenAI RoBERTa-Large detector from 0.84 to 0.62, while perplexity on OpenWebText increases from 8.7 to only 9.0; with a larger perplexity budget, we reduce AUROC to 0.30 (worse than random), with a perplexity increase to 9.9. Similar to traditional adversarial attacks, we find that this increase in 'detector evasion' generalizes to other detectors not used during training. In light of our empirical results, we advise against continued reliance on LLM-generated text detectors."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e6b0acda84b76f8d74020f5a1b3a7e49c32838a8.pdf"}, "_bibtex": {"value": "@inproceedings{\nnicks2024language,\ntitle={Language Model Detectors Are Easily Optimized Against},\nauthor={Charlotte Nicks and Eric Mitchell and Rafael Rafailov and Archit Sharma and Christopher D Manning and Chelsea Finn and Stefano Ermon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4eJDMjYZZG}\n}"}, "paperhash": {"value": "nicks|language_model_detectors_are_easily_optimized_against"}}, "number": 8488, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8488/-/Revision", "ICLR.cc/2024/Conference/Submission8488/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8488/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695512427095, "cdate": 1695512427095, "tmdate": 1713162754288, "mdate": 1713162754288, "pdate": 1705411041759, "version": 2}, {"id": "c0chJTSbci", "forum": "c0chJTSbci", "signatures": ["ICLR.cc/2024/Conference/Submission8486/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8486/Authors"], "content": {"title": {"value": "Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models"}, "authors": {"value": ["Kevin Black", "Mitsuhiko Nakamoto", "Pranav Atreya", "Homer Rich Walke", "Chelsea Finn", "Aviral Kumar", "Sergey Levine"]}, "authorids": {"value": ["~Kevin_Black2", "~Mitsuhiko_Nakamoto1", "~Pranav_Atreya1", "~Homer_Rich_Walke1", "~Chelsea_Finn1", "~Aviral_Kumar2", "~Sergey_Levine1"]}, "keywords": {"value": ["robot learning", "diffusion model"]}, "abstract": {"value": "If generalist robots are to operate in truly unstructured environments, they need to be able to recognize and reason about novel objects and scenarios. Such objects and scenarios might not be present in the robot\u2019s own training data. We propose SuSIE, a method that leverages an image-editing diffusion model to act as a high-level planner by proposing intermediate subgoals that a low-level controller can accomplish. Specifically, we finetune InstructPix2Pix on video data, consisting of both human videos and robot rollouts, such that it outputs hypothetical future \u201csubgoal\u201d observations given the robot\u2019s current observation and a language command. We also use the robot data to train a low-level goal-conditioned policy to act as the aforementioned low-level controller. We find that the high-level subgoal predictions can utilize Internet scale pretraining and visual understanding to guide the low-level goal-conditioned policy, achieving significantly better generalization and precision than conventional language-conditioned policies. We achieve state-of-the-art results on the CALVIN benchmark, and also demonstrate robust generalization on real-world manipulation tasks, beating strong baselines that have access to privileged information or that utilize orders of magnitude more compute and training data. The project website can be found at http://rail-berkeley.github.io/susie."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c0ae16a0a57aa4ec4f933f90e44a5e9f250f076e.pdf"}, "supplementary_material": {"value": "/attachment/1674c6d00b0e3e294c545ab2398d5ab5382e0713.zip"}, "_bibtex": {"value": "@inproceedings{\nblack2024zeroshot,\ntitle={Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models},\nauthor={Kevin Black and Mitsuhiko Nakamoto and Pranav Atreya and Homer Rich Walke and Chelsea Finn and Aviral Kumar and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=c0chJTSbci}\n}"}, "paperhash": {"value": "black|zeroshot_robotic_manipulation_with_pretrained_imageediting_diffusion_models"}}, "number": 8486, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8486/-/Revision", "ICLR.cc/2024/Conference/Submission8486/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8486/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695512347177, "cdate": 1695512347177, "tmdate": 1712698570750, "mdate": 1712698570750, "pdate": 1705411041690, "version": 2}, {"id": "kXHEBK9uAY", "forum": "kXHEBK9uAY", "signatures": ["ICLR.cc/2024/Conference/Submission8463/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8463/Authors"], "content": {"title": {"value": "Simple Hierarchical Planning with Diffusion"}, "authors": {"value": ["Chang Chen", "Fei Deng", "Kenji Kawaguchi", "Caglar Gulcehre", "Sungjin Ahn"]}, "authorids": {"value": ["~Chang_Chen1", "~Fei_Deng1", "~Kenji_Kawaguchi1", "~Caglar_Gulcehre1", "~Sungjin_Ahn1"]}, "keywords": {"value": ["Hierarchical Offline RL", "Hierarchical planning", "Hierarchical Reinforcement Learning", "Diffusion-Based Planning"]}, "abstract": {"value": "Diffusion-based generative methods have proven effective in modeling trajectories with offline datasets. However, they often face computational challenges and can falter in generalization, especially in capturing temporal abstractions for long-horizon tasks. To overcome this, we introduce the Hierarchical Diffuser, a simple, fast, yet effective planning method combining the advantages of hierarchical and diffusion-based planning. Our model adopts a \u201cjumpy\u201d planning strategy at the high level, which allows it to have a larger receptive field but at a lower computational cost\u2014a crucial factor for diffusion-based planning methods, as we have empirically verified. Additionally, the jumpy sub-goals guide our low-level planner, facilitating a fine-tuning stage and further improving our approach\u2019s effectiveness. We conducted empirical evaluations on standard offline reinforcement learning benchmarks, demonstrating our method\u2019s superior performance and efficiency in terms of training and planning speed compared to the non-hierarchical Diffuser as well as other hierarchical planning methods. Moreover, we explore our model\u2019s generalization capability, particularly on how our method improves generalization capabilities on compositional out-of-distribution tasks."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f89e3aae3f83ac51a96585f5927e7d0026e19d8c.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024simple,\ntitle={Simple Hierarchical Planning with Diffusion},\nauthor={Chang Chen and Fei Deng and Kenji Kawaguchi and Caglar Gulcehre and Sungjin Ahn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kXHEBK9uAY}\n}"}, "supplementary_material": {"value": "/attachment/5226776c9fa436a6bdb040c7434032b505f9f9f3.pdf"}, "paperhash": {"value": "chen|simple_hierarchical_planning_with_diffusion"}}, "number": 8463, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8463/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8463/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695511537927, "cdate": 1695511537927, "tmdate": 1710561131787, "mdate": 1710561131787, "pdate": 1705411041265, "version": 2}, {"id": "fj2E5OcLFn", "forum": "fj2E5OcLFn", "signatures": ["ICLR.cc/2024/Conference/Submission8461/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8461/Authors"], "content": {"title": {"value": "Stochastic Gradient Descent for Gaussian Processes Done Right"}, "authors": {"value": ["Jihao Andreas Lin", "Shreyas Padhy", "Javier Antoran", "Austin Tripp", "Alexander Terenin", "Csaba Szepesvari", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "David Janz"]}, "authorids": {"value": ["~Jihao_Andreas_Lin1", "~Shreyas_Padhy1", "~Javier_Antoran1", "~Austin_Tripp1", "~Alexander_Terenin1", "~Csaba_Szepesvari1", "~Jos\u00e9_Miguel_Hern\u00e1ndez-Lobato1", "~David_Janz1"]}, "keywords": {"value": ["Gaussian process", "stochastic gradient descent"]}, "abstract": {"value": "As is well known, both sampling from the posterior and computing the mean of the posterior in Gaussian process regression reduces to solving a large linear system of equations. We study the use of stochastic gradient descent for solving this linear system, and show that when done right---by which we mean using specific insights from the optimisation and kernel communities---stochastic gradient descent is highly effective. To that end, we introduce a particularly simple stochastic dual descent algorithm, explain its design in an intuitive manner and illustrate the design choices through a series of ablation studies. Further experiments demonstrate that our new method is highly competitive. In particular, our evaluations on the UCI regression tasks and on Bayesian optimisation set our approach apart from preconditioned conjugate gradients and variational Gaussian process approximations. Moreover, our method places Gaussian process regression on par with state-of-the-art graph neural networks for molecular binding affinity prediction."}, "pdf": {"value": "/pdf/1a24ae39cc44caaeb65f4c46067a7b5c53a0ed95.pdf"}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nlin2024stochastic,\ntitle={Stochastic Gradient Descent for Gaussian Processes Done Right},\nauthor={Jihao Andreas Lin and Shreyas Padhy and Javier Antoran and Austin Tripp and Alexander Terenin and Csaba Szepesvari and Jos{\\'e} Miguel Hern{\\'a}ndez-Lobato and David Janz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fj2E5OcLFn}\n}"}, "paperhash": {"value": "lin|stochastic_gradient_descent_for_gaussian_processes_done_right"}}, "number": 8461, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8461/-/Revision", "ICLR.cc/2024/Conference/Submission8461/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8461/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695511343689, "cdate": 1695511343689, "tmdate": 1713119864958, "mdate": 1713119864958, "pdate": 1705411041234, "version": 2}, {"id": "c56TWtYp0W", "forum": "c56TWtYp0W", "signatures": ["ICLR.cc/2024/Conference/Submission8459/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8459/Authors"], "content": {"title": {"value": "GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings"}, "authors": {"value": ["Jingyun Xiao", "Ran Liu", "Eva L Dyer"]}, "authorids": {"value": ["~Jingyun_Xiao1", "~Ran_Liu2", "~Eva_L_Dyer1"]}, "keywords": {"value": ["Time-series", "Transformer", "Spatiotemporal"]}, "TLDR": {"value": "We propose a group embedding framework which is aware of latent spatiotemporal structure of time-series data"}, "abstract": {"value": "Analyzing multivariate time series is important in many domains. However, it has been difficult to learn robust and generalizable representations within multivariate datasets due to complex inter-channel relationships and dynamic shifts. In this paper, we introduce a novel approach for learning spatiotemporal structure and using it to improve the application of transformers to timeseries datasets. Our framework learns a set of group tokens, and builds an instance-specific group embedding (GE) layer that assigns input tokens to a small number of group tokens to incorporate  structure into learning. We then introduce a novel architecture, Group-Aware transFormer (GAFormer), which incorporates both spatial and temporal group embeddings to achieve state-of-the-art performance on a number of time-series classification and regression tasks. In evaluations on a number of diverse timeseries datasets, we show that GE on its own can provide a nice enhancement to a number of backbones, and that by coupling spatial and temporal group embeddings, the GAFormer can outperform the existing baselines. Finally, we show how our approach discerns latent structures in data even without information about the spatial ordering of channels, and yields a more interpretable decomposition of spatial and temporal structure underlying complex multivariate datasets."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ff7ebc8e9c684fb44b643768f8c6408950abf031.pdf"}, "supplementary_material": {"value": "/attachment/93384ae6696f7c89f0e41e80fc067da1714ac108.pdf"}, "_bibtex": {"value": "@inproceedings{\nxiao2024gaformer,\ntitle={{GAF}ormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings},\nauthor={Jingyun Xiao and Ran Liu and Eva L Dyer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=c56TWtYp0W}\n}"}, "paperhash": {"value": "xiao|gaformer_enhancing_timeseries_transformers_through_groupaware_embeddings"}}, "number": 8459, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8459/-/Revision", "ICLR.cc/2024/Conference/Submission8459/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695511281385, "cdate": 1695511281385, "tmdate": 1707625647550, "mdate": 1707625647550, "pdate": 1705411041142, "version": 2}, {"id": "3aZCPl3ZvR", "forum": "3aZCPl3ZvR", "signatures": ["ICLR.cc/2024/Conference/Submission8452/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8452/Authors"], "content": {"title": {"value": "Why is SAM Robust to Label Noise?"}, "authors": {"value": ["Christina Baek", "J Zico Kolter", "Aditi Raghunathan"]}, "authorids": {"value": ["~Christina_Baek2", "~J_Zico_Kolter1", "~Aditi_Raghunathan1"]}, "keywords": {"value": ["generalization", "sharpness", "robustness", "SAM"]}, "abstract": {"value": "Sharpness-Aware Minimization (SAM) is most known for achieving state-of the-art performances on natural image and language tasks. However, its most pronounced improvements (of tens of percent) is rather in the presence of label noise. Understanding SAM's label noise robustness requires a departure from characterizing the robustness of minimas lying in ``flatter'' regions of the loss landscape. In particular, the peak performance occurs with early stopping, far before the loss converges. We decompose SAM's robustness into two effects: one induced by changes to the logit term and the other induced by changes to the network Jacobian. The first can be observed in linear logistic regression where SAM provably upweights the gradient contribution from clean examples. Although this explicit upweighting is also observable in neural networks, when we intervene and modify SAM to remove this effect, surprisingly, we see no visible degradation in performance. We infer that SAM's effect in deeper networks is instead explained entirely by the effect SAM has on the network Jacobian. We theoretically derive the explicit regularization induced by this Jacobian effect in two layer linear networks. Motivated by our analysis, we see that cheaper alternatives to SAM that explicitly induce these regularization effects largely recover the benefits even in deep networks trained on real-world datasets."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5557f8d9c98c0d72e0584e24409bf799caa6b945.pdf"}, "_bibtex": {"value": "@inproceedings{\nbaek2024why,\ntitle={Why is {SAM} Robust to Label Noise?},\nauthor={Christina Baek and J Zico Kolter and Aditi Raghunathan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3aZCPl3ZvR}\n}"}, "paperhash": {"value": "baek|why_is_sam_robust_to_label_noise"}}, "number": 8452, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8452/-/Revision", "ICLR.cc/2024/Conference/Submission8452/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695510842198, "cdate": 1695510842198, "tmdate": 1707625647514, "mdate": 1707625647514, "pdate": 1705411040968, "version": 2}, {"id": "xxaEhwC1I4", "forum": "xxaEhwC1I4", "signatures": ["ICLR.cc/2024/Conference/Submission8446/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8446/Authors"], "content": {"title": {"value": "Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods"}, "authors": {"value": ["Zijian Liu", "Zhengyuan Zhou"]}, "authorids": {"value": ["~Zijian_Liu1", "~Zhengyuan_Zhou2"]}, "keywords": {"value": ["Convex Optimization", "Stochastic Optimization", "Last Iterate"]}, "abstract": {"value": "In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\\log(1/\\delta)\\log T/\\sqrt{T})$ or $O(\\sqrt{\\log(1/\\delta)/T})$ high-probability convergence rates for the final iterate, where $T$ is the time horizon and $\\delta$ is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smooth problems, only few results for smooth optimization have yet been developed. Additionally, the existing results are all limited to a non-composite objective and the standard Euclidean norm. It still remains unclear whether the last-iterate convergence can be provably extended to wider composite optimization and non-Euclidean norms. In this work, to address the issues mentioned above, we revisit the last-iterate convergence of stochastic gradient methods and provide the first unified way to prove the convergence rates both in expectation and in high probability to accommodate general domains, composite objectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity simultaneously."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/49e36604c5405004e38defe39ca3ff6ecf070ca6.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024revisiting,\ntitle={Revisiting the Last-Iterative Convergence of Stochastic Gradient Methods},\nauthor={Zijian Liu and Zhengyuan Zhou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xxaEhwC1I4}\n}"}, "paperhash": {"value": "liu|revisiting_the_lastiterate_convergence_of_stochastic_gradient_methods"}}, "number": 8446, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8446/-/Revision", "ICLR.cc/2024/Conference/Submission8446/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8446/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695510633123, "cdate": 1695510633123, "tmdate": 1709757397969, "mdate": 1709757397969, "pdate": 1705411040807, "version": 2}, {"id": "O8ouVV8PjF", "forum": "O8ouVV8PjF", "signatures": ["ICLR.cc/2024/Conference/Submission8442/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8442/Authors"], "content": {"title": {"value": "CNN Kernels Can Be the Best Shapelets"}, "authors": {"value": ["Eric Qu", "Yansen Wang", "Xufang Luo", "Wenqiang He", "Kan Ren", "Dongsheng Li"]}, "authorids": {"value": ["~Eric_Qu1", "~Yansen_Wang2", "~Xufang_Luo1", "~Wenqiang_He1", "~Kan_Ren1", "~Dongsheng_Li2"]}, "keywords": {"value": ["Shapelet", "Covolutional Neural Network", "Time-series"]}, "abstract": {"value": "Shapelets and CNN are two typical approaches to model time series. Shapelets aim at finding a set of sub-sequences that extract feature-based interpretable shapes, but may suffer from accuracy and efficiency issues. CNN performs well by encoding sequences with a series of hidden representations, but lacks interpretability. In this paper, we demonstrate that shapelets are essentially equivalent to a specific type of CNN kernel with a squared norm and pooling. Based on this finding, we propose ShapeConv, an interpretable CNN layer with its kernel serving as shapelets to conduct time-series modeling tasks in both supervised and unsupervised settings. By incorporating shaping regularization, we enforce the similarity for maximum interpretability. We also find human knowledge can be easily injected to ShapeConv by adjusting its initialization and model performance is boosted with it. Experiments show that ShapeConv can achieve state-of-the-art performance on time-series benchmarks without sacrificing interpretability and controllability."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/69b308cc2c2320f9051d94361939bb8848074ab0.pdf"}, "supplementary_material": {"value": "/attachment/b4abd24de48bab7b0270d60e94970935257d9d0b.zip"}, "_bibtex": {"value": "@inproceedings{\nqu2024cnn,\ntitle={{CNN} Kernels Can Be the Best Shapelets},\nauthor={Eric Qu and Yansen Wang and Xufang Luo and Wenqiang He and Kan Ren and Dongsheng Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=O8ouVV8PjF}\n}"}, "paperhash": {"value": "qu|cnn_kernels_can_be_the_best_shapelets"}}, "number": 8442, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8442/-/Revision", "ICLR.cc/2024/Conference/Submission8442/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8442/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695510415421, "cdate": 1695510415421, "tmdate": 1710485317043, "mdate": 1710485317043, "pdate": 1705411040722, "version": 2}, {"id": "WPZ2yPag4K", "forum": "WPZ2yPag4K", "signatures": ["ICLR.cc/2024/Conference/Submission8435/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8435/Authors"], "content": {"title": {"value": "Fine-Tuning Language Models for Factuality"}, "authors": {"value": ["Katherine Tian", "Eric Mitchell", "Huaxiu Yao", "Christopher D Manning", "Chelsea Finn"]}, "authorids": {"value": ["~Katherine_Tian1", "~Eric_Mitchell1", "~Huaxiu_Yao1", "~Christopher_D_Manning1", "~Chelsea_Finn1"]}, "keywords": {"value": ["factuality", "hallucination", "language model", "dpo"]}, "TLDR": {"value": "We fine-tune language models to significantly improve factuality without relying on human annotation, leveraging recent advances in learning from preferences and automated fact verification"}, "abstract": {"value": "The fluency and creativity of large pre-trained language models (LLMs) have led to their widespread use, sometimes even as a replacement for traditional search engines. Yet language models are prone to making convincing but factually inaccurate claims, often referred to as `hallucinations.' These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions. Further, manual fact-checking of model responses is a time-consuming process, making human factuality labels expensive to acquire. In this work, we fine-tune language models to be more factual, without human labeling and targeting more open-ended generation settings than past work. We leverage two key recent innovations in NLP to do so. First, several recent works have proposed methods for judging the factuality of open-ended text by measuring consistency with an external knowledge base or simply a large model's confidence scores. Second, the Direct Preference Optimization algorithm enables straightforward fine-tuning of language models on objectives other than supervised imitation, using a preference ranking over possible model responses. We show that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or our novel retrieval-free approach, significantly improves the factuality (percent of generated claims that are correct) of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. At 7B scale, compared to Llama-2-Chat, we observe 53% and 50% reduction in factual error rate when generating biographies and answering medical questions, respectively. A reference implementation can be found at https://github.com/kttian/llm_factuality_tuning."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f90a225c9859565a8e1ed01840ea046b406c7d4f.pdf"}, "_bibtex": {"value": "@inproceedings{\ntian2024finetuning,\ntitle={Fine-Tuning Language Models for Factuality},\nauthor={Katherine Tian and Eric Mitchell and Huaxiu Yao and Christopher D Manning and Chelsea Finn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WPZ2yPag4K}\n}"}, "paperhash": {"value": "tian|finetuning_language_models_for_factuality"}}, "number": 8435, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8435/-/Revision", "ICLR.cc/2024/Conference/Submission8435/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8435/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695510227836, "cdate": 1695510227836, "tmdate": 1713164419385, "mdate": 1713164419385, "pdate": 1705411040445, "version": 2}, {"id": "dEz3ge8QSo", "forum": "dEz3ge8QSo", "signatures": ["ICLR.cc/2024/Conference/Submission8422/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8422/Authors"], "content": {"title": {"value": "Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity"}, "authors": {"value": ["Runyu Zhang", "Yang Hu", "Na Li"]}, "authorids": {"value": ["~Runyu_Zhang1", "~Yang_Hu6", "~Na_Li3"]}, "keywords": {"value": ["risk-sensitive reinforcement learning", "robust Markov Decision Processes"]}, "abstract": {"value": "Robust Markov Decision Processes (MDPs) and risk-sensitive MDPs are both powerful tools for making decisions in the presence of uncertainties. Previous efforts have aimed to establish their connections, revealing equivalences in specific formulations. This paper introduces a new formulation for risk-sensitive MDPs, which assesses risk in a slightly different manner compared to the classical Markov risk measure [Ruszczy \u0301nski 2010], and establishes its equivalence with a class of soft robust MDP (RMDP) problems, including the standard RMDP as a special case. Leveraging this equivalence, we further derive the policy gradient theorem for both problems, proving gradient domination and global convergence of the exact policy gradient method under the tabular setting with direct parameterization. This forms a sharp contrast to the Markov risk measure, known to be potentially non-gradient-dominant [Huang et al. 2021]. We also propose a sample-based offline learning algorithm, namely the robust fitted-Z iteration (RFZI), for a specific soft RMDP problem with a KL-divergence regularization term (or equivalently the risk-sensitive MDP with an entropy risk measure). We showcase its streamlined\ndesign and less stringent assumptions due to the equivalence and analyze its sample complexity."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/317b11f5d5ce4a86be220bbd6715b66f4a55103a.pdf"}, "supplementary_material": {"value": "/attachment/80ebceed744cbf49fcc9f3e6e2624bf81d5c1e1f.pdf"}, "TLDR": {"value": "We propose a new formulation of risk-sensitive MDP and establish its equivalence with the (soft) robust MDP. Building upon the equivalence, we analyzed the policy gradient and offline sample complexity of the two problems."}, "_bibtex": {"value": "@inproceedings{\nzhang2024regularized,\ntitle={Regularized Robust {MDP}s and Risk-Sensitive {MDP}s: Equivalence, Policy Gradient, and Sample Complexity},\nauthor={Runyu Zhang and Yang Hu and Na Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dEz3ge8QSo}\n}"}, "paperhash": {"value": "zhang|soft_robust_mdps_and_risksensitive_mdps_equivalence_policy_gradient_and_sample_complexity"}}, "number": 8422, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8422/-/Revision", "ICLR.cc/2024/Conference/Submission8422/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8422/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509838413, "cdate": 1695509838413, "tmdate": 1712713657504, "mdate": 1712713657504, "pdate": 1705411040037, "version": 2}, {"id": "17pVDnpwwl", "forum": "17pVDnpwwl", "signatures": ["ICLR.cc/2024/Conference/Submission8419/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8419/Authors"], "content": {"title": {"value": "Tensor Programs VI: Feature Learning in Infinite Depth Neural Networks"}, "authors": {"value": ["Greg Yang", "Dingli Yu", "Chen Zhu", "Soufiane Hayou"]}, "authorids": {"value": ["~Greg_Yang1", "~Dingli_Yu1", "~Chen_Zhu2", "~Soufiane_Hayou1"]}, "keywords": {"value": ["Tensor Programs", "mup", "deep learning", "optimization", "optimal hyperparameter transfer"]}, "abstract": {"value": "Empirical studies have consistently demonstrated that increasing the size of neural networks often yields superior performance in practical applications. However, there is a lack of consensus regarding the appropriate scaling strategy, particularly when it comes to increasing the depth of neural networks. In practice, excessively large depths can lead to model performance degradation. In this paper, we introduce Depth-$\\mu$P, a principled approach for depth scaling, allowing for the training of arbitrarily deep architectures while maximizing feature learning and diversity among nearby layers. Our method involves dividing the contribution of each residual block and the parameter update by the square root of the depth. Through the use of Tensor Programs, we rigorously establish the existence of a limit for infinitely deep neural networks under the proposed scaling scheme. This scaling strategy ensures more stable training for deep neural networks and guarantees the transferability of hyperparameters from shallow to deep models. To substantiate the efficacy of our scaling method, we conduct empirical validation on neural networks with depths up to $2^{10}$."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a2d69b77708b87f741baac0303581cfb7924d0b7.pdf"}, "TLDR": {"value": "We introduce Depth-$\\mu$P, a principled approach for depth scaling, allowing for the training of arbitrarily deep networks while maximizing feature learning and feature diversity."}, "_bibtex": {"value": "@inproceedings{\nyang2024feature,\ntitle={Feature Learning in Infinite Depth Neural Networks},\nauthor={Greg Yang and Dingli Yu and Chen Zhu and Soufiane Hayou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=17pVDnpwwl}\n}"}, "paperhash": {"value": "yang|tensor_programs_vi_feature_learning_in_infinite_depth_neural_networks"}}, "number": 8419, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8419/-/Revision", "ICLR.cc/2024/Conference/Submission8419/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8419/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509632961, "cdate": 1695509632961, "tmdate": 1710540516276, "mdate": 1710540516276, "pdate": 1705411039975, "version": 2}, {"id": "BPHcEpGvF8", "forum": "BPHcEpGvF8", "signatures": ["ICLR.cc/2024/Conference/Submission8404/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8404/Authors"], "content": {"title": {"value": "Demystifying Poisoning Backdoor Attacks from a Statistical Perspective"}, "authors": {"value": ["Ganghua Wang", "Xun Xian", "Ashish Kundu", "Jayanth Srinivasa", "Xuan Bi", "Mingyi Hong", "Jie Ding"]}, "authorids": {"value": ["~Ganghua_Wang1", "~Xun_Xian1", "~Ashish_Kundu1", "~Jayanth_Srinivasa1", "~Xuan_Bi1", "~Mingyi_Hong1", "~Jie_Ding2"]}, "keywords": {"value": ["backdoor attack", "machine learning safety", "asymptotic", "statistical risk"]}, "TLDR": {"value": "We provide both finite-sample and asymptotic statistical analysis for theoretically understanding the backdoor attack."}, "abstract": {"value": "Backdoor attacks pose a significant security risk to machine learning applications due to their stealthy nature and potentially serious consequences. Such attacks involve embedding triggers within a learning model with the intention of causing malicious behavior when an active trigger is present while maintaining regular functionality without it. This paper derives a fundamental understanding of backdoor attacks that applies to both discriminative and generative models, including diffusion models and large language models. We evaluate the effectiveness of any backdoor attack incorporating a constant trigger, by establishing tight lower and upper boundaries for the performance of the compromised model on both clean and backdoor test data. The developed theory answers a series of fundamental but previously underexplored problems, including (1) what are the determining factors for a backdoor attack's success, (2) what is the direction of the most effective backdoor attack, and (3) when will a human-imperceptible trigger succeed. We demonstrate the theory by conducting experiments using benchmark datasets and state-of-the-art backdoor attack scenarios. Our code is available \\href{https://github.com/KeyWgh/DemystifyBackdoor}{here}."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2b97a4885cd767d5e6fad5ceeb1c8e5da20147c4.pdf"}, "supplementary_material": {"value": "/attachment/d1d4f7b70b114eb7ce8739d1ff6e5ea4fa6435a9.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024demystifying,\ntitle={Demystifying Poisoning Backdoor Attacks from a Statistical Perspective},\nauthor={Ganghua Wang and Xun Xian and Ashish Kundu and Jayanth Srinivasa and Xuan Bi and Mingyi Hong and Jie Ding},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BPHcEpGvF8}\n}"}, "paperhash": {"value": "wang|demystifying_poisoning_backdoor_attacks_from_a_statistical_perspective"}}, "number": 8404, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8404/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8404/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509024311, "cdate": 1695509024311, "tmdate": 1710183520702, "mdate": 1710183520702, "pdate": 1705411039811, "version": 2}, {"id": "RgELE1dQXx", "forum": "RgELE1dQXx", "signatures": ["ICLR.cc/2024/Conference/Submission8402/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8402/Authors"], "content": {"title": {"value": "Learning to Make Adherence-aware Advice"}, "authors": {"value": ["Guanting Chen", "Xiaocheng Li", "Chunlin Sun", "Hanzhao Wang"]}, "authorids": {"value": ["~Guanting_Chen1", "~Xiaocheng_Li1", "~Chunlin_Sun1", "~Hanzhao_Wang1"]}, "keywords": {"value": ["Human-AI interaction", "Reinforcement Learning"]}, "TLDR": {"value": "This paper provides models and algorithms that analyze the optimal advice policy, taking into account the possibility that humans might distrust the advice."}, "abstract": {"value": "As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/23fc1fd51c338383a74e3c5989a6dcd7a273a1c0.pdf"}, "supplementary_material": {"value": "/attachment/1e0d36661bd1ba4d7dd88f5f6fb9664bacdefda4.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024learning,\ntitle={Learning to make adherence-aware advice},\nauthor={Guanting Chen and Xiaocheng Li and Chunlin Sun and Hanzhao Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RgELE1dQXx}\n}"}, "paperhash": {"value": "chen|learning_to_make_adherenceaware_advice"}}, "number": 8402, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8402/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8402/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509003047, "cdate": 1695509003047, "tmdate": 1710985636780, "mdate": 1710985636780, "pdate": 1705411039702, "version": 2}, {"id": "uvFhCUPjtI", "forum": "uvFhCUPjtI", "signatures": ["ICLR.cc/2024/Conference/Submission8395/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8395/Authors"], "content": {"title": {"value": "Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs"}, "authors": {"value": ["Anson Bastos", "Kuldeep Singh", "Abhishek Nadgeri", "Manish Singh", "Toyotaro Suzumura"]}, "authorids": {"value": ["~Anson_Bastos1", "~Kuldeep_Singh1", "~Abhishek_Nadgeri1", "~Manish_Singh4", "~Toyotaro_Suzumura1"]}, "keywords": {"value": ["Temporal Dynamic Graphs", "Spectral Transform", "GNN"]}, "TLDR": {"value": "First work that proposes a concept to transform an evolving temporal graph to its frequency domain, we call it \"Evolving Graph Fourier Transform (EFT)\"."}, "abstract": {"value": "We present the Evolving Graph Fourier Transform (EFT), the first invertible spectral transform that captures evolving representations on temporal graphs. We motivate our work by the inadequacy of existing methods for capturing the evolving graph spectra, which are also computationally expensive due to the temporal aspect along with the graph vertex domain. We view the problem as an optimization over the Laplacian of the continuous time dynamic graph. Additionally, we propose pseudo-spectrum relaxations that decompose the transformation process, making it highly computationally efficient. The EFT method adeptly captures the evolving graph's structural and positional properties, making it effective for downstream tasks on evolving graphs. Hence, as a reference implementation, we develop a simple neural model induced with \\eft for capturing evolving graph spectra. We empirically validate our theoretical findings on a number of large-scale and standard temporal graph benchmarks and demonstrate that our model achieves state-of-the-art performance."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e8fdad4d187aeac65f168d4d33d4fa14828d52cb.pdf"}, "_bibtex": {"value": "@inproceedings{\nbastos2024beyond,\ntitle={Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs},\nauthor={Anson Bastos and Kuldeep Singh and Abhishek Nadgeri and Manish Singh and Toyotaro Suzumura},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uvFhCUPjtI}\n}"}, "paperhash": {"value": "bastos|beyond_spatiotemporal_representations_evolving_fourier_transform_for_temporal_graphs"}}, "number": 8395, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8395/-/Revision", "ICLR.cc/2024/Conference/Submission8395/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8395/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695508681383, "cdate": 1695508681383, "tmdate": 1710597404640, "mdate": 1710597404640, "pdate": 1705411039531, "version": 2}, {"id": "f1xnBr4WD6", "forum": "f1xnBr4WD6", "signatures": ["ICLR.cc/2024/Conference/Submission8392/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8392/Authors"], "content": {"title": {"value": "Cycle Consistency Driven Object Discovery"}, "authors": {"value": ["Aniket Rajiv Didolkar", "Anirudh Goyal", "Yoshua Bengio"]}, "authorids": {"value": ["~Aniket_Rajiv_Didolkar1", "~Anirudh_Goyal1", "~Yoshua_Bengio1"]}, "keywords": {"value": ["cycle consistency", "object discovery", "downstream RL"]}, "abstract": {"value": "Developing deep learning models that effectively learn object-centric representations, akin to human cognition, remains a challenging task. Existing approaches facilitate object discovery by representing objects as fixed-size vectors, called ``slots'' or ``object files''. While these approaches have shown promise in certain scenarios, they still exhibit certain limitations. First, they rely on architectural priors which can be unreliable and usually require meticulous engineering to identify the correct objects. Second, there has been a notable gap in investigating the practical utility of these representations in downstream tasks. To address the first limitation, we introduce a method that explicitly optimizes the constraint that each object in a scene should be associated with a distinct slot. We formalize this constraint by introducing  consistency objectives which are cyclic in nature. By integrating these consistency objectives into various existing slot-based object-centric methods, we showcase substantial improvements in object-discovery performance. These enhancements consistently hold true across both synthetic and real-world scenes, underscoring the effectiveness and adaptability of the proposed approach. To tackle the second limitation, we apply the learned object-centric representations from the proposed method to two downstream reinforcement learning tasks, demonstrating considerable performance enhancements compared to conventional slot-based and monolithic representation learning methods. Our results suggest that the proposed approach not only improves object discovery, but also provides richer features for downstream tasks."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/18ace982ecbf580ad919f876edd9b3a6e1652550.pdf"}, "_bibtex": {"value": "@inproceedings{\ndidolkar2024cycle,\ntitle={Cycle Consistency Driven Object Discovery},\nauthor={Aniket Rajiv Didolkar and Anirudh Goyal and Yoshua Bengio},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=f1xnBr4WD6}\n}"}, "paperhash": {"value": "didolkar|cycle_consistency_driven_object_discovery"}}, "number": 8392, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8392/-/Revision", "ICLR.cc/2024/Conference/Submission8392/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8392/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695508566103, "cdate": 1695508566103, "tmdate": 1710503052827, "mdate": 1710503052827, "pdate": 1705411039436, "version": 2}, {"id": "RVrINT6MT7", "forum": "RVrINT6MT7", "signatures": ["ICLR.cc/2024/Conference/Submission8388/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8388/Authors"], "content": {"title": {"value": "Sufficient conditions for offline reactivation in recurrent neural networks"}, "authors": {"value": ["Nanda H Krishna", "Colin Bredenberg", "Daniel Levenstein", "Blake Aaron Richards", "Guillaume Lajoie"]}, "authorids": {"value": ["~Nanda_H_Krishna1", "~Colin_Bredenberg1", "~Daniel_Levenstein1", "~Blake_Aaron_Richards1", "~Guillaume_Lajoie1"]}, "keywords": {"value": ["computational neuroscience", "offline reactivation", "replay", "recurrent neural networks", "path integration", "noise"]}, "TLDR": {"value": "We present theory and experiments which suggest that task optimization in noisy neural circuits can be sufficient to produce offline reactivation phenomena."}, "abstract": {"value": "During periods of quiescence, such as sleep, neural activity in many brain circuits resembles that observed during periods of task engagement. However, the precise conditions under which task-optimized networks can autonomously reactivate the same network states responsible for online behavior is poorly understood. In this study, we develop a mathematical framework that outlines sufficient conditions for the emergence of neural reactivation in circuits that encode features of smoothly varying stimuli. We demonstrate mathematically that noisy recurrent networks optimized to track environmental state variables using change-based sensory information naturally develop denoising dynamics, which, in the absence of input, cause the network to revisit state configurations observed during periods of online activity. We validate our findings using numerical experiments on two canonical neuroscience tasks: spatial position estimation based on self-motion cues, and head direction estimation based on angular velocity cues. Overall, our work provides theoretical support for modeling offline reactivation as an emergent consequence of task optimization in noisy neural circuits."}, "pdf": {"value": "/pdf/aeb8a90ea19ce51e6941aed794afc4e5ab5df2f4.pdf"}, "supplementary_material": {"value": "/attachment/c1af0b91b38721f0d7b100aa6f4448c35767cdae.zip"}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nkrishna2024sufficient,\ntitle={Sufficient conditions for offline reactivation in recurrent neural networks},\nauthor={Nanda H Krishna and Colin Bredenberg and Daniel Levenstein and Blake Aaron Richards and Guillaume Lajoie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RVrINT6MT7}\n}"}, "paperhash": {"value": "krishna|sufficient_conditions_for_offline_reactivation_in_recurrent_neural_networks"}}, "number": 8388, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8388/-/Revision", "ICLR.cc/2024/Conference/Submission8388/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8388/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695508203176, "cdate": 1695508203176, "tmdate": 1713165481683, "mdate": 1713165481683, "pdate": 1705411039294, "version": 2}, {"id": "Abr7dU98ME", "forum": "Abr7dU98ME", "signatures": ["ICLR.cc/2024/Conference/Submission8383/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8383/Authors"], "content": {"title": {"value": "Forward Learning of Graph Neural Networks"}, "authors": {"value": ["Namyong Park", "Xing Wang", "Antoine Simoulin", "Shuai Yang", "Grey Yang", "Ryan A. Rossi", "Puja Trivedi", "Nesreen K. Ahmed"]}, "authorids": {"value": ["~Namyong_Park1", "~Xing_Wang8", "~Antoine_Simoulin1", "~Shuai_Yang9", "~Grey_Yang1", "~Ryan_A._Rossi2", "~Puja_Trivedi1", "~Nesreen_K._Ahmed2"]}, "keywords": {"value": ["graph neural networks", "forward learning", "forward-forward algorithm"]}, "TLDR": {"value": "This paper develops a new forward learning procedure for graph neural networks."}, "abstract": {"value": "Graph neural networks (GNNs) have achieved remarkable success across a wide range of applications, such as recommendation, drug discovery, and question answering. Behind the success of GNNs lies the backpropagation (BP) algorithm, which is the de facto standard for training deep neural networks (NNs). However, despite its effectiveness, BP imposes several constraints, which are not only biologically implausible, but also limit the scalability, parallelism, and flexibility in learning NNs. Examples of such constraints include storage of neural activities computed in the forward pass for use in the subsequent backward pass, and the dependence of parameter updates on non-local signals. To address these limitations, the forward-forward algorithm (FF) was recently proposed as an alternative to BP in the image classification domain, which trains NNs by performing two forward passes over positive and negative data. Inspired by this advance, we propose ForwardGNN in this work, a new forward learning procedure for GNNs, which avoids the constraints imposed by BP via an effective layer-wise local forward training. ForwardGNN extends the original FF to deal with graph data and GNNs, and makes it possible to operate without generating negative inputs (hence no longer forward-forward). Further, ForwardGNN enables each layer to learn from both the bottom-up and top-down signals without relying on the backpropagation of errors. Extensive experiments on real-world datasets show the effectiveness and generality of the proposed forward graph learning framework. We release our code at https://github.com/facebookresearch/forwardgnn."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/78ce77aec3cb18418df9c216e801999677415163.pdf"}, "_bibtex": {"value": "@inproceedings{\npark2024forward,\ntitle={Forward Learning of Graph Neural Networks},\nauthor={Namyong Park and Xing Wang and Antoine Simoulin and Shuai Yang and Grey Yang and Ryan A. Rossi and Puja Trivedi and Nesreen K. Ahmed},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Abr7dU98ME}\n}"}, "paperhash": {"value": "park|forward_learning_of_graph_neural_networks"}}, "number": 8383, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8383/-/Revision", "ICLR.cc/2024/Conference/Submission8383/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8383/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695508012700, "cdate": 1695508012700, "tmdate": 1712966717049, "mdate": 1712966717049, "pdate": 1705411039192, "version": 2}, {"id": "rINBD8jPoP", "forum": "rINBD8jPoP", "signatures": ["ICLR.cc/2024/Conference/Submission8370/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8370/Authors"], "content": {"title": {"value": "Curriculum reinforcement learning for quantum architecture search under hardware errors"}, "authors": {"value": ["Yash J. Patel", "Akash Kundu", "Mateusz Ostaszewski", "Xavier Bonet-Monroig", "Vedran Dunjko", "Onur Danaci"]}, "authorids": {"value": ["~Yash_J._Patel1", "akundu@iitis.pl", "~Mateusz_Ostaszewski1", "bonet@lorentz.leidenuniv.nl", "~Vedran_Dunjko1", "danaci@lorentz.leidenuniv.nl"]}, "keywords": {"value": ["Quantum Computing", "Reinforcement Learning", "Quantum Chemistry", "Quantum Architecture Search", "Optimization"]}, "abstract": {"value": "The key challenge in the noisy intermediate-scale quantum era is finding useful circuits compatible with current device limitations.\nVariational quantum algorithms (VQAs) offer a potential solution by fixing the circuit architecture and optimizing individual gate parameters in an external loop. However, parameter optimization can become intractable, and the overall performance of the algorithm depends heavily on the initially chosen circuit architecture. Several quantum architecture search (QAS) algorithms have been developed to design useful circuit architectures automatically. In the case of parameter optimization alone, noise effects have been observed to dramatically influence the performance of the optimizer and final outcomes, which is a key line of study. However, the effects of noise on the architecture search, which could be just as critical, are poorly understood. This work addresses this gap by introducing a curriculum-based reinforcement learning QAS (CRLQAS) algorithm designed to tackle challenges in realistic VQA deployment. The algorithm incorporates (i) a 3D architecture encoding and restrictions on environment dynamics to explore the search space of possible circuits efficiently, (ii) an episode halting scheme to steer the agent to find shorter circuits, and (iii) a novel variant of simultaneous perturbation stochastic approximation as an optimizer for faster convergence. To facilitate studies, we developed an optimized simulator for our algorithm, significantly improving computational efficiency in simulating noisy quantum circuits by employing the Pauli-transfer matrix formalism in the Pauli-Liouville basis. Numerical experiments focusing on quantum chemistry tasks demonstrate that CRLQAS outperforms existing QAS algorithms across several metrics in both noiseless and noisy environments."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e6b75e0b94d3c31e7f0e5d1c7d11b4ccb1aca361.pdf"}, "_bibtex": {"value": "@inproceedings{\npatel2024curriculum,\ntitle={Curriculum reinforcement learning for quantum architecture search under hardware errors},\nauthor={Yash J. Patel and Akash Kundu and Mateusz Ostaszewski and Xavier Bonet-Monroig and Vedran Dunjko and Onur Danaci},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rINBD8jPoP}\n}"}, "paperhash": {"value": "patel|curriculum_reinforcement_learning_for_quantum_architecture_search_under_hardware_errors"}}, "number": 8370, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8370/-/Revision", "ICLR.cc/2024/Conference/Submission8370/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8370/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695507644607, "cdate": 1695507644607, "tmdate": 1709661547973, "mdate": 1709661547973, "pdate": 1705411038860, "version": 2}, {"id": "tnBaiidobu", "forum": "tnBaiidobu", "signatures": ["ICLR.cc/2024/Conference/Submission8369/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8369/Authors"], "content": {"title": {"value": "Does CLIP\u2019s generalization performance mainly stem from high train-test similarity?"}, "authors": {"value": ["Prasanna Mayilvahanan", "Thadd\u00e4us Wiedemer", "Evgenia Rusak", "Matthias Bethge", "Wieland Brendel"]}, "authorids": {"value": ["~Prasanna_Mayilvahanan2", "~Thadd\u00e4us_Wiedemer1", "~Evgenia_Rusak1", "~Matthias_Bethge1", "~Wieland_Brendel1"]}, "keywords": {"value": ["robustness", "foundation models", "CLIP", "LAION", "ImageNet", "generalization", "OOD robustness", "distribution shift", "vision language models", "self-supervised learning", "contrastive learning", "ObjectNet", "ImageNet-R", "ImageNet-Sketch", "ImageNet-A", "ImageNet-V2"]}, "TLDR": {"value": "CLIP's ability to generalize to standard OOD benchmarks does not mainly stem from highly similar images in its training dataset."}, "abstract": {"value": "Foundation models like CLIP are trained on hundreds of millions of samples and effortlessly generalize to new tasks and inputs. Out of the box, CLIP shows stellar zero-shot and few-shot capabilities on a wide range of out-of-distribution (OOD) benchmarks, which prior works attribute mainly to today's large and comprehensive training dataset (like LAION). However, it is questionable how meaningful terms like out-of-distribution generalization are for CLIP as it seems likely that web-scale datasets like LAION simply contain many samples that are similar to common OOD benchmarks originally designed for ImageNet. To test this hypothesis, we retrain CLIP on pruned LAION splits that replicate ImageNet\u2019s train-test similarity with respect to common OOD benchmarks. While we observe a performance drop on some benchmarks, surprisingly, CLIP\u2019s overall performance remains high. This shows that high train-test similarity is insufficient to explain CLIP\u2019s OOD performance, and other properties of the training data must drive CLIP to learn more generalizable representations. Additionally, by pruning data points that are dissimilar to the OOD benchmarks, we uncover a 100M split of LAION (\u00bc of its original size) on which CLIP can be trained to match its original OOD performance."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/914ba616ab5450c89e489fa002bc6f6587152c84.pdf"}, "supplementary_material": {"value": "/attachment/ac7e23ca9202031246ae12159d59894c02c97524.zip"}, "_bibtex": {"value": "@inproceedings{\nmayilvahanan2024does,\ntitle={Does {CLIP}{\\textquoteright}s generalization performance mainly stem from high train-test similarity?},\nauthor={Prasanna Mayilvahanan and Thadd{\\\"a}us Wiedemer and Evgenia Rusak and Matthias Bethge and Wieland Brendel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tnBaiidobu}\n}"}, "paperhash": {"value": "mayilvahanan|does_clips_generalization_performance_mainly_stem_from_high_traintest_similarity"}}, "number": 8369, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8369/-/Revision", "ICLR.cc/2024/Conference/Submission8369/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8369/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695507602250, "cdate": 1695507602250, "tmdate": 1710440116318, "mdate": 1710440116318, "pdate": 1705411038816, "version": 2}, {"id": "H4A9e8HvIn", "forum": "H4A9e8HvIn", "signatures": ["ICLR.cc/2024/Conference/Submission8364/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8364/Authors"], "content": {"title": {"value": "Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization"}, "authors": {"value": ["Mohammad Pedramfar", "Yididiya Y. Nadew", "Christopher John Quinn", "Vaneet Aggarwal"]}, "authorids": {"value": ["~Mohammad_Pedramfar1", "~Yididiya_Y._Nadew1", "~Christopher_John_Quinn1", "~Vaneet_Aggarwal1"]}, "keywords": {"value": ["Stochastic optimization", "submodular maximization", "Frank-Wolfe algorithm"]}, "abstract": {"value": "This paper introduces unified projection-free Frank-Wolfe type algorithms for adversarial continuous DR-submodular optimization, spanning scenarios such as full information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. For every problem considered in the non-monotone setting, the proposed algorithms are either the first with proven sub-linear $\\alpha$-regret bounds or have better $\\alpha$-regret bounds than the state of the art, where $\\alpha$ is a corresponding approximation bound in the offline setting. In the monotone setting, the proposed approach gives state-of-the-art sub-linear $\\alpha$-regret bounds among projection-free algorithms in 7 of the 8 considered cases while matching the result of the remaining case. Additionally, this paper addresses semi-bandit and bandit feedback for adversarial DR-submodular optimization, advancing the understanding of this optimization area."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c8701ec65ea9e2a9ef05a94e26ebcad8d0d3e58f.pdf"}, "_bibtex": {"value": "@inproceedings{\npedramfar2024a,\ntitle={A Unified Approach for Online Continuous {DR}-Submodular Maximization},\nauthor={Mohammad Pedramfar and Yididiya Y. Nadew and Christopher John Quinn and Vaneet Aggarwal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=H4A9e8HvIn}\n}"}, "paperhash": {"value": "pedramfar|unified_projectionfree_algorithms_for_adversarial_drsubmodular_optimization"}}, "number": 8364, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8364/-/Revision", "ICLR.cc/2024/Conference/Submission8364/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8364/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695507210920, "cdate": 1695507210920, "tmdate": 1710484671421, "mdate": 1710484671421, "pdate": 1705411038758, "version": 2}, {"id": "5HCnKDeTws", "forum": "5HCnKDeTws", "signatures": ["ICLR.cc/2024/Conference/Submission8351/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8351/Authors"], "content": {"title": {"value": "When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"}, "authors": {"value": ["Biao Zhang", "Zhongtao Liu", "Colin Cherry", "Orhan Firat"]}, "authorids": {"value": ["~Biao_Zhang2", "zhongtao@google.com", "~Colin_Cherry1", "~Orhan_Firat1"]}, "keywords": {"value": ["LLM finetuning", "Scaling Laws", "Full-model finetuning", "Parameter efficient tuning", "Machine Translation", "Multilingual Summarization"]}, "abstract": {"value": "While large language models (LLMs) often adopt finetuning to unlock their capabilities for downstream applications, our understanding on the inductive biases (especially the scaling properties) of different finetuning methods is still limited. To fill this gap, we conduct systematic experiments studying whether and how different scaling factors, including LLM model size, pretraining data size, new finetuning parameter size and finetuning data size, affect the finetuning performance. We consider two types of finetuning \u2013 full-model tuning (FMT) and parameter efficient tuning (PET, including prompt tuning and LoRA), and explore their scaling behaviors in the data-limited regime where the LLM model size substantially outweighs the finetuning data size. Based on two sets of pretrained bilingual LLMs from 1B to 16B and experiments on bilingual machine translation and multilingual summarization benchmarks, we find that 1) LLM finetuning follows a powerbased multiplicative joint scaling law between finetuning data size and each other scaling factor; 2) LLM finetuning benefits more from LLM model scaling than pretraining data scaling, and PET parameter scaling is generally ineffective; and 3) the optimal finetuning method is highly task- and finetuning data-dependent. We hope our findings could shed light on understanding, selecting and developing LLM finetuning methods."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c50285d47fae2fec5f5aa87de6d9e6a921de02b9.pdf"}, "TLDR": {"value": "We explore the scaling for LLM finetuning and consider multiple factors, including LLM model size, pretraining data size, finetuning data size, and new finetuning parameter size."}, "_bibtex": {"value": "@inproceedings{\nzhang2024when,\ntitle={When Scaling Meets {LLM} Finetuning: The Effect of Data, Model and Finetuning Method},\nauthor={Biao Zhang and Zhongtao Liu and Colin Cherry and Orhan Firat},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5HCnKDeTws}\n}"}, "paperhash": {"value": "zhang|when_scaling_meets_llm_finetuning_the_effect_of_data_model_and_finetuning_method"}}, "number": 8351, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8351/-/Revision", "ICLR.cc/2024/Conference/Submission8351/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8351/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695506447665, "cdate": 1695506447665, "tmdate": 1709661547847, "mdate": 1709661547847, "pdate": 1705411038594, "version": 2}, {"id": "xcMmebCT7s", "forum": "xcMmebCT7s", "signatures": ["ICLR.cc/2024/Conference/Submission8349/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8349/Authors"], "content": {"title": {"value": "Learning to design protein-protein interactions with enhanced generalization"}, "authors": {"value": ["Anton Bushuiev", "Roman Bushuiev", "Petr Kouba", "Anatolii Filkin", "Marketa Gabrielova", "Michal Gabriel", "Jiri Sedlar", "Tomas Pluskal", "Jiri Damborsky", "Stanislav Mazurenko", "Josef Sivic"]}, "authorids": {"value": ["~Anton_Bushuiev1", "roman.bushuiev@uochb.cas.cz", "koubape9@fel.cvut.cz", "filkiana@student.cvut.cz", "makyta.gabrielova@seznam.cz", "gabriel.michal@post.cz", "~Jiri_Sedlar1", "tomas.pluskal@uochb.cas.cz", "jiri@chemi.muni.cz", "mazurenko@mail.muni.cz", "~Josef_Sivic1"]}, "keywords": {"value": ["protein-protein interactions", "protein design", "generalization", "self-supervised learning", "equivariant 3D representations"]}, "abstract": {"value": "Discovering mutations enhancing protein-protein interactions (PPIs) is critical for advancing biomedical research and developing improved therapeutics. While machine learning approaches have substantially advanced the field, they often struggle to generalize beyond training data in practical scenarios. The contributions of this work are three-fold. First, we construct PPIRef, the largest and non-redundant dataset of 3D protein-protein interactions, enabling effective large-scale learning. Second, we leverage the PPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model generalizing across diverse protein-binder variants. We fine-tune PPIformer to predict effects of mutations on protein-protein interactions via a thermodynamically motivated adjustment of the pre-training loss function. Finally, we demonstrate the enhanced generalization of our new PPIformer approach by outperforming other state-of-the-art methods on new, non-leaking splits of standard labeled PPI mutational data and independent case studies optimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic activity of staphylokinase."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/03bb8ce604b1ff6fb6f9d6504d13322265401a20.pdf"}, "_bibtex": {"value": "@inproceedings{\nbushuiev2024learning,\ntitle={Learning to design protein-protein interactions with enhanced generalization},\nauthor={Anton Bushuiev and Roman Bushuiev and Petr Kouba and Anatolii Filkin and Marketa Gabrielova and Michal Gabriel and Jiri Sedlar and Tomas Pluskal and Jiri Damborsky and Stanislav Mazurenko and Josef Sivic},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xcMmebCT7s}\n}"}, "TLDR": {"value": "We introduce PPIRef dataset and PPIformer model to predict mutation effects on protein-protein interactions, achieving state-of-the-art performance on standard data and practical case studies in SARS-CoV-2 antibody design and thrombolytic engineering"}, "paperhash": {"value": "bushuiev|learning_to_design_proteinprotein_interactions_with_enhanced_generalization"}}, "number": 8349, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8349/-/Revision", "ICLR.cc/2024/Conference/Submission8349/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8349/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695506177862, "cdate": 1695506177862, "tmdate": 1710607890205, "mdate": 1710607890205, "pdate": 1705411038526, "version": 2}, {"id": "EhrzQwsV4K", "forum": "EhrzQwsV4K", "signatures": ["ICLR.cc/2024/Conference/Submission8334/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8334/Authors"], "content": {"title": {"value": "L2MAC: Large Language Model Automatic Computer for Extensive Code Generation"}, "authors": {"value": ["Samuel Holt", "Max Ruiz Luyten", "Mihaela van der Schaar"]}, "authorids": {"value": ["~Samuel_Holt1", "~Max_Ruiz_Luyten1", "~Mihaela_van_der_Schaar2"]}, "keywords": {"value": ["Code Generation", "Memory-augmented LLMs", "Large Language Models (LLMs)", "LLM coder agent", "LLM Agent", "Stored-program computer", "von neumann architecture"]}, "abstract": {"value": "Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and coherent outputs. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long output generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based general-purpose stored-program automatic computer (von Neumann architecture) framework, an LLM-based multi-agent system, for long and consistent output generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction in turn is executed by a separate LLM agent, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective interaction with the file store. These components enable L2MAC to generate extensive outputs, bypassing the constraints of the finite context window while producing outputs that fulfill a complex user-specified task. We empirically demonstrate that L2MAC achieves state-of-the-art performance in generating large codebases for system design tasks, significantly outperforming other coding methods in implementing the detailed user-specified task; we show that L2MAC works for general-purpose extensive text-based tasks, such as writing an entire book; and we provide valuable insights into L2MAC's performance improvement over existing methods."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/95b79a48ec0b2b890a4402573535697cd59c4435.pdf"}, "_bibtex": {"value": "@inproceedings{\nholt2024lmac,\ntitle={L2{MAC}: Large Language Model Automatic Computer for Unbounded Code Generation},\nauthor={Samuel Holt and Max Ruiz Luyten and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EhrzQwsV4K}\n}"}, "TLDR": {"value": "Introducing L2MAC, pioneering the first practical LLM-based stored-program automatic computer (von Neumann architecture) framework in an LLM-based multi-agent system, for solving complex tasks through generating extensive and consistent outputs."}, "paperhash": {"value": "holt|l2mac_large_language_model_automatic_computer_for_extensive_code_generation"}}, "number": 8334, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8334/-/Revision", "ICLR.cc/2024/Conference/Submission8334/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8334/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695505780327, "cdate": 1695505780327, "tmdate": 1712753311863, "mdate": 1712753311863, "pdate": 1705411038230, "version": 2}, {"id": "c93SBwz1Ma", "forum": "c93SBwz1Ma", "signatures": ["ICLR.cc/2024/Conference/Submission8331/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8331/Authors"], "content": {"title": {"value": "BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models"}, "authors": {"value": ["Zhen Xiang", "Fengqing Jiang", "Zidi Xiong", "Bhaskar Ramasubramanian", "Radha Poovendran", "Bo Li"]}, "authorids": {"value": ["~Zhen_Xiang1", "~Fengqing_Jiang1", "~Zidi_Xiong2", "~Bhaskar_Ramasubramanian1", "~Radha_Poovendran1", "~Bo_Li19"]}, "keywords": {"value": ["large language model", "chain-of-thought", "backdoor attack", "reasoning task"]}, "TLDR": {"value": "We proposed the first backdoor attack against LLMs with COT prompting that does not require access to the training set or model parameters."}, "abstract": {"value": "Large language models (LLMs) are shown to benefit from chain-of-thought (COT) prompting, particularly when tackling tasks that require systematic reasoning processes. On the other hand, COT prompting also poses new vulnerabilities in the form of backdoor attacks, wherein the model will output unintended malicious content under specific backdoor-triggered conditions during inference. Traditional methods for launching backdoor attacks involve either contaminating the training dataset with backdoored instances or directly manipulating the model parameters during deployment. However, these approaches are not practical for commercial LLMs that typically operate via API access. In this paper, we propose BadChain, the first backdoor attack against LLMs employing COT prompting, which does not require access to the training dataset or model parameters and imposes low computational overhead. BadChain leverages the inherent reasoning capabilities of LLMs by inserting a backdoor reasoning step into the sequence of reasoning steps of the model output, thereby altering the final response when a backdoor trigger is embedded in the query prompt. In particular, a subset of demonstrations will be manipulated to incorporate a backdoor reasoning step in COT prompting. Consequently, given any query prompt containing the backdoor trigger, the LLM will be misled to output unintended content. Empirically, we show the effectiveness of BadChain for two COT strategies across four LLMs (Llama2, GPT-3.5, PaLM2, and GPT-4) and six complex benchmark tasks encompassing arithmetic, commonsense, and symbolic reasoning. We show that the baseline backdoor attacks designed for simpler tasks such as semantic classification will fail on these complicated tasks. In addition, our findings reveal that LLMs endowed with stronger reasoning capabilities exhibit higher susceptibility to BadChain, exemplified by a high average attack success rate of 97.0\\% across the six benchmark tasks on GPT-4. We also demonstrate the interpretability of BadChain by showing that the relationship between the trigger and the backdoor reasoning step can be well-explained based on the output of the backdoored model. Finally, we propose two defenses based on shuffling and demonstrate their overall ineffectiveness against BadChain. Therefore, BadChain remains a severe threat to LLMs, underscoring the urgency for the development of robust and effective future defenses."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f55f665827c60d9ab1815886945cb4b0fcd9b12b.pdf"}, "_bibtex": {"value": "@inproceedings{\nxiang2024badchain,\ntitle={BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models},\nauthor={Zhen Xiang and Fengqing Jiang and Zidi Xiong and Bhaskar Ramasubramanian and Radha Poovendran and Bo Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=c93SBwz1Ma}\n}"}, "paperhash": {"value": "xiang|badchain_backdoor_chainofthought_prompting_for_large_language_models"}}, "number": 8331, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8331/-/Revision", "ICLR.cc/2024/Conference/Submission8331/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8331/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695505607351, "cdate": 1695505607351, "tmdate": 1709661547655, "mdate": 1709661547655, "pdate": 1705411038055, "version": 2}, {"id": "samyfu6G93", "forum": "samyfu6G93", "signatures": ["ICLR.cc/2024/Conference/Submission8318/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8318/Authors"], "content": {"title": {"value": "NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks"}, "authors": {"value": ["Wenxi Wang", "Yang Hu", "Mohit Tiwari", "Sarfraz Khurshid", "Kenneth McMillan", "Risto Miikkulainen"]}, "authorids": {"value": ["~Wenxi_Wang1", "~Yang_Hu7", "~Mohit_Tiwari1", "~Sarfraz_Khurshid1", "~Kenneth_McMillan1", "~Risto_Miikkulainen1"]}, "keywords": {"value": ["Propositional satisfiability", "Graph Neural Networks", "CDCL SAT Solving", "Backbone", "Phase Prediction"]}, "TLDR": {"value": "The paper applies GNN to predict the backbone in an offline manner to obtain the phase information of important variables for improving CDCL solving."}, "abstract": {"value": "Propositional satisfiability (SAT) is an NP-complete problem that impacts many\nresearch fields, such as planning, verification, and security. Mainstream modern\nSAT solvers are based on the Conflict-Driven Clause Learning (CDCL) algorithm.\nRecent work aimed to enhance CDCL SAT solvers using Graph Neural Networks\n(GNNs). However, so far this approach either has not made solving more effective,\nor required substantial GPU resources for frequent online model inferences. Aiming\nto make GNN improvements practical, this paper proposes an approach called\nNeuroBack, which builds on two insights: (1) predicting phases (i.e., values) of\nvariables appearing in the majority (or even all) of the satisfying assignments are\nessential for CDCL SAT solving, and (2) it is sufficient to query the neural model\nonly once for the predictions before the SAT solving starts. Once trained, the\noffline model inference allows NeuroBack to execute exclusively on the CPU,\nremoving its reliance on GPU resources. To train NeuroBack, a new dataset called\nDataBack containing 120,286 data samples is created. Finally, NeuroBack is implemented\nas an enhancement to a state-of-the-art SAT solver called Kissat. As a result,\nit allowed Kissat to solve 5.2% more problems on the recent SAT competition\nproblem set, SATCOMP-2022. NeuroBack therefore shows how machine learning\ncan be harnessed to improve SAT solving in an effective and practical manner."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/68668727b395677105cd2bfd38dc554dc5b67212.pdf"}, "supplementary_material": {"value": "/attachment/2bd9af40997253cdf1dedc050273ec7060af5871.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024neuroback,\ntitle={NeuroBack: Improving {CDCL} {SAT} Solving using Graph Neural Networks},\nauthor={Wenxi Wang and Yang Hu and Mohit Tiwari and Sarfraz Khurshid and Kenneth McMillan and Risto Miikkulainen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=samyfu6G93}\n}"}, "paperhash": {"value": "wang|neuroback_improving_cdcl_sat_solving_using_graph_neural_networks"}}, "number": 8318, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8318/-/Revision", "ICLR.cc/2024/Conference/Submission8318/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8318/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695505221832, "cdate": 1695505221832, "tmdate": 1713153562047, "mdate": 1713153562047, "pdate": 1705411037789, "version": 2}, {"id": "DpFeMH4l8Q", "forum": "DpFeMH4l8Q", "signatures": ["ICLR.cc/2024/Conference/Submission8317/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8317/Authors"], "content": {"title": {"value": "Group Preference Optimization: Few-Shot Alignment of Large Language Models"}, "authors": {"value": ["Siyan Zhao", "John Dang", "Aditya Grover"]}, "authorids": {"value": ["~Siyan_Zhao1", "~John_Dang1", "~Aditya_Grover1"]}, "keywords": {"value": ["Large Language Models", "alignment", "group preference alignment", "few-shot learning", "in-context learning", "fine-tuning"]}, "abstract": {"value": "Many applications of large language models (LLMs), ranging from chatbots to\ncreative writing, require nuanced subjective judgments that can differ significantly\nacross different groups. Existing alignment algorithms can be expensive to align\nfor each group, requiring prohibitive amounts of group-specific preference data\nand computation for real-world use cases. We introduce Group Preference Optimization (GPO), an alignment framework that steers language models to preferences of individual groups in a few-shot manner. In GPO, we augment the base\nLLM with an independent transformer module trained to predict the preferences\nof a group for the LLM generations. For few-shot learning, we parameterize this\nmodule as an in-context autoregressive transformer and train it via meta-learning\non several groups. We empirically validate the efficacy of GPO through rigorous evaluations using LLMs with varied sizes on three human opinion adaptation tasks. These tasks involve adapting to the preferences of US demographic\ngroups, global countries, and individual users. Our results demonstrate that GPO\nnot only aligns models more accurately but also requires fewer group-specific\npreferences and less training and inference computing resources, outperforming\nexisting strategies such as in-context steering and fine-tuning methods."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e743356473984605880070de9402840ffe780599.pdf"}, "supplementary_material": {"value": "/attachment/e6e6b38cf6f535fca8024cf016c0544a43b2bd0e.zip"}, "_bibtex": {"value": "@inproceedings{\nzhao2024group,\ntitle={Group Preference Optimization: Few-Shot Alignment of Large Language Models},\nauthor={Siyan Zhao and John Dang and Aditya Grover},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DpFeMH4l8Q}\n}"}, "paperhash": {"value": "zhao|group_preference_optimization_fewshot_alignment_of_large_language_models"}}, "number": 8317, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8317/-/Revision", "ICLR.cc/2024/Conference/Submission8317/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8317/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695505031049, "cdate": 1695505031049, "tmdate": 1713156664963, "mdate": 1713156664963, "pdate": 1705411037787, "version": 2}, {"id": "w3YZ9MSlBu", "forum": "w3YZ9MSlBu", "signatures": ["ICLR.cc/2024/Conference/Submission8278/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8278/Authors"], "content": {"title": {"value": "MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training"}, "authors": {"value": ["Yizhi LI", "Ruibin Yuan", "Ge Zhang", "Yinghao Ma", "Xingran Chen", "Hanzhi Yin", "Chenghao Xiao", "Chenghua Lin", "Anton Ragni", "Emmanouil Benetos", "Norbert Gyenge", "Roger Dannenberg", "Ruibo Liu", "Wenhu Chen", "Gus Xia", "Yemin Shi", "Wenhao Huang", "Zili Wang", "Yike Guo", "Jie Fu"]}, "authorids": {"value": ["~Yizhi_LI1", "~Ruibin_Yuan1", "~Ge_Zhang5", "~Yinghao_Ma1", "~Xingran_Chen1", "~Hanzhi_Yin1", "~Chenghao_Xiao1", "~Chenghua_Lin1", "~Anton_Ragni1", "~Emmanouil_Benetos1", "~Norbert_Gyenge1", "~Roger_Dannenberg1", "~Ruibo_Liu1", "~Wenhu_Chen3", "~Gus_Xia1", "~Yemin_Shi2", "~Wenhao_Huang1", "~Zili_Wang1", "~Yike_Guo1", "~Jie_Fu2"]}, "keywords": {"value": ["self-supervised learning", "music", "audio", "language model"]}, "TLDR": {"value": "We propose MERT, a self-supervised acoustic music understading model that generalises well on a wide range of tasks."}, "abstract": {"value": "Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. \nAlthough SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is partially due to the distinctive challenges associated with modelling musical knowledge, particularly tonal and pitched characteristics of music.\nTo address this research gap, we propose an acoustic **M**usic und**ER**standing model with large-scale self-supervised **T**raining (**MERT**), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training.\nIn our exploration, we identified an effective combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. \nThis combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a musical teacher based on the Constant-Q Transform (CQT). \nFurthermore, we explore a wide range of settings to overcome the instability in acoustic language model pre-training, which allows our designed paradigm to scale from 95M to 330M parameters.\nExperimental results indicate that our model can generalise and perform well on 14 music understanding tasks and attain state-of-the-art (SOTA) overall scores."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b0691ff4b8bef0f41861ce3bd2ea50491707b93c.pdf"}, "supplementary_material": {"value": "/attachment/9d763e939566248881f9f354240d07393dbe1124.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024mert,\ntitle={{MERT}: Acoustic Music Understanding Model with Large-Scale Self-supervised Training},\nauthor={Yizhi LI and Ruibin Yuan and Ge Zhang and Yinghao Ma and Xingran Chen and Hanzhi Yin and Chenghao Xiao and Chenghua Lin and Anton Ragni and Emmanouil Benetos and Norbert Gyenge and Roger Dannenberg and Ruibo Liu and Wenhu Chen and Gus Xia and Yemin Shi and Wenhao Huang and Zili Wang and Yike Guo and Jie Fu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w3YZ9MSlBu}\n}"}, "paperhash": {"value": "li|mert_acoustic_music_understanding_model_with_largescale_selfsupervised_training"}}, "number": 8278, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8278/-/Revision", "ICLR.cc/2024/Conference/Submission8278/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8278/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695503587389, "cdate": 1695503587389, "tmdate": 1709661547442, "mdate": 1709661547442, "pdate": 1705411036714, "version": 2}, {"id": "rDH7dIFn20", "forum": "rDH7dIFn20", "signatures": ["ICLR.cc/2024/Conference/Submission8277/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8277/Authors"], "content": {"title": {"value": "Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits"}, "authors": {"value": ["Qiwei Di", "Tao Jin", "Yue Wu", "Heyang Zhao", "Farzad Farnoud", "Quanquan Gu"]}, "authorids": {"value": ["~Qiwei_Di1", "~Tao_Jin3", "~Yue_Wu12", "~Heyang_Zhao1", "~Farzad_Farnoud1", "~Quanquan_Gu1"]}, "keywords": {"value": ["Dueling Bandit", "Variance-aware", "contextual bandit"]}, "TLDR": {"value": "We study the problem of dueling bandit and prove a variance-aware regret bound."}, "abstract": {"value": "Dueling bandits is a prominent framework for decision-making involving preferential feedback, a valuable feature that fits various applications involving human interaction, such as ranking, information retrieval, and recommendation systems. While substantial efforts have been made to minimize the cumulative regret in dueling bandits, a notable gap in the current research is the absence of regret bounds that account for the inherent uncertainty in pairwise comparisons between the dueling arms. Intuitively, greater uncertainty suggests a higher level of difficulty in the problem.  To bridge this gap, this paper studies the problem of contextual dueling bandits, where the binary comparison of dueling arms is generated from a generalized linear model (GLM). We propose a new SupLinUCB-type algorithm that enjoys computational efficiency and a variance-aware regret bound $\\tilde O\\big(d\\sqrt{\\sum_{t=1}^T\\sigma_t^2} + d\\big)$, where $\\sigma_t$ is the variance of the pairwise comparison at round $t$, $d$ is the dimension of the context vectors, and $T$ is the time horizon. Our regret bound naturally aligns with the intuitive expectation \u2014 in scenarios where the comparison is deterministic, the algorithm only suffers from an $\\tilde O(d)$ regret. We perform empirical experiments on synthetic data to confirm the advantage of our method over previous variance-agnostic algorithms."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4c1a08aad3975e9de1adbba054eea8e3f1287418.pdf"}, "_bibtex": {"value": "@inproceedings{\ndi2024varianceaware,\ntitle={Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits},\nauthor={Qiwei Di and Tao Jin and Yue Wu and Heyang Zhao and Farzad Farnoud and Quanquan Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rDH7dIFn20}\n}"}, "paperhash": {"value": "di|varianceaware_regret_bounds_for_stochastic_contextual_dueling_bandits"}}, "number": 8277, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8277/-/Revision", "ICLR.cc/2024/Conference/Submission8277/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8277/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695503559474, "cdate": 1695503559474, "tmdate": 1710563948652, "mdate": 1710563948652, "pdate": 1705411036601, "version": 2}, {"id": "ueTdErd5Ib", "forum": "ueTdErd5Ib", "signatures": ["ICLR.cc/2024/Conference/Submission8275/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8275/Authors"], "content": {"title": {"value": "A Discretization Framework for Robust Contextual Stochastic Optimization"}, "authors": {"value": ["Rares C Cristian", "Georgia Perakis"]}, "authorids": {"value": ["~Rares_C_Cristian1", "~Georgia_Perakis1"]}, "keywords": {"value": ["Robust Optimization", "Stochastic Optimization", "End-to-End learning"]}, "abstract": {"value": "We study contextual stochastic optimization problems. Optimization problems have uncertain parameters stemming from unknown, context-dependent, distributions. Due to the inherent uncertainty in these problems, one is often interested not only in minimizing expected cost, but also to be robust and protect against worst case scenarios. We propose a novel method that combines the learning stage with knowledge of the downstream optimization task. The method prescribes decisions which aim to maximize the likelihood that the cost is below a (user-controlled) threshold. The key idea is (1) to discretize the feasible region into subsets so that the uncertain objective function can be well approximated deterministically within each subset, and (2) devise a secondary optimization problem to prescribe decisions by integrating the individual approximations determined in step (1). We provide theoretical guarantees bounding the underlying regret of decisions proposed by our method. In addition, experimental results demonstrate that our approach is competitive in terms of average regret and yields more robust solutions than other methods proposed in the literature, including up to 20 times lower worst-case cost on a real-world electricity generation problem."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2097641b7d16f85a6d284604d4e690fc32f2e79e.pdf"}, "supplementary_material": {"value": "/attachment/cb31544457c0f095d12494db5a9dd866dc6dc266.zip"}, "_bibtex": {"value": "@inproceedings{\ncristian2024a,\ntitle={A Discretization Framework for Robust Contextual Stochastic Optimization},\nauthor={Rares C Cristian and Georgia Perakis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ueTdErd5Ib}\n}"}, "paperhash": {"value": "cristian|a_discretization_framework_for_robust_contextual_stochastic_optimization"}}, "number": 8275, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8275/-/Revision", "ICLR.cc/2024/Conference/Submission8275/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8275/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695503360095, "cdate": 1695503360095, "tmdate": 1710356595209, "mdate": 1710356595209, "pdate": 1705411036534, "version": 2}, {"id": "AcoXPIPh4A", "forum": "AcoXPIPh4A", "signatures": ["ICLR.cc/2024/Conference/Submission8252/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8252/Authors"], "content": {"title": {"value": "Risk Bounds of Accelerated SGD for Overparameterized Linear Regression"}, "authors": {"value": ["Xuheng Li", "Yihe Deng", "Jingfeng Wu", "Dongruo Zhou", "Quanquan Gu"]}, "authorids": {"value": ["~Xuheng_Li1", "~Yihe_Deng1", "~Jingfeng_Wu1", "~Dongruo_Zhou1", "~Quanquan_Gu1"]}, "keywords": {"value": ["Accelerated stochastic gradient descent", "excess risk", "linear regression", "overparameterization"]}, "abstract": {"value": "Accelerated stochastic gradient descent (ASGD) is a workhorse in deep learning and often achieves better generalization performance than SGD. However, existing optimization theory can only explain the faster convergence of ASGD, but cannot explain its better generalization. In this paper, we study the generalization of ASGD for overparameterized linear regression, which is possibly the simplest setting of learning with overparameterization. We establish an instance-dependent excess risk bound for ASGD within each eigen-subspace of the data covariance matrix. Our analysis shows that (i) ASGD outperforms SGD in the subspace of small eigenvalues, exhibiting a faster rate of exponential decay for bias error, while in the subspace of large eigenvalues, its bias error decays slower than SGD; and (ii) the variance error of ASGD is always larger than that of SGD. Our result suggests that ASGD can outperform SGD when the difference between the initialization and the true weight vector is mostly confined to the subspace of small eigenvalues. Additionally, when our analysis is specialized to linear regression in the strongly convex setting, it yields a tighter bound for bias error than the best-known result."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c07f79889c3181ba8d25abe3732708eda102cceb.pdf"}, "supplementary_material": {"value": "/attachment/81ed44f42960f9d6a83ba25e890d44117641bc92.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024risk,\ntitle={Risk Bounds of Accelerated {SGD} for Overparameterized Linear Regression},\nauthor={Xuheng Li and Yihe Deng and Jingfeng Wu and Dongruo Zhou and Quanquan Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AcoXPIPh4A}\n}"}, "paperhash": {"value": "li|risk_bounds_of_accelerated_sgd_for_overparameterized_linear_regression"}}, "number": 8252, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8252/-/Revision", "ICLR.cc/2024/Conference/Submission8252/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8252/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695502194930, "cdate": 1695502194930, "tmdate": 1710481576731, "mdate": 1710481576731, "pdate": 1705411036051, "version": 2}, {"id": "k9t8dQ30kU", "forum": "k9t8dQ30kU", "signatures": ["ICLR.cc/2024/Conference/Submission8246/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8246/Authors"], "content": {"title": {"value": "Task structure and nonlinearity jointly determine learned representational geometry"}, "authors": {"value": ["Matteo Alleman", "Jack Lindsey", "Stefano Fusi"]}, "authorids": {"value": ["~Matteo_Alleman1", "~Jack_Lindsey1", "~Stefano_Fusi1"]}, "keywords": {"value": ["representational geometry", "kernel target alignment", "disentanglement", "activation function", "out-of-distribution generalization"]}, "TLDR": {"value": "We show that the geometry of learned representations can be understood in terms of input and target geometries, and that tanh networks, more than relu networks, tend to align with output geometry"}, "abstract": {"value": "The utility of a learned neural representation depends on how well its geometry supports performance in downstream tasks. This geometry depends on the structure of the inputs, the structure of the target outputs, and on the architecture of the network.  By studying the learning dynamics of networks with one hidden layer, we discovered that the network's activation function has an unexpectedly strong impact on the representational geometry: Tanh networks tend to learn representations that reflect the structure of the target outputs, while ReLU networks retain more information about the structure of the raw inputs. This difference is consistently observed across a broad class of parameterized tasks in which we modulated the degree of alignment between the geometry of the task inputs and that of the task labels. We analyzed the learning dynamics in weight space and show how the differences between the networks with Tanh and ReLU nonlinearities arise from the asymmetric saturation of ReLU, which leads feature neurons to specialize for different regions of input space. Feature neurons in Tanh networks, by contrast, tend to inherit the task label structure. Consequently, when the target outputs are low dimensional, Tanh networks generate neural representations that are more disentangled than those obtained with a ReLU nonlinearity. Our findings shed light on the interplay between input-output geometry, nonlinearity, and learned representations in neural networks."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b8a9d014f343b3669b6457839a9e6aa1801d1174.pdf"}, "supplementary_material": {"value": "/attachment/d73ef6192109d283a6bd1ae9ace97dc1eb0dd296.pdf"}, "_bibtex": {"value": "@inproceedings{\nalleman2024task,\ntitle={Task structure and nonlinearity jointly determine learned representational geometry},\nauthor={Matteo Alleman and Jack Lindsey and Stefano Fusi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=k9t8dQ30kU}\n}"}, "paperhash": {"value": "alleman|task_structure_and_nonlinearity_jointly_determine_learned_representational_geometry"}}, "number": 8246, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8246/-/Revision", "ICLR.cc/2024/Conference/Submission8246/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8246/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695502059841, "cdate": 1695502059841, "tmdate": 1709661547257, "mdate": 1709661547257, "pdate": 1705411035786, "version": 2}, {"id": "4WnqRR915j", "forum": "4WnqRR915j", "signatures": ["ICLR.cc/2024/Conference/Submission8243/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8243/Authors"], "content": {"title": {"value": "Llemma: An Open Language Model for Mathematics"}, "authors": {"value": ["Zhangir Azerbayev", "Hailey Schoelkopf", "Keiran Paster", "Marco Dos Santos", "Stephen Marcus McAleer", "Albert Q. Jiang", "Jia Deng", "Stella Biderman", "Sean Welleck"]}, "authorids": {"value": ["~Zhangir_Azerbayev1", "~Hailey_Schoelkopf1", "~Keiran_Paster1", "~Marco_Dos_Santos1", "~Stephen_Marcus_McAleer1", "~Albert_Q._Jiang1", "~Jia_Deng1", "~Stella_Biderman1", "~Sean_Welleck1"]}, "keywords": {"value": ["reasoning", "language models", "pretraining"]}, "abstract": {"value": "We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the MATH benchmark Llemma outperforms all known openly released models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/be75740b06066f002fed0867925b737ec1f8757f.pdf"}, "supplementary_material": {"value": "/attachment/1db90b39240173c73d9cf5a455dc8fb7ce342985.zip"}, "_bibtex": {"value": "@inproceedings{\nazerbayev2024llemma,\ntitle={Llemma: An Open Language Model for Mathematics},\nauthor={Zhangir Azerbayev and Hailey Schoelkopf and Keiran Paster and Marco Dos Santos and Stephen Marcus McAleer and Albert Q. Jiang and Jia Deng and Stella Biderman and Sean Welleck},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4WnqRR915j}\n}"}, "paperhash": {"value": "azerbayev|llemma_an_open_language_model_for_mathematics"}}, "number": 8243, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8243/-/Revision", "ICLR.cc/2024/Conference/Submission8243/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8243/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501968355, "cdate": 1695501968355, "tmdate": 1710529746066, "mdate": 1710529746066, "pdate": 1705411035606, "version": 2}, {"id": "1vmSEVL19f", "forum": "1vmSEVL19f", "signatures": ["ICLR.cc/2024/Conference/Submission8236/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8236/Authors"], "content": {"title": {"value": "Directly Fine-Tuning Diffusion Models on Differentiable Rewards"}, "authors": {"value": ["Kevin Clark", "Paul Vicol", "Kevin Swersky", "David J. Fleet"]}, "authorids": {"value": ["~Kevin_Clark1", "~Paul_Vicol1", "~Kevin_Swersky1", "~David_J._Fleet1"]}, "keywords": {"value": ["diffusion models", "preference-based learning"]}, "TLDR": {"value": "We present methods that efficiently fine-tune diffusion models on reward functions by backpropagating through the reward."}, "abstract": {"value": "We present Direct Reward Fine-Tuning (DRaFT), a simple and effective method for fine-tuning diffusion models to maximize differentiable reward functions, such as scores from human preference models. We first show that it is possible to backpropagate the reward function gradient through the full sampling procedure, and that doing so achieves strong performance on a variety of rewards, outperforming reinforcement learning-based approaches. We then propose more efficient variants of DRaFT: DRaFT-K, which truncates backpropagation to only the last K steps of sampling, and DRaFT-LV, which obtains lower-variance gradient estimates for the case when K=1. We show that our methods work well for a variety of reward functions and can be used to substantially improve the aesthetic quality of images generated by Stable Diffusion 1.4. Finally, we draw connections between our approach and prior work, providing a unifying perspective on the design space of gradient-based fine-tuning algorithms."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4f6a4d187763cd647549b92a33f6f1c84f23bdec.pdf"}, "_bibtex": {"value": "@inproceedings{\nclark2024directly,\ntitle={Directly Fine-Tuning Diffusion Models on Differentiable Rewards},\nauthor={Kevin Clark and Paul Vicol and Kevin Swersky and David J. Fleet},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1vmSEVL19f}\n}"}, "paperhash": {"value": "clark|directly_finetuning_diffusion_models_on_differentiable_rewards"}}, "number": 8236, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8236/-/Revision", "ICLR.cc/2024/Conference/Submission8236/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8236/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501638562, "cdate": 1695501638562, "tmdate": 1710553431552, "mdate": 1710553431552, "pdate": 1705411035596, "version": 2}, {"id": "eoTCKKOgIs", "forum": "eoTCKKOgIs", "signatures": ["ICLR.cc/2024/Conference/Submission8233/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8233/Authors"], "content": {"title": {"value": "Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift"}, "authors": {"value": ["Jiawei Ge", "Shange Tang", "Jianqing Fan", "Cong Ma", "Chi Jin"]}, "authorids": {"value": ["~Jiawei_Ge3", "~Shange_Tang1", "~Jianqing_Fan1", "~Cong_Ma1", "~Chi_Jin1"]}, "keywords": {"value": ["Covariate shift; Maximum Likelihood Estimation; Out-of-Distribution generalization;"]}, "abstract": {"value": "A key challenge of modern machine learning systems is to achieve Out-of-Distribution (OOD) generalization---generalizing to target data whose distribution differs from that of source data. Despite its significant importance, the fundamental question of ``what are the most effective algorithms for OOD generalization'' remains open even under the standard setting of covariate shift.\nThis paper addresses this fundamental question by proving that, surprisingly, classical Maximum Likelihood Estimation (MLE) purely using source data (without any modification) achieves the *minimax* optimality for covariate shift under the *well-specified* setting. That is, *no* algorithm performs better than MLE in this setting (up to a constant factor), justifying MLE is all you need.\nOur result holds for a very rich class of parametric models, and does not require any boundedness condition on the density ratio. We illustrate the wide applicability of our framework by instantiating it to three concrete examples---linear regression, logistic regression, and phase retrieval. This paper further complement the study by proving that, under the *misspecified setting*, MLE is no longer the optimal choice, whereas Maximum Weighted Likelihood Estimator (MWLE) emerges as minimax optimal in certain scenarios."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a7c9e2c8b894e55b7cdff72359975a63bd0b405a.pdf"}, "supplementary_material": {"value": "/attachment/7aa9325b7cf23c23a96064f06aba175096ad9968.pdf"}, "_bibtex": {"value": "@inproceedings{\nge2024maximum,\ntitle={Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift},\nauthor={Jiawei Ge and Shange Tang and Jianqing Fan and Cong Ma and Chi Jin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eoTCKKOgIs}\n}"}, "paperhash": {"value": "ge|maximum_likelihood_estimation_is_all_you_need_for_wellspecified_covariate_shift"}}, "number": 8233, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8233/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8233/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501467847, "cdate": 1695501467847, "tmdate": 1709661547124, "mdate": 1709661547124, "pdate": 1705411035454, "version": 2}, {"id": "pAVJKp3Dvn", "forum": "pAVJKp3Dvn", "signatures": ["ICLR.cc/2024/Conference/Submission8231/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8231/Authors"], "content": {"title": {"value": "Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks"}, "authors": {"value": ["Changwoo Lee", "Hun-Seok Kim"]}, "authorids": {"value": ["~Changwoo_Lee2", "~Hun-Seok_Kim1"]}, "keywords": {"value": ["Structured Matrix", "Block Low Rank", "Low Rank", "Efficient Neural Network", "Transformer", "Fourier", "Dirichlet Kernel", "FFT", "Boxcar", "Pruning", "Compression"]}, "abstract": {"value": "This paper investigates efficient deep neural networks (DNNs) to replace dense unstructured weight matrices with structured ones that possess desired properties. The challenge arises because the optimal weight matrix structure in popular neural network models is obscure in most cases and may vary from layer to layer even in the same network. Prior structured matrices proposed for efficient DNNs were mostly hand-crafted without a generalized framework to systematically learn them. To address this issue, we propose a generalized and differentiable framework to learn efficient structures of weight matrices by gradient descent. We first define a new class of structured matrices that covers a wide range of structured matrices in the literature by adjusting the structural parameters. Then, the frequency-domain differentiable parameterization scheme based on the Gaussian-Dirichlet kernel is adopted to learn the structural parameters by proximal gradient descent. On the image and language tasks, our method learns efficient DNNs with structured matrices, achieving lower complexity and/or higher performance than prior approaches that employ low-rank, block-sparse, or block-low-rank matrices."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f49f086736d3cb7e71497a7fe09351bb020f7175.pdf"}, "supplementary_material": {"value": "/attachment/c1f38678ceffaad61bc8f8383fdd441da3fcc60c.zip"}, "TLDR": {"value": "A differentiable structured matrix learning framework that can discover new types of structured matrices for efficient DNNs."}, "_bibtex": {"value": "@inproceedings{\nlee2024differentiable,\ntitle={Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks},\nauthor={Changwoo Lee and Hun-Seok Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pAVJKp3Dvn}\n}"}, "paperhash": {"value": "lee|differentiable_learning_of_generalized_structured_matrices_for_efficient_deep_neural_networks"}}, "number": 8231, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8231/-/Revision", "ICLR.cc/2024/Conference/Submission8231/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8231/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501390544, "cdate": 1695501390544, "tmdate": 1709862594150, "mdate": 1709862594150, "pdate": 1705411035266, "version": 2}, {"id": "W2tCmRrj7H", "forum": "W2tCmRrj7H", "signatures": ["ICLR.cc/2024/Conference/Submission8225/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8225/Authors"], "content": {"title": {"value": "A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality"}, "authors": {"value": ["Huan He", "William hao", "Yuanzhe Xi", "Yong Chen", "Bradley Malin", "Joyce Ho"]}, "authorids": {"value": ["~Huan_He2", "william.hao@emory.edu", "~Yuanzhe_Xi1", "~Yong_Chen10", "~Bradley_Malin1", "~Joyce_Ho1"]}, "keywords": {"value": ["Generative Model", "Synthetic EHR"]}, "abstract": {"value": "Realistic synthetic electronic health records (EHRs) can be leveraged to acceler- ate methodological developments for research purposes while mitigating privacy concerns associated with data sharing. However, the training of Generative Ad- versarial Networks remains challenging, often resulting in issues like mode col- lapse. While diffusion models have demonstrated progress in generating qual- ity synthetic samples for tabular EHRs given ample denoising steps, their perfor- mance wanes when confronted with missing modalities in heterogeneous tabular EHRs data. For example, some EHRs contain solely static measurements, and some contain only contain temporal measurements, or a blend of both data types. To bridge this gap, we introduce FLEXGEN-EHR\u2013 a versatile diffusion model tai- lored for heterogeneous tabular EHRs, equipped with the capability of handling missing modalities in an integrative learning framework. We define an optimal transport module to align and accentuate the common feature space of hetero- geneity of EHRs. We empirically show that our model consistently outperforms existing state-of-the-art synthetic EHR generation methods both in fidelity by up to 3.10% and utility by up to 7.16%. Additionally, we show that our method can be successfully used in privacy-sensitive settings, where the original patient-level data cannot be shared."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0f51150d30c333ef2c370a265b35e4b865e21ab0.pdf"}, "supplementary_material": {"value": "/attachment/d825e1894e3ef065c763e072c829870d2542621f.pdf"}, "_bibtex": {"value": "@inproceedings{\nhe2024a,\ntitle={A Flexible Generative Model for Heterogeneous Tabular {EHR} with Missing Modality},\nauthor={Huan He and William hao and Yuanzhe Xi and Yong Chen and Bradley Malin and Joyce Ho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=W2tCmRrj7H}\n}"}, "paperhash": {"value": "he|a_flexible_generative_model_for_heterogeneous_tabular_ehr_with_missing_modality"}}, "number": 8225, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8225/-/Revision", "ICLR.cc/2024/Conference/Submission8225/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8225/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501269212, "cdate": 1695501269212, "tmdate": 1713071745946, "mdate": 1713071745946, "pdate": 1705411035155, "version": 2}, {"id": "79rfgv3jw4", "forum": "79rfgv3jw4", "signatures": ["ICLR.cc/2024/Conference/Submission8221/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8221/Authors"], "content": {"title": {"value": "Designing Skill-Compatible AI: Methodologies and Frameworks in Chess"}, "authors": {"value": ["Karim Hamade", "Reid McIlroy-Young", "Siddhartha Sen", "Jon Kleinberg", "Ashton Anderson"]}, "authorids": {"value": ["~Karim_Hamade1", "~Reid_McIlroy-Young1", "~Siddhartha_Sen1", "~Jon_Kleinberg1", "~Ashton_Anderson1"]}, "keywords": {"value": ["Skill-AI compatibility", "Agent Systems", "Decision-making", "Chess", "Deep RL"]}, "abstract": {"value": "Powerful artificial intelligence systems are often used in settings where they must interact with agents that are computationally much weaker, for example when they work alongside humans or operate in complex environments where some tasks are handled by algorithms, heuristics, or other entities of varying computational power. For AI agents to successfully interact in these settings, however, achieving superhuman performance alone is not sufficient; they also need to account for suboptimal actions or idiosyncratic style from their less-skilled counterparts. We propose a formal evaluation framework for assessing the compatibility of near-optimal AI with interaction partners who may have much lower levels of skill; we use popular collaborative chess variants as model systems to study and develop AI agents that can successfully interact with lower-skill entities. Traditional chess engines designed to output near-optimal moves prove to be inadequate partners when paired with engines of various lower skill levels in this domain, as they are not designed to consider the presence of other agents. We contribute three methodologies to explicitly create skill-compatible AI agents in complex decision-making settings, and two chess game frameworks designed to foster collaboration between powerful AI agents and less-skilled partners. On these frameworks, our agents outperform state-of-the-art chess AI (based on AlphaZero) despite being weaker in conventional chess, demonstrating that skill-compatibility is a tangible trait that is qualitatively and measurably distinct from raw performance. Our evaluations further explore and clarify the mechanisms by which our agents achieve skill-compatibility."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b21e7de733143ca1fd7e2af2fc6d9be736bd73b.pdf"}, "supplementary_material": {"value": "/attachment/d067ff4cd68eb84dc82fae7b1d69cea1c70699ea.zip"}, "_bibtex": {"value": "@inproceedings{\nhamade2024designing,\ntitle={Designing Skill-Compatible {AI}: Methodologies and Frameworks in Chess},\nauthor={Karim Hamade and Reid McIlroy-Young and Siddhartha Sen and Jon Kleinberg and Ashton Anderson},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=79rfgv3jw4}\n}"}, "paperhash": {"value": "hamade|designing_skillcompatible_ai_methodologies_and_frameworks_in_chess"}}, "number": 8221, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8221/-/Revision", "ICLR.cc/2024/Conference/Submission8221/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8221/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695501227711, "cdate": 1695501227711, "tmdate": 1710575410395, "mdate": 1710575410395, "pdate": 1705411035083, "version": 2}, {"id": "RaqZX9LSGA", "forum": "RaqZX9LSGA", "signatures": ["ICLR.cc/2024/Conference/Submission8215/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8215/Authors"], "content": {"title": {"value": "Tree Search-Based Policy Optimization under Stochastic Execution Delay"}, "authors": {"value": ["David Valensi", "Esther Derman", "Shie Mannor", "Gal Dalal"]}, "authorids": {"value": ["~David_Valensi1", "~Esther_Derman1", "~Shie_Mannor2", "~Gal_Dalal2"]}, "keywords": {"value": ["Reinforcement Learning", "Delay", "EfficientZero", "Tree-search", "Sample efficiency"]}, "TLDR": {"value": "We prove results for Reinforcement Learning with stochastic delay, devise a corresponding tree-search based algorithm, and successfully test it on such environments."}, "abstract": {"value": "The standard formulation of Markov decision processes (MDPs) assumes that the agent's decisions are executed immediately.\nHowever, in numerous realistic applications such as robotics or healthcare, actions are performed with a delay whose value can even be stochastic. In this work, we introduce stochastic delayed execution MDPs, a new formalism addressing random delays without resorting to state augmentation. We show that given observed delay values, it is sufficient to perform a policy search in the class of Markov policies in order to reach optimal performance, thus extending the deterministic fixed delay case. Armed with this insight, we devise DEZ, a model-based algorithm that optimizes over the class of Markov policies. DEZ leverages Monte-Carlo tree search similar to its non-delayed variant EfficientZero to accurately infer future states from the action queue. Thus, it handles delayed execution while preserving the sample efficiency of EfficientZero. Through empirical analysis, we stress that none of the prior benchmarks consistently outperforms others across different delays. We demonstrate that our algorithm surpasses all benchmark methods in Atari games when dealing with constant or stochastic delays. The code is available at \\url{https://github.com/davidva1/Delayed-EZ}."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8830f6b3cafc9913288b14d81260c6f589144619.pdf"}, "supplementary_material": {"value": "/attachment/f629821f2c338399309992cc79dc12d8436ea6df.pdf"}, "_bibtex": {"value": "@inproceedings{\nvalensi2024tree,\ntitle={Tree Search-Based Policy Optimization under Stochastic Execution Delay},\nauthor={David Valensi and Esther Derman and Shie Mannor and Gal Dalal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RaqZX9LSGA}\n}"}, "paperhash": {"value": "valensi|tree_searchbased_policy_optimization_under_stochastic_execution_delay"}}, "number": 8215, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8215/-/Revision", "ICLR.cc/2024/Conference/Submission8215/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8215/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500922179, "cdate": 1695500922179, "tmdate": 1712563778610, "mdate": 1712563778610, "pdate": 1705411034856, "version": 2}, {"id": "lJYAkDVnRU", "forum": "lJYAkDVnRU", "signatures": ["ICLR.cc/2024/Conference/Submission8213/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8213/Authors"], "content": {"title": {"value": "Context-Aware Meta-Learning"}, "authors": {"value": ["Christopher Fifty", "Dennis Duan", "Ronald Guenther Junkins", "Ehsan Amid", "Jure Leskovec", "Christopher Re", "Sebastian Thrun"]}, "authorids": {"value": ["~Christopher_Fifty2", "~Dennis_Duan1", "~Ronald_Guenther_Junkins1", "~Ehsan_Amid1", "~Jure_Leskovec1", "~Christopher_Re1", "~Sebastian_Thrun1"]}, "keywords": {"value": ["meta-learning", "in-context learning"]}, "abstract": {"value": "Large Language Models like ChatGPT demonstrate a remarkable capacity to learn new concepts during inference without any fine-tuning. However, visual models trained to detect new objects during inference have been unable to replicate this ability, and instead either perform poorly or require meta-training and/or fine-tuning on similar objects. In this work, we propose a meta-learning algorithm that emulates Large Language Models by learning new visual concepts during inference without fine-tuning. Our approach leverages a frozen pre-trained feature extractor, and analogous to in-context learning, recasts meta-learning as sequence modeling over datapoints with known labels and a test datapoint with an unknown label. On 8 out of 11 meta-learning benchmarks, our approach---without meta-training or fine-tuning---exceeds or matches the state-of-the-art algorithm, P>M>F, which is meta-trained on these benchmarks."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2b890b5667cfd1af349d0022584e53a3221e408c.pdf"}, "_bibtex": {"value": "@inproceedings{\nfifty2024contextaware,\ntitle={Context-Aware Meta-Learning},\nauthor={Christopher Fifty and Dennis Duan and Ronald Guenther Junkins and Ehsan Amid and Jure Leskovec and Christopher Re and Sebastian Thrun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lJYAkDVnRU}\n}"}, "paperhash": {"value": "fifty|contextaware_metalearning"}}, "number": 8213, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8213/-/Revision", "ICLR.cc/2024/Conference/Submission8213/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8213/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500893164, "cdate": 1695500893164, "tmdate": 1711145871136, "mdate": 1711145871136, "pdate": 1705411034822, "version": 2}, {"id": "caW7LdAALh", "forum": "caW7LdAALh", "signatures": ["ICLR.cc/2024/Conference/Submission8199/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8199/Authors"], "content": {"title": {"value": "Beyond Accuracy: Evaluating Self-Consistency of Code Large Language Models with IdentityChain"}, "authors": {"value": ["Marcus J. Min", "Yangruibo Ding", "Luca Buratti", "Saurabh Pujar", "Gail Kaiser", "Suman Jana", "Baishakhi Ray"]}, "authorids": {"value": ["~Marcus_J._Min1", "~Yangruibo_Ding1", "~Luca_Buratti1", "~Saurabh_Pujar1", "~Gail_Kaiser1", "~Suman_Jana1", "~Baishakhi_Ray2"]}, "keywords": {"value": ["Large Language Models", "Code Generation", "Code Summarization", "LLM Evaluation", "Self-Consistency"]}, "TLDR": {"value": "Self-consistency of Code LLMs is overlooked. We design a new framework that evaluates self-consistency and general accuracy simultaneously, showing that self-consistency is a different aspect from accuracy which needs to be improved."}, "abstract": {"value": "Code Large Language Models (Code LLMs) are being increasingly employed in real-life applications, so evaluating them is critical. While the conventional accuracy evaluates the performance of Code LLMs on a set of individual tasks, their self-consistency across different tasks is overlooked. Intuitively, a trustworthy model should be self-consistent when generating natural language specifications for its own code and generating code for its own specifications. Failure to preserve self-consistency reveals a lack of understanding of the shared semantics underlying natural language and programming language, and therefore undermines the trustworthiness of a model. In this paper, we first formally define the self-consistency of Code LLMs and then design a framework, IdentityChain, which effectively and efficiently evaluates the self-consistency and conventional accuracy of a model at the same time. We study eleven Code LLMs and show that they fail to preserve self-consistency, which is indeed a distinct aspect from conventional accuracy. Furthermore, we show that IdentityChain can be used as a model debugging tool to expose weaknesses of Code LLMs by demonstrating three major weaknesses that we identify in current models using IdentityChain. Our code is available at https://github.com/marcusm117/IdentityChain."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cc6882135f5b0d5720cfc7705e5db5b102b72cbf.pdf"}, "supplementary_material": {"value": "/attachment/b07a154e80218d27e217a307848c24d7b93c13b5.zip"}, "_bibtex": {"value": "@inproceedings{\nmin2024beyond,\ntitle={Beyond Accuracy: Evaluating Self-Consistency of Code {LLM}s},\nauthor={Marcus J. Min and Yangruibo Ding and Luca Buratti and Saurabh Pujar and Gail Kaiser and Suman Jana and Baishakhi Ray},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=caW7LdAALh}\n}"}, "paperhash": {"value": "min|beyond_accuracy_evaluating_selfconsistency_of_code_large_language_models_with_identitychain"}}, "number": 8199, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8199/-/Revision", "ICLR.cc/2024/Conference/Submission8199/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8199/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500416674, "cdate": 1695500416674, "tmdate": 1709661546890, "mdate": 1709661546890, "pdate": 1705411034092, "version": 2}, {"id": "fjpfCOV4ru", "forum": "fjpfCOV4ru", "signatures": ["ICLR.cc/2024/Conference/Submission8195/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8195/Authors"], "content": {"title": {"value": "Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting"}, "authors": {"value": ["Aleksei Ustimenko", "Aleksandr Beznosikov"]}, "authorids": {"value": ["~Aleksei_Ustimenko1", "~Aleksandr_Beznosikov1"]}, "keywords": {"value": ["markov chains", "diffusion processes"]}, "TLDR": {"value": "Approximating General Markov Chains by Diffusion Processes without assuming Gaussian noise."}, "abstract": {"value": "In this work, we consider rather general and broad class of Markov chains, Ito chains, that look like Euler-Maryama discretization of some Stochastic Differential Equation. The chain we study is a unified framework for theoretical analysis. It comes with almost arbitrary isotropic and state-dependent  noise instead of normal and state-independent one as in most related papers. Moreover, in our chain the drift and diffusion coefficient can be inexact in order to cover wide range of applications as Stochastic Gradient Langevin Dynamics, sampling, Stochastic Gradient Descent or Stochastic Gradient Boosting. We prove the bound in $\\mathcal{W}_{2}$-distance between the laws of our Ito chain and corresponding differential equation. These results improve or cover most of the known estimates. And for some particular cases, our analysis is the first."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6096e5c08f636d6144a7e20b80523e0168fe0a4a.pdf"}, "_bibtex": {"value": "@inproceedings{\nustimenko2024ito,\ntitle={Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting},\nauthor={Aleksei Ustimenko and Aleksandr Beznosikov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fjpfCOV4ru}\n}"}, "paperhash": {"value": "ustimenko|ito_diffusion_approximation_of_universal_ito_chains_for_sampling_optimization_and_boosting"}}, "number": 8195, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8195/-/Revision", "ICLR.cc/2024/Conference/Submission8195/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8195/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500304127, "cdate": 1695500304127, "tmdate": 1710332122965, "mdate": 1710332122965, "pdate": 1705411033937, "version": 2}, {"id": "W3VsHuga3j", "forum": "W3VsHuga3j", "signatures": ["ICLR.cc/2024/Conference/Submission8185/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8185/Authors"], "content": {"title": {"value": "Modeling Boundedly Rational Agents with Latent Inference Budgets"}, "authors": {"value": ["Athul Paul Jacob", "Abhishek Gupta", "Jacob Andreas"]}, "authorids": {"value": ["~Athul_Paul_Jacob1", "~Abhishek_Gupta1", "~Jacob_Andreas1"]}, "keywords": {"value": ["neurosymbolic", "planning", "rationality"]}, "abstract": {"value": "We study the problem of modeling a population of agents pursuing unknown goals subject to unknown computational constraints. In standard models of bounded rationality, sub-optimal decision-making is simulated by adding homoscedastic noise to optimal decisions rather than actually simulating constrained inference. In this work, we introduce a latent inference budget model (L-IBM) that models these constraints explicitly, via a latent variable (inferred jointly with a model of agents\u2019 goals) that controls the runtime of an iterative inference algorithm. L-IBMs make it possible to learn agent models using data from diverse populations of suboptimal actors. In three modeling tasks\u2014inferring navigation goals from routes, inferring communicative intents from human utterances, and predicting next moves in human chess games\u2014we show that L-IBMs match or outperforms Boltzmann models of decision-making under uncertainty. Moreover, the inferred inference budgets are themselves meaningful, efficient to compute, and correlated with measures of player skill, partner skill and task difficulty."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b6fcabc7a4521fa9b8ff72f6d09fbafc1e118951.pdf"}, "_bibtex": {"value": "@inproceedings{\njacob2024modeling,\ntitle={Modeling Boundedly Rational Agents with Latent Inference Budgets},\nauthor={Athul Paul Jacob and Abhishek Gupta and Jacob Andreas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=W3VsHuga3j}\n}"}, "paperhash": {"value": "jacob|modeling_boundedly_rational_agents_with_latent_inference_budgets"}}, "number": 8185, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8185/-/Revision", "ICLR.cc/2024/Conference/Submission8185/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8185/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500110247, "cdate": 1695500110247, "tmdate": 1713131245212, "mdate": 1713131245212, "pdate": 1705411033476, "version": 2}, {"id": "MEGQGNUfPx", "forum": "MEGQGNUfPx", "signatures": ["ICLR.cc/2024/Conference/Submission8178/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8178/Authors"], "content": {"title": {"value": "The Effectiveness of Random Forgetting for Robust Generalization"}, "authors": {"value": ["Vijaya Raghavan T Ramkumar", "Bahram Zonooz", "Elahe Arani"]}, "authorids": {"value": ["~Vijaya_Raghavan_T_Ramkumar1", "~Bahram_Zonooz1", "~Elahe_Arani1"]}, "keywords": {"value": ["Adversarial training", "robust overfitting", "forgetting", "reinitialization", "robust accuracy", "generalization"]}, "TLDR": {"value": "A method alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model's information through weight reinitialization, and the relearning phase, which mitigate robust overfitting."}, "abstract": {"value": "Deep neural networks are susceptible to adversarial attacks, which can compromise their performance and accuracy. Adversarial Training (AT) has emerged as a popular approach for protecting neural networks against such attacks. However, a key challenge of AT is robust overfitting, where the network's robust performance on test data deteriorates with further training, thus hindering generalization. Motivated by the concept of active forgetting in the brain, we introduce a novel learning paradigm called \"Forget to Mitigate Overfitting (FOMO)\". FOMO alternates between the forgetting phase, which randomly forgets a subset of weights and regulates the model's information through weight reinitialization, and the relearning phase, which emphasizes learning generalizable features. Our experiments on benchmark datasets and adversarial attacks show that FOMO alleviates robust overfitting by significantly reducing the gap between the best and last robust test accuracy while improving the state-of-the-art robustness. Furthermore, FOMO provides a better trade-off between the standard and robust accuracy outperforming baseline adversarial methods. Finally, our framework is robust to AutoAttacks and increases generalization in many real-world scenarios."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/23ffd81fb8a0b8a1c30e255410b712c66490ed39.pdf"}, "supplementary_material": {"value": "/attachment/3904f1d8a430852e46442521fb0beb94ebd02ab6.pdf"}, "_bibtex": {"value": "@inproceedings{\nramkumar2024the,\ntitle={The Effectiveness of Random Forgetting for Robust Generalization},\nauthor={Vijaya Raghavan T Ramkumar and Bahram Zonooz and Elahe Arani},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MEGQGNUfPx}\n}"}, "paperhash": {"value": "ramkumar|the_effectiveness_of_random_forgetting_for_robust_generalization"}}, "number": 8178, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8178/-/Revision", "ICLR.cc/2024/Conference/Submission8178/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8178/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695499587541, "cdate": 1695499587541, "tmdate": 1709933588378, "mdate": 1709933588378, "pdate": 1705411033356, "version": 2}, {"id": "gxhRR8vUQb", "forum": "gxhRR8vUQb", "signatures": ["ICLR.cc/2024/Conference/Submission8175/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8175/Authors"], "content": {"title": {"value": "Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction"}, "authors": {"value": ["Thanh Tung Le", "Khai Nguyen", "shanlin sun", "Kun Han", "Nhat Ho", "Xiaohui Xie"]}, "authorids": {"value": ["~Thanh_Tung_Le1", "~Khai_Nguyen1", "~shanlin_sun1", "~Kun_Han3", "~Nhat_Ho1", "~Xiaohui_Xie2"]}, "keywords": {"value": ["Mesh deformation", "optimal transport", "cortical surface reconstruction", "computer vision", "medical imaging."]}, "TLDR": {"value": "Our new approach for 3D mesh deformation outperforms other methods in cortical surface reconstruction by encoding a mesh into a probability measure, using sliced Wasserstein distance for comparison, and employing a neural ODE for deformation."}, "abstract": {"value": "Mesh deformation plays a pivotal role in many 3D vision tasks including dynamic simulations, rendering, and reconstruction. However, defining an efficient discrepancy between predicted and target meshes remains an open problem. A prevalent approach in current deep learning is the set-based approach which measures the discrepancy between two surfaces by comparing two randomly sampled point-clouds from the two meshes with Chamfer pseudo-distance. Nevertheless, the set-based approach still has limitations such as lacking a theoretical guarantee for choosing the number of points in sampled point-clouds, and the pseudo-metricity and the quadratic complexity of the Chamfer divergence. To address these issues, we propose a novel metric for learning mesh deformation. The metric is defined by sliced Wasserstein distance on meshes represented as probability measures that generalize the set-based approach. By leveraging probability measure space, we gain flexibility in encoding meshes using diverse forms of probability measures, such as continuous, empirical, and discrete measures via \\textit{varifold} representation. After having encoded probability measures, we can compare meshes by using the sliced Wasserstein distance which is an effective optimal transport distance with linear computational complexity and can provide a fast statistical rate for approximating the surface of meshes. To the end, we employ a neural ordinary differential equation (ODE) to deform the input surface into the target shape by modeling the trajectories of the points on the surface. Our experiments on cortical surface reconstruction demonstrate that our approach surpasses other competing methods in multiple datasets and metrics."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/57b2a95817608783ca78a3f2e620841dc4facc1e.pdf"}, "supplementary_material": {"value": "/attachment/bb8c1180bf7e175a58d7f17682a8bd008cd12edc.zip"}, "_bibtex": {"value": "@inproceedings{\nle2024diffeomorphic,\ntitle={Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction},\nauthor={Thanh Tung Le and Khai Nguyen and shanlin sun and Kun Han and Nhat Ho and Xiaohui Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gxhRR8vUQb}\n}"}, "paperhash": {"value": "le|diffeomorphic_mesh_deformation_via_efficient_optimal_transport_for_cortical_surface_reconstruction"}}, "number": 8175, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8175/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8175/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695499527190, "cdate": 1695499527190, "tmdate": 1710655845822, "mdate": 1710655845822, "pdate": 1705411033276, "version": 2}, {"id": "p34fRKp8qA", "forum": "p34fRKp8qA", "signatures": ["ICLR.cc/2024/Conference/Submission8173/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8173/Authors"], "content": {"title": {"value": "Lie Group Decompositions for Equivariant Neural Networks"}, "authors": {"value": ["Mircea Mironenco", "Patrick Forr\u00e9"]}, "authorids": {"value": ["~Mircea_Mironenco2", "~Patrick_Forr\u00e91"]}, "keywords": {"value": ["equivariant neural networks", "lie groups", "group convolution", "geometric deep learning"]}, "abstract": {"value": "Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime.\nMuch work has focused on the case where the symmetry group employed is compact or abelian, or both.\nRecent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps.\nThe applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest $G$, the exponential map may not be surjective.\nFurther limitations are encountered when $G$ is neither compact nor abelian.\nUsing the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups $G = \\textnormal{GL}^{+}(n, \\mathbb{R})$ and $G = \\textnormal{SL}(n, \\mathbb{R})$, as well as their representation as affine transformations $\\mathbb{R}^{n} \\rtimes G$.\nInvariant integration as well as a global parametrization is realized by decomposing the \"larger\" groups into subgroups and submanifolds which can be handled individually.\nUnder this framework, we show how convolution kernels can be parametrized to build models equivariant with respect to affine transformations.\nWe evaluate the robustness and out-of-distribution generalisation capability of our model on the standard affine-invariant benchmark classification task, where we outperform all previous equivariant models as well as all Capsule Network proposals."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/adb13612b54de26d4a224d8cb2080a3bf578d58a.pdf"}, "_bibtex": {"value": "@inproceedings{\nmironenco2024lie,\ntitle={Lie Group Decompositions for Equivariant Neural Networks},\nauthor={Mircea Mironenco and Patrick Forr{\\'e}},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=p34fRKp8qA}\n}"}, "paperhash": {"value": "mironenco|lie_group_decompositions_for_equivariant_neural_networks"}}, "number": 8173, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8173/-/Revision", "ICLR.cc/2024/Conference/Submission8173/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8173/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695499485016, "cdate": 1695499485016, "tmdate": 1713163618585, "mdate": 1713163618585, "pdate": 1705411033213, "version": 2}, {"id": "QiJuMJl0QS", "forum": "QiJuMJl0QS", "signatures": ["ICLR.cc/2024/Conference/Submission8171/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8171/Authors"], "content": {"title": {"value": "Efficient Heterogeneous Meta-Learning via Channel Shuffling Modulation"}, "authors": {"value": ["Minh Hoang", "Carl Kingsford"]}, "authorids": {"value": ["~Minh_Hoang1", "~Carl_Kingsford1"]}, "keywords": {"value": ["Meta Learning; Deep Learning Architecture; General Machine Learning"]}, "TLDR": {"value": "Heterogeneous Meta Learning via Channel Shuffling Modulation"}, "abstract": {"value": "We tackle the problem of meta-learning across heterogenous tasks. This problem seeks to extract and generalize transferable meta-knowledge through streaming task sets from a multi-modal task distribution. The extracted meta-knowledge can be used to create predictors for new tasks using a small number of labeled samples. Most meta-learning methods assume a homogeneous task distribution, thus limiting their generalization capacity when handling multi-modal task distributions. Recent work has shown that the generalization of meta-learning depends on the similarity of tasks in the training distribution, and this has led to many clustering approaches that aim to detect homogeneous clusters of tasks. However, these methods suffer from a significant increase in parameter complexity. To overcome this weakness, we propose a new heterogeneous meta-learning strategy that efficiently captures the multi-modality of the task distribution via modulating the routing between convolution channels in the network, instead of directly modulating the network weights. This new mechanism can be cast as a permutation learning problem. We further introduce a novel neural permutation layer based on the classical Benes routing network, which has sub-quadratic parameter complexity in the total number of channels, as compared to the quadratic complexity of the state-of-the-art Gumbel-Sinkhorn layer. We demonstrate our approach on various multi-modal meta-learning benchmarks, showing that our framework outperforms previous methods in both generalization accuracy and convergence speed."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2372b26cc6c55bb1b97f26c7f0b9cc2e897ede18.pdf"}, "_bibtex": {"value": "@inproceedings{\nhoang2024efficient,\ntitle={Efficient Heterogeneous Meta-Learning via Channel Shuffling Modulation},\nauthor={Minh Hoang and Carl Kingsford},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QiJuMJl0QS}\n}"}, "supplementary_material": {"value": "/attachment/409c8e2d977efaa256cdcc689b5c11bb53dba048.pdf"}, "paperhash": {"value": "hoang|efficient_heterogeneous_metalearning_via_channel_shuffling_modulation"}}, "number": 8171, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8171/-/Revision", "ICLR.cc/2024/Conference/Submission8171/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8171/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695499466576, "cdate": 1695499466576, "tmdate": 1710430135809, "mdate": 1710430135809, "pdate": 1705411033057, "version": 2}, {"id": "UHjE5v5MB7", "forum": "UHjE5v5MB7", "signatures": ["ICLR.cc/2024/Conference/Submission8168/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8168/Authors"], "content": {"title": {"value": "To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets"}, "authors": {"value": ["Darshil Doshi", "Aritra Das", "Tianyu He", "Andrey Gromov"]}, "authorids": {"value": ["~Darshil_Doshi1", "~Aritra_Das1", "~Tianyu_He2", "~Andrey_Gromov1"]}, "keywords": {"value": ["Interpretability", "Grokking", "Label noise", "Generalization", "Memorization", "Representations", "Modular Arithmetic"]}, "TLDR": {"value": "We study interpretable models+task where generalizing and memorizing representations are distinguishable. Training with corrupted data, we isolate the performance on corrupted and uncorrupted data; and explain the effect of explicit regularization."}, "abstract": {"value": "Robust generalization is a major challenge in deep learning, particularly when the number of trainable parameters is very large. In general, it is very difficult to know if the network has memorized a particular set of examples or understood the underlying rule (or both). Motivated by this challenge, we study an interpretable model where generalizing representations are understood analytically, and are easily distinguishable from the memorizing ones. Namely, we consider multi-layer perceptron (MLP) and Transformer architectures trained on modular arithmetic tasks, where ($\\xi \\cdot 100\\\\%$) of labels are corrupted (*i.e.* some results of the modular operations in the training set are incorrect). We show that (i) it is possible for the network to memorize the corrupted labels *and* achieve $100\\\\%$ generalization at the same time; (ii) the memorizing neurons can be identified and pruned, lowering the accuracy on corrupted data and improving the accuracy on uncorrupted data; (iii) regularization methods such as weight decay, dropout and BatchNorm force the network to ignore the corrupted data during optimization, and achieve $100\\\\%$ accuracy on the uncorrupted dataset; and (iv) the effect of these regularization methods is (\"mechanistically\") interpretable: weight decay and dropout force all the neurons to learn generalizing representations, while BatchNorm de-amplifies the output of memorizing neurons and amplifies the output of the generalizing ones. Finally, we show that in the presence of regularization, the training dynamics involves two consecutive stages: first, the network undergoes *grokking* dynamics reaching high train *and* test accuracy; second, it unlearns the memorizing representations, where the train accuracy suddenly jumps from $100\\\\%$ to $100 (1-\\xi)\\\\%$."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b5a7d2b34d54912009b544ef9c33ac0e3d8050a2.pdf"}, "supplementary_material": {"value": "/attachment/77f468170606157796e5fdaf48507f5f8d9e16c7.zip"}, "_bibtex": {"value": "@inproceedings{\ndoshi2024to,\ntitle={To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets},\nauthor={Darshil Doshi and Aritra Das and Tianyu He and Andrey Gromov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UHjE5v5MB7}\n}"}, "paperhash": {"value": "doshi|to_grok_or_not_to_grok_disentangling_generalization_and_memorization_on_corrupted_algorithmic_datasets"}}, "number": 8168, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8168/-/Revision", "ICLR.cc/2024/Conference/Submission8168/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8168/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695499457255, "cdate": 1695499457255, "tmdate": 1709661546520, "mdate": 1709661546520, "pdate": 1705411033020, "version": 2}, {"id": "SUUrkC3STJ", "forum": "SUUrkC3STJ", "signatures": ["ICLR.cc/2024/Conference/Submission8156/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8156/Authors"], "content": {"title": {"value": "VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections"}, "authors": {"value": ["Dongqi Fu", "Zhigang Hua", "Yan Xie", "Jin Fang", "Si Zhang", "Kaan Sancak", "Hao Wu", "Andrey Malevich", "Jingrui He", "Bo Long"]}, "authorids": {"value": ["~Dongqi_Fu1", "~Zhigang_Hua2", "~Yan_Xie2", "~Jin_Fang4", "~Si_Zhang1", "~Kaan_Sancak1", "~Hao_Wu16", "~Andrey_Malevich1", "~Jingrui_He1", "~Bo_Long3"]}, "keywords": {"value": ["Graph Representation Learning", "Graph Transformer"]}, "abstract": {"value": "Graph transformer has been proven as an effective graph learning method for its adoption of attention mechanism that is capable of capturing expressive representations from complex topological and feature information of graphs. Graph transformer conventionally performs dense attention (or global attention) for every pair of nodes to learn node representation vectors, resulting in quadratic computational costs that are unaffordable for large-scale graph data. Therefore, mini-batch training for graph transformers is a promising direction, but limited samples in each mini-batch can not support effective dense attention to encode informative representations. Facing this bottleneck, (1) we start by assigning each node a token list that is sampled by personalized PageRank (PPR) and then apply standard multi-head self-attention only on this list to compute its node representations. This PPR tokenization method decouples model training from complex graph topological information and makes heavy feature engineering offline and independent, such that mini-batch training of graph transformers is possible by loading each node's token list in batches. We further prove this PPR tokenization is viable as a graph convolution network with a fixed polynomial filter and jumping knowledge. However, only using personalized PageRank may limit information carried by a token list, which could not support different graph inductive biases for model training. To this end, (2) we rewire graphs by introducing multiple types of virtual connections through structure- and content-based super nodes that enable PPR tokenization to encode local and global contexts, long-range interaction, and heterophilous information into each node's token list, and then formalize our $\\underline{\\textbf{V}}$irtual $\\underline{\\textbf{C}}$onnection $\\underline{\\textbf{R}}$anking based $\\underline{\\textbf{Graph}}$ Trans$\\underline{\\textbf{former}}$ (VCR-Graphormer). Overall, VCR-Graphormer needs $O(m+klogk)$ complexity for graph tokenization as compared to $O(n^{3})$ of previous works. The [code](https://github.com/DongqiFu/VCR-Graphormer) is provided."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5914f5217eeed4b267eb84117a931ad9f7dbd355.pdf"}, "_bibtex": {"value": "@inproceedings{\nfu2024vcrgraphormer,\ntitle={{VCR}-Graphormer: A Mini-batch Graph Transformer via Virtual Connections},\nauthor={Dongqi Fu and Zhigang Hua and Yan Xie and Jin Fang and Si Zhang and Kaan Sancak and Hao Wu and Andrey Malevich and Jingrui He and Bo Long},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SUUrkC3STJ}\n}"}, "paperhash": {"value": "fu|vcrgraphormer_a_minibatch_graph_transformer_via_virtual_connections"}}, "number": 8156, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8156/-/Revision", "ICLR.cc/2024/Conference/Submission8156/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8156/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695499020263, "cdate": 1695499020263, "tmdate": 1710564552644, "mdate": 1710564552644, "pdate": 1705411032606, "version": 2}, {"id": "D4NJFfrqoq", "forum": "D4NJFfrqoq", "signatures": ["ICLR.cc/2024/Conference/Submission8149/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8149/Authors"], "content": {"title": {"value": "Optimistic Bayesian Optimization with Unknown Constraints"}, "authors": {"value": ["Quoc Phong Nguyen", "Wan Theng Ruth Chew", "Le Song", "Bryan Kian Hsiang Low", "Patrick Jaillet"]}, "authorids": {"value": ["~Quoc_Phong_Nguyen2", "~Wan_Theng_Ruth_Chew1", "~Le_Song3", "~Bryan_Kian_Hsiang_Low1", "~Patrick_Jaillet1"]}, "keywords": {"value": ["Bayesian optimization", "black box constraint", "decoupled query"]}, "TLDR": {"value": "We introduce a constrained Bayesian optimization method with a theoretical guarantee for decoupled queries."}, "abstract": {"value": "Though some research efforts have been dedicated to constrained Bayesian optimization (BO), there remains a notable absence of a principled approach with a theoretical performance guarantee in the decoupled setting. Such a setting involves independent evaluations of the objective function and constraints at different inputs, and is hence a relaxation of the commonly-studied coupled setting where functions must be evaluated together. As a result, the decoupled setting requires an adaptive selection between evaluating either the objective function or a constraint, in addition to selecting an input (in the coupled setting). This paper presents a novel constrained BO algorithm with a provable performance guarantee that can address the above relaxed setting. Specifically, it considers the fundamental trade-off between exploration and exploitation in constrained BO, and, interestingly, affords a noteworthy connection to active learning. The performance of our proposed algorithms is also empirically evaluated using several synthetic and real-world optimization problems."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b9f8e9fc8f8a6b5a79bf0426ca34210e1c6552ff.pdf"}, "supplementary_material": {"value": "/attachment/60b2855fb945a2d05ac8ca4790531970aaf9af9e.pdf"}, "_bibtex": {"value": "@inproceedings{\nnguyen2024optimistic,\ntitle={Optimistic Bayesian Optimization with Unknown Constraints},\nauthor={Quoc Phong Nguyen and Wan Theng Ruth Chew and Le Song and Bryan Kian Hsiang Low and Patrick Jaillet},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=D4NJFfrqoq}\n}"}, "paperhash": {"value": "nguyen|optimistic_bayesian_optimization_with_unknown_constraints"}}, "number": 8149, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8149/-/Revision", "ICLR.cc/2024/Conference/Submission8149/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8149/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695498681399, "cdate": 1695498681399, "tmdate": 1711454746562, "mdate": 1711454746562, "pdate": 1705411032573, "version": 2}, {"id": "m7aPLHwsLr", "forum": "m7aPLHwsLr", "signatures": ["ICLR.cc/2024/Conference/Submission8147/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8147/Authors"], "content": {"title": {"value": "DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness"}, "authors": {"value": ["Shoumik Saha", "Wenxiao Wang", "Yigitcan Kaya", "Soheil Feizi", "Tudor Dumitras"]}, "authorids": {"value": ["~Shoumik_Saha1", "~Wenxiao_Wang1", "~Yigitcan_Kaya2", "~Soheil_Feizi2", "~Tudor_Dumitras1"]}, "keywords": {"value": ["machine learning", "adversarial", "malware", "smoothing", "robustness", "defense", "attack"]}, "abstract": {"value": "Machine Learning (ML) models have been utilized for malware detection for over two decades. Consequently, this ignited an ongoing arms race between malware authors and antivirus systems, compelling researchers to propose defenses for malware-detection models against evasion attacks. However, most if not all existing defenses against evasion attacks suffer from sizable performance degradation and/or can defend against only specific attacks, which makes them less practical in real-world settings. In this work, we develop a certified defense, DRSM (De-Randomized Smoothed MalConv), by redesigning the *de-randomized smoothing* technique for the domain of malware detection. Specifically, we propose a *window ablation* scheme to provably limit the impact of adversarial bytes while maximally preserving local structures of the executables. After showing how DRSM is theoretically robust against attacks with contiguous adversarial bytes, we verify its performance and certified robustness experimentally, where we observe only marginal accuracy drops as the cost of robustness. To our knowledge, we are the first to offer certified robustness in the realm of static detection of malware executables. More surprisingly, through evaluating DRSM against $9$ empirical attacks of different types, we observe that the proposed defense is empirically robust to some extent against a diverse set of attacks, some of which even fall out of the scope of its original threat model. In addition, we collected $15.5K$ recent benign raw executables from diverse sources, which will be made public as a dataset called PACE (Publicly Accessible Collection(s) of Executables) to alleviate the scarcity of publicly available benign datasets for studying malware detection and provide future research with more representative data of the time. Our code and dataset are available at - https://github.com/ShoumikSaha/DRSM"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f16a6785a007c48f8e9c460b978613135d30e8c3.pdf"}, "supplementary_material": {"value": "/attachment/7a8d6e8734a35870a66ba71905608d3d1a61888d.zip"}, "_bibtex": {"value": "@inproceedings{\nsaha2024drsm,\ntitle={{DRSM}: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness},\nauthor={Shoumik Saha and Wenxiao Wang and Yigitcan Kaya and Soheil Feizi and Tudor Dumitras},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=m7aPLHwsLr}\n}"}, "TLDR": {"value": "We proposed a framework to make the ML-based malware detection model more robust"}, "paperhash": {"value": "saha|drsm_derandomized_smoothing_on_malware_classifier_providing_certified_robustness"}}, "number": 8147, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8147/-/Revision", "ICLR.cc/2024/Conference/Submission8147/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8147/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695498649060, "cdate": 1695498649060, "tmdate": 1710455042972, "mdate": 1710455042972, "pdate": 1705411032559, "version": 2}, {"id": "pEGSdJu52I", "forum": "pEGSdJu52I", "signatures": ["ICLR.cc/2024/Conference/Submission8145/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8145/Authors"], "content": {"title": {"value": "On the Variance of Neural Network Training with respect to Test Sets and Distributions"}, "authors": {"value": ["Keller Jordan"]}, "authorids": {"value": ["~Keller_Jordan1"]}, "keywords": {"value": ["stochasticity", "distribution shift", "randomness", "deep learning", "variance", "random seed"]}, "abstract": {"value": "Neural network trainings are stochastic, causing the performance of trained networks to vary across repeated runs of training.\nWe contribute the following results towards understanding this variation.\n(1) Despite having significant variance on their test-sets, we demonstrate that standard CIFAR-10 and ImageNet trainings have little variance in their performance on the test-distributions from which their test-sets are sampled.\n(2) We introduce the independent errors assumption and show that it suffices to recover the structure and variance of the empirical accuracy distribution across repeated runs of training.\n(3) We prove that test-set variance is unavoidable given the observation that ensembles of identically trained networks are calibrated (Jiang et al., 2021), and demonstrate that the variance of binary classification trainings closely follows a simple formula based on the error rate and number of test examples.\n(4) We conduct preliminary studies of data augmentation, learning rate, finetuning instability and distribution-shift through the lens of variance between runs."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2de59bd3955e067d8a7c6a4eee59896af773422d.pdf"}, "TLDR": {"value": "Neural network trainings are nondeterministic; this paper presents and experimentally justifies a statistical model for the variation between independent runs of training."}, "_bibtex": {"value": "@inproceedings{\njordan2024calibrated,\ntitle={Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable},\nauthor={Keller Jordan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pEGSdJu52I}\n}"}, "paperhash": {"value": "jordan|on_the_variance_of_neural_network_training_with_respect_to_test_sets_and_distributions"}}, "number": 8145, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8145/-/Revision", "ICLR.cc/2024/Conference/Submission8145/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8145/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695498608181, "cdate": 1695498608181, "tmdate": 1710476572391, "mdate": 1710476572391, "pdate": 1705411032458, "version": 2}, {"id": "OOxotBmGol", "forum": "OOxotBmGol", "signatures": ["ICLR.cc/2024/Conference/Submission8133/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8133/Authors"], "content": {"title": {"value": "Large Language Models to Enhance Bayesian Optimization"}, "authors": {"value": ["Tennison Liu", "Nicol\u00e1s Astorga", "Nabeel Seedat", "Mihaela van der Schaar"]}, "authorids": {"value": ["~Tennison_Liu1", "~Nicol\u00e1s_Astorga1", "~Nabeel_Seedat1", "~Mihaela_van_der_Schaar2"]}, "keywords": {"value": ["bayesian optimization", "LLMs"]}, "abstract": {"value": "Bayesian optimization (BO) is a powerful approach for optimizing complex and expensive-to-evaluate black-box functions. Its importance is underscored in many applications, notably including hyperparameter tuning, but its efficacy depends on efficiently balancing exploration and exploitation. While there has been substantial progress in BO methods, striking this balance remains a delicate process. In this light, we present \\texttt{LLAMBO}, a novel approach that integrates the capabilities of Large Language Models (LLM) within BO. At a high level, we frame the BO problem in natural language, enabling LLMs to iteratively \\emph{propose} and \\emph{evaluate} promising solutions conditioned on historical evaluations. More specifically, we explore how combining contextual understanding, few-shot learning proficiency, and domain knowledge of LLMs can improve model-based BO. Our findings illustrate that \\texttt{LLAMBO} is effective at zero-shot warmstarting, and enhances surrogate modeling and candidate sampling, especially in the early stages of search when observations are sparse. Our approach is performed in context and does not require LLM finetuning. Additionally, it is modular by design, allowing individual components to be integrated into existing BO frameworks, or function cohesively as an end-to-end method. We empirically validate \\texttt{LLAMBO}'s efficacy on the problem of hyperparameter tuning, highlighting strong empirical performance across a range of diverse benchmarks, proprietary, and synthetic tasks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b22b6ea9b84dd474cf4871acc78a784c45bac294.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024large,\ntitle={Large Language Models to Enhance Bayesian Optimization},\nauthor={Tennison Liu and Nicol{\\'a}s Astorga and Nabeel Seedat and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OOxotBmGol}\n}"}, "paperhash": {"value": "liu|large_language_models_to_enhance_bayesian_optimization"}}, "number": 8133, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8133/-/Revision", "ICLR.cc/2024/Conference/Submission8133/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/Submission8133/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695498093945, "cdate": 1695498093945, "tmdate": 1710413250732, "mdate": 1710413250732, "pdate": 1706844954378, "version": 2}, {"id": "55uj7mU7Cv", "forum": "55uj7mU7Cv", "signatures": ["ICLR.cc/2024/Conference/Submission8129/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8129/Authors"], "content": {"title": {"value": "Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach"}, "authors": {"value": ["Sagar Shrestha", "Xiao Fu"]}, "authorids": {"value": ["~Sagar_Shrestha1", "~Xiao_Fu1"]}, "keywords": {"value": ["unsupervised domain translation", "translation identifiability", "distribution matching", "unpaired image to image translation"]}, "abstract": {"value": "Unsupervised domain translation (UDT) aims to find functions that convert samples from one domain (e.g., sketches) to another domain (e.g., photos) without changing the high-level semantic meaning (also referred to as \"content\"). The translation functions are often sought by probability distribution matching of the transformed source domain and target domain. CycleGAN stands as arguably the most representative approach among this line of work. However, it was noticed in the literature that CycleGAN and variants could fail to identify the desired translation functions and produce content-misaligned translations.\nThis limitation arises due to the presence of multiple translation functions---referred to as ``measure-preserving automorphism\" (MPA)---in the solution space of the learning criteria. Despite awareness of such identifiability issues, solutions have remained elusive. This study delves into the core identifiability inquiry and introduces an MPA elimination theory. Our analysis shows that MPA is unlikely to exist, if multiple pairs of diverse cross-domain conditional distributions are matched by the learning function.\nOur theory leads to a UDT learner using distribution matching over auxiliary variable-induced subsets of the domains---other than over the entire data domains as in the classical approaches.  The proposed framework is the first to rigorously establish translation identifiability under reasonable UDT settings, to our best knowledge.\nExperiments corroborate with our theoretical claims."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/310f0697e921696dbb723b2f938345c38befe7d6.pdf"}, "supplementary_material": {"value": "/attachment/bba6017fc2dc8543fc915d43386eaa33f05f7b0a.zip"}, "_bibtex": {"value": "@inproceedings{\nshrestha2024towards,\ntitle={Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach},\nauthor={Sagar Shrestha and Xiao Fu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=55uj7mU7Cv}\n}"}, "paperhash": {"value": "shrestha|towards_identifiable_unsupervised_domain_translation_a_diversified_distribution_matching_approach"}}, "number": 8129, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8129/-/Revision", "ICLR.cc/2024/Conference/Submission8129/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8129/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695497815023, "cdate": 1695497815023, "tmdate": 1712356312196, "mdate": 1712356312196, "pdate": 1705411032120, "version": 2}, {"id": "LSYhE2hLWG", "forum": "LSYhE2hLWG", "signatures": ["ICLR.cc/2024/Conference/Submission8112/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8112/Authors"], "content": {"title": {"value": "SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations"}, "authors": {"value": ["Xuan Zhang", "Jacob Helwig", "Yuchao Lin", "Yaochen Xie", "Cong Fu", "Stephan Wojtowytsch", "Shuiwang Ji"]}, "authorids": {"value": ["~Xuan_Zhang3", "~Jacob_Helwig1", "~Yuchao_Lin1", "~Yaochen_Xie1", "~Cong_Fu2", "~Stephan_Wojtowytsch1", "~Shuiwang_Ji1"]}, "keywords": {"value": ["Partial differential equations", "Physics simulation", "Dynamics learning"]}, "abstract": {"value": "We consider using deep neural networks to solve time-dependent partial differential equations (PDEs), where multi-scale processing is crucial for modeling complex, time-evolving dynamics. While the U-Net architecture with skip connections is commonly used by prior studies to enable multi-scale processing, our analysis shows that the need for features to evolve across layers results in temporally misaligned features in skip connections, which limits the model\u2019s performance. To address this limitation, we propose SineNet, consisting of multiple sequentially connected U-shaped network blocks, referred to as waves. In SineNet, high-resolution features are evolved progressively through multiple stages, thereby reducing the amount of misalignment within each stage. We furthermore analyze the role of skip connections in enabling both parallel and sequential processing of multi-scale information. Our method is rigorously tested on multiple PDE datasets, including the Navier-Stokes equations and shallow water equations, showcasing the advantages of our proposed approach over conventional U-Nets with a comparable parameter budget. We further demonstrate that increasing the number of waves in SineNet while maintaining the same number of parameters leads to a monotonically improved performance. The results highlight the effectiveness of SineNet and the potential of our approach in advancing the state-of-the-art in neural PDE solver design. Our code is available as part of AIRS (https://github.com/divelab/AIRS)."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "Multi-stage U-Net for time-evolving PDEs"}, "pdf": {"value": "/pdf/e09653bff41011adca550b8b7e3e27bd1e59e9f1.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024sinenet,\ntitle={SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations},\nauthor={Xuan Zhang and Jacob Helwig and Yuchao Lin and Yaochen Xie and Cong Fu and Stephan Wojtowytsch and Shuiwang Ji},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LSYhE2hLWG}\n}"}, "paperhash": {"value": "zhang|sinenet_learning_temporal_dynamics_in_timedependent_partial_differential_equations"}}, "number": 8112, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8112/-/Revision", "ICLR.cc/2024/Conference/Submission8112/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8112/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695497134947, "cdate": 1695497134947, "tmdate": 1711480645541, "mdate": 1711480645541, "pdate": 1705411031762, "version": 2}, {"id": "WIzzXCVYiH", "forum": "WIzzXCVYiH", "signatures": ["ICLR.cc/2024/Conference/Submission8107/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8107/Authors"], "content": {"title": {"value": "GNNBoundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries"}, "authors": {"value": ["Xiaoqi Wang", "Han Wei Shen"]}, "authorids": {"value": ["~Xiaoqi_Wang2", "~Han_Wei_Shen1"]}, "keywords": {"value": ["AI Interpretability", "Graph Neural Networks", "Model-Level Explanation of Neural Networks", "Decision Boundaries"]}, "abstract": {"value": "While Graph Neural Networks (GNNs) have achieved remarkable performance on various machine learning tasks on graph data, they also raised questions regarding their transparency and interpretability. Recently, there have been extensive research efforts to explain the decision-making process of GNNs. These efforts often focus on explaining why a certain prediction is made for a particular instance, or what discriminative features the GNNs try to detect for each class. However, to the best of our knowledge, there is no existing study on understanding the decision boundaries of GNNs, even though the decision-making process of GNNs is directly determined by the decision boundaries. To bridge this research gap, we propose a model-level explainability method called GNNBoundary, which attempts to gain deeper insights into the decision boundaries of graph classifiers. Specifically, we first develop an algorithm to identify the pairs of classes whose decision regions are adjacent. For an adjacent class pair, the near-boundary graphs between them are effectively generated by optimizing a novel objective function specifically designed for boundary graph generation. Thus, by analyzing the nearboundary graphs, the important characteristics of decision boundaries can be uncovered. To evaluate the efficacy of GNNBoundary, we conduct experiments on both synthetic and public real-world datasets. The results demonstrate that, via the analysis of faithful near-boundary graphs generated by GNNBoundary, we can thoroughly assess the robustness and generalizability of the explained GNNs. The official implementation can be found at https://github.com/yolandalalala/GNNBoundary."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4c88af58e7fea802a541ca1a850768e448700110.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024gnnboundary,\ntitle={{GNNB}oundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries},\nauthor={Xiaoqi Wang and Han Wei Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WIzzXCVYiH}\n}"}, "paperhash": {"value": "wang|gnnboundary_towards_explaining_graph_neural_networks_through_the_lens_of_decision_boundaries"}}, "number": 8107, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8107/-/Revision", "ICLR.cc/2024/Conference/Submission8107/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8107/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695496983024, "cdate": 1695496983024, "tmdate": 1710651893072, "mdate": 1710651893072, "pdate": 1705411031621, "version": 2}, {"id": "0jsfesDZDq", "forum": "0jsfesDZDq", "signatures": ["ICLR.cc/2024/Conference/Submission8098/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8098/Authors"], "content": {"title": {"value": "Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN"}, "authors": {"value": ["Biswadeep Chakraborty", "Beomseok Kang", "Harshit Kumar", "Saibal Mukhopadhyay"]}, "authorids": {"value": ["~Biswadeep_Chakraborty1", "~Beomseok_Kang1", "hkumar64@gatech.edu", "~Saibal_Mukhopadhyay2"]}, "keywords": {"value": ["spiking neural network", "SNN", "network pruning", "stability", "neuromorphic", "leaky integrate and fire", "STDP", "sparsification", "task-agnostic pruning", "timescale optimization"]}, "TLDR": {"value": "A task-agnostic pruning method that exploits the diversity in timescales for heterogeneous RSNNs and gives small, stable pruned networks"}, "abstract": {"value": "Recurrent Spiking Neural Networks (RSNNs) have emerged as a computationally efficient and brain-inspired machine learning model. The design of sparse RSNNs with fewer neurons and synapses helps reduce the computational complexity of RSNNs. Traditionally, sparse SNNs are obtained by first training a dense and complex SNN for a target task and, next, eliminating neurons with low activity (activity-based pruning) while maintaining task performance. In contrast, this paper presents a task-agnostic methodology for designing sparse RSNNs by pruning an untrained (arbitrarily initialized) large model. \nWe introduce a novel Lyapunov Noise Pruning (LNP) algorithm that uses graph sparsification methods and utilizes Lyapunov exponents to design a stable sparse RSNN from an untrained RSNN. We show that the LNP can leverage diversity in neuronal timescales to design a sparse Heterogeneous RSNN (HRSNN). Further, we show that the same sparse HRSNN model can be trained for different tasks, such as image classification and time-series prediction. The experimental results show that, in spite of being task-agnostic, LNP increases computational efficiency (fewer neurons and synapses) and prediction performance of RSNNs compared to traditional activity-based pruning of trained dense models."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7e55c6eb14311819313269f9b7f133c8cee91597.pdf"}, "supplementary_material": {"value": "/attachment/d86e0dbdc96d62a023bc91a41b638f899c25509b.zip"}, "_bibtex": {"value": "@inproceedings{\nchakraborty2024sparse,\ntitle={Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent {SNN}},\nauthor={Biswadeep Chakraborty and Beomseok Kang and Harshit Kumar and Saibal Mukhopadhyay},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0jsfesDZDq}\n}"}, "paperhash": {"value": "chakraborty|sparse_spiking_neural_network_exploiting_heterogeneity_in_timescales_for_pruning_recurrent_snn"}}, "number": 8098, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8098/-/Revision", "ICLR.cc/2024/Conference/Submission8098/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8098/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695496666852, "cdate": 1695496666852, "tmdate": 1709661545861, "mdate": 1709661545861, "pdate": 1705411031472, "version": 2}, {"id": "GgEAdqYPNA", "forum": "GgEAdqYPNA", "signatures": ["ICLR.cc/2024/Conference/Submission8091/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8091/Authors"], "content": {"title": {"value": "Investigating the Benefits of Projection Head for Representation Learning"}, "authors": {"value": ["Yihao Xue", "Eric Gan", "Jiayi Ni", "Siddharth Joshi", "Baharan Mirzasoleiman"]}, "authorids": {"value": ["~Yihao_Xue1", "~Eric_Gan1", "~Jiayi_Ni1", "~Siddharth_Joshi1", "~Baharan_Mirzasoleiman1"]}, "keywords": {"value": ["representation learning", "representation learning theory", "contrastive learning", "robustness"]}, "abstract": {"value": "An effective technique for obtaining high-quality representations is adding a projection head on top of the encoder during training, then discarding it and using the pre-projection representations. Despite its proven practical effectiveness, the reason behind the success of this technique is poorly understood. The pre-projection representations are not directly optimized by the loss function, raising the question: what makes them better? In this work, we provide a rigorous theoretical answer to this question. We start by examining linear models trained with self-supervised contrastive loss. We reveal that the implicit bias of  training algorithms leads to layer-wise progressive feature weighting, where features become increasingly unequal as we go deeper into the layers. Consequently, lower layers tend to have more normalized and less specialized representations. We theoretically characterize scenarios where such representations are more beneficial, highlighting the intricate interplay between data augmentation and input features. Additionally, we demonstrate that introducing non-linearity into the network allows lower layers to learn features that are completely absent in higher layers. Finally, we show how this mechanism improves the robustness in supervised contrastive learning and supervised learning. We empirically validate our results through various experiments on CIFAR-10/100, UrbanCars and shifted versions of ImageNet. We also introduce a potential alternative to projection head, which offers a more interpretable and controllable design."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/274d4b0de6e23f1e7b5f267ab4aa084835b1eec5.pdf"}, "_bibtex": {"value": "@inproceedings{\nxue2024investigating,\ntitle={Investigating the Benefits of Projection Head for Representation Learning},\nauthor={Yihao Xue and Eric Gan and Jiayi Ni and Siddharth Joshi and Baharan Mirzasoleiman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GgEAdqYPNA}\n}"}, "paperhash": {"value": "xue|investigating_the_benefits_of_projection_head_for_representation_learning"}}, "number": 8091, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8091/-/Revision", "ICLR.cc/2024/Conference/Submission8091/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8091/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695496408169, "cdate": 1695496408169, "tmdate": 1710575707173, "mdate": 1710575707173, "pdate": 1705411031257, "version": 2}, {"id": "1YO4EE3SPB", "forum": "1YO4EE3SPB", "signatures": ["ICLR.cc/2024/Conference/Submission8090/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8090/Authors"], "content": {"title": {"value": "A Variational Perspective on Solving Inverse Problems with Diffusion Models"}, "authors": {"value": ["Morteza Mardani", "Jiaming Song", "Jan Kautz", "Arash Vahdat"]}, "authorids": {"value": ["~Morteza_Mardani1", "~Jiaming_Song1", "~Jan_Kautz1", "~Arash_Vahdat3"]}, "keywords": {"value": ["diffusion models", "score matching", "variational approximation", "regularization by denoising", "inverse problems"]}, "abstract": {"value": "Diffusion models have emerged as a key pillar of foundation models in visual domains. One of their critical applications is to universally solve different downstream inverse tasks via a single diffusion prior without re-training for each task. Most inverse tasks can be formulated as inferring a posterior distribution over data (e.g., a full image) given a measurement (e.g., a masked image). This is however challenging in diffusion models since the nonlinear and iterative nature of the diffusion process renders the posterior intractable. To cope with this challenge, we propose a variational approach that by design seeks to approximate the true posterior distribution. We show that our approach naturally leads to regularization by denoising diffusion process (RED-diff) where denoisers at different timesteps concurrently impose different structural constraints over the image. To gauge the contribution of denoisers from different timesteps, we propose a weighting mechanism based on signal-to-noise-ratio (SNR). Our approach provides a new variational perspective for solving inverse problems with diffusion models, allowing us to formulate sampling as stochastic optimization, where one can simply apply off-the-shelf solvers with lightweight iterates. Our experiments for various linear and nonlinear image restoration tasks demonstrate the strengths of our method compared with state-of-the-art sampling-based diffusion models. The code is available online \\footnote{\\url{https://github.com/NVlabs/RED-diff}}."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/98565461a56247bb80f25ac785745223d4ec97f7.pdf"}, "_bibtex": {"value": "@inproceedings{\nmardani2024a,\ntitle={A Variational Perspective on Solving Inverse Problems with Diffusion Models},\nauthor={Morteza Mardani and Jiaming Song and Jan Kautz and Arash Vahdat},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1YO4EE3SPB}\n}"}, "paperhash": {"value": "mardani|a_variational_perspective_on_solving_inverse_problems_with_diffusion_models"}}, "number": 8090, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8090/-/Revision", "ICLR.cc/2024/Conference/Submission8090/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8090/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695496338348, "cdate": 1695496338348, "tmdate": 1713147164535, "mdate": 1713147164535, "pdate": 1705411031235, "version": 2}, {"id": "vqIH0ObdqL", "forum": "vqIH0ObdqL", "signatures": ["ICLR.cc/2024/Conference/Submission8089/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8089/Authors"], "content": {"title": {"value": "Can Large Language Models Infer Causation from Correlation?"}, "authors": {"value": ["Zhijing Jin", "Jiarui Liu", "Zhiheng LYU", "Spencer Poff", "Mrinmaya Sachan", "Rada Mihalcea", "Mona T. Diab", "Bernhard Sch\u00f6lkopf"]}, "authorids": {"value": ["~Zhijing_Jin1", "~Jiarui_Liu1", "~Zhiheng_LYU1", "~Spencer_Poff1", "~Mrinmaya_Sachan3", "~Rada_Mihalcea1", "~Mona_T._Diab1", "~Bernhard_Sch\u00f6lkopf1"]}, "keywords": {"value": ["Large Language Models", "Natural Language Inference", "Causal Reasoning", "Correlation-to-Causation Inference", "Benchmark Dataset", "Causal Discovery"]}, "TLDR": {"value": "We propose Corr2Cause, the first dataset to infer causation from correlation by pure reasoning, and test 17 LLMs' performance on it."}, "abstract": {"value": "Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize \u2013 they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and can be helpful in guiding future research on improving LLMs\u2019 pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c32089ff7c53b6e59610da92bace7b326b0a622c.pdf"}, "_bibtex": {"value": "@inproceedings{\njin2024can,\ntitle={Can Large Language Models Infer Causation from Correlation?},\nauthor={Zhijing Jin and Jiarui Liu and Zhiheng LYU and Spencer Poff and Mrinmaya Sachan and Rada Mihalcea and Mona T. Diab and Bernhard Sch{\\\"o}lkopf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vqIH0ObdqL}\n}"}, "paperhash": {"value": "jin|can_large_language_models_infer_causation_from_correlation"}}, "number": 8089, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8089/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8089/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695496293454, "cdate": 1695496293454, "tmdate": 1713162676710, "mdate": 1713162676710, "pdate": 1705411031152, "version": 2}, {"id": "Of2nEDc4s7", "forum": "Of2nEDc4s7", "signatures": ["ICLR.cc/2024/Conference/Submission8085/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8085/Authors"], "content": {"title": {"value": "Improved statistical and computational complexity of the mean-field Langevin dynamics under structured data"}, "authors": {"value": ["Atsushi Nitanda", "Kazusato Oko", "Taiji Suzuki", "Denny Wu"]}, "authorids": {"value": ["~Atsushi_Nitanda1", "~Kazusato_Oko1", "~Taiji_Suzuki1", "~Denny_Wu2"]}, "keywords": {"value": ["neural network optimization", "feature learning", "mean-field Langevin dynamics"]}, "abstract": {"value": "Recent works have shown that neural networks optimized by gradient-based methods can adapt to sparse or low-dimensional target functions through feature learning; an often studied target is the sparse parity function on the unit hypercube. However, such isotropic data setting does not capture the anisotropy and low intrinsic dimensionality exhibited in realistic datasets. In this work, we address this shortcoming by studying how gradient-based feature learning interacts with structured (anisotropic) input data: we consider the classification of $k$-sparse parity on high-dimensional orthotope where the feature coordinates have varying magnitudes, and analyze the learning complexity of the mean-field Langevin dynamics (MFLD), which describes the noisy gradient descent update on two-layer neural network. We show that the statistical complexity (i.e. sample size) and computational complexity (i.e. network width) of MFLD can both be improved when prominent directions of the anisotropic input data align with the support of the target function. Moreover, by employing a coordinate transform determined by the gradient covariance, the width can be made independent of the target degree $k$. Lastly, we demonstrate the benefit of feature learning by establishing a kernel lower bound on the classification error, which applies to neural networks in the lazy regime."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5513243838f990d8d7323b2afa870a627e9c9484.pdf"}, "_bibtex": {"value": "@inproceedings{\nnitanda2024anisotropy,\ntitle={Anisotropy helps: improved statistical and computational complexity of the mean-field Langevin dynamics under structured data},\nauthor={Atsushi Nitanda and Kazusato Oko and Taiji Suzuki and Denny Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Of2nEDc4s7}\n}"}, "paperhash": {"value": "nitanda|improved_statistical_and_computational_complexity_of_the_meanfield_langevin_dynamics_under_structured_data"}}, "number": 8085, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8085/-/Revision", "ICLR.cc/2024/Conference/Submission8085/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8085/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695496052320, "cdate": 1695496052320, "tmdate": 1713155869540, "mdate": 1713155869540, "pdate": 1705411030981, "version": 2}, {"id": "jX2DT7qDam", "forum": "jX2DT7qDam", "signatures": ["ICLR.cc/2024/Conference/Submission8069/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8069/Authors"], "content": {"title": {"value": "Jointly-Learned Exit and Inference for a Dynamic Neural Network"}, "authors": {"value": ["florence regol", "Joud Chataoui", "Mark Coates"]}, "authorids": {"value": ["~florence_regol1", "~Joud_Chataoui1", "~Mark_Coates1"]}, "keywords": {"value": ["early-exit dynamic networks", "efficient inference"]}, "abstract": {"value": "Large pretrained models, coupled with fine-tuning, are slowly becoming established as the dominant architecture in machine learning. Even though these models offer impressive performance, their practical application is often limited by the prohibitive amount of resources required for $\\textit{every}$ inference. Early-exiting dynamic neural networks (EDNN) circumvent this issue by allowing a model to make some of its predictions from intermediate layers (i.e., early-exit). Training an EDNN architecture is challenging as it consists of two intertwined components: the gating mechanism (GM) that controls early-exiting decisions and the intermediate inference modules (IMs) that perform inference from intermediate representations. As a result, most existing approaches rely on thresholding confidence metrics for the gating mechanism and strive to improve the underlying backbone network and the inference modules. Although successful, this approach has two fundamental shortcomings: 1) the GMs and the IMs are decoupled during training, leading to a train-test mismatch; and 2) the thresholding gating mechanism introduces a positive bias into the predictive probabilities, making it difficult to readily extract uncertainty information. We propose a novel architecture that connects these two modules. This leads to significant performance improvements on classification datasets and enables better uncertainty characterization capabilities."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/530fc74c8de9fa89f925873092154bf72fa2e92c.pdf"}, "supplementary_material": {"value": "/attachment/4f5f35a9616fcd3c3ed4bab4fede00362b25f8b4.zip"}, "_bibtex": {"value": "@inproceedings{\nregol2024jointlylearned,\ntitle={Jointly-Learned Exit and Inference for a Dynamic Neural Network},\nauthor={florence regol and Joud Chataoui and Mark Coates},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jX2DT7qDam}\n}"}, "paperhash": {"value": "regol|jointlylearned_exit_and_inference_for_a_dynamic_neural_network"}}, "number": 8069, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8069/-/Revision", "ICLR.cc/2024/Conference/Submission8069/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8069/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495477158, "cdate": 1695495477158, "tmdate": 1710792201855, "mdate": 1710792201855, "pdate": 1705411030236, "version": 2}, {"id": "rtl4XnJYBh", "forum": "rtl4XnJYBh", "signatures": ["ICLR.cc/2024/Conference/Submission8064/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8064/Authors"], "content": {"title": {"value": "Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift"}, "authors": {"value": ["Yihao Xue", "Siddharth Joshi", "Dang Nguyen", "Baharan Mirzasoleiman"]}, "authorids": {"value": ["~Yihao_Xue1", "~Siddharth_Joshi1", "~Dang_Nguyen2", "~Baharan_Mirzasoleiman1"]}, "keywords": {"value": ["multi-model contrastive learning", "contrastive learning theory", "representation learning", "theory", "robustness", "distribution shift"]}, "abstract": {"value": "Recently, multimodal contrastive learning (MMCL) approaches, such as CLIP, have achieved a remarkable success in learning representations that are robust against distribution shift and generalize to new domains. Despite the empirical success, the mechanism behind learning such generalizable representations is not understood. In this work, we rigorously analyze this problem and \nuncover two mechanisms behind MMCL's robustness: \\emph{intra-class contrasting}, which allows the model to learn features with a high variance, and \\emph{inter-class feature sharing}, where annotated details in one class help learning other classes better. Both mechanisms prevent spurious features that are over-represented in the training data to overshadow the generalizable core features. This yields superior zero-shot classification accuracy under distribution shift. Furthermore, we theoretically demonstrate the benefits of using rich captions on robustness and explore the effect of annotating different types of details in the captions. We validate our theoretical findings through experiments, including a well-designed synthetic experiment and an experiment involving training CLIP models on MSCOCO/Conceptual Captions and evaluating them on shifted ImageNets."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6a626c46d27f126eacb827909e73e287e464009d.pdf"}, "_bibtex": {"value": "@inproceedings{\nxue2024understanding,\ntitle={Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift},\nauthor={Yihao Xue and Siddharth Joshi and Dang Nguyen and Baharan Mirzasoleiman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rtl4XnJYBh}\n}"}, "paperhash": {"value": "xue|understanding_the_robustness_of_multimodal_contrastive_learning_to_distribution_shift"}}, "number": 8064, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8064/-/Revision", "ICLR.cc/2024/Conference/Submission8064/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8064/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495340902, "cdate": 1695495340902, "tmdate": 1710571536476, "mdate": 1710571536476, "pdate": 1705411029755, "version": 2}, {"id": "FJWT0692hw", "forum": "FJWT0692hw", "signatures": ["ICLR.cc/2024/Conference/Submission8061/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8061/Authors"], "content": {"title": {"value": "SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking"}, "authors": {"value": ["Chris Cundy", "Stefano Ermon"]}, "authorids": {"value": ["~Chris_Cundy1", "~Stefano_Ermon1"]}, "keywords": {"value": ["Sequence Modelling", "Imitiation Learning", "Language Modelling"]}, "TLDR": {"value": "We formulate sequence modelling as an imitation learning problem, allowing use of alternative losses and backspace characters to improve OOD behavior"}, "abstract": {"value": "In many domains, autoregressive models can attain high likelihood on the task of predicting the next observation. However, this maximum-likelihood (MLE) objective does not necessarily match a downstream use-case of autoregressively generating high-quality sequences. The MLE objective weights sequences proportionally to their frequency under the data distribution, with no guidance for the model's behaviour out of distribution (OOD): leading to compounding error during autoregressive generation. In order to address this compounding error problem, we formulate sequence generation as an imitation learning (IL) problem. This allows us to minimize a variety of divergences between the distribution of sequences generated by an autoregressive model and sequences from a dataset, including divergences with weight on OOD generated sequences. The IL framework also allows us to incorporate backtracking by introducing a backspace action into the generation process. This further mitigates the compounding error problem by allowing the model to revert a sampled token if it takes the sequence OOD. Our resulting method, SequenceMatch, can be implemented without adversarial training or major architectural changes. We identify the SequenceMatch-\u03c72 divergence as a more suitable training objective for autoregressive models which are used for generation. We show that empirically, SequenceMatch training leads to improvements over MLE on text generation with language models and arithmetic"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c034cb58427202bff4ad7164db6d76d3e815b9d6.pdf"}, "supplementary_material": {"value": "/attachment/e4fc212a684d7bd02f8fddc68e8d65a37913041d.pdf"}, "_bibtex": {"value": "@inproceedings{\ncundy2024sequencematch,\ntitle={SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking},\nauthor={Chris Cundy and Stefano Ermon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FJWT0692hw}\n}"}, "paperhash": {"value": "cundy|sequencematch_imitation_learning_for_autoregressive_sequence_modelling_with_backtracking"}}, "number": 8061, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8061/-/Revision", "ICLR.cc/2024/Conference/Submission8061/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8061/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495240012, "cdate": 1695495240012, "tmdate": 1710477569376, "mdate": 1710477569376, "pdate": 1705411029580, "version": 2}, {"id": "LfmZh91tDI", "forum": "LfmZh91tDI", "signatures": ["ICLR.cc/2024/Conference/Submission8060/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8060/Authors"], "content": {"title": {"value": "Layer-wise linear mode connectivity"}, "authors": {"value": ["Linara Adilova", "Maksym Andriushchenko", "Michael Kamp", "Asja Fischer", "Martin Jaggi"]}, "authorids": {"value": ["~Linara_Adilova1", "~Maksym_Andriushchenko1", "~Michael_Kamp1", "~Asja_Fischer1", "~Martin_Jaggi1"]}, "keywords": {"value": ["linear mode connectivity", "layer-wise", "federated averaging"]}, "TLDR": {"value": "Investigation of the layer-wise structure of the barriers on the line between two parametrizations of deep models"}, "abstract": {"value": "Averaging neural network parameters is an intuitive method for fusing the knowledge of two independent models. It is most prominently used in federated learning. If models are averaged at the end of training, this can only lead to a good performing model if the loss surface of interest is very particular, i.e., the loss in the midpoint between the two models needs to be sufficiently low. This is impossible to guarantee for the non-convex losses of state-of-the-art networks. For averaging models trained on vastly different datasets, it was proposed to average only the parameters of particular layers or combinations of layers, resulting in better performing models. To get a better understanding of the effect of layer-wise averaging, we analyse the performance of the models that result from averaging single layers, or groups of layers. Based on our empirical and theoretical investigation, we introduce a novel notion of the layer-wise linear connectivity, and show that deep networks do not have layer-wise barriers between them."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/039a426405636e0c6ee6fd6ea0035e1d20b6bc28.pdf"}, "_bibtex": {"value": "@inproceedings{\nadilova2024layerwise,\ntitle={Layer-wise linear mode connectivity},\nauthor={Linara Adilova and Maksym Andriushchenko and Michael Kamp and Asja Fischer and Martin Jaggi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LfmZh91tDI}\n}"}, "paperhash": {"value": "adilova|layerwise_linear_mode_connectivity"}}, "number": 8060, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8060/-/Revision", "ICLR.cc/2024/Conference/Submission8060/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8060/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495229128, "cdate": 1695495229128, "tmdate": 1710851522100, "mdate": 1710851522100, "pdate": 1705411029509, "version": 2}, {"id": "h05eQniJsQ", "forum": "h05eQniJsQ", "signatures": ["ICLR.cc/2024/Conference/Submission8059/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8059/Authors"], "content": {"title": {"value": "Understanding Certified Training with Interval Bound Propagation"}, "authors": {"value": ["Yuhao Mao", "Mark Niklas Mueller", "Marc Fischer", "Martin Vechev"]}, "authorids": {"value": ["~Yuhao_Mao1", "~Mark_Niklas_Mueller2", "~Marc_Fischer1", "~Martin_Vechev1"]}, "keywords": {"value": ["Certified Robustness", "Adversarial Robustness", "Neural Network Verification", "Certified Training"]}, "TLDR": {"value": "We theoretically investigate certified training with Interval Bound Propagation, using a novel metric measuring the tightness of the resulting bounds."}, "abstract": {"value": "As robustness verification methods are becoming more precise, training certifiably robust neural networks is becoming ever more relevant. To this end, certified training methods compute and then optimize an upper bound on the worst-case loss over a robustness specification. Curiously, training methods based on the imprecise interval bound propagation (IBP) consistently outperform those leveraging more precise bounds. Still, we lack a theoretical understanding of the mechanisms making IBP so successful. In this work, we investigate these mechanisms by leveraging a novel metric measuring the tightness of IBP bounds. We first show theoretically that, for deep linear models (DLNs), tightness decreases with width and depth at initialization, but improves with IBP training. We, then, derive sufficient and necessary conditions on weight matrices for IBP bounds to become exact and demonstrate that these impose strong regularization, providing an explanation for the observed robustness-accuracy trade-off. Finally, we show how these results on DLNs transfer to ReLU networks, before conducting an extensive empirical study, (i) confirming this transferability and yielding state-of-the-art certified accuracy, (ii) finding that while all IBP-based training methods lead to high tightness, this increase is dominated by the size of the propagated input regions rather than the robustness specification, and finally (iii) observing that non-IBP-based methods do not increase tightness. Together, these results help explain the success of recent certified training methods and may guide the development of new ones."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3368ca8a5f0ec99ee88301ab1de8634647f5ce72.pdf"}, "supplementary_material": {"value": "/attachment/7f5bcc61c7aee3f08a9a7e07902214ebe9655bb6.zip"}, "_bibtex": {"value": "@inproceedings{\nmao2024understanding,\ntitle={Understanding Certified Training with Interval Bound Propagation},\nauthor={Yuhao Mao and Mark Niklas Mueller and Marc Fischer and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=h05eQniJsQ}\n}"}, "paperhash": {"value": "mao|understanding_certified_training_with_interval_bound_propagation"}}, "number": 8059, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8059/-/Revision", "ICLR.cc/2024/Conference/Submission8059/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8059/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495162964, "cdate": 1695495162964, "tmdate": 1709661545389, "mdate": 1709661545389, "pdate": 1705411029508, "version": 2}, {"id": "GnOLWS4Llt", "forum": "GnOLWS4Llt", "signatures": ["ICLR.cc/2024/Conference/Submission8057/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8057/Authors"], "content": {"title": {"value": "Offline RL with Observation Histories: Analyzing and Improving Sample Complexity"}, "authors": {"value": ["Joey Hong", "Anca Dragan", "Sergey Levine"]}, "authorids": {"value": ["~Joey_Hong2", "~Anca_Dragan1", "~Sergey_Levine1"]}, "keywords": {"value": ["offline reinforcement learning", "POMDPs", "representation learning"]}, "abstract": {"value": "Offline reinforcement learning (RL) can in principle synthesize more optimal behavior from a dataset consisting only of suboptimal trials. One way that this can happen is by \"stitching\" together the best parts of otherwise suboptimal trajectories that overlap on similar states, to create new behaviors where each individual state is in-distribution, but the overall returns are higher. However, in many interesting and complex applications, such as autonomous navigation and dialogue systems, the state is partially observed. Even worse, the state representation is unknown or not easy to define. In such cases, policies and value functions are often conditioned on observation histories instead of states. In these cases, it is not clear if the same kind of \"stitching\" is feasible at the level of observation histories, since two different trajectories would always have different histories, and thus \"similar states\" that might lead to effective stitching cannot be leveraged.  Theoretically, we show that standard offline RL algorithms conditioned on observation histories suffer from poor sample complexity, in accordance with the above intuition. We then identify sufficient conditions under which offline RL can still be efficient -- intuitively, it needs to learn a compact representation of history comprising only features relevant for action selection. We introduce a bisimulation loss that captures the extent to which this happens, and propose that offline RL can explicitly optimize this loss to aid worst-case sample complexity. Empirically, we show that across a variety of tasks either our proposed loss improves performance, or the value of this loss is already minimized as a consequence of standard offline RL, indicating that it correlates well with good performance."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/efd5f3cf56edfff0bb4ff14fb974d994bfaa976f.pdf"}, "_bibtex": {"value": "@inproceedings{\nhong2024offline,\ntitle={Offline {RL} with Observation Histories: Analyzing and Improving Sample Complexity},\nauthor={Joey Hong and Anca Dragan and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GnOLWS4Llt}\n}"}, "paperhash": {"value": "hong|offline_rl_with_observation_histories_analyzing_and_improving_sample_complexity"}}, "number": 8057, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8057/-/Revision", "ICLR.cc/2024/Conference/Submission8057/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8057/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695495078001, "cdate": 1695495078001, "tmdate": 1710563298161, "mdate": 1710563298161, "pdate": 1705411029431, "version": 2}, {"id": "CAqdG2dy5s", "forum": "CAqdG2dy5s", "signatures": ["ICLR.cc/2024/Conference/Submission8051/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8051/Authors"], "content": {"title": {"value": "Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"}, "authors": {"value": ["Giovanni De Felice", "Andrea Cini", "Daniele Zambon", "Vladimir Gusev", "Cesare Alippi"]}, "authorids": {"value": ["~Giovanni_De_Felice1", "~Andrea_Cini1", "~Daniele_Zambon1", "~Vladimir_Gusev1", "~Cesare_Alippi1"]}, "keywords": {"value": ["Spatio-temporal data", "time series", "virtual sensing", "imputation", "graph neural networks", "deep learning"]}, "TLDR": {"value": "We present a novel framework for sparse multivariate virtual sensing that leverages dependencies between the target variable and available covariates."}, "abstract": {"value": "Virtual sensing techniques allow for inferring signals at new unmonitored locations by exploiting spatio-temporal measurements coming from physical sensors at different locations. However, as the sensor coverage becomes sparse due to costs or other constraints, physical proximity cannot be used to support interpolation. In this paper, we overcome this challenge by leveraging dependencies between the target variable and a set of correlated variables (covariates) that can frequently be associated with each location of interest. From this viewpoint, covariates provide partial observability, and the problem consists of inferring values for unobserved channels by exploiting observations at other locations to learn how such variables can correlate. We introduce a novel graph-based methodology to exploit such relationships and design a graph deep learning architecture, named GgNet, implementing the framework. The proposed approach relies on propagating information over a nested graph structure that is used to learn dependencies between variables as well as locations. GgNet is extensively evaluated under different virtual sensing scenarios, demonstrating higher reconstruction accuracy compared to the state-of-the-art."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f134ca075964391b30baa22a0bf6a338d01598c.pdf"}, "supplementary_material": {"value": "/attachment/3ddf1b04e040086b80baaeee6ef42235e44d3223.zip"}, "_bibtex": {"value": "@inproceedings{\nfelice2024graphbased,\ntitle={Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations},\nauthor={Giovanni De Felice and Andrea Cini and Daniele Zambon and Vladimir Gusev and Cesare Alippi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CAqdG2dy5s}\n}"}, "paperhash": {"value": "felice|graphbased_virtual_sensing_from_sparse_and_partial_multivariate_observations"}}, "number": 8051, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8051/-/Revision", "ICLR.cc/2024/Conference/Submission8051/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8051/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695494838895, "cdate": 1695494838895, "tmdate": 1709661545302, "mdate": 1709661545302, "pdate": 1705411029036, "version": 2}, {"id": "0bMmZ3fkCk", "forum": "0bMmZ3fkCk", "signatures": ["ICLR.cc/2024/Conference/Submission8050/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8050/Authors"], "content": {"title": {"value": "NEFTune: Noisy Embeddings Improve Instruction Finetuning"}, "authors": {"value": ["Neel Jain", "Ping-yeh Chiang", "Yuxin Wen", "John Kirchenbauer", "Hong-Min Chu", "Gowthami Somepalli", "Brian R. Bartoldson", "Bhavya Kailkhura", "Avi Schwarzschild", "Aniruddha Saha", "Micah Goldblum", "Jonas Geiping", "Tom Goldstein"]}, "authorids": {"value": ["~Neel_Jain1", "~Ping-yeh_Chiang1", "~Yuxin_Wen2", "~John_Kirchenbauer1", "~Hong-Min_Chu1", "~Gowthami_Somepalli1", "~Brian_R._Bartoldson1", "~Bhavya_Kailkhura1", "~Avi_Schwarzschild1", "~Aniruddha_Saha1", "~Micah_Goldblum1", "~Jonas_Geiping1", "~Tom_Goldstein1"]}, "keywords": {"value": ["Instruction Finetuning"]}, "abstract": {"value": "We show that language model finetuning can be improved, sometimes dramatically, with a simple augmentation. \nNEFTune adds noise to the embedding vectors during training.\nStandard finetuning of LLaMA-2-7B using Alpaca achieves $29.79$\\% on AlpacaEval, which rises to $64.69$\\% using noisy embeddings. NEFTune also improves over strong baselines on modern instruction datasets.\nModels trained with Evol-Instruct see a $10$\\% improvement, with ShareGPT an $8$\\% improvement, and with OpenPlatypus an $8$\\% improvement. \nEven powerful models further refined with RLHF such as LLaMA-2-Chat benefit from additional training with NEFTune. Particularly, we see these improvements on the conversational abilities of the instruction model and not on traditional tasks like those on the OpenLLM Leaderboard, where performance is the same."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ab62341bb5a8f427d4042033bd3b7c9f59652b51.pdf"}, "supplementary_material": {"value": "/attachment/d78c3905a8b9202b58358079384a6a098d702065.zip"}, "_bibtex": {"value": "@inproceedings{\njain2024neftune,\ntitle={{NEFT}une: Noisy Embeddings Improve Instruction Finetuning},\nauthor={Neel Jain and Ping-yeh Chiang and Yuxin Wen and John Kirchenbauer and Hong-Min Chu and Gowthami Somepalli and Brian R. Bartoldson and Bhavya Kailkhura and Avi Schwarzschild and Aniruddha Saha and Micah Goldblum and Jonas Geiping and Tom Goldstein},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0bMmZ3fkCk}\n}"}, "paperhash": {"value": "jain|neftune_noisy_embeddings_improve_instruction_finetuning"}}, "number": 8050, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8050/-/Revision", "ICLR.cc/2024/Conference/Submission8050/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8050/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695494818101, "cdate": 1695494818101, "tmdate": 1710423235073, "mdate": 1710423235073, "pdate": 1705411029033, "version": 2}, {"id": "WWlxFtR5sV", "forum": "WWlxFtR5sV", "signatures": ["ICLR.cc/2024/Conference/Submission8048/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8048/Authors"], "content": {"title": {"value": "An operator preconditioning perspective on training in physics-informed machine learning"}, "authors": {"value": ["Tim De Ryck", "Florent Bonnet", "Siddhartha Mishra", "Emmanuel de Bezenac"]}, "authorids": {"value": ["~Tim_De_Ryck1", "~Florent_Bonnet1", "~Siddhartha_Mishra1", "~Emmanuel_de_Bezenac2"]}, "keywords": {"value": ["physics-informed machine learning", "operator preconditioning", "deep learning", "neural network training"]}, "abstract": {"value": "In this paper, we investigate the behavior of gradient descent algorithms in physics-informed machine learning methods like PINNs, which minimize residuals connected to partial differential equations (PDEs). Our key result is that the difficulty in training these models is closely related to the conditioning of a specific differential operator. This operator, in turn, is associated to the Hermitian square of the differential operator of the underlying PDE. If this operator is ill-conditioned, it results in slow or infeasible training. Therefore, preconditioning this operator is crucial. We employ both rigorous mathematical analysis and empirical evaluations to investigate various strategies, explaining how they better condition this critical operator, and consequently improve training."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bb2db7fa354d99feb2b3b02f70bf881aab7de2f6.pdf"}, "supplementary_material": {"value": "/attachment/568cb8219bb910cc7b94fb8693517025f45de9a7.zip"}, "_bibtex": {"value": "@inproceedings{\nryck2024an,\ntitle={An operator preconditioning perspective on training in physics-informed machine learning},\nauthor={Tim De Ryck and Florent Bonnet and Siddhartha Mishra and Emmanuel de Bezenac},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WWlxFtR5sV}\n}"}, "paperhash": {"value": "ryck|an_operator_preconditioning_perspective_on_training_in_physicsinformed_machine_learning"}}, "number": 8048, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8048/-/Revision", "ICLR.cc/2024/Conference/Submission8048/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8048/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695494775581, "cdate": 1695494775581, "tmdate": 1713109217744, "mdate": 1713109217744, "pdate": 1705411028862, "version": 2}, {"id": "pCEgna6Qco", "forum": "pCEgna6Qco", "signatures": ["ICLR.cc/2024/Conference/Submission8041/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8041/Authors"], "content": {"title": {"value": "Two-stage LLM Fine-tuning with Less Specialization and More Generalization"}, "authors": {"value": ["Yihan Wang", "Si Si", "Daliang Li", "Michal Lukasik", "Felix Yu", "Cho-Jui Hsieh", "Inderjit S Dhillon", "Sanjiv Kumar"]}, "authorids": {"value": ["~Yihan_Wang2", "~Si_Si1", "~Daliang_Li1", "~Michal_Lukasik1", "~Felix_Yu1", "~Cho-Jui_Hsieh1", "~Inderjit_S_Dhillon1", "~Sanjiv_Kumar1"]}, "keywords": {"value": ["language model", "Generalization"]}, "abstract": {"value": "Pretrained large language models (LLMs) are general purpose problem solvers applicable to a diverse set of tasks with prompts. They can be further improved towards a specific task by fine-tuning on a specialized dataset. However, fine-tuning usually makes the model narrowly specialized on this dataset with reduced general in-context learning performances, which is undesirable whenever the fine-tuned model needs to handle additional tasks where no fine-tuning data is available. \nIn this work, we first demonstrate that fine-tuning on a single task indeed decreases LLMs' general in-context learning performance. We discover one important cause of such forgetting, format specialization, where the model overfits to the format of the fine-tuned task.We further show that format specialization happens at the very beginning of fine-tuning. To solve this problem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet effective two-stage fine-tuning framework that reduces format specialization and improves generalization.ProMoT offloads task-specific format learning into additional and removable parameters by first doing prompt tuning and then fine-tuning the model itself with this soft prompt attached. \nWith experiments on several fine-tuning tasks and 8 in-context evaluation tasks, we show that ProMoT achieves comparable performance on fine-tuned tasks to standard fine-tuning, but with much less loss of in-context learning performances across a board range of  out-of-domain evaluation tasks. More importantly, ProMoT can even enhance generalization on in-context learning tasks that are semantically related to the fine-tuned task, e.g. ProMoT on En-Fr translation significantly improves performance on other language pairs, and ProMoT on NLI improves performance on summarization.\nExperiments also show that ProMoT can improve the generalization performance of  multi-task training."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/967d482dc9ddfbf84e0116bc826d1f2205123e77.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024twostage,\ntitle={Two-stage {LLM} Fine-tuning with Less Specialization and More Generalization},\nauthor={Yihan Wang and Si Si and Daliang Li and Michal Lukasik and Felix Yu and Cho-Jui Hsieh and Inderjit S Dhillon and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pCEgna6Qco}\n}"}, "paperhash": {"value": "wang|twostage_llm_finetuning_with_less_specialization_and_more_generalization"}}, "number": 8041, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8041/-/Revision", "ICLR.cc/2024/Conference/Submission8041/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8041/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695494655424, "cdate": 1695494655424, "tmdate": 1710280324163, "mdate": 1710280324163, "pdate": 1705411028651, "version": 2}, {"id": "mzyZ4wzKlM", "forum": "mzyZ4wzKlM", "signatures": ["ICLR.cc/2024/Conference/Submission8030/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8030/Authors"], "content": {"title": {"value": "Expressive Losses for Verified Robustness via Convex Combinations"}, "authors": {"value": ["Alessandro De Palma", "Rudy R Bunel", "Krishnamurthy Dj Dvijotham", "M. Pawan Kumar", "Robert Stanforth", "Alessio Lomuscio"]}, "authorids": {"value": ["~Alessandro_De_Palma1", "~Rudy_R_Bunel1", "~Krishnamurthy_Dj_Dvijotham1", "~M._Pawan_Kumar1", "~Robert_Stanforth1", "~Alessio_Lomuscio1"]}, "keywords": {"value": ["Verified Training", "Neural Network Verification", "Verified Adversarial Robustness"]}, "TLDR": {"value": "Expressive losses (ranging from lower to upper bounds to the true robust loss) are all you need to attain state-of-the-art verified robustness."}, "abstract": {"value": "In order to train networks for verified adversarial robustness, it is common to over-approximate the worst-case loss over perturbation regions, resulting in networks that attain verifiability at the expense of standard performance.\nAs shown in recent work, better trade-offs between accuracy and robustness can be obtained by carefully coupling adversarial training with over-approximations. \nWe hypothesize that the expressivity of a loss function, which we formalize as the ability to span a range of trade-offs between lower and upper bounds to the worst-case loss through a single parameter (the over-approximation coefficient), is key to attaining state-of-the-art performance. \nTo support our hypothesis, we show that trivial expressive losses, obtained via convex combinations between adversarial attacks and IBP bounds, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity.\nWe provide a detailed analysis of the relationship between the over-approximation coefficient and performance profiles across different expressive losses, showing that, while expressivity is essential, better approximations of the worst-case loss are not necessarily linked to superior robustness-accuracy trade-offs."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/40ce9bb1de770f815cc5905ce78d2b4957712ed0.pdf"}, "_bibtex": {"value": "@inproceedings{\npalma2024expressive,\ntitle={Expressive Losses for Verified Robustness via Convex Combinations},\nauthor={Alessandro De Palma and Rudy R Bunel and Krishnamurthy Dj Dvijotham and M. Pawan Kumar and Robert Stanforth and Alessio Lomuscio},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mzyZ4wzKlM}\n}"}, "paperhash": {"value": "palma|expressive_losses_for_verified_robustness_via_convex_combinations"}}, "number": 8030, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8030/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8030/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695494202456, "cdate": 1695494202456, "tmdate": 1710580675496, "mdate": 1710580675496, "pdate": 1705411028046, "version": 2}, {"id": "5RielfrDkP", "forum": "5RielfrDkP", "signatures": ["ICLR.cc/2024/Conference/Submission8015/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8015/Authors"], "content": {"title": {"value": "Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network"}, "authors": {"value": ["Tianze Luo", "Zhanfeng Mo", "Sinno Jialin Pan"]}, "authorids": {"value": ["~Tianze_Luo1", "~Zhanfeng_Mo1", "~Sinno_Jialin_Pan1"]}, "keywords": {"value": ["Graph neural networks", "graph multiresolution analysis"]}, "abstract": {"value": "Graph Neural Networks are popular tools in graph representation learning that capture the graph structural properties. However, most GNNs employ single-resolution graph feature extraction, thereby failing to capture micro-level local patterns (high resolution) and macro-level graph cluster and community patterns (low resolution) simultaneously. Many multiresolution methods have been developed to capture graph patterns at multiple scales, but most of them depend on predefined and handcrafted multiresolution transforms that remain fixed throughout the training process once formulated. Due to variations in graph instances and distributions, fixed handcrafted transforms can not effectively tailor multiresolution representations to each graph instance. To acquire multiresolution representation suited to different graph instances and distributions, we introduce the Multiresolution Meta-Framelet-based Graph Convolutional Network (MM-FGCN), facilitating comprehensive and adaptive multiresolution analysis across diverse graphs. Extensive experiments demonstrate that our MM-FGCN achieves SOTA performance on various graph learning tasks."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/78d38cf91a8f58ca68193e324a079c22002fffa8.pdf"}, "supplementary_material": {"value": "/attachment/69b2419b7e2027cca1feb8016c59f2e8caabceec.zip"}, "TLDR": {"value": "We propose the MM-FGCN, a novel framework designed to learn adaptive graph multiresolution transforms, resulting in the attainment of state-of-the-art performance in various graph representation learning tasks."}, "_bibtex": {"value": "@inproceedings{\nluo2024learning,\ntitle={Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network},\nauthor={Tianze Luo and Zhanfeng Mo and Sinno Jialin Pan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5RielfrDkP}\n}"}, "paperhash": {"value": "luo|learning_adaptive_multiresolution_transforms_via_metaframeletbased_graph_convolutional_network"}}, "number": 8015, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8015/-/Revision", "ICLR.cc/2024/Conference/Submission8015/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8015/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493914551, "cdate": 1695493914551, "tmdate": 1710323520866, "mdate": 1710323520866, "pdate": 1705411027327, "version": 2}, {"id": "fgKjiVrm6u", "forum": "fgKjiVrm6u", "signatures": ["ICLR.cc/2024/Conference/Submission8011/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8011/Authors"], "content": {"title": {"value": "REFACTOR: Learning to Extract Theorems from Proofs"}, "authors": {"value": ["Jin Peng Zhou", "Yuhuai Wu", "Qiyang Li", "Roger Baker Grosse"]}, "authorids": {"value": ["~Jin_Peng_Zhou1", "~Yuhuai_Wu1", "~Qiyang_Li1", "~Roger_Baker_Grosse1"]}, "keywords": {"value": ["theorem extraction", "mathematical reasoning", "theorem proving"]}, "TLDR": {"value": "We extract useful mathematical theorems using graph neural networks, evaluating on several downstream tasks to demonstrate their great utility."}, "abstract": {"value": "Human mathematicians are often good at recognizing modular and reusable theorems that make complex mathematical results within reach. In this paper, we propose a novel method called theoREm-from-prooF extrACTOR (REFACTOR) for training neural networks to mimic this ability in formal mathematical theorem proving. We show on a set of unseen proofs, REFACTOR is able to extract 19.6\\% of the theorems that humans would use to write the proofs. When applying the model to the existing Metamath library, REFACTOR extracted 16 new theorems. With newly extracted theorems, we show that the existing proofs in the MetaMath database can be refactored. The new theorems are used very frequently after refactoring, with an average usage of 733.5 times, and help shorten the proof lengths. Lastly, we demonstrate that the prover trained on the new-theorem refactored dataset proves more test theorems and outperforms state-of-the-art baselines by frequently leveraging a diverse set of newly extracted theorems. Code can be found at https://github.com/jinpz/refactor."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e4944ce26133003e30b0fe056311fca837baa9a1.pdf"}, "supplementary_material": {"value": "/attachment/2a597972e19fa9d3d81cb6d1928b074ed58235da.zip"}, "_bibtex": {"value": "@inproceedings{\nzhou2024refactor,\ntitle={{REFACTOR}: Learning to Extract Theorems from Proofs},\nauthor={Jin Peng Zhou and Yuhuai Wu and Qiyang Li and Roger Baker Grosse},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fgKjiVrm6u}\n}"}, "paperhash": {"value": "zhou|refactor_learning_to_extract_theorems_from_proofs"}}, "number": 8011, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8011/-/Revision", "ICLR.cc/2024/Conference/Submission8011/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8011/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493599730, "cdate": 1695493599730, "tmdate": 1710469046882, "mdate": 1710469046882, "pdate": 1705411026996, "version": 2}, {"id": "Fj7Fzm5lWL", "forum": "Fj7Fzm5lWL", "signatures": ["ICLR.cc/2024/Conference/Submission8007/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8007/Authors"], "content": {"title": {"value": "Let's do the time-warp-attend: Learning topological invariants of dynamical systems"}, "authors": {"value": ["Noa Moriel", "Matt Ricci", "Mor Nitzan"]}, "authorids": {"value": ["~Noa_Moriel1", "~Matt_Ricci1", "~Mor_Nitzan1"]}, "keywords": {"value": ["dynamical systems", "bifurcations", "topological invariance", "Hopf bifurcation", "physics-informed machine learning", "augmentation", "single-cell RNA-sequencing"]}, "abstract": {"value": "Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boundaries in unseen systems and to design models of biological systems like oscillatory gene regulatory networks. We further demonstrate our method's use in analyzing real data by recovering distinct proliferation and differentiation dynamics along pancreatic endocrinogenesis trajectory in gene expression space based on single-cell data. Our method provides valuable insights into the qualitative, long-term behavior of a wide range of dynamical systems, and can detect bifurcations or catastrophic transitions in large-scale physical and biological systems."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8dc9a0a901c8cc5a3348f7f9bb9b466a836c04e9.pdf"}, "_bibtex": {"value": "@inproceedings{\nmoriel2024lets,\ntitle={Let's do the time-warp-attend: Learning topological invariants of dynamical systems},\nauthor={Noa Moriel and Matt Ricci and Mor Nitzan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Fj7Fzm5lWL}\n}"}, "paperhash": {"value": "moriel|lets_do_the_timewarpattend_learning_topological_invariants_of_dynamical_systems"}}, "number": 8007, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8007/-/Revision", "ICLR.cc/2024/Conference/Submission8007/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8007/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493533854, "cdate": 1695493533854, "tmdate": 1710393725643, "mdate": 1710393725643, "pdate": 1705411026771, "version": 2}, {"id": "ySS7hH1smL", "forum": "ySS7hH1smL", "signatures": ["ICLR.cc/2024/Conference/Submission8004/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8004/Authors"], "content": {"title": {"value": "Sparse MoE with Language Guided Routing for Multilingual Machine Translation"}, "authors": {"value": ["Xinyu Zhao", "Xuxi Chen", "Yu Cheng", "Tianlong Chen"]}, "authorids": {"value": ["~Xinyu_Zhao3", "~Xuxi_Chen1", "~Yu_Cheng1", "~Tianlong_Chen1"]}, "keywords": {"value": ["Sparse Mixture-of-Experts", "Multilingual Machine Translation", "Language Guided Routing"]}, "abstract": {"value": "Sparse Mixture-of-Experts (SMoE) has gained increasing popularity as a promising framework for scaling up multilingual machine translation (MMT) models with negligible extra computational overheads. However, current SMoE solutions neglect the intrinsic structures of the MMT problem: ($a$) $\\textit{Linguistics Hierarchy.}$ Languages are naturally grouped according to their lingual properties like genetic families, phonological characteristics, etc; ($b$) $\\textit{Language Complexity.}$ The learning difficulties are varied for diverse languages due to their grammar complexity, available resources, etc. Therefore, routing a fixed number of experts (e.g., $1$ or $2$ experts in usual) only at the word level leads to inferior performance. To fill in the missing puzzle, we propose $\\textbf{\\texttt{Lingual-SMoE}}$ by equipping the SMoE with adaptive and linguistic-guided routing policies. Specifically, it ($1$) extracts language representations to incorporate linguistic knowledge and uses them to allocate experts into different groups; ($2$) determines the number of activated experts for each target language in an adaptive and automatic manner, according to their translation difficulties, which aims to mitigate the potential over-/under-fitting issues of learning simple/challenges translations. Sufficient experimental studies on MMT benchmarks with {$16$, $50$, $100$} language pairs and various network architectures, consistently validate the superior performance of our proposals. For instance, $\\texttt{Lingual-SMoE}$ outperforms its dense counterpart by over $5\\%$ BLEU scores on $\\texttt{OPUS-100}$ dataset."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We power up SMoE with language-guided rounting based on language hierarchy and difficulty, leading to superior machine translation performance."}, "pdf": {"value": "/pdf/2f14a8bdcce65ee1907499fef8fcdf05b7ce4f91.pdf"}, "supplementary_material": {"value": "/attachment/6d2d920fd5b7dffab96f43149620a57b945b95a8.zip"}, "_bibtex": {"value": "@inproceedings{\nzhao2024sparse,\ntitle={Sparse MoE with Language Guided Routing for Multilingual Machine Translation},\nauthor={Xinyu Zhao and Xuxi Chen and Yu Cheng and Tianlong Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ySS7hH1smL}\n}"}, "paperhash": {"value": "zhao|sparse_moe_with_language_guided_routing_for_multilingual_machine_translation"}}, "number": 8004, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8004/-/Revision", "ICLR.cc/2024/Conference/Submission8004/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8004/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493340499, "cdate": 1695493340499, "tmdate": 1713082091101, "mdate": 1713082091101, "pdate": 1705411026602, "version": 2}, {"id": "zWqr3MQuNs", "forum": "zWqr3MQuNs", "signatures": ["ICLR.cc/2024/Conference/Submission8002/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8002/Authors"], "content": {"title": {"value": "Detecting Pretraining Data from Large Language Models"}, "authors": {"value": ["Weijia Shi", "Anirudh Ajith", "Mengzhou Xia", "Yangsibo Huang", "Daogao Liu", "Terra Blevins", "Danqi Chen", "Luke Zettlemoyer"]}, "authorids": {"value": ["~Weijia_Shi1", "~Anirudh_Ajith1", "~Mengzhou_Xia1", "~Yangsibo_Huang2", "~Daogao_Liu1", "~Terra_Blevins1", "~Danqi_Chen1", "~Luke_Zettlemoyer1"]}, "keywords": {"value": ["Large language models", "detecting pretraining data"]}, "abstract": {"value": "Although large language models (LLMs) are widely deployed, the data used to train them is rarely disclosed. Given the incredible scale of this data, up to trillions of tokens, it is all but certain that it includes potentially problematic text such as copyrighted materials, personally identifiable information, and test data for widely reported reference benchmarks. However, we currently have no way to know which data of these types is included or in what proportions. In this paper, we study the pretraining data detection problem: given a piece of text and black-box access to an LLM without knowing the pretraining data, can we determine if the model was trained on the provided text? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that uses data created before and after model training to support gold truth detection. We also introduce a new detection method MIN-K PROB based on a simple hypothesis: an unseen example is likely to contain a few outlier words with low probabilities under the LLM, while a seen example is less likely to have words with such low probabilities. MIN-K PROB can be applied without any knowledge about the pretrainig corpus or any additional training, departing from previous detection methods that require training a reference model on data that is similar to the pretraining data. Moreover, our experiments demonstrate that MIN-K PROB achieves a 7.4% improvement on WIKIMIA over these previous methods. We apply MIN-K PROB to two real-world scenarios, copyrighted book detection and contaminated downstream example detection, and find that it to be a consistently effective solution."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0d224da3c14b884532028169f92fd03868dcd86e.pdf"}, "_bibtex": {"value": "@inproceedings{\nshi2024detecting,\ntitle={Detecting Pretraining Data from Large Language Models},\nauthor={Weijia Shi and Anirudh Ajith and Mengzhou Xia and Yangsibo Huang and Daogao Liu and Terra Blevins and Danqi Chen and Luke Zettlemoyer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zWqr3MQuNs}\n}"}, "paperhash": {"value": "shi|detecting_pretraining_data_from_large_language_models"}}, "number": 8002, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8002/-/Revision", "ICLR.cc/2024/Conference/Submission8002/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8002/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493332007, "cdate": 1695493332007, "tmdate": 1710474796746, "mdate": 1710474796746, "pdate": 1705411026406, "version": 2}, {"id": "V5tdi14ple", "forum": "V5tdi14ple", "signatures": ["ICLR.cc/2024/Conference/Submission8001/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8001/Authors"], "content": {"title": {"value": "Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization"}, "authors": {"value": ["Jin Peng Zhou", "Charles E Staats", "Wenda Li", "Christian Szegedy", "Kilian Q Weinberger", "Yuhuai Wu"]}, "authorids": {"value": ["~Jin_Peng_Zhou1", "~Charles_E_Staats1", "~Wenda_Li1", "~Christian_Szegedy1", "~Kilian_Q_Weinberger1", "~Yuhuai_Wu1"]}, "keywords": {"value": ["mathematical reasoning", "autoformalization", "automated theorem proving", "quantitative reasoning"]}, "TLDR": {"value": "We show that automatically formalizing and verifying LLM generated quantitative reasoning solutions consistently outperforms vanilla majority voting."}, "abstract": {"value": "Large language models (LLM), such as Google's Minerva and OpenAI's GPT families, are becoming increasingly capable of solving mathematical quantitative reasoning problems. However, they still make unjustified logical and computational errors in their reasoning steps and answers. In this paper, we leverage the fact that if the training corpus of LLMs contained sufficiently many examples of formal mathematics (e.g. in Isabelle, a formal theorem proving environment), they can be prompted to translate i.e. autoformalize informal mathematical statements into formal Isabelle code --- which can be verified automatically for internal consistency. This provides a mechanism to automatically reject solutions whose formalized versions are inconsistent within themselves or with the formalized problem statement. We evaluate our method on GSM8K, MATH and MultiArith datasets and demonstrate that our approach provides a consistently better heuristic than vanilla majority voting --- the previously best method to identify correct answers, by more than 12\\% on GSM8K. In our experiments it improves results consistently across all datasets and LLM model sizes. The code can be found at https://github.com/jinpz/dtv."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f2feee3c9af794ca03a85d1ab69dd06c8330981e.pdf"}, "supplementary_material": {"value": "/attachment/07d65845b587ea195c96872b0bbc30fef43edeac.zip"}, "_bibtex": {"value": "@inproceedings{\nzhou2024dont,\ntitle={Don't Trust: Verify -- Grounding {LLM} Quantitative Reasoning with Autoformalization},\nauthor={Jin Peng Zhou and Charles E Staats and Wenda Li and Christian Szegedy and Kilian Q Weinberger and Yuhuai Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=V5tdi14ple}\n}"}, "paperhash": {"value": "zhou|dont_trust_verify_grounding_llm_quantitative_reasoning_with_autoformalization"}}, "number": 8001, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8001/-/Revision", "ICLR.cc/2024/Conference/Submission8001/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8001/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493299993, "cdate": 1695493299993, "tmdate": 1710468538276, "mdate": 1710468538276, "pdate": 1705411026318, "version": 2}, {"id": "Tvwf4Vsi5F", "forum": "Tvwf4Vsi5F", "signatures": ["ICLR.cc/2024/Conference/Submission7997/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7997/Authors"], "content": {"title": {"value": "PubDef: Defending Against Transfer Attacks From Public Models"}, "authors": {"value": ["Chawin Sitawarin", "Jaewon Chang", "David Huang", "Wesson Altoyan", "David Wagner"]}, "authorids": {"value": ["~Chawin_Sitawarin1", "changjaewon0315@berkeley.edu", "huang33176@berkeley.edu", "~Wesson_Altoyan1", "~David_Wagner3"]}, "keywords": {"value": ["adversarial robustness", "adversarial examples", "transfer attack", "security"]}, "abstract": {"value": "Adversarial attacks have been a looming and unaddressed threat in the industry. However, through a decade-long history of the robustness evaluation literature, we have learned that mounting a strong or optimal attack is challenging. It requires both machine learning and domain expertise. In other words, the white-box threat model, religiously assumed by a large majority of the past literature, is unrealistic. In this paper, we propose a new practical threat model where the adversary relies on transfer attacks through publicly available surrogate models. We argue that this setting will become the most prevalent for security-sensitive applications in the future. We evaluate the transfer attacks in this setting and propose a specialized defense method based on a game-theoretic perspective. The defenses are evaluated under 24 public models and 11 attack algorithms across three datasets (CIFAR-10, CIFAR-100, and ImageNet). Under this threat model, our defense, PubDef, outperforms the state-of-the-art white-box adversarial training by a large margin with almost no loss in the normal accuracy. For instance, on ImageNet, our defense achieves 62% accuracy under the strongest transfer attack vs only 36% of the best adversarially trained model. Its accuracy when not under attack is only 2% lower than that of an undefended model (78% vs 80%). We release our code at https://github.com/wagner-group/pubdef."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1c48a415047176b3fbdb5c594a119648fea8e3d8.pdf"}, "supplementary_material": {"value": "/attachment/74cb37ecb33d459096a4a041d9e0b1b77f150d51.zip"}, "TLDR": {"value": "We propose a new practical threat model, transfer attacks from public models (TAPM), and build a defense that provides higher robustness than adversarial training with almost no drop in the clean accuracy compared to undefended models."}, "_bibtex": {"value": "@inproceedings{\nsitawarin2024defending,\ntitle={Defending Against Transfer Attacks From Public Models},\nauthor={Chawin Sitawarin and Jaewon Chang and David Huang and Wesson Altoyan and David Wagner},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tvwf4Vsi5F}\n}"}, "paperhash": {"value": "sitawarin|pubdef_defending_against_transfer_attacks_from_public_models"}}, "number": 7997, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7997/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7997/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695493256947, "cdate": 1695493256947, "tmdate": 1710650381215, "mdate": 1710650381215, "pdate": 1705411026251, "version": 2}, {"id": "v3K5TVP8kZ", "forum": "v3K5TVP8kZ", "signatures": ["ICLR.cc/2024/Conference/Submission7987/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7987/Authors"], "content": {"title": {"value": "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"}, "authors": {"value": ["Jonas Belouadi", "Anne Lauscher", "Steffen Eger"]}, "authorids": {"value": ["~Jonas_Belouadi1", "~Anne_Lauscher1", "~Steffen_Eger1"]}, "keywords": {"value": ["Vector Graphics Generation", "Code Generation", "Science Generation", "TikZ", "Text-to-Image"]}, "TLDR": {"value": "We train large language models on TikZ code, conditioned on captions, to automatically generate scientific vector graphics."}, "abstract": {"value": "Generating bitmap graphics from text has gained considerable attention, yet for scientific figures, vector graphics are often preferred. Given that vector graphics are typically encoded using low-level graphics primitives, generating them directly is difficult. To address this, we propose the use of TikZ, a well-known abstract graphics language that can be compiled to vector graphics, as an intermediate representation of scientific figures. TikZ offers human-oriented, high-level commands, thereby facilitating conditional language modeling with any large language model. To this end, we introduce DaTikZ the first large-scale TikZ dataset, consisting of 120k TikZ drawings aligned with captions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, which augments LLaMA with multimodal CLIP embeddings. In both human and automatic evaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in terms of similarity to human-created figures, with CLiMA additionally improving text-image alignment. Our detailed analysis shows that all models generalize well and are not susceptible to memorization. GPT-4 and Claude 2, however, tend to generate more simplistic figures compared to both humans and our models. We make our framework, AutomaTikZ, along with model weights and datasets, publicly available."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/eb9ccf8fa1a97129a5a38ac09ddf4f1257daa864.pdf"}, "supplementary_material": {"value": "/attachment/8cc68b43add54f87433a0c539a594a545b6b9782.zip"}, "_bibtex": {"value": "@inproceedings{\nbelouadi2024automatikz,\ntitle={AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ},\nauthor={Jonas Belouadi and Anne Lauscher and Steffen Eger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=v3K5TVP8kZ}\n}"}, "paperhash": {"value": "belouadi|automatikz_textguided_synthesis_of_scientific_vector_graphics_with_tikz"}}, "number": 7987, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7987/-/Revision", "ICLR.cc/2024/Conference/Submission7987/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7987/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492955383, "cdate": 1695492955383, "tmdate": 1710501687091, "mdate": 1710501687091, "pdate": 1705411025834, "version": 2}, {"id": "3xDaj4pRna", "forum": "3xDaj4pRna", "signatures": ["ICLR.cc/2024/Conference/Submission7986/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7986/Authors"], "content": {"title": {"value": "Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning"}, "authors": {"value": ["Jacob Mitchell Springer", "Vaishnavh Nagarajan", "Aditi Raghunathan"]}, "authorids": {"value": ["~Jacob_Mitchell_Springer1", "~Vaishnavh_Nagarajan3", "~Aditi_Raghunathan1"]}, "keywords": {"value": ["sharpness-aware minimization", "representation learning", "spurious correlations"]}, "abstract": {"value": "Sharpness-Aware Minimization (SAM) has emerged as a promising alternative to stochastic gradient descent (SGD) as an optimizer for neural networks. The originally-proposed motivation behind SAM was to bias models towards flatter minima that are believed to generalize better. However, recent studies have shown conflicting evidence on the relationship between flatness and generalization, suggesting that flatness does fully explain SAM's success. Sidestepping this debate, we identify an orthogonal effect of SAM that is beneficial out-of-distribution: we argue that SAM implicitly balances features. At a high level, we demonstrate that SAM improves the quality of features by adaptively suppressing well-learned features which gives remaining features opportunity to be learned. We show that this mechanism is beneficial in datasets that contain redundant or spurious features where SGD falls for the simplicity bias and would not otherwise learn all available features. Our insights are supported by experiments on real data: we demonstrate that SAM improves the quality of features in datasets containing redundant or spurious features, including CelebA, Waterbirds, CIFAR-MNIST, and DomainBed."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cf303620bba687ddcab9ada6bc54c77470e7427a.pdf"}, "_bibtex": {"value": "@inproceedings{\nspringer2024sharpnessaware,\ntitle={Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning},\nauthor={Jacob Mitchell Springer and Vaishnavh Nagarajan and Aditi Raghunathan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3xDaj4pRna}\n}"}, "paperhash": {"value": "springer|sharpnessaware_minimization_enhances_feature_quality_via_balanced_learning"}}, "number": 7986, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7986/-/Revision", "ICLR.cc/2024/Conference/Submission7986/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7986/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492783951, "cdate": 1695492783951, "tmdate": 1713135273617, "mdate": 1713135273617, "pdate": 1705411025793, "version": 2}, {"id": "ccxD4mtkTU", "forum": "ccxD4mtkTU", "signatures": ["ICLR.cc/2024/Conference/Submission7983/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7983/Authors"], "content": {"title": {"value": "Can LLM-Generated Misinformation Be Detected?"}, "authors": {"value": ["Canyu Chen", "Kai Shu"]}, "authorids": {"value": ["~Canyu_Chen1", "~Kai_Shu1"]}, "keywords": {"value": ["Large Language Models", "misinformation"]}, "TLDR": {"value": "We discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm."}, "abstract": {"value": "The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery on combating misinformation in the age of LLMs and the countermeasures."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/11673bbb0599a3ceabd2ce8909267f797e217f62.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024can,\ntitle={Can {LLM}-Generated Misinformation Be Detected?},\nauthor={Canyu Chen and Kai Shu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ccxD4mtkTU}\n}"}, "paperhash": {"value": "chen|can_llmgenerated_misinformation_be_detected"}}, "number": 7983, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7983/-/Revision", "ICLR.cc/2024/Conference/Submission7983/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7983/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492699508, "cdate": 1695492699508, "tmdate": 1713149561657, "mdate": 1713149561657, "pdate": 1705411025630, "version": 2}, {"id": "bkdWThqE6q", "forum": "bkdWThqE6q", "signatures": ["ICLR.cc/2024/Conference/Submission7979/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7979/Authors"], "content": {"title": {"value": "A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"}, "authors": {"value": ["DIPANJYOTI PAUL", "Arpita Chowdhury", "Xinqi Xiong", "Feng-Ju Chang", "David Edward Carlyn", "Samuel Stevens", "Kaiya L Provost", "Anuj Karpatne", "Bryan Carstens", "Daniel Rubenstein", "Charles Stewart", "Tanya Berger-Wolf", "Yu Su", "Wei-Lun Chao"]}, "authorids": {"value": ["~DIPANJYOTI_PAUL2", "~Arpita_Chowdhury1", "~Xinqi_Xiong1", "~Feng-Ju_Chang4", "~David_Edward_Carlyn1", "~Samuel_Stevens1", "~Kaiya_L_Provost1", "~Anuj_Karpatne1", "~Bryan_Carstens1", "~Daniel_Rubenstein1", "~Charles_Stewart1", "~Tanya_Berger-Wolf2", "~Yu_Su2", "~Wei-Lun_Chao1"]}, "keywords": {"value": ["Explainability", "Interpretability", "Transformer", "Fine-grained recognition", "Attribute discovery"]}, "TLDR": {"value": "Transformer based Interpretable Image recognition where each query in the decoder will learn class specific features."}, "abstract": {"value": "We present a novel usage of Transformers to make image classification interpretable. Unlike mainstream classifiers that wait until the last fully connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image. We realize this idea via a Transformer encoder-decoder inspired by DEtection TRansformer (DETR). We learn ''class-specific'' queries (one for each class) as input to the decoder, enabling each class to localize its patterns in an image via cross-attention. We name our approach INterpretable TRansformer (INTR), which is fairly easy to implement and exhibits several compelling properties. We show that INTR intrinsically encourages each class to attend distinctively; the cross-attention weights thus provide a faithful interpretation of the prediction. Interestingly, via ''multi-head'' cross-attention, INTR could identify different ''attributes'' of a class, making it particularly suitable for fine-grained classification and analysis, which we demonstrate on eight datasets. Our code and pre-trained models are publicly accessible at the Imageomics Institute GitHub site: https://github.com/Imageomics/INTR."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e21cb9d249269cc5614d57ddd6d9742e2a3a5d2a.pdf"}, "_bibtex": {"value": "@inproceedings{\npaul2024a,\ntitle={A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis},\nauthor={DIPANJYOTI PAUL and Arpita Chowdhury and Xinqi Xiong and Feng-Ju Chang and David Edward Carlyn and Samuel Stevens and Kaiya L Provost and Anuj Karpatne and Bryan Carstens and Daniel Rubenstein and Charles Stewart and Tanya Berger-Wolf and Yu Su and Wei-Lun Chao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bkdWThqE6q}\n}"}, "paperhash": {"value": "paul|a_simple_interpretable_transformer_for_finegrained_image_classification_and_analysis"}}, "number": 7979, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7979/-/Revision", "ICLR.cc/2024/Conference/Submission7979/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7979/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492636310, "cdate": 1695492636310, "tmdate": 1713169462840, "mdate": 1713169462840, "pdate": 1705411025523, "version": 2}, {"id": "EDXkkUAIFW", "forum": "EDXkkUAIFW", "signatures": ["ICLR.cc/2024/Conference/Submission7970/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7970/Authors"], "content": {"title": {"value": "One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models"}, "authors": {"value": ["Sheng-Jun Huang", "Yi Li", "Yiming Sun", "Ying-Peng Tang"]}, "authorids": {"value": ["~Sheng-Jun_Huang1", "~Yi_Li8", "~Yiming_Sun2", "~Ying-Peng_Tang1"]}, "keywords": {"value": ["active learning", "Lewis weight sampling", "machine learning", "deep learning"]}, "abstract": {"value": "Active learning (AL) for multiple target models aims to reduce labeled data querying while effectively training multiple models concurrently. Existing AL algorithms often rely on iterative model training, which can be computationally expensive, particularly for deep models. In this paper, we propose a one-shot AL method to address this challenge, which performs all label queries without repeated model training. Specifically, we extract different representations of the same dataset using distinct network backbones, and actively learn the linear prediction layer on each representation via an $\\ell_p$-regression formulation. The regression problems are solved approximately by \nsampling and reweighting the unlabeled instances based on their maximum Lewis weights across the representations. An upper bound on the number of samples needed is provided with a rigorous analysis for $p\\in [1, +\\infty)$. Experimental results on 11 benchmarks show that our one-shot approach achieves competitive performances with the state-of-the-art AL methods for multiple target models."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/151a8c3cbd0951af8b2abf96dd2fee8beaee4ae7.pdf"}, "supplementary_material": {"value": "/attachment/8eb4cbc751fb593c976f0278660ef5021b7257f6.zip"}, "_bibtex": {"value": "@inproceedings{\nhuang2024oneshot,\ntitle={One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models},\nauthor={Sheng-Jun Huang and Yi Li and Yiming Sun and Ying-Peng Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EDXkkUAIFW}\n}"}, "paperhash": {"value": "huang|oneshot_active_learning_based_on_lewis_weight_sampling_for_multiple_deep_models"}}, "number": 7970, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7970/-/Revision", "ICLR.cc/2024/Conference/Submission7970/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7970/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492362635, "cdate": 1695492362635, "tmdate": 1710656081968, "mdate": 1710656081968, "pdate": 1705411025145, "version": 2}, {"id": "iI7hZSczxE", "forum": "iI7hZSczxE", "signatures": ["ICLR.cc/2024/Conference/Submission7969/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7969/Authors"], "content": {"title": {"value": "Disentangling Time Series Representations via Contrastive Independence-of-Support on l-Variational Inference"}, "authors": {"value": ["Khalid Oublal", "Said Ladjal", "David Benhaiem", "Emmanuel LE BORGNE", "Fran\u00e7ois Roueff"]}, "authorids": {"value": ["~Khalid_Oublal2", "~Said_Ladjal1", "~David_Benhaiem1", "~Emmanuel_LE_BORGNE1", "~Fran\u00e7ois_Roueff1"]}, "keywords": {"value": ["Learning disentangled representations", "Generalization", "Weak supervised learning", "Appliance usage Electricity", "Multi-modal learning"]}, "TLDR": {"value": "Disentanglement under Independence-of-Support via Contrastive Learning based $l$-Variational Inference for appliance usage electricity, addressing realistic correlations during training to capture real-world complexity."}, "abstract": {"value": "Learning disentangled representations for Time Series is a promising path to facilitate reliable generalization to in- and out-of distribution, offering benefits like feature derivation and improved interpretability and fairness, thereby enhancing downstream tasks. We focus on disentangled representation learning for home appliance electricity usage, enabling users to understand and optimize their consumption for a reduced carbon footprint. Our approach frames the problem as disentangling each attribute\u2019s role in total consumption. Unlike existing methods assuming attribute independence which leads to non-identiability, we acknowledge real-world time series attribute correlations, learned up to a smooth bijection using contrastive learning and a single encoder. To address this, we propose a Disentanglement under Independence-of-Support via Contrastive Learning, facilitating representation generalization across diverse correlated scenarios. Our method utilizes innovative l-variational inference layers with self-attention, effectively addressing temporal dependencies across bottom-up and top-down networks. We find that DIOSC can enhance the task of representation of time series electricity consumption. We introduce TDS (Time Disentangling Score) to gauge disentanglement quality. TDS reliably reflects disentanglement performance, making it a valuable metric for evaluating time series representations disentanglement. Code available at https://github.com/time-disentanglement-lib."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3f950ba9c79f48669b2613d1286b36f327b0d100.pdf"}, "supplementary_material": {"value": "/attachment/35a7779db63a7740e36972d28180f7b28bf9f021.pdf"}, "_bibtex": {"value": "@inproceedings{\noublal2024disentangling,\ntitle={Disentangling Time Series Representations via Contrastive based \\$l\\$-Variational Inference},\nauthor={Khalid Oublal and Said Ladjal and David Benhaiem and Emmanuel LE BORGNE and Fran{\\c{c}}ois Roueff},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iI7hZSczxE}\n}"}, "paperhash": {"value": "oublal|disentangling_time_series_representations_via_contrastive_independenceofsupport_on_lvariational_inference"}}, "number": 7969, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7969/-/Revision", "ICLR.cc/2024/Conference/Submission7969/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7969/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492194239, "cdate": 1695492194239, "tmdate": 1712504729150, "mdate": 1712504729150, "pdate": 1705411025143, "version": 2}, {"id": "GlpawHh80l", "forum": "GlpawHh80l", "signatures": ["ICLR.cc/2024/Conference/Submission7965/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7965/Authors"], "content": {"title": {"value": "Improved algorithm and bounds for successive projection"}, "authors": {"value": ["Jiashun Jin", "Tracy Ke", "Gabriel Moryoussef", "Jiajun Tang", "Jingming Wang"]}, "authorids": {"value": ["~Jiashun_Jin1", "~Tracy_Ke1", "~Gabriel_Moryoussef1", "jiajuntang@fas.harvard.edu", "jingmingwang@fas.harvard.edu"]}, "keywords": {"value": ["Simplex", "vertex hunting", "successive projection", "pseudo-points", "pruning", "hyper-spectral unmixing", "archetypal analysis", "network analysis."]}, "TLDR": {"value": "A new approach to estimating the vertices of a simplex"}, "abstract": {"value": "Consider a $K$-vertex simplex in a $d$-dimensional  space. We measure $n$ points on the simplex, but due to the measurement noise, \nsome of the observed points fall outside the simplex. The interest is vertex hunting (i.e.,  estimating the vertices of the simplex).  The successive projection algorithm (SPA)  is one of the most popular approaches to vertex hunting, but it is vulnerable to noise and outliers, and may perform unsatisfactorily.  We propose pseudo-point SPA  (pp-SPA) as a new approach to vertex hunting. The approach contains \ntwo novel ideas (a projection step and a denoise step) and generates roughly $n$ pseudo-points, which can be fed in to SPA for vertex hunting. For theory, we first derive an improved non-asymptotic bound for the orthodox SPA, and then use the result to derive the bounds for pp-SPA.  Compared with the orthodox SPA,  pp-SPA has a faster rate and more satisfactory numerical performance in a broad setting.  The analysis is quite delicate: the non-asymptotic bound is hard to derive, and we need precise results on the extreme values of (possibly) high-dimensional random vectors."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7ebdcea695b8aa3a70d605879db5781a831c5f96.pdf"}, "supplementary_material": {"value": "/attachment/96e83130c61651e54037f34cc3b6e56103e42f30.pdf"}, "_bibtex": {"value": "@inproceedings{\njin2024improved,\ntitle={Improved algorithm and bounds for successive projection},\nauthor={Jiashun Jin and Tracy Ke and Gabriel Moryoussef and Jiajun Tang and Jingming Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GlpawHh80l}\n}"}, "paperhash": {"value": "jin|improved_algorithm_and_bounds_for_successive_projection"}}, "number": 7965, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7965/-/Revision", "ICLR.cc/2024/Conference/Submission7965/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7965/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492140932, "cdate": 1695492140932, "tmdate": 1710621339808, "mdate": 1710621339808, "pdate": 1705411025037, "version": 2}, {"id": "0tWTxYYPnW", "forum": "0tWTxYYPnW", "signatures": ["ICLR.cc/2024/Conference/Submission7959/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7959/Authors"], "content": {"title": {"value": "Understanding Hidden Context in Preference Learning: Consequences for RLHF"}, "authors": {"value": ["Anand Siththaranjan", "Cassidy Laidlaw", "Dylan Hadfield-Menell"]}, "authorids": {"value": ["~Anand_Siththaranjan1", "~Cassidy_Laidlaw1", "~Dylan_Hadfield-Menell2"]}, "keywords": {"value": ["Preference Learning", "Reinforcement Learning from Human Feedback", "Social Choice Theory"]}, "abstract": {"value": "In practice, preference learning from human feedback depends on incomplete data with hidden context. Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model. This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria. We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called *Borda count*. We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility. Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function. A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF. As a step towards mitigating these problems, we introduce a class of methods called *distributional preference learning* (DPL). DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context. Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We show that missing context in standard preference learning for methods such as RLHF is aggregated according to the Borda count voting rule and introduce distributional preference learning to mitigate the associated challenges."}, "pdf": {"value": "/pdf/a114fcc8d31e1e15f2e05527812d230356cbabc8.pdf"}, "_bibtex": {"value": "@inproceedings{\nsiththaranjan2024understanding,\ntitle={Understanding Hidden Context in Preference Learning: Consequences for {RLHF}},\nauthor={Anand Siththaranjan and Cassidy Laidlaw and Dylan Hadfield-Menell},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0tWTxYYPnW}\n}"}, "paperhash": {"value": "siththaranjan|understanding_hidden_context_in_preference_learning_consequences_for_rlhf"}}, "number": 7959, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7959/-/Revision", "ICLR.cc/2024/Conference/Submission7959/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7959/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695491922409, "cdate": 1695491922409, "tmdate": 1713156194671, "mdate": 1713156194671, "pdate": 1705411024721, "version": 2}, {"id": "kvByNnMERu", "forum": "kvByNnMERu", "signatures": ["ICLR.cc/2024/Conference/Submission7957/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7957/Authors"], "content": {"title": {"value": "Estimating Shape Distances on Neural Representations with Limited Samples"}, "authors": {"value": ["Dean A Pospisil", "Brett W. Larsen", "Sarah E Harvey", "Alex H Williams"]}, "authorids": {"value": ["~Dean_A_Pospisil1", "~Brett_W._Larsen1", "~Sarah_E_Harvey1", "~Alex_H_Williams1"]}, "keywords": {"value": ["representational geometry", "shape metrics", "dissimilarity metrics"]}, "abstract": {"value": "Measuring geometric similarity between high-dimensional network representations is a topic of longstanding interest to neuroscience and deep learning. Although many methods have been proposed, only a few works have rigorously analyzed their statistical efficiency or quantified estimator uncertainty in data-limited regimes. Here, we derive upper and lower bounds on the worst-case convergence\nof standard estimators of shape distance\u2014a measure of representational dissimilarity proposed by Williams et al. (2021). These bounds reveal the challenging nature of the problem in high-dimensional feature spaces. To overcome these challenges, we introduce a novel method-of-moments estimator with a tunable bias-variance tradeoff parameterized by an upper bound on bias. We show that this estimator achieves superior performance to standard estimators in simulation and on neural data, particularly in high-dimensional settings. Our theoretical work and estimator thus respectively define and dramatically expand the scope of neural data for which geometric similarity can be accurately measured."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "Novel estimator of geometric similarity with tunable bias-variance tradeoff, outperforms standard estimators in high-dimensional settings."}, "pdf": {"value": "/pdf/cc1e959c8a6eec0004bd40509131279fa05e6610.pdf"}, "_bibtex": {"value": "@inproceedings{\npospisil2024estimating,\ntitle={Estimating Shape Distances on Neural Representations with Limited Samples},\nauthor={Dean A Pospisil and Brett W. Larsen and Sarah E Harvey and Alex H Williams},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kvByNnMERu}\n}"}, "paperhash": {"value": "pospisil|estimating_shape_distances_on_neural_representations_with_limited_samples"}}, "number": 7957, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7957/-/Revision", "ICLR.cc/2024/Conference/Submission7957/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7957/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695491790845, "cdate": 1695491790845, "tmdate": 1710553053718, "mdate": 1710553053718, "pdate": 1705411024670, "version": 2}, {"id": "ZMv6zKYYUs", "forum": "ZMv6zKYYUs", "signatures": ["ICLR.cc/2024/Conference/Submission7952/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7952/Authors"], "content": {"title": {"value": "Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation."}, "authors": {"value": ["Ashutosh Singh", "Ricardo Augusto Borsoi", "Deniz Erdogmus", "Tales Imbiriba"]}, "authorids": {"value": ["~Ashutosh_Singh2", "~Ricardo_Augusto_Borsoi1", "~Deniz_Erdogmus1", "~Tales_Imbiriba1"]}, "keywords": {"value": ["Neural operator", "PDEs", "semi-linear evolution", "sequential learning", "filtering", "data assimilation"]}, "TLDR": {"value": "We propose a flexible recursive neural operator approach for prediction and data assimilation with semilinear PDEs."}, "abstract": {"value": "Recent advances in the theory of Neural Operators (NOs) have enabled fast and accurate computation of the solutions to complex systems described by partial differential equations (PDEs). Despite their great success, current NO-based solutions face important challenges when dealing with spatio-temporal PDEs over long time scales. Specifically, the current theory of NOs does not present a systematic framework to perform data assimilation and efficiently correct the evolution of PDE solutions over time based on sparsely sampled noisy measurements. In this paper, we propose a learning-based state-space approach to compute the solution operators to infinite-dimensional semilinear PDEs. Exploiting the structure of semilinear PDEs and the theory of nonlinear observers in function spaces, we develop a flexible recursive method that allows for both prediction and data assimilation by combining prediction and correction operations. The proposed framework is capable of producing fast and accurate predictions over long time horizons, dealing with irregularly sampled noisy measurements to correct the solution, and benefits from the decoupling between the spatial and temporal dynamics of this class of PDEs. We show through experiments on the Kuramoto-Sivashinsky, Navier-Stokes and Korteweg-de Vries equations that the proposed model is robust to noise and can leverage arbitrary amounts of measurements to correct its prediction over a long time horizon with little computational overhead."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1560d1f0bd3603f9f3ab40125342ea9969adfe14.pdf"}, "_bibtex": {"value": "@inproceedings{\nsingh2024learning,\ntitle={Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation.},\nauthor={Ashutosh Singh and Ricardo Augusto Borsoi and Deniz Erdogmus and Tales Imbiriba},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZMv6zKYYUs}\n}"}, "paperhash": {"value": "singh|learning_semilinear_neural_operators_a_unified_recursive_framework_for_prediction_and_data_assimilation"}}, "number": 7952, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7952/-/Revision", "ICLR.cc/2024/Conference/Submission7952/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7952/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695491631693, "cdate": 1695491631693, "tmdate": 1710487251882, "mdate": 1710487251882, "pdate": 1705411024490, "version": 2}, {"id": "IEduRUO55F", "forum": "IEduRUO55F", "signatures": ["ICLR.cc/2024/Conference/Submission7937/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7937/Authors"], "content": {"title": {"value": "Eureka: Human-Level Reward Design via Coding Large Language Models"}, "authors": {"value": ["Yecheng Jason Ma", "William Liang", "Guanzhi Wang", "De-An Huang", "Osbert Bastani", "Dinesh Jayaraman", "Yuke Zhu", "Linxi Fan", "Anima Anandkumar"]}, "authorids": {"value": ["~Yecheng_Jason_Ma2", "~William_Liang1", "~Guanzhi_Wang1", "~De-An_Huang1", "~Osbert_Bastani1", "~Dinesh_Jayaraman2", "~Yuke_Zhu1", "~Linxi_Fan2", "~Anima_Anandkumar1"]}, "keywords": {"value": ["Large Language Models", "Reinforcement Learning", "Dexterous Manipulation", "Reward Learning", "Robotics"]}, "abstract": {"value": "Large Language Models (LLMs) have excelled as high-level semantic planners for sequential decision-making tasks. However, harnessing them to learn complex low-level manipulation tasks, such as dexterous pen spinning, remains an open problem. We bridge this fundamental gap and present Eureka, a human-level reward design algorithm powered by LLMs. Eureka exploits the remarkable zero-shot generation, code-writing, and in-context improvement capabilities of state-of-the-art LLMs, such as GPT-4, to perform evolutionary optimization over reward code. The resulting rewards can then be used to acquire complex skills via reinforcement learning. Without any task-specific prompting or pre-defined reward templates, Eureka generates reward functions that outperform expert human-engineered rewards. In a diverse suite of 29 open-source RL environments that include 10 distinct robot morphologies, Eureka outperforms human experts on 83% of the tasks, leading to an average normalized improvement of 52%. The generality of Eureka also enables a new gradient-free in-context learning approach to reinforcement learning from human feedback (RLHF), readily incorporating human inputs to improve the quality and the safety of the generated rewards without model updating. Finally, using Eureka rewards in a curriculum learning setting, we demonstrate for the first time, a simulated Shadow Hand capable of performing pen spinning tricks, adeptly manipulating a pen in circles at rapid speed."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6c6607629a103a06c7c1b52817845f25aa866b8b.pdf"}, "_bibtex": {"value": "@inproceedings{\nma2024eureka,\ntitle={Eureka: Human-Level Reward Design via Coding Large Language Models},\nauthor={Yecheng Jason Ma and William Liang and Guanzhi Wang and De-An Huang and Osbert Bastani and Dinesh Jayaraman and Yuke Zhu and Linxi Fan and Anima Anandkumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IEduRUO55F}\n}"}, "paperhash": {"value": "ma|eureka_humanlevel_reward_design_via_coding_large_language_models"}}, "number": 7937, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7937/-/Revision", "ICLR.cc/2024/Conference/Submission7937/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7937/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695491091791, "cdate": 1695491091791, "tmdate": 1711583882575, "mdate": 1711583882575, "pdate": 1705411024064, "version": 2}, {"id": "s90VIdza2K", "forum": "s90VIdza2K", "signatures": ["ICLR.cc/2024/Conference/Submission7936/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7936/Authors"], "content": {"title": {"value": "f-FERM: A  Scalable Framework for  Robust Fair Empirical Risk Minimization"}, "authors": {"value": ["Sina Baharlouei", "Shivam Patel", "Meisam Razaviyayn"]}, "authorids": {"value": ["~Sina_Baharlouei1", "~Shivam_Patel1", "~Meisam_Razaviyayn1"]}, "keywords": {"value": ["Algorithmic Fairness", "Distributionally Robust Optimization", "Distribution Shift", "Fairness", "f-divergences"]}, "abstract": {"value": "Training and deploying machine learning models that meet fairness criteria for protected groups are fundamental in modern artificial intelligence. \nWhile numerous constraints and regularization terms have been proposed in the literature to promote fairness in machine learning tasks, most of these approaches are not amenable to stochastic optimization due to the complex and nonlinear structure of constraints and regularizers. Here, the term ``stochastic'' refers to the ability of the algorithm to work with small mini-batches of data. Motivated by the limitation of existing literature, this paper presents a unified stochastic optimization framework for fair empirical risk minimization based on $f$-divergence measures ($f$-FERM). The proposed stochastic algorithm enjoys theoretical convergence guarantees. In addition, our experiments demonstrate the superiority of fairness-accuracy tradeoffs offered by $f$-FERM for almost all batch sizes (ranging from full-batch to batch size of one). Moreover, we show that our framework can be extended to the case where there is a distribution shift from training to the test data. \nOur extension is based on a distributionally robust optimization reformulation of $f$-FERM objective under $\\ell_p$ norms as uncertainty sets. Again, in this distributionally robust setting, $f$-FERM not only enjoys theoretical convergence guarantees but also outperforms other baselines in the literature in the tasks involving distribution shifts. \n An efficient stochastic implementation of $f$-FERM is publicly available."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1d2b7d920918fe102d32b04476b29c2c607925bd.pdf"}, "supplementary_material": {"value": "/attachment/85a64a2594f7a9b4158b0c6f61ef8d1fc7a31ed0.pdf"}, "_bibtex": {"value": "@inproceedings{\nbaharlouei2024fferm,\ntitle={f-{FERM}: A  Scalable Framework for  Robust Fair Empirical Risk Minimization},\nauthor={Sina Baharlouei and Shivam Patel and Meisam Razaviyayn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=s90VIdza2K}\n}"}, "paperhash": {"value": "baharlouei|fferm_a_scalable_framework_for_robust_fair_empirical_risk_minimization"}}, "number": 7936, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7936/-/Revision", "ICLR.cc/2024/Conference/Submission7936/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7936/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695491022544, "cdate": 1695491022544, "tmdate": 1712483123558, "mdate": 1712483123558, "pdate": 1705411023984, "version": 2}, {"id": "UPvufoBAIs", "forum": "UPvufoBAIs", "signatures": ["ICLR.cc/2024/Conference/Submission7928/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7928/Authors"], "content": {"title": {"value": "Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation"}, "authors": {"value": ["Prakhar Kaushik", "Aayush Mishra", "Adam Kortylewski", "Alan Yuille"]}, "authorids": {"value": ["~Prakhar_Kaushik1", "~Aayush_Mishra1", "~Adam_Kortylewski1", "~Alan_Yuille1"]}, "keywords": {"value": ["3D Pose Estimation", "Unsupervised Learning", "Neural Rendering", "Analysis-by-Synthesis"]}, "TLDR": {"value": "We propose the first method to do UDA for 3D pose estimation using only images from target domain by incremental and selective vertex feature updates of a source neural mesh model of a feature level render and compare model."}, "abstract": {"value": "We consider the problem of source-free unsupervised category-level 3D pose estimation from only RGB images to an non-annotated and unlabelled target domain without any access to source domain data or annotations during adaptation. Collecting and annotating real world 3D data and corresponding images is laborious, expensive yet unavoidable process since even 3D pose domain adaptation methods require 3D data in the target domain. We introduce a method which is capable of adapting to a nuisance ridden target domain without any 3D data or annotations. We represent object categories as simple cuboid meshes, and harness a generative model of neural feature activations modeled as a von Mises Fisher distribution at each mesh vertex learnt using differential rendering. We focus on individual mesh vertex features and iteratively update them based on their proximity to corresponding features in the target domain. Our key insight stems from the observation that specific object subparts remain stable across out-of-domain (OOD) scenarios, enabling strategic utilization of these invariant subcomponents for effective model updates. Our model is then trained in an EM fashion alternating between updating the vertex features and feature extractor. We show that our method simulates fine-tuning on a global-pseudo labelled dataset under mild assumptions which converges to the target domain asymptotically. Through extensive empirical validation, we demonstrate the potency of our simple approach in addressing the domain shift challenge and significantly enhancing pose estimation accuracy. By accentuating robust and less changed object subcomponents, our framework contributes to the evolution of UDA techniques in the context of 3D pose estimation using only images from the target domain."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2713fa61c35aea3d714ed1c74104eb90194b1f28.pdf"}, "supplementary_material": {"value": "/attachment/9e06220e2a5d5fa827804acd87f1022ccb913ca5.zip"}, "_bibtex": {"value": "@inproceedings{\nkaushik2024sourcefree,\ntitle={Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation},\nauthor={Prakhar Kaushik and Aayush Mishra and Adam Kortylewski and Alan Yuille},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UPvufoBAIs}\n}"}, "paperhash": {"value": "kaushik|sourcefree_and_imageonly_unsupervised_domain_adaptation_for_category_level_object_pose_estimation"}}, "number": 7928, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7928/-/Revision", "ICLR.cc/2024/Conference/Submission7928/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7928/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490673312, "cdate": 1695490673312, "tmdate": 1710396852568, "mdate": 1710396852568, "pdate": 1705411023791, "version": 2}, {"id": "dONpC9GL1o", "forum": "dONpC9GL1o", "signatures": ["ICLR.cc/2024/Conference/Submission7923/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7923/Authors"], "content": {"title": {"value": "Closing the Curious Case of Neural Text Degeneration"}, "authors": {"value": ["Matthew Finlayson", "John Hewitt", "Alexander Koller", "Swabha Swayamdipta", "Ashish Sabharwal"]}, "authorids": {"value": ["~Matthew_Finlayson1", "~John_Hewitt1", "~Alexander_Koller2", "~Swabha_Swayamdipta1", "~Ashish_Sabharwal1"]}, "keywords": {"value": ["softmax", "bottleneck", "truncation", "sampling", "nucleus", "top-k", "theory", "linear programming", "linear algebra", "decoding", "generation", "autoregressive", "language model", "NLP", "open-ended generation"]}, "TLDR": {"value": "We show that truncation sampling coarsely eliminates errors due to the softmax bottleneck, and develop a precise sampling method which outperforms truncation on open-ended text generation."}, "abstract": {"value": "Despite their ubiquity in language generation, it remains unknown why truncation sampling heuristics like nucleus sampling are so effective. We provide a theoretical explanation for the effectiveness of the truncation sampling by proving that truncation methods that discard tokens below some probability threshold (the most common type of truncation) can guarantee that all sampled tokens have nonzero true probability. However, thresholds are a coarse heuristic, and necessarily discard some tokens with nonzero true probability as well. In pursuit of a more precise sampling strategy, we show that we can leverage a known source of model errors, the softmax bottleneck, to prove that certain tokens have nonzero true probability, without relying on a threshold. Based on our findings, we develop an experimental truncation strategy and the present pilot studies demonstrating the promise of this type of algorithm. Our evaluations show that our method outperforms its threshold-based counterparts under automatic and human evaluation metrics for low-entropy (i.e., close to greedy) open-ended text generation. Our theoretical findings and pilot experiments provide both insight into why truncation sampling works, and make progress toward more expressive sampling algorithms that better surface the generative capabilities of large language models."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3208517640b1a7c17b6a44cc2d44f67bdc006e33.pdf"}, "_bibtex": {"value": "@inproceedings{\nfinlayson2024closing,\ntitle={Closing the Curious Case of Neural Text Degeneration},\nauthor={Matthew Finlayson and John Hewitt and Alexander Koller and Swabha Swayamdipta and Ashish Sabharwal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dONpC9GL1o}\n}"}, "paperhash": {"value": "finlayson|closing_the_curious_case_of_neural_text_degeneration"}}, "number": 7923, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7923/-/Revision", "ICLR.cc/2024/Conference/Submission7923/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7923/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490613268, "cdate": 1695490613268, "tmdate": 1710518192298, "mdate": 1710518192298, "pdate": 1705411023605, "version": 2}, {"id": "bsKMPAFHO7", "forum": "bsKMPAFHO7", "signatures": ["ICLR.cc/2024/Conference/Submission7922/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7922/Authors"], "content": {"title": {"value": "Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Sequential Games"}, "authors": {"value": ["Brian Hu Zhang", "Gabriele Farina", "Tuomas Sandholm"]}, "authorids": {"value": ["~Brian_Hu_Zhang1", "~Gabriele_Farina1", "~Tuomas_Sandholm1"]}, "keywords": {"value": ["extensive-form games", "correlated equilibria", "no-regret learning"]}, "abstract": {"value": "A recent paper by Farina and Pipis (2023) established the existence of uncoupled no-linear-swap regret dynamics with polynomial-time iterations in extensive-form games. The equilibrium points reached by these dynamics, known as linear correlated equilibria, are currently the tightest known relaxation of correlated equilibrium that can be learned in polynomial time in any finite extensive-form game. However, their properties remain vastly unexplored, and their computation is onerous. In this paper, we provide several contributions shedding light on the fundamental nature of linear-swap regret. First, we show a connection between linear deviations and a generalization of communication deviations in which the player can make queries to a ``mediator'' who replies with action recommendations, and, critically, the player is not constrained to match the timing of the game as would be the case for communication deviations. We coin this latter set the untimed communication (UTC) deviations. We show that the UTC deviations coincide precisely with the linear deviations, and therefore that any player minimizing UTC regret also minimizes linear-swap regret. We then leverage this connection to develop state-of-the-art no-regret algorithms for computing linear correlated equilibria, both in theory and in practice. In theory, our algorithms achieve polynomially better per-iteration runtimes; in practice, our algorithms represent the state of the art by several orders of magnitude."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cc579eed7f8cd682cf460a081609c0c02ed9a3b9.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024mediator,\ntitle={Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Sequential Games},\nauthor={Brian Hu Zhang and Gabriele Farina and Tuomas Sandholm},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bsKMPAFHO7}\n}"}, "paperhash": {"value": "zhang|mediator_interpretation_and_faster_learning_algorithms_for_linear_correlated_equilibria_in_general_sequential_games"}}, "number": 7922, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7922/-/Revision", "ICLR.cc/2024/Conference/Submission7922/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7922/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490591943, "cdate": 1695490591943, "tmdate": 1710557148857, "mdate": 1710557148857, "pdate": 1705411023604, "version": 2}, {"id": "LokR2TTFMs", "forum": "LokR2TTFMs", "signatures": ["ICLR.cc/2024/Conference/Submission7920/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7920/Authors"], "content": {"title": {"value": "3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining"}, "authors": {"value": ["Siming Yan", "Yuqi Yang", "Yu-Xiao Guo", "Hao Pan", "Peng-Shuai Wang", "Xin Tong", "Yang Liu", "Qixing Huang"]}, "authorids": {"value": ["~Siming_Yan1", "~Yuqi_Yang1", "~Yu-Xiao_Guo1", "~Hao_Pan4", "~Peng-Shuai_Wang1", "~Xin_Tong1", "~Yang_Liu49", "~Qixing_Huang1"]}, "keywords": {"value": ["point cloud", "point cloud self-supervised learning", "point cloud pre-training"]}, "TLDR": {"value": "We propose a masked-autoencoder-based method for point-cloud pre-training. The model is enhanced by focusing on intrinsic features using a novel attention-based decoder, showing improved performance."}, "abstract": {"value": "Masked autoencoders (MAE) have recently been introduced to 3D self-supervised pretraining for point clouds due to their great success in NLP and computer vision. Unlike MAEs used in the image domain, where the pretext task is to restore features at the masked pixels, such as colors, the existing 3D MAE works reconstruct the missing geometry only, i.e, the location of the masked points. In contrast to previous studies, we advocate that point location recovery is inessential and restoring intrinsic point features is much superior. To this end, we propose to ignore point position reconstruction and recover high-order features at masked points including surface normals and surface variations, through a novel attention-based decoder which is independent of the encoder design. We validate the effectiveness of our pretext task and decoder design using different encoder structures for 3D training and demonstrate the advantages of our pretrained networks on various point cloud analysis tasks."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2ecf6db8536bd51a51f39e4d291975d6fdf06840.pdf"}, "supplementary_material": {"value": "/attachment/9b790dfe56bba9843dfec0c9fe544305c425c053.pdf"}, "_bibtex": {"value": "@inproceedings{\nyan2024d,\ntitle={3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining},\nauthor={Siming Yan and Yuqi Yang and Yu-Xiao Guo and Hao Pan and Peng-Shuai Wang and Xin Tong and Yang Liu and Qixing Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LokR2TTFMs}\n}"}, "paperhash": {"value": "yan|3d_feature_prediction_for_maskedautoencoderbased_point_cloud_pretraining"}}, "number": 7920, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7920/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7920/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490512194, "cdate": 1695490512194, "tmdate": 1710168843109, "mdate": 1710168843109, "pdate": 1705411023478, "version": 2}, {"id": "VrHiF2hsrm", "forum": "VrHiF2hsrm", "signatures": ["ICLR.cc/2024/Conference/Submission7917/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7917/Authors"], "content": {"title": {"value": "Understanding Catastrophic Forgetting in Language Models via Implicit Inference"}, "authors": {"value": ["Suhas Kotha", "Jacob Mitchell Springer", "Aditi Raghunathan"]}, "authorids": {"value": ["~Suhas_Kotha1", "~Jacob_Mitchell_Springer1", "~Aditi_Raghunathan1"]}, "keywords": {"value": ["implicit inference in language models", "fine-tuning", "catastrophic forgetting"]}, "TLDR": {"value": "Fine-tuning may be understood as changing how a model infers the task of the prompt, and this allows us to recover the pretrained capabilities of language models through conjugate prompting."}, "abstract": {"value": "We lack a systematic understanding of the effects of fine-tuning (via methods such as instruction-tuning or reinforcement learning from human feedback), particularly on tasks outside the narrow fine-tuning distribution. In a simplified scenario, we demonstrate that improving performance on tasks within the fine-tuning data distribution comes at the expense of capabilities on other tasks. We hypothesize that language models implicitly infer the task of the prompt and that fine-tuning skews this inference towards tasks in the fine-tuning distribution. To test this, we propose Conjugate Prompting, which artificially makes the task look farther from the fine-tuning distribution while requiring the same capability, and we find that this recovers some of the pretraining capabilities in our synthetic setup. Since real-world fine-tuning distributions are predominantly English, we apply conjugate prompting to recover pretrained capabilities in LLMs by simply translating the prompts to different languages. This allows us to recover in-context learning abilities lost via instruction tuning, natural reasoning capability lost during code fine-tuning, and, more concerningly, harmful content generation suppressed by safety fine-tuning in chatbots like ChatGPT."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fba453c1032d524bc23b1106ab3a598979c31704.pdf"}, "_bibtex": {"value": "@inproceedings{\nkotha2024understanding,\ntitle={Understanding Catastrophic Forgetting in Language Models via Implicit Inference},\nauthor={Suhas Kotha and Jacob Mitchell Springer and Aditi Raghunathan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VrHiF2hsrm}\n}"}, "paperhash": {"value": "kotha|understanding_catastrophic_forgetting_in_language_models_via_implicit_inference"}}, "number": 7917, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7917/-/Revision", "ICLR.cc/2024/Conference/Submission7917/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7917/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695490389339, "cdate": 1695490389339, "tmdate": 1713056885243, "mdate": 1713056885243, "pdate": 1705411023475, "version": 2}, {"id": "gppLqZLQeY", "forum": "gppLqZLQeY", "signatures": ["ICLR.cc/2024/Conference/Submission7883/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7883/Authors"], "content": {"title": {"value": "Efficient Subgraph GNNs by Learning Effective Selection Policies"}, "authors": {"value": ["Beatrice Bevilacqua", "Moshe Eliasof", "Eli Meirom", "Bruno Ribeiro", "Haggai Maron"]}, "authorids": {"value": ["~Beatrice_Bevilacqua1", "~Moshe_Eliasof1", "~Eli_Meirom2", "~Bruno_Ribeiro1", "~Haggai_Maron1"]}, "keywords": {"value": ["Graph Neural Networks", "Subgraphs", "Expressive power", "Sampling"]}, "TLDR": {"value": "We propose a novel framework that learns to select subgraphs sequentially in order to reduce the computational cost of Subgraph GNNs."}, "abstract": {"value": "Subgraph GNNs are provably expressive neural architectures that learn graph representations from sets of subgraphs. Unfortunately, their applicability is hampered by the computational complexity associated with performing message passing on many subgraphs. In this paper, we consider the problem of learning to select a small subset of the large set of possible subgraphs in a data-driven fashion. We first motivate the problem by proving that there are families of WL-indistinguishable graphs for which there exist efficient subgraph selection policies: small subsets of subgraphs that can already identify all the graphs within the family. We then propose a new approach, called _Policy-Learn_, that learns how to select subgraphs in an iterative manner. We prove that, unlike popular random policies and prior work addressing the same problem, our architecture is able to learn the efficient policies mentioned above. Our experimental results demonstrate that _Policy-Learn_ outperforms existing baselines across a wide range of datasets."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bb667e3793f646c96519efa8bde1df46581bd0cc.pdf"}, "_bibtex": {"value": "@inproceedings{\nbevilacqua2024efficient,\ntitle={Efficient Subgraph {GNN}s by Learning Effective Selection Policies},\nauthor={Beatrice Bevilacqua and Moshe Eliasof and Eli Meirom and Bruno Ribeiro and Haggai Maron},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gppLqZLQeY}\n}"}, "paperhash": {"value": "bevilacqua|efficient_subgraph_gnns_by_learning_effective_selection_policies"}}, "number": 7883, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7883/-/Revision", "ICLR.cc/2024/Conference/Submission7883/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7883/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695489419488, "cdate": 1695489419488, "tmdate": 1712255005118, "mdate": 1712255005118, "pdate": 1705411022429, "version": 2}, {"id": "YIls9HEa52", "forum": "YIls9HEa52", "signatures": ["ICLR.cc/2024/Conference/Submission7878/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7878/Authors"], "content": {"title": {"value": "Parsing neural dynamics with infinite recurrent switching linear dynamical systems"}, "authors": {"value": ["Victor Geadah", "International Brain Laboratory", "Jonathan W. Pillow"]}, "authorids": {"value": ["~Victor_Geadah1", "~International_Brain_Laboratory1", "~Jonathan_W._Pillow1"]}, "keywords": {"value": ["Markov switching processes", "Neural data analysis", "State-space models"]}, "abstract": {"value": "Unsupervised methods for dimensionality reduction of neural activity and behavior have provided unprecedented insights into the underpinnings of neural information processing. One popular approach involves the recurrent switching linear dynamical system (rSLDS) model, which describes the latent dynamics of neural spike train data using discrete switches between a finite number of low-dimensional linear dynamical systems. However, a few properties of rSLDS model limit its deployability on trial-varying data, such as a fixed number of states over trials, and no latent structure or organization of states. Here we overcome these limitations by endowing the rSLDS model with a semi-Markov discrete state process, with latent geometry, that captures key properties of stochastic processes over partitions with flexible state cardinality. We leverage partial differential equations (PDE) theory to derive an efficient, semi-parametric formulation for dynamical sufficient statistics to the discrete states. This process, combined with switching dynamics, defines our infinite recurrent switching linear dynamical system (irSLDS) model class. We first validate and demonstrate the capabilities of our model on synthetic data. Next, we turn to the analysis of mice electrophysiological data during decision-making, and uncover strong non-stationary processes underlying both within-trial and trial-averaged neural activity."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cb95b9a8fb40ebbe01a3c397596d85282ca2955e.pdf"}, "TLDR": {"value": "We extend switching state-space models with a PDE prior that induces a state geometry, and showcase the model's abilities for uncovering trial-varying structure in neural data"}, "_bibtex": {"value": "@inproceedings{\ngeadah2024parsing,\ntitle={Parsing neural dynamics with infinite recurrent switching linear dynamical systems},\nauthor={Victor Geadah and International Brain Laboratory and Jonathan W. Pillow},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YIls9HEa52}\n}"}, "paperhash": {"value": "geadah|parsing_neural_dynamics_with_infinite_recurrent_switching_linear_dynamical_systems"}}, "number": 7878, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7878/-/Revision", "ICLR.cc/2024/Conference/Submission7878/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7878/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695489166579, "cdate": 1695489166579, "tmdate": 1710461226941, "mdate": 1710461226941, "pdate": 1705411022402, "version": 2}, {"id": "h7DGnWGeos", "forum": "h7DGnWGeos", "signatures": ["ICLR.cc/2024/Conference/Submission7875/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7875/Authors"], "content": {"title": {"value": "Active Retrosynthetic Planning Aware of Route Quality"}, "authors": {"value": ["Luotian Yuan", "Yemin Yu", "Ying Wei", "Yongwei Wang", "Zhihua Wang", "Fei Wu"]}, "authorids": {"value": ["~Luotian_Yuan1", "~Yemin_Yu1", "~Ying_Wei1", "~Yongwei_Wang1", "~Zhihua_Wang4", "~Fei_Wu1"]}, "keywords": {"value": ["Retrosynthetic planning", "route evaluation", "reinforcement learning"]}, "abstract": {"value": "Retrosynthetic planning is a sequential decision-making process of identifying synthetic routes from the available building block materials to reach a desired target molecule.\nThough existing planning approaches show promisingly high solving rates and low costs, the trivial route cost evaluation via pre-trained forward reaction prediction models certainly falls short of real-world chemical practice.\nAn alternative option is to annotate the actual cost of a route, such as yield, through chemical experiments or input from chemists, while \nthis often leads to substantial query costs.\nIn order to strike the balance between query costs and route quality evaluation, we propose an Active Retrosynthetic Planning (ARP) framework that remains compatible with the established retrosynthetic planners.\nOn one hand, the proposed ARP trains an actor that decides whether to query the cost of a reaction; on the other hand, it resorts to a critic to estimate the value of a molecule with its preceding reaction cost as input. \nThose molecules with low reaction costs are preferred to expand first.\nWe apply our framework to different existing approaches on both the benchmark and an expert dataset and demonstrate that it outperforms the existing state-of-the-art approach by 6.2\\% in route quality while reducing the query cost by 12.8\\%.\nIn addition, \nARP consistently plans \nhigh-quality routes with either abundant or sparse annotations."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0eba4d55c6b2d267c53e120ccbcbe1c0a441de5a.pdf"}, "supplementary_material": {"value": "/attachment/713e89ddf1aad5f74ca8fa9945bd587f7653c3e5.pdf"}, "_bibtex": {"value": "@inproceedings{\nyuan2024active,\ntitle={Active Retrosynthetic Planning Aware of Route Quality},\nauthor={Luotian Yuan and Yemin Yu and Ying Wei and Yongwei Wang and Zhihua Wang and Fei Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=h7DGnWGeos}\n}"}, "paperhash": {"value": "yuan|active_retrosynthetic_planning_aware_of_route_quality"}}, "number": 7875, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7875/-/Revision", "ICLR.cc/2024/Conference/Submission7875/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7875/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695488958136, "cdate": 1695488958136, "tmdate": 1712154998942, "mdate": 1712154998942, "pdate": 1705411022323, "version": 2}, {"id": "zb3b6oKO77", "forum": "zb3b6oKO77", "signatures": ["ICLR.cc/2024/Conference/Submission7872/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7872/Authors"], "content": {"title": {"value": "How do Language Models Bind Entities in Context?"}, "authors": {"value": ["Jiahai Feng", "Jacob Steinhardt"]}, "authorids": {"value": ["~Jiahai_Feng1", "~Jacob_Steinhardt1"]}, "keywords": {"value": ["Interpretability", "Learned Representations", "Neurosymbolic AI"]}, "abstract": {"value": "Language models (LMs) can recall facts mentioned in context, as shown by their performance on reading comprehension tasks. When the context describes facts about more than one entity, the LM has to correctly bind attributes to their corresponding entity. We show, via causal experiments, that LMs' internal activations represent binding information by exhibiting appropriate binding ID vectors at the entity and attribute positions. We further show that binding ID vectors form a subspace and often transfer across tasks. Our results demonstrate that LMs learn interpretable strategies for representing symbolic knowledge in context, and that studying context activations is a fruitful direction for understanding LM cognition."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/28b9cffab0e6b66ae449e4a74e7e3c4798f5be18.pdf"}, "_bibtex": {"value": "@inproceedings{\nfeng2024how,\ntitle={How do Language Models Bind Entities in Context?},\nauthor={Jiahai Feng and Jacob Steinhardt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zb3b6oKO77}\n}"}, "paperhash": {"value": "feng|how_do_language_models_bind_entities_in_context"}}, "number": 7872, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7872/-/Revision", "ICLR.cc/2024/Conference/Submission7872/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7872/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695488747957, "cdate": 1695488747957, "tmdate": 1710114762750, "mdate": 1710114762750, "pdate": 1705411022227, "version": 2}, {"id": "HfXDrAzFvG", "forum": "HfXDrAzFvG", "signatures": ["ICLR.cc/2024/Conference/Submission7869/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7869/Authors"], "content": {"title": {"value": "Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations"}, "authors": {"value": ["Patricia Pauli", "Aaron J Havens", "Alexandre Araujo", "Siddharth Garg", "Farshad Khorrami", "Frank Allg\u00f6wer", "Bin Hu"]}, "authorids": {"value": ["~Patricia_Pauli1", "~Aaron_J_Havens1", "~Alexandre_Araujo3", "~Siddharth_Garg1", "~Farshad_Khorrami1", "~Frank_Allg\u00f6wer1", "~Bin_Hu2"]}, "keywords": {"value": ["Neural Networks", "Semidefinite Programming", "Lipschitz Constant Estimation"]}, "abstract": {"value": "Recently, semidefinite programming (SDP) techniques have shown great promise in providing accurate Lipschitz bounds for neural networks. Specifically, the LipSDP approach (Fazlyab et al., 2019) has received much attention and provides the least conservative Lipschitz upper bounds that can be computed with polynomial time guarantees. However, one main restriction of LipSDP is that its formulation requires the activation functions to be slope-restricted on $[0,1]$, preventing its further use for more general activation functions such as GroupSort, MaxMin, and Householder. One can rewrite MaxMin activations for example as residual ReLU networks. However, a direct application of LipSDP to the resultant residual ReLU networks is conservative and even fails in recovering the well-known fact that the MaxMin activation is 1-Lipschitz. Our paper bridges this gap and extends LipSDP  beyond slope-restricted activation functions. To this end, we provide novel quadratic constraints for GroupSort, MaxMin, and Householder activations via leveraging their underlying properties such as sum preservation. Our proposed analysis is general and provides a unified approach for estimating $\\ell_2$ and $\\ell_\\infty$ Lipschitz bounds for a rich class of neural network architectures, including non-residual and residual neural networks and implicit models,  with GroupSort, MaxMin, and HouseHolder activations. Finally, we illustrate the utility of our approach with a variety of experiments and show that our proposed SDPs generate less conservative Lipschitz bounds in comparison to existing approaches."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/77c8f16bf84c684bfa1e6014821209b562511cc5.pdf"}, "supplementary_material": {"value": "/attachment/a625ac89dfbf7df2fe2416b661167d7cf90836ac.zip"}, "_bibtex": {"value": "@inproceedings{\npauli2024novel,\ntitle={Novel Quadratic Constraints for Extending Lip{SDP} beyond Slope-Restricted Activations},\nauthor={Patricia Pauli and Aaron J Havens and Alexandre Araujo and Siddharth Garg and Farshad Khorrami and Frank Allg{\\\"o}wer and Bin Hu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HfXDrAzFvG}\n}"}, "paperhash": {"value": "pauli|novel_quadratic_constraints_for_extending_lipsdp_beyond_sloperestricted_activations"}}, "number": 7869, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7869/-/Revision", "ICLR.cc/2024/Conference/Submission7869/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7869/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695488636128, "cdate": 1695488636128, "tmdate": 1710450079101, "mdate": 1710450079101, "pdate": 1705411022112, "version": 2}, {"id": "2UnCj3jeao", "forum": "2UnCj3jeao", "signatures": ["ICLR.cc/2024/Conference/Submission7863/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7863/Authors"], "content": {"title": {"value": "Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation"}, "authors": {"value": ["Luca Eyring", "Dominik Klein", "Th\u00e9o Uscidda", "Giovanni Palla", "Niki Kilbertus", "Zeynep Akata", "Fabian J Theis"]}, "authorids": {"value": ["~Luca_Eyring1", "~Dominik_Klein1", "~Th\u00e9o_Uscidda1", "~Giovanni_Palla1", "~Niki_Kilbertus1", "~Zeynep_Akata1", "~Fabian_J_Theis1"]}, "keywords": {"value": ["optimal transport", "domain translation", "image translation", "flow matching"]}, "abstract": {"value": "In optimal transport (OT), a Monge map is known as a mapping that transports a source distribution to a target distribution in the most cost-efficient way. Recently, multiple neural estimators for Monge maps have been developed and applied in diverse unpaired domain translation tasks, e.g. in single-cell biology and computer vision. However, the classic OT framework enforces mass conservation, which\nmakes it prone to outliers and limits its applicability in real-world scenarios. The latter can be particularly harmful in OT domain translation tasks, where the relative position of a sample within a distribution is explicitly taken into account. While unbalanced OT tackles this challenge in the discrete setting, its integration into neural Monge map estimators has received limited attention. We propose a theoretically\ngrounded method to incorporate unbalancedness into any Monge map estimator. We improve existing estimators to model cell trajectories over time and to predict cellular responses to perturbations. Moreover, our approach seamlessly integrates with the OT flow matching (OT-FM) framework. While we show that OT-FM performs competitively in image translation, we further improve performance by\nincorporating unbalancedness (UOT-FM), which better preserves relevant features. We hence establish UOT-FM as a principled method for unpaired image translation."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4e007c37023074d72d5fdc49366594785523cb68.pdf"}, "TLDR": {"value": "We propose a theoretically grounded method to incorporate unbalancedness into any Monge map estimator and show how unbalancedness yields enhanced results across three distinct tasks employing three estimators."}, "_bibtex": {"value": "@inproceedings{\neyring2024unbalancedness,\ntitle={Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation},\nauthor={Luca Eyring and Dominik Klein and Th{\\'e}o Uscidda and Giovanni Palla and Niki Kilbertus and Zeynep Akata and Fabian J Theis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2UnCj3jeao}\n}"}, "paperhash": {"value": "eyring|unbalancedness_in_neural_monge_maps_improves_unpaired_domain_translation"}}, "number": 7863, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7863/-/Revision", "ICLR.cc/2024/Conference/Submission7863/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7863/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695488360161, "cdate": 1695488360161, "tmdate": 1710530821752, "mdate": 1710530821752, "pdate": 1705411022103, "version": 2}, {"id": "uZfjFyPAvn", "forum": "uZfjFyPAvn", "signatures": ["ICLR.cc/2024/Conference/Submission7842/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7842/Authors"], "content": {"title": {"value": "Implicit Neural Representations and the Algebra of Complex Wavelets"}, "authors": {"value": ["T Mitchell Roddenberry", "Vishwanath Saragadam", "Maarten V. de Hoop", "Richard Baraniuk"]}, "authorids": {"value": ["~T_Mitchell_Roddenberry1", "~Vishwanath_Saragadam1", "~Maarten_V._de_Hoop2", "~Richard_Baraniuk1"]}, "keywords": {"value": ["implicit neural representations", "algebra", "multilayer perceptrons", "wavelet"]}, "TLDR": {"value": "We discuss the algebra of implicit neural representations from an applied harmonic analysis perspective"}, "abstract": {"value": "Implicit neural representations (INRs) have arisen as useful methods for representing signals on Euclidean domains. By parameterizing an image as a multilayer perceptron (MLP) on Euclidean space, INRs effectively couple spatial and spectral features of the represented signal in a way that is not obvious in the usual discrete representation. Although INRs using sinusoidal activation functions have been studied in terms of Fourier theory, recent works have shown the advantage of using wavelets instead of sinusoids as activation functions, due to their ability to simultaneously localize in both frequency and space. In this work, we approach such INRs and demonstrate how they resolve high-frequency features of signals from coarse approximations performed in the first layer of the MLP. This leads to multiple prescriptions for the design of INR architectures, including the use of progressive wavelets, decoupling of low and high-pass approximations, and initialization schemes based on the singularities of the target signal."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4204c82f9ab502c4460ea36edf09dabf851c3781.pdf"}, "_bibtex": {"value": "@inproceedings{\nroddenberry2024implicit,\ntitle={Implicit Neural Representations and the Algebra of Complex Wavelets},\nauthor={T Mitchell Roddenberry and Vishwanath Saragadam and Maarten V. de Hoop and Richard Baraniuk},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uZfjFyPAvn}\n}"}, "paperhash": {"value": "roddenberry|implicit_neural_representations_and_the_algebra_of_complex_wavelets"}}, "number": 7842, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7842/-/Revision", "ICLR.cc/2024/Conference/Submission7842/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7842/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695487799594, "cdate": 1695487799594, "tmdate": 1710542732402, "mdate": 1710542732402, "pdate": 1705411021704, "version": 2}, {"id": "sP1tCl2QBk", "forum": "sP1tCl2QBk", "signatures": ["ICLR.cc/2024/Conference/Submission7841/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7841/Authors"], "content": {"title": {"value": "Fiber Monte Carlo"}, "authors": {"value": ["Nick Richardson", "Deniz Oktay", "Yaniv Ovadia", "James C Bowden", "Ryan P Adams"]}, "authorids": {"value": ["~Nick_Richardson1", "~Deniz_Oktay2", "~Yaniv_Ovadia2", "~James_C_Bowden1", "~Ryan_P_Adams1"]}, "keywords": {"value": ["Stochastic Methods"]}, "abstract": {"value": "Integrals with discontinuous integrands are ubiquitous, arising from discrete structure in applications like topology optimization, graphics, and computational geometry.\n    These integrals are often part of a forward model in an inverse problem where it is necessary to reason backwards about the parameters, ideally using gradient-based optimization. \n    Monte Carlo methods are widely used to estimate the value of integrals, but this results in a non-differentiable approximation that is amenable to neither conventional automatic differentiation nor reparameterization-based gradient methods. \n    This significantly disrupts efforts to integrate machine learning methods in areas that exhibit these discontinuities: physical simulation and robotics, design, graphics, and computational geometry.  \n    Although bespoke domain-specific techniques can handle special cases, a general methodology to wield automatic differentiation in these discrete contexts is wanting. \n    We introduce a differentiable variant of the simple Monte Carlo estimator which samples line segments rather than points from the domain. \n    We justify our estimator analytically as conditional Monte Carlo and demonstrate the diverse functionality of the method as applied to image stylization, topology optimization, and computational geometry."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7d5a83d7a94183d1d9225cc666d97a8d77188d5b.pdf"}, "supplementary_material": {"value": "/attachment/415dba228924d664a7b810fa4eea8b83f59867d6.pdf"}, "_bibtex": {"value": "@inproceedings{\nrichardson2024fiber,\ntitle={Fiber Monte Carlo},\nauthor={Nick Richardson and Deniz Oktay and Yaniv Ovadia and James C Bowden and Ryan P Adams},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sP1tCl2QBk}\n}"}, "paperhash": {"value": "richardson|fiber_monte_carlo"}}, "number": 7841, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7841/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7841/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695487761854, "cdate": 1695487761854, "tmdate": 1711548200007, "mdate": 1711548200007, "pdate": 1705411021680, "version": 2}, {"id": "KQe9tHd0k8", "forum": "KQe9tHd0k8", "signatures": ["ICLR.cc/2024/Conference/Submission7839/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7839/Authors"], "content": {"title": {"value": "Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"}, "authors": {"value": ["Shreyas Havaldar", "Navodita Sharma", "Shubhi Sareen", "Karthikeyan Shanmugam", "Aravindan Raghuveer"]}, "authorids": {"value": ["~Shreyas_Havaldar1", "~Navodita_Sharma1", "~Shubhi_Sareen1", "~Karthikeyan_Shanmugam1", "~Aravindan_Raghuveer1"]}, "keywords": {"value": ["Learning from Label Proportions", "Belief Propagation", "Pseudo-Labeling", "Embedding Learning"]}, "TLDR": {"value": "Pseudo-labeling through BP leveraging unsupervised covariate information for LLP"}, "abstract": {"value": "Learning from Label Proportions (LLP) is a learning problem where only aggregate level labels are available for groups of instances, called bags, during training, and the aim is to get the best performance at the instance-level on the test data. This setting arises in domains like advertising and medicine due to privacy considerations. We propose a novel algorithmic framework for this problem that iteratively performs two main steps. For the first step (Pseudo Labeling) in every iteration, we define a Gibbs distribution over binary instance labels that incorporates a) covariate information through the constraint that instances with similar covariates should have similar labels and b) the bag level aggregated label. We then use Belief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo labels. In the second step (Embedding Refinement), we use the pseudo labels to provide supervision for a learner that yields a better embedding. Further, we iterate on the two steps again by using the second step's embeddings as new covariates for the next iteration. In the final iteration, a classifier is trained using the pseudo labels. Our algorithm displays strong gains  against several SOTA baselines (upto **15%**) for the LLP Binary Classification problem on various dataset types - tabular and Image. We achieve these improvements with minimal computational overhead above standard supervised learning due to Belief Propagation, for large bag sizes, even for a million samples."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fe1295b607d0d088fa07653fbda2b9c5a57e521f.pdf"}, "_bibtex": {"value": "@inproceedings{\nhavaldar2024learning,\ntitle={Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation},\nauthor={Shreyas Havaldar and Navodita Sharma and Shubhi Sareen and Karthikeyan Shanmugam and Aravindan Raghuveer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KQe9tHd0k8}\n}"}, "paperhash": {"value": "havaldar|learning_from_label_proportions_bootstrapping_supervised_learners_via_belief_propagation"}}, "number": 7839, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7839/-/Revision", "ICLR.cc/2024/Conference/Submission7839/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7839/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695487707916, "cdate": 1695487707916, "tmdate": 1710919454177, "mdate": 1710919454177, "pdate": 1705411021595, "version": 2}, {"id": "WQwV7Y8qwa", "forum": "WQwV7Y8qwa", "signatures": ["ICLR.cc/2024/Conference/Submission7836/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7836/Authors"], "content": {"title": {"value": "Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems"}, "authors": {"value": ["Orren Karniol-Tambour", "David M. Zoltowski", "E. Mika Diamanti", "Lucas Pinto", "Carlos D Brody", "David W. Tank", "Jonathan W. Pillow"]}, "authorids": {"value": ["~Orren_Karniol-Tambour1", "~David_M._Zoltowski1", "~E._Mika_Diamanti1", "~Lucas_Pinto1", "~Carlos_D_Brody1", "~David_W._Tank1", "~Jonathan_W._Pillow1"]}, "keywords": {"value": ["neuroscience", "neural dynamics", "dynamical systems", "decision making"]}, "TLDR": {"value": "We propose a multiregion, switching nonlinear state space model to model neural dynamics and communication"}, "abstract": {"value": "Understanding how multiple brain regions interact to produce behavior is a major challenge in systems neuroscience, with many regions causally implicated in common tasks such as sensory processing and decision making. A precise description of interactions between regions remains an open problem. Moreover, neural dynamics are nonlinear and non-stationary. Here, we propose MR-SDS, a multiregion, switching nonlinear state space model that decomposes global dynamics into local and cross-communication components in the latent space. MR-SDS includes directed interactions between brain regions, allowing for estimation of state-dependent communication signals, and accounts for sensory inputs effects, history effects, and heterogeneity across days and animals. We show that our model accurately recovers latent trajectories, vector fields underlying switching nonlinear dynamics, and cross-region communication profiles in three simulations. We then apply our method to two large-scale, multi-region neural datasets involving mouse decision making. The first includes hundreds of neurons per region, recorded simultaneously at single-cell-resolution across 3 distant cortical regions. The second is a mesoscale widefield dataset of 8 adjacent cortical regions imaged across both hemispheres. On these multi-region datasets, our model outperforms existing piece-wise linear multi-region models and reveals multiple distinct dynamical states and a rich set of cross-region communication profiles."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8c7655d5e83a3e06fcdc8e1ac3051119e53843b2.pdf"}, "_bibtex": {"value": "@inproceedings{\nkarniol-tambour2024modeling,\ntitle={Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems},\nauthor={Orren Karniol-Tambour and David M. Zoltowski and E. Mika Diamanti and Lucas Pinto and Carlos D Brody and David W. Tank and Jonathan W. Pillow},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WQwV7Y8qwa}\n}"}, "paperhash": {"value": "karnioltambour|modeling_statedependent_communication_between_brain_regions_with_switching_nonlinear_dynamical_systems"}}, "number": 7836, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7836/-/Revision", "ICLR.cc/2024/Conference/Submission7836/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695487609782, "cdate": 1695487609782, "tmdate": 1707625642954, "mdate": 1707625642954, "pdate": 1705411021509, "version": 2}, {"id": "HYyRwm367m", "forum": "HYyRwm367m", "signatures": ["ICLR.cc/2024/Conference/Submission7823/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7823/Authors"], "content": {"title": {"value": "Neural Language of Thought Models"}, "authors": {"value": ["Yi-Fu Wu", "Minseung Lee", "Sungjin Ahn"]}, "authorids": {"value": ["~Yi-Fu_Wu1", "~Minseung_Lee2", "~Sungjin_Ahn1"]}, "keywords": {"value": ["unsupervised object-centric learning", "discrete representations"]}, "TLDR": {"value": "We introduce a model that can obtain semantic discrete representations of a visual scene."}, "abstract": {"value": "The Language of Thought Hypothesis suggests that human cognition operates on a structured, language-like system of mental representations. While neural language models can naturally benefit from the compositional structure inherently and explicitly expressed in language data, learning such representations from non-linguistic general observations, like images, remains a challenge. In this work, we introduce the Neural Language of Thought Model (NLoTM), a novel approach for unsupervised learning of LoTH-inspired representation and generation. NLoTM comprises two key components: (1) the Semantic Vector-Quantized Variational Autoencoder, which learns hierarchical, composable discrete representations aligned with objects and their properties, and (2) the Autoregressive LoT Prior, an autoregressive transformer that learns to generate semantic concept tokens compositionally, capturing the underlying data distribution. We evaluate NLoTM on several 2D and 3D image datasets, demonstrating superior performance in downstream tasks, out-of-distribution generalization, and image generation quality compared to patch-based VQ-VAE and continuous object-centric representations. Our work presents a significant step towards creating neural networks exhibiting more human-like understanding by developing LoT-like representations and offers insights into the intersection of cognitive science and machine learning."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/49107366def27f8426cf313dc870595042c85c07.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024objectcentric,\ntitle={Object-Centric Semantic Vector Quantization},\nauthor={Yi-Fu Wu and Minseung Lee and Sungjin Ahn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HYyRwm367m}\n}"}, "paperhash": {"value": "wu|neural_language_of_thought_models"}}, "number": 7823, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7823/-/Revision", "ICLR.cc/2024/Conference/Submission7823/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7823/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695487029042, "cdate": 1695487029042, "tmdate": 1713070082837, "mdate": 1713070082837, "pdate": 1705411021330, "version": 2}, {"id": "0t1O8ziRZp", "forum": "0t1O8ziRZp", "signatures": ["ICLR.cc/2024/Conference/Submission7821/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7821/Authors"], "content": {"title": {"value": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization"}, "authors": {"value": ["Animesh Basak Chowdhury", "Marco Romanelli", "Benjamin Tan", "Ramesh Karri", "Siddharth Garg"]}, "authorids": {"value": ["~Animesh_Basak_Chowdhury1", "~Marco_Romanelli1", "~Benjamin_Tan1", "~Ramesh_Karri1", "~Siddharth_Garg1"]}, "keywords": {"value": ["Electronics Design Automation (EDA)", "Logic Synthesis", "Reinforcement Learning", "Hardware design", "Circuits"]}, "TLDR": {"value": "We propose Retrieval Guided RL for logic synthesis to generalize for diverse hardware. Pre-trained agents, combined with MCTS fails on novel designs. We adjusts agent recommendations using nearest neighbor similarity scores for improved synthesis."}, "abstract": {"value": "Logic synthesis, a pivotal stage in chip design, entails optimizing chip specifications encoded in hardware description languages like Verilog into highly efficient implementations using Boolean logic gates. The process involves a sequential application of logic minimization heuristics (``synthesis recipe\"), with their arrangement significantly impacting crucial metrics such as area and delay. Addressing the challenge posed by the broad spectrum of hardware design complexities \u2014 from variations of past designs (e.g., adders and multipliers) to entirely novel configurations (e.g., innovative processor instructions) \u2014 requires a nuanced 'synthesis recipe' guided by human expertise and intuition. This study conducts a thorough examination of learning and search techniques for logic synthesis, unearthing a surprising revelation: pre-trained agents, when confronted with entirely novel designs, may veer off course, detrimentally affecting the search trajectory. We present ABC-RL, a meticulously tuned $\\alpha$ parameter that adeptly adjusts recommendations from pre-trained agents during the search process. Computed based on similarity scores through nearest neighbor retrieval from the training dataset, ABC-RL yields superior synthesis recipes tailored for a wide array of hardware designs. Our findings showcase substantial enhancements in the Quality of Result (QoR) of synthesized circuits, boasting improvements of up to 24.8\\% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an impressive up to 9x reduction in runtime (iso-QoR) when compared to current state-of-the-art methodologies."}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/45352e5a0436249e936152d04e6550dff1475ac5.pdf"}, "supplementary_material": {"value": "/attachment/96d64b30ce8657cadea469fc4c3cdb5c78c4313c.zip"}, "_bibtex": {"value": "@inproceedings{\nchowdhury2024retrievalguided,\ntitle={Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization},\nauthor={Animesh Basak Chowdhury and Marco Romanelli and Benjamin Tan and Ramesh Karri and Siddharth Garg},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0t1O8ziRZp}\n}"}, "paperhash": {"value": "chowdhury|retrievalguided_reinforcement_learning_for_boolean_circuit_minimization"}}, "number": 7821, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7821/-/Revision", "ICLR.cc/2024/Conference/Submission7821/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7821/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695487002693, "cdate": 1695487002693, "tmdate": 1710540982066, "mdate": 1710540982066, "pdate": 1705411021224, "version": 2}, {"id": "ztpy1gsUpT", "forum": "ztpy1gsUpT", "signatures": ["ICLR.cc/2024/Conference/Submission7807/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7807/Authors"], "content": {"title": {"value": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting"}, "authors": {"value": ["Xinlu Zhang", "Shiyang Li", "Xianjun Yang", "Chenxin Tian", "Yao Qin", "Linda Ruth Petzold"]}, "authorids": {"value": ["~Xinlu_Zhang1", "~Shiyang_Li1", "~Xianjun_Yang1", "~Chenxin_Tian1", "~Yao_Qin1", "~Linda_Ruth_Petzold1"]}, "keywords": {"value": ["natural language processing", "large language model prompting", "application in healthcare", "privacy"]}, "abstract": {"value": "Large language models (LLMs) demonstrate remarkable medical expertise, but data privacy concerns impede their direct use in healthcare environments. Although offering improved data privacy protection, domain-specific small language models (SLMs) often underperform LLMs, emphasizing the need for methods that reduce this performance gap while alleviating privacy concerns. In this paper, we present a simple yet effective method that harnesses LLMs' medical proficiency to boost SLM performance in medical tasks under $privacy-restricted$ scenarios. Specifically, we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM to generate a medical knowledge-intensive context by simulating clinicians' thought processes. This context serves as additional input for SLMs, augmenting their decision-making capabilities. Our method significantly enhances performance in both few-shot and full training settings across three medical knowledge-intensive tasks, achieving up to a 22.57% increase in absolute accuracy compared to SLM fine-tuning without context, and sets new state-of-the-art results in two medical tasks within privacy-restricted scenarios. Further out-of-domain testing and experiments in two general domain datasets showcase its generalizability and broad applicability."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/870c2d2b9c207c1295cc917d1fe533ee69e399a9.pdf"}, "supplementary_material": {"value": "/attachment/d8d2f75fb2a6dc8fb0455ed0712335805dac6fbc.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024enhancing,\ntitle={Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting},\nauthor={Xinlu Zhang and Shiyang Li and Xianjun Yang and Chenxin Tian and Yao Qin and Linda Ruth Petzold},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ztpy1gsUpT}\n}"}, "paperhash": {"value": "zhang|enhancing_small_medical_learners_with_privacypreserving_contextual_prompting"}}, "number": 7807, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7807/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7807/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695486586687, "cdate": 1695486586687, "tmdate": 1709661543228, "mdate": 1709661543228, "pdate": 1705411020822, "version": 2}, {"id": "jsvvPVVzwf", "forum": "jsvvPVVzwf", "signatures": ["ICLR.cc/2024/Conference/Submission7800/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7800/Authors"], "content": {"title": {"value": "What Makes a Good Prune? Maximal Unstructured Pruning for Maximal Cosine Similarity"}, "authors": {"value": ["Gabryel Mason-Williams", "Fredrik Dahlqvist"]}, "authorids": {"value": ["~Gabryel_Mason-Williams1", "f.dahlqvist@qmul.ac.uk"]}, "keywords": {"value": ["Pruning", "Deep Learning", "Neural Networks", "Interpretability", "Loss landscapes", "Optimization", "Kurtosis"]}, "TLDR": {"value": "This paper explores the mechanisms that underpin pruning, ultimately showing that the higher the kurtosis of a model's parameter distribution, the more it can be pruned while maintaining performance."}, "abstract": {"value": "Pruning is an effective method to reduce the size of deep neural network models, maintain accuracy, and, in some cases, improve the network's overall performance. However, the mechanisms underpinning pruning remain unclear. Why can different methods prune by different percentages yet achieve similar performance? Why can we not prune at the start of training? Why are some models more amenable to being pruned than others? Given a model, what is the maximum amount it can be pruned before significantly affecting the performance? This paper explores and answers these questions from the global unstructured magnitude pruning perspective with one epoch of fine-tuning. We develop the idea that cosine similarity is an effective proxy measure for functional similarity between the parent and the pruned network. We prove that the L1 pruning method is optimal when pruning by cosine similarity. We show that the higher the kurtosis of a model's parameter distribution, the more it can be pruned while maintaining performance. Finally, we present a simple method to determine the optimal amount by which a network can be L1-pruned based on its parameter distribution. The code demonstrating the method is available at https://github.com/gmw99/what_makes_a_good_prune"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d36cb7ab7a56f325f5bb6a9e1bbccce752db0563.pdf"}, "_bibtex": {"value": "@inproceedings{\nmason-williams2024what,\ntitle={What Makes a Good Prune? Optimal Unstructured Pruning for Maximal Cosine Similarity},\nauthor={Gabryel Mason-Williams and Fredrik Dahlqvist},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jsvvPVVzwf}\n}"}, "paperhash": {"value": "masonwilliams|what_makes_a_good_prune_maximal_unstructured_pruning_for_maximal_cosine_similarity"}}, "number": 7800, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7800/-/Revision", "ICLR.cc/2024/Conference/Submission7800/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7800/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695486433706, "cdate": 1695486433706, "tmdate": 1710428328386, "mdate": 1710428328386, "pdate": 1705411020572, "version": 2}, {"id": "BqEvdOS1Hs", "forum": "BqEvdOS1Hs", "signatures": ["ICLR.cc/2024/Conference/Submission7798/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7798/Authors"], "content": {"title": {"value": "Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain"}, "authors": {"value": ["Yiming Gao", "Feiyu Liu", "Liang Wang", "Dehua Zheng", "Zhenjie Lian", "Weixuan Wang", "Wenjin Yang", "Siqin Li", "Xianliang Wang", "Wenhui Chen", "Jing Dai", "QIANG FU", "Yang Wei", "Lanxiao Huang", "Wei Liu"]}, "authorids": {"value": ["~Yiming_Gao4", "~Feiyu_Liu1", "~Liang_Wang10", "~Dehua_Zheng1", "~Zhenjie_Lian1", "~Weixuan_Wang1", "~Wenjin_Yang2", "~Siqin_Li1", "~Xianliang_Wang1", "~Wenhui_Chen1", "~Jing_Dai2", "~QIANG_FU8", "~Yang_Wei2", "~Lanxiao_Huang1", "~Wei_Liu3"]}, "keywords": {"value": ["human enhancement", "human-agent collaboration", "game playing", "deep reinforcement learning"]}, "abstract": {"value": "Existing game AI research mainly focuses on enhancing agents' abilities to win games, but this does not inherently make humans have a better experience when collaborating with these agents. For example, agents may dominate the collaboration and exhibit unintended or detrimental behaviors, leading to poor experiences for their human partners. In other words, most game AI agents are modeled in a \"self-centered\" manner. In this paper, we propose a \"human-centered\" modeling scheme for collaborative agents that aims to enhance the experience of humans. Specifically, we model the experience of humans as the goals they expect to achieve during the task. We expect that agents should learn to enhance the extent to which humans achieve these goals while maintaining agents' original abilities (e.g., winning games). To achieve this, we propose the Reinforcement Learning from Human Gain (RLHG) approach. The RLHG approach introduces a \"baseline\", which corresponds to the extent to which humans primitively achieve their goals, and encourages agents to learn behaviors that can effectively enhance humans in achieving their goals better. We evaluate the RLHG agent in the popular Multi-player Online Battle Arena (MOBA) game, Honor of Kings, by conducting real-world human-agent tests. Both objective performance and subjective preference results show that the RLHG agent provides participants better gaming experience."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6ce678ca6108e4a85517e2526c83d7d968f7108b.pdf"}, "TLDR": {"value": "We propose a human-centered modeling approach for collaborative agents that aims to effectively enhance the experience of humans."}, "_bibtex": {"value": "@inproceedings{\ngao2024enhancing,\ntitle={Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain},\nauthor={Yiming Gao and Feiyu Liu and Liang Wang and Dehua Zheng and Zhenjie Lian and Weixuan Wang and Wenjin Yang and Siqin Li and Xianliang Wang and Wenhui Chen and Jing Dai and QIANG FU and Yang Wei and Lanxiao Huang and Wei Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BqEvdOS1Hs}\n}"}, "paperhash": {"value": "gao|enhancing_human_experience_in_humanagent_collaboration_a_humancentered_modeling_approach_based_on_positive_human_gain"}}, "number": 7798, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7798/-/Revision", "ICLR.cc/2024/Conference/Submission7798/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7798/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695486352627, "cdate": 1695486352627, "tmdate": 1709661543199, "mdate": 1709661543199, "pdate": 1705411020471, "version": 2}, {"id": "vY9nzQmQBw", "forum": "vY9nzQmQBw", "signatures": ["ICLR.cc/2024/Conference/Submission7794/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7794/Authors"], "content": {"title": {"value": "Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis"}, "authors": {"value": ["Hubert Siuzdak"]}, "authorids": {"value": ["~Hubert_Siuzdak1"]}, "keywords": {"value": ["audio synthesis", "vocoder", "GAN"]}, "abstract": {"value": "Recent advancements in neural vocoding are predominantly driven by Generative Adversarial Networks (GANs) operating in the time-domain. While effective, this approach neglects the inductive bias offered by time-frequency representations, resulting in reduntant and computionally-intensive upsampling operations. Fourier-based time-frequency representation is an appealing alternative, aligning more accurately with human auditory perception, and benefitting from well-established fast algorithms for its computation. Nevertheless, direct reconstruction of complex-valued spectrograms has been historically problematic, primarily due to phase recovery issues. This study seeks to close this gap by presenting Vocos, a new model that directly generates Fourier spectral coefficients. Vocos not only matches the state-of-the-art in audio quality, as demonstrated in our evaluations, but it also substantially improves computational efficiency, achieving an order of magnitude increase in speed compared to prevailing time-domain neural vocoding approaches. The source code and model weights have been open-sourced."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d6b6fd2b9464f306e29d42b554de0a493bb52ade.pdf"}, "_bibtex": {"value": "@inproceedings{\nsiuzdak2024vocos,\ntitle={Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis},\nauthor={Hubert Siuzdak},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vY9nzQmQBw}\n}"}, "paperhash": {"value": "siuzdak|vocos_closing_the_gap_between_timedomain_and_fourierbased_neural_vocoders_for_highquality_audio_synthesis"}}, "number": 7794, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7794/-/Revision", "ICLR.cc/2024/Conference/Submission7794/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7794/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695486177500, "cdate": 1695486177500, "tmdate": 1710557852280, "mdate": 1710557852280, "pdate": 1705411020458, "version": 2}, {"id": "YrTI2Zu0dd", "forum": "YrTI2Zu0dd", "signatures": ["ICLR.cc/2024/Conference/Submission7789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7789/Authors"], "content": {"title": {"value": "An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression"}, "authors": {"value": ["Lijia Zhou", "James B Simon", "Gal Vardi", "Nathan Srebro"]}, "authorids": {"value": ["~Lijia_Zhou1", "~James_B_Simon1", "~Gal_Vardi1", "~Nathan_Srebro1"]}, "keywords": {"value": ["kernel ridge regression", "cost of overfitting", "benign overfitting", "tempered overfitting"]}, "abstract": {"value": "We study the cost of overfitting in noisy kernel ridge regression (KRR), which we define as the ratio between the test error of the interpolating ridgeless model and the test error of the optimally-tuned model. We take an ``agnostic'' view in the following sense: we consider the cost as a function of sample size for any target function, even if the sample size is not large enough for consistency or the target is outside the RKHS. We analyze the cost of overfitting under a Gaussian universality ansatz using recently derived (non-rigorous) risk estimates in terms of the task eigenstructure. Our analysis provides a more refined characterization of benign, tempered and catastrophic overfitting (cf. Mallinar et al. 2022)."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d8be4e90683a3f7e1634819a4732c562ef29b8a9.pdf"}, "TLDR": {"value": "We study the cost of overfitting in noisy kernel ridge regression (KRR)"}, "_bibtex": {"value": "@inproceedings{\nzhou2024an,\ntitle={An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression},\nauthor={Lijia Zhou and James B Simon and Gal Vardi and Nathan Srebro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YrTI2Zu0dd}\n}"}, "paperhash": {"value": "zhou|an_agnostic_view_on_the_cost_of_overfitting_in_kernel_ridge_regression"}}, "number": 7789, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7789/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7789/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695486079195, "cdate": 1695486079195, "tmdate": 1709978053747, "mdate": 1709978053747, "pdate": 1705411020377, "version": 2}, {"id": "FAGtjl7HOw", "forum": "FAGtjl7HOw", "signatures": ["ICLR.cc/2024/Conference/Submission7781/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7781/Authors"], "content": {"title": {"value": "Explaining Kernel Clustering via Decision Trees"}, "authors": {"value": ["Maximilian Fleissner", "Leena Chennuru Vankadara", "Debarghya Ghoshdastidar"]}, "authorids": {"value": ["~Maximilian_Fleissner1", "~Leena_Chennuru_Vankadara2", "~Debarghya_Ghoshdastidar1"]}, "keywords": {"value": ["Kernel k-means", "Price of explainability"]}, "abstract": {"value": "Despite the growing popularity of explainable and interpretable machine learning, there is still surprisingly limited work on inherently interpretable clustering methods. Recently, there has been a surge of interest in explaining the classic k-means algorithm, leading to efficient algorithms that approximate k-means clusters using axis-aligned decision trees. However, interpretable variants of k-means have limited applicability in practice, where more flexible clustering methods are often needed to obtain useful partitions of the data. In this work, we investigate interpretable kernel clustering, and propose algorithms that construct decision trees to approximate the partitions induced by kernel k-means, a nonlinear extension of k-means. We further build on previous work on explainable k-means and demonstrate how a suitable choice of features allows preserving interpretability without sacrificing approximation guarantees on the interpretable model."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/92e83ec19298dc4bbddbca30bcb2e45b1a0e9a39.pdf"}, "supplementary_material": {"value": "/attachment/28ce2b712266260e3bbde5a7263b55cd3c74b9b4.zip"}, "_bibtex": {"value": "@inproceedings{\nfleissner2024explaining,\ntitle={Explaining Kernel Clustering via Decision Trees},\nauthor={Maximilian Fleissner and Leena Chennuru Vankadara and Debarghya Ghoshdastidar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FAGtjl7HOw}\n}"}, "paperhash": {"value": "fleissner|explaining_kernel_clustering_via_decision_trees"}}, "number": 7781, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7781/-/Revision", "ICLR.cc/2024/Conference/Submission7781/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7781/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695485704016, "cdate": 1695485704016, "tmdate": 1710432213096, "mdate": 1710432213096, "pdate": 1705411020127, "version": 2}, {"id": "U6Qulbv2qT", "forum": "U6Qulbv2qT", "signatures": ["ICLR.cc/2024/Conference/Submission7759/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7759/Authors"], "content": {"title": {"value": "Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes"}, "authors": {"value": ["Ruiquan Huang", "Yuan Cheng", "Jing Yang", "Vincent Tan", "Yingbin Liang"]}, "authorids": {"value": ["~Ruiquan_Huang1", "~Yuan_Cheng6", "~Jing_Yang3", "~Vincent_Tan1", "~Yingbin_Liang1"]}, "keywords": {"value": ["Reinforcement learning", "multi-task learning", "bracketing number", "predictive state representation", "POMDP"]}, "abstract": {"value": "In multi-task reinforcement learning (RL) under Markov decision processes (MDPs), the presence of shared latent structures among multiple MDPs has been shown to yield significant benefits to the sample efficiency compared to single-task RL. In this paper, we investigate whether such a benefit can extend to more general sequential decision making problems such as predictive state representations (PSRs). The main challenge here is that the large and complex model space makes it hard to identify what types of common latent structure of multi-task PSRs can reduce the model complexity and improve sample efficiency.\nTo this end, we posit a  joint model class for tasks and use the notion of $\\eta$-bracketing number to quantify its complexity; this number also serves as a general metric  to capture the similarity of tasks and thus determines the benefit of multi-task over single-task RL. We first study  upstream multi-task learning over PSRs, in which all tasks share the same observation and action spaces. We propose a provably efficient algorithm  UMT-PSR for finding near-optimal policies for all PSRs, and demonstrate that the advantage of multi-task learning manifests if the joint model class of PSRs has a smaller $\\eta$-bracketing number compared to that of individual single-task learning. We further investigate downstream learning, in which the agent needs to learn a new target task that shares some commonalities with the upstream tasks via a similarity constraint. By exploiting the learned PSRs from the upstream, we develop a sample-efficient algorithm that provably finds a near-optimal policy. \nUpon specialization to some examples with small $\\eta$-bracketing numbers, our results further highlight the benefit compared to directly learning a single-task PSR."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e04e45de352848ad2466d4c254699426119e2e33.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024provable,\ntitle={Provable Benefits of Multi-task {RL} under Non-Markovian Decision Making Processes},\nauthor={Ruiquan Huang and Yuan Cheng and Jing Yang and Vincent Tan and Yingbin Liang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=U6Qulbv2qT}\n}"}, "paperhash": {"value": "huang|provable_benefits_of_multitask_rl_under_nonmarkovian_decision_making_processes"}}, "number": 7759, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7759/-/Revision", "ICLR.cc/2024/Conference/Submission7759/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7759/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695484935692, "cdate": 1695484935692, "tmdate": 1710380540117, "mdate": 1710380540117, "pdate": 1705411019596, "version": 2}, {"id": "4r2ybzJnmN", "forum": "4r2ybzJnmN", "signatures": ["ICLR.cc/2024/Conference/Submission7757/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7757/Authors"], "content": {"title": {"value": "Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings"}, "authors": {"value": ["Ilyass Hammouamri", "Ismail Khalfaoui-Hassani", "Timoth\u00e9e Masquelier"]}, "authorids": {"value": ["~Ilyass_Hammouamri1", "~Ismail_Khalfaoui-Hassani1", "~Timoth\u00e9e_Masquelier1"]}, "keywords": {"value": ["Spiking Neural Networks", "Delays", "Neuromorphic Computing", "Speech Recognition"]}, "TLDR": {"value": "A new method to learn delays with backprop in deep spiking neural networks"}, "abstract": {"value": "Spiking Neural Networks (SNNs) are a promising research direction for building power-efficient information processing systems, especially for temporal tasks such as speech recognition. In SNNs, delays refer to the time needed for one spike to travel from one neuron to another. These delays matter because they influence the spike arrival times, and it is well-known that spiking neurons respond more strongly to coincident input spikes. More formally, it has been shown theoretically that plastic delays greatly increase the expressivity in SNNs. Yet, efficient algorithms to learn these delays have been lacking. Here, we propose a new discrete-time algorithm that addresses this issue in deep feedforward SNNs using backpropagation, in an offline manner. To simulate delays between consecutive layers, we use 1D convolutions across time. The kernels contain only a few non-zero weights \u2013 one per synapse \u2013 whose positions correspond to the delays. These positions are learned together with the weights using the recently proposed Dilated Convolution with Learnable Spacings (DCLS). We evaluated our method on three datasets: the Spiking Heidelberg Dataset (SHD), the Spiking Speech Commands (SSC) and its non spiking version Google Speech Commands v0.02 (GSC) benchmarks, which require detecting temporal patterns. We used feedforward SNNs with two or three hidden fully connected layers, and vanilla leaky integrate-and-fire neurons. We showed that fixed random delays help and that learning them helps even more. Furthermore, our method outperformed the state-of-the-art in the three datasets without using recurrent connections and with substantially fewer parameters. Our work demonstrates the potential of delay learning in developing accurate and precise models for temporal data processing. Our code is based on PyTorch / SpikingJelly and available at: https://github.com/Thvnvtos/SNN-delays"}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f1fd6afaca66ead7463f3e4cd5a92340f8e9e81e.pdf"}, "_bibtex": {"value": "@inproceedings{\nhammouamri2024learning,\ntitle={Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings},\nauthor={Ilyass Hammouamri and Ismail Khalfaoui-Hassani and Timoth{\\'e}e Masquelier},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4r2ybzJnmN}\n}"}, "paperhash": {"value": "hammouamri|learning_delays_in_spiking_neural_networks_using_dilated_convolutions_with_learnable_spacings"}}, "number": 7757, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7757/-/Revision", "ICLR.cc/2024/Conference/Submission7757/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7757/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695484891913, "cdate": 1695484891913, "tmdate": 1709661542908, "mdate": 1709661542908, "pdate": 1705411019543, "version": 2}, {"id": "GPKTIktA0k", "forum": "GPKTIktA0k", "signatures": ["ICLR.cc/2024/Conference/Submission7755/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7755/Authors"], "content": {"title": {"value": "The Reversal Curse: LLMs trained on \u201cA is B\u201d fail to learn \u201cB is A\u201d"}, "authors": {"value": ["Lukas Berglund", "Meg Tong", "Maximilian Kaufmann", "Mikita Balesni", "Asa Cooper Stickland", "Tomasz Korbak", "Owain Evans"]}, "authorids": {"value": ["~Lukas_Berglund1", "~Meg_Tong1", "~Maximilian_Kaufmann1", "~Mikita_Balesni1", "~Asa_Cooper_Stickland1", "~Tomasz_Korbak1", "~Owain_Evans1"]}, "keywords": {"value": ["LLMs", "Large Language Models", "Question Answering", "Generalization", "Knowledge Representation", "Logical Inference", "Relations"]}, "TLDR": {"value": "We demonstrate experimentally that LLMs trained on facts in one direction (\"A is B\") do not generalize to the reverse direction (\"B is A\")."}, "abstract": {"value": "We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form ''_A_ is _B_'', it will not automatically generalize to the reverse direction ''_B_ is _A_''. This is the **Reversal Curse**. For instance, if a model is trained on ''Valentina Tereshkova was the first woman to travel to space'', it will not automatically be able to answer the question, ''Who was the first woman to travel to space?''. Moreover, the likelihood of the correct answer (''Valentina Tershkova'') will not be higher than for a random name. Thus, models do not generalize a prevalent pattern in their training set: if ''_A_ is _B_'' occurs, ''_B_ is _A_'' is more likely to occur. It is worth noting, however, that if ''_A_ is _B_'' appears _in-context_, models can deduce the reverse relationship. \n\nWe provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as ''Uriah Hawthorne is the composer of _Abyssal Melodies_'' and showing that they fail to correctly answer ''Who composed _Abyssal Melodies?_''. The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation.\n\nWe also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as ''Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]'' and the reverse ''Who is Mary Lee Pfeiffer's son?''. GPT-4 correctly answers questions like the former 79\\% of the time, compared to 33\\% for the latter.\n\n Code available at: https://github.com/lukasberglund/reversal_curse."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8f0b327c2fe27ca52094fdbede8101325e1e7800.pdf"}, "supplementary_material": {"value": "/attachment/a0fb1a9ca3f83664ef1eafc51cf04c1cd0bd33d0.pdf"}, "_bibtex": {"value": "@inproceedings{\nberglund2024the,\ntitle={The Reversal Curse: {LLM}s trained on {\\textquotedblleft}A is B{\\textquotedblright} fail to learn {\\textquotedblleft}B is A{\\textquotedblright}},\nauthor={Lukas Berglund and Meg Tong and Maximilian Kaufmann and Mikita Balesni and Asa Cooper Stickland and Tomasz Korbak and Owain Evans},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GPKTIktA0k}\n}"}, "paperhash": {"value": "berglund|the_reversal_curse_llms_trained_on_a_is_b_fail_to_learn_b_is_a"}}, "number": 7755, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7755/-/Revision", "ICLR.cc/2024/Conference/Submission7755/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7755/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695484844648, "cdate": 1695484844648, "tmdate": 1712265187562, "mdate": 1712265187562, "pdate": 1705411019474, "version": 2}, {"id": "7Jwpw4qKkb", "forum": "7Jwpw4qKkb", "signatures": ["ICLR.cc/2024/Conference/Submission7739/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7739/Authors"], "content": {"title": {"value": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"}, "authors": {"value": ["Xiaogeng Liu", "Nan Xu", "Muhao Chen", "Chaowei Xiao"]}, "authorids": {"value": ["~Xiaogeng_Liu1", "~Nan_Xu2", "~Muhao_Chen1", "~Chaowei_Xiao2"]}, "keywords": {"value": ["Large Language Models", "Jailbreak Attack", "Adversarial Attack"]}, "TLDR": {"value": "In this paper, we propose a novel attack against LLMs that can automatically generate stealthy jailbreak prompts with semantic meaningfulness preserved."}, "abstract": {"value": "The aligned Large Language Models (LLMs) are powerful language understanding and decision-making tools that are created through extensive alignment with human feedback. However, these large models remain susceptible to jailbreak attacks, where adversaries manipulate prompts to elicit malicious outputs that should not be given by aligned LLMs. Investigating jailbreak prompts can lead us to delve into the limitations of LLMs and further guide us to secure them. Unfortunately, existing jailbreak techniques suffer from either (1) scalability issues, where attacks heavily rely on manual crafting of prompts, or (2) stealthiness problems, as attacks depend on token-based algorithms to generate prompts that are often semantically meaningless, making them susceptible to detection through basic perplexity testing. In light of these challenges, we intend to answer this question: Can we develop an approach that can automatically generate stealthy jailbreak prompts? In this paper, we introduce AutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can automatically generate stealthy jailbreak prompts by the carefully designed hierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN not only automates the process while preserving semantic meaningfulness, but also demonstrates superior attack strength in cross-model transferability, and cross-sample universality compared with the baseline. Moreover, we also compare AutoDAN with perplexity-based defense methods and show that AutoDAN can bypass them effectively. Code is available at https://github.com/SheltonLiu-N/AutoDAN."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7f7805e88bbe936e341887640330e3f74da3b650.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024generating,\ntitle={Generating Stealthy Jailbreak Prompts on Aligned Large Language Models},\nauthor={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7Jwpw4qKkb}\n}"}, "paperhash": {"value": "liu|autodan_generating_stealthy_jailbreak_prompts_on_aligned_large_language_models"}}, "number": 7739, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7739/-/Revision", "ICLR.cc/2024/Conference/Submission7739/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7739/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695484446326, "cdate": 1695484446326, "tmdate": 1710557692653, "mdate": 1710557692653, "pdate": 1705411019027, "version": 2}, {"id": "PXXuLvIH5r", "forum": "PXXuLvIH5r", "signatures": ["ICLR.cc/2024/Conference/Submission7734/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7734/Authors"], "content": {"title": {"value": "MixSATGEN: Learning Graph Mixing for SAT Instance Generation"}, "authors": {"value": ["Xinyan Chen", "Yang Li", "Runzhong Wang", "Junchi Yan"]}, "authorids": {"value": ["~Xinyan_Chen1", "~Yang_Li32", "~Runzhong_Wang1", "~Junchi_Yan2"]}, "keywords": {"value": ["Combinatorial Optimization", "Boolean Satisfiability Problem", "Graph Generation", "Graph Matching"]}, "abstract": {"value": "The Boolean satisfiability problem (SAT) stands as a canonical NP-complete task. In particular, the scarcity of real-world SAT instances and their usefulness for tuning SAT solvers underscore the necessity for effective and efficient ways of hard instance generation, whereas existing methods either struggle to maintain plausible hardness or suffer from limited applicability. Different from the typical construction-based methods, this paper introduces an adaptive and efficient graph interpolation approach that in place modifies the raw structure of graph-represented SAT instance by replacing it with a counterpart from another instance. Specifically, it involves a two-stage matching and mixing pipeline. The matching aims to find a correspondence map of literal nodes from two instance graphs via learned features from a matching network; while the mixing stage involves iteratively exchanging clause pairs with the highest correspondence scores until a specified replacement ratio is achieved. We further show that under our matching-mixing framework, moderate randomness can avoid hardness degradation of instances by introducing Gumbel noise. Experimental results show the superiority of our method with both resemblance in structure and hardness, and general applicability."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/deb8544197d35dd8d0d5d3613853b75f5351bb71.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024from,\ntitle={From Matching to Mixing: A Graph Interpolation Approach for {SAT} Instance Generation},\nauthor={Xinyan Chen and Yang Li and Runzhong Wang and Junchi Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PXXuLvIH5r}\n}"}, "paperhash": {"value": "chen|mixsatgen_learning_graph_mixing_for_sat_instance_generation"}}, "number": 7734, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7734/-/Revision", "ICLR.cc/2024/Conference/Submission7734/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7734/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695484240878, "cdate": 1695484240878, "tmdate": 1711437966609, "mdate": 1711437966609, "pdate": 1705411018955, "version": 2}, {"id": "RyUvzda8GH", "forum": "RyUvzda8GH", "signatures": ["ICLR.cc/2024/Conference/Submission7725/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7725/Authors"], "content": {"title": {"value": "A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks"}, "authors": {"value": ["Tommaso Salvatori", "Yuhang Song", "Yordan Yordanov", "Beren Millidge", "Lei Sha", "Cornelius Emde", "Zhenghua Xu", "Rafal Bogacz", "Thomas Lukasiewicz"]}, "authorids": {"value": ["~Tommaso_Salvatori1", "~Yuhang_Song1", "~Yordan_Yordanov1", "~Beren_Millidge1", "~Lei_Sha1", "~Cornelius_Emde1", "~Zhenghua_Xu1", "~Rafal_Bogacz1", "~Thomas_Lukasiewicz2"]}, "keywords": {"value": ["Cognitive Science", "parallelization"]}, "abstract": {"value": "Predictive coding networks are neuroscience-inspired models with roots in both Bayesian statistics and neuroscience. Training such models, however, is quite inefficient and unstable. In this work, we show how by simply changing the temporal scheduling of the update rule for the synaptic weights leads to an algorithm that is much more efficient and stable than the original one, and has theoretical guarantees in terms of convergence. The proposed algorithm, that we call incremental predictive coding (iPC) is also more biologically plausible than the original one, as it it fully automatic. In an extensive set of experiments, we show that iPC constantly performs better than the original formulation on a large number of benchmarks for image classification, as well as for the training of both conditional and masked language models, in terms of test accuracy, efficiency, and convergence with respect to a large set of hyperparameters."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/44d053d08f335ed3b0c3e59491bc957e0c2cc2eb.pdf"}, "_bibtex": {"value": "@inproceedings{\nsalvatori2024a,\ntitle={A Stable, Fast, and Fully Automatic Learning Algorithm for Predictive Coding Networks},\nauthor={Tommaso Salvatori and Yuhang Song and Yordan Yordanov and Beren Millidge and Lei Sha and Cornelius Emde and Zhenghua Xu and Rafal Bogacz and Thomas Lukasiewicz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RyUvzda8GH}\n}"}, "paperhash": {"value": "salvatori|a_stable_fast_and_fully_automatic_learning_algorithm_for_predictive_coding_networks"}}, "number": 7725, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7725/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7725/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483893553, "cdate": 1695483893553, "tmdate": 1710436558691, "mdate": 1710436558691, "pdate": 1705411018681, "version": 2}, {"id": "DjIsNDEOYX", "forum": "DjIsNDEOYX", "signatures": ["ICLR.cc/2024/Conference/Submission7723/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7723/Authors"], "content": {"title": {"value": "Scalable Monotonic Neural Networks"}, "authors": {"value": ["Hyunho Kim", "Jong-Seok Lee"]}, "authorids": {"value": ["~Hyunho_Kim2", "~Jong-Seok_Lee2"]}, "keywords": {"value": ["neural networks", "monotonicity", "scalability", "conventional error-backpropagation"]}, "abstract": {"value": "In this research, we focus on the problem of learning monotonic neural networks, as preserving the monotonicity of a model with respect to a subset of inputs is crucial for practical applications across various domains. Although several methods have recently been proposed to address this problem, they have limitations such as not guaranteeing monotonicity in certain cases, requiring additional inference time, lacking scalability with increasing network size and number of monotonic inputs, and manipulating network weights during training. To overcome these limitations, we introduce a simple but novel architecture of the partially connected network which incorporates a 'scalable monotonic hidden layer' comprising three units: the exponentiated unit, ReLU unit, and confluence unit. This allows for the repetitive integration of the scalable monotonic hidden layers without other structural constraints. Consequently, our method offers ease of implementation and rapid training through the conventional error-backpropagation algorithm. We accordingly term this method as Scalable Monotonic Neural Networks (SMNN). Numerical experiments demonstrated that our method achieved comparable prediction accuracy to the state-of-the-art approaches while effectively addressing the aforementioned weaknesses."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4659f41f940610cc73b4142d71235fc0bbdff339.pdf"}, "supplementary_material": {"value": "/attachment/9d0f373f9c75711c40bc57099dc4e044b4f00804.zip"}, "_bibtex": {"value": "@inproceedings{\nkim2024scalable,\ntitle={Scalable Monotonic Neural Networks},\nauthor={Hyunho Kim and Jong-Seok Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DjIsNDEOYX}\n}"}, "paperhash": {"value": "kim|scalable_monotonic_neural_networks"}}, "number": 7723, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7723/-/Revision", "ICLR.cc/2024/Conference/Submission7723/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7723/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483864579, "cdate": 1695483864579, "tmdate": 1710420225413, "mdate": 1710420225413, "pdate": 1705411018585, "version": 2}, {"id": "s2NjWfaYdZ", "forum": "s2NjWfaYdZ", "signatures": ["ICLR.cc/2024/Conference/Submission7722/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7722/Authors"], "content": {"title": {"value": "Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models"}, "authors": {"value": ["Seungcheol Park", "Hojun Choi", "U Kang"]}, "authorids": {"value": ["~Seungcheol_Park1", "~Hojun_Choi1", "~U_Kang1"]}, "keywords": {"value": ["Retraining-free", "Pruning", "Compression", "Transformers"]}, "TLDR": {"value": "We propose Kprune, an accurate retraining-free structured pruning algorithm for Transformers. Kprune shows up to 58%p higher F1 score than existing retraining-free pruning algorithms on the SQuAD benchmark."}, "abstract": {"value": "Given a pretrained encoder-based language model, how can we accurately compress it without retraining? Retraining-free structured pruning algorithms are crucial in pretrained language model compression due to their significantly reduced pruning cost and capability to prune large language models. However, existing retraining-free algorithms encounter severe accuracy degradation, as they fail to handle pruning errors, especially at high compression rates. In this paper, we propose KPrune (Knowledge-preserving pruning), an accurate retraining-free structured pruning algorithm for pretrained encoder-based language models.\nKPrune focuses on preserving the useful knowledge of the pretrained model to minimize pruning errors through a carefully designed iterative pruning process composed of knowledge measurement, knowledge-preserving mask search, and knowledge-preserving weight-tuning. As a result, KPrune shows significant accuracy improvements up to 58.02%p higher F1 score compared to existing retraining-free pruning algorithms under a high compression rate of 80% on the SQuAD benchmark without any retraining process."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7be529579f3a50dbe8a628d518b7986357e95d8c.pdf"}, "_bibtex": {"value": "@inproceedings{\npark2024accurate,\ntitle={Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models},\nauthor={Seungcheol Park and Hojun Choi and U Kang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=s2NjWfaYdZ}\n}"}, "paperhash": {"value": "park|accurate_retrainingfree_pruning_for_pretrained_encoderbased_language_models"}}, "number": 7722, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7722/-/Revision", "ICLR.cc/2024/Conference/Submission7722/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7722/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483853468, "cdate": 1695483853468, "tmdate": 1709661542462, "mdate": 1709661542462, "pdate": 1705411018548, "version": 2}, {"id": "x5LvBK43wg", "forum": "x5LvBK43wg", "signatures": ["ICLR.cc/2024/Conference/Submission7713/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7713/Authors"], "content": {"title": {"value": "PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation"}, "authors": {"value": ["Haopeng Sun", "Lumin Xu", "Sheng Jin", "Ping Luo", "Chen Qian", "Wentao Liu"]}, "authorids": {"value": ["~Haopeng_Sun1", "~Lumin_Xu1", "~Sheng_Jin1", "~Ping_Luo2", "~Chen_Qian1", "~Wentao_Liu1"]}, "keywords": {"value": ["test-time adaptation", "domain adaptation", "domain shift"]}, "TLDR": {"value": "This work proposes a novel test-time adaptation method, namely PROGRAM, for robust target domain adaptation by exploiting noisy pseudo-labels."}, "abstract": {"value": "Test-time adaptation (TTA) aims to adapt a pre-trained model from a source domain to a target domain only using online unlabeled target data during testing, without accessing to the source data or modifying the original training process. Among the various TTA methods, pseudo-labeling has gained popularity. However, the presence of incorrect pseudo-labels can hinder the effectiveness of target domain adaptation. To overcome this challenge, we propose a novel TTA method, called PROtotype GRAph Model based pseudo-label learning (PROGRAM). PROGRAM consists of two key components: (1) Prototype Graph Model (PGM) for reliable pseudo-label generation; (2) Robust Self-Training (RST) for test-time adaptation with noisy pseudo-labels. PGM constructs the graph using prototypes and test samples, facilitating effective message passing among them to generate more reliable pseudo-labels. RST combines the advantages of consistency regularization and pseudo-labeling to achieve robust target domain adaptation in the presence of noisy pseudo-labels. Our proposed PROGRAM can be easily integrated into existing baselines, resulting in consistent improvement. Extensive experiments show that our PROGRAM outperforms the existing TTA methods on multiple domain generalization and image corruption benchmarks."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/abf81b71b6719508d36fb748baf090a1daf94937.pdf"}, "_bibtex": {"value": "@inproceedings{\nsun2024program,\ntitle={{PROGRAM}: {PRO}totype {GRA}ph Model based Pseudo-Label Learning for Test-Time Adaptation},\nauthor={Haopeng Sun and Lumin Xu and Sheng Jin and Ping Luo and Chen Qian and Wentao Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=x5LvBK43wg}\n}"}, "paperhash": {"value": "sun|program_prototype_graph_model_based_pseudolabel_learning_for_testtime_adaptation"}}, "number": 7713, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7713/-/Revision", "ICLR.cc/2024/Conference/Submission7713/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7713/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483589206, "cdate": 1695483589206, "tmdate": 1710389709840, "mdate": 1710389709840, "pdate": 1705411018108, "version": 2}, {"id": "xC8xh2RSs2", "forum": "xC8xh2RSs2", "signatures": ["ICLR.cc/2024/Conference/Submission7712/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7712/Authors"], "content": {"title": {"value": "Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace"}, "authors": {"value": ["Xinyu Yang", "Weixin Liang", "James Zou"]}, "authorids": {"value": ["~Xinyu_Yang5", "~Weixin_Liang1", "~James_Zou1"]}, "keywords": {"value": ["dataset documentation", "data-centric AI", "large-scale analysis"]}, "abstract": {"value": "Advances in machine learning are closely tied to the creation of datasets. While data documentation is widely recognized as essential to the reliability, reproducibility, and transparency of ML, we lack a systematic empirical understanding of current dataset documentation practices. To shed light on this question, here we take Hugging Face - one of the largest platforms for sharing and collaborating on ML models and datasets -  as a prominent case study. By analyzing all 7,433 dataset documentation on Hugging Face, our investigation provides an overview of the Hugging Face dataset ecosystem and insights into dataset documentation practices, yielding 5 main findings: (1) The dataset card completion rate shows marked heterogeneity correlated with dataset popularity: While 86.0\\% of the top 100 downloaded dataset cards fill out all sections suggested by Hugging Face community, only 7.9\\% of dataset cards with no downloads complete all these sections. (2) A granular examination of each section within the dataset card reveals that the practitioners seem to prioritize Dataset Description and Dataset Structure sections, accounting for 36.2\\% and 33.6\\% of the total card length, respectively, for the most downloaded datasets. In contrast, the Considerations for Using the Data section receives the lowest proportion of content, accounting for just 2.1\\% of the text. (3) By analyzing the subsections within each section and utilizing topic modeling to identify key topics, we uncover what is discussed in each section, and underscore significant themes encompassing both technical and social impacts, as well as limitations within the Considerations for Using the Data section. (4) Our findings also highlight the need for improved accessibility and reproducibility of datasets in the Usage sections. (5) In addition, our human annotation evaluation emphasizes the pivotal role of comprehensive dataset content in shaping individuals' perceptions of a dataset card's overall quality. Overall, our study offers a unique perspective on analyzing dataset documentation through large-scale data science analysis and underlines the need for more thorough dataset documentation in machine learning research."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/57002f23415c9a3640dd438f61e8487b5eb59bc2.pdf"}, "supplementary_material": {"value": "/attachment/c830b9d0854d4c57d08ce58506ae91ba3a22ed10.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024navigating,\ntitle={Navigating Dataset Documentations in {AI}: A Large-Scale Analysis of Dataset Cards on HuggingFace},\nauthor={Xinyu Yang and Weixin Liang and James Zou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xC8xh2RSs2}\n}"}, "paperhash": {"value": "yang|navigating_dataset_documentations_in_ai_a_largescale_analysis_of_dataset_cards_on_huggingface"}}, "number": 7712, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7712/-/Revision", "ICLR.cc/2024/Conference/Submission7712/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7712/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483527955, "cdate": 1695483527955, "tmdate": 1710357605464, "mdate": 1710357605464, "pdate": 1705411018092, "version": 2}, {"id": "hkSjjs4o5d", "forum": "hkSjjs4o5d", "signatures": ["ICLR.cc/2024/Conference/Submission7708/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7708/Authors"], "content": {"title": {"value": "A Differentially Private Clustering Algorithm for Well-Clustered Graphs"}, "authors": {"value": ["Weiqiang He", "Hendrik Fichtenberger", "Pan Peng"]}, "authorids": {"value": ["~Weiqiang_He1", "~Hendrik_Fichtenberger1", "~Pan_Peng1"]}, "keywords": {"value": ["differential privacy", "graph clustering", "semidefinite programming", "spectral clustering"]}, "abstract": {"value": "We study differentially private (DP) algorithms for recovering clusters in well-clustered graphs, which are graphs whose vertex set can be partitioned into a small number of sets, each inducing a subgraph of high inner conductance and small outer conductance. Such graphs have widespread application as a benchmark in the theoretical analysis of spectral clustering.\nWe provide an efficient ($\\epsilon$,$\\delta$)-DP algorithm tailored specifically for such graphs. Our algorithm draws inspiration from the recent work of Chen et al., who developed DP algorithms for recovery of stochastic block models in cases where the graph comprises exactly two nearly-balanced clusters. Our algorithm works for well-clustered graphs with $k$ nearly-balanced clusters, and the misclassification ratio almost matches the one of the best-known non-private algorithms. We conduct experimental evaluations on datasets with known ground truth clusters to substantiate the prowess of our algorithm. We also show that any (pure) $\\epsilon$-DP algorithm would result in substantial error."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/932c357f99c7bafe3b57c4d6ba322cd4ad35c5c6.pdf"}, "TLDR": {"value": "Differentially private spectral clustering that nearly matches non-private bounds"}, "_bibtex": {"value": "@inproceedings{\nhe2024a,\ntitle={A Differentially Private Clustering Algorithm for Well-Clustered Graphs},\nauthor={Weiqiang He and Hendrik Fichtenberger and Pan Peng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hkSjjs4o5d}\n}"}, "paperhash": {"value": "he|a_differentially_private_clustering_algorithm_for_wellclustered_graphs"}}, "number": 7708, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7708/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7708/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483462525, "cdate": 1695483462525, "tmdate": 1710929429402, "mdate": 1710929429402, "pdate": 1705411017979, "version": 2}, {"id": "EW8ZExRZkJ", "forum": "EW8ZExRZkJ", "signatures": ["ICLR.cc/2024/Conference/Submission7702/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7702/Authors"], "content": {"title": {"value": "Minimax optimality of convolutional neural networks for infinite dimensional input-output problems and separation from kernel methods"}, "authors": {"value": ["Yuto Nishimura", "Taiji Suzuki"]}, "authorids": {"value": ["~Yuto_Nishimura1", "~Taiji_Suzuki1"]}, "keywords": {"value": ["neural network", "nonlinear operator learning", "convolutional network", "estimation error analysis"]}, "abstract": {"value": "Recent deep learning applications, exemplified by text-to-image tasks, often involve high-dimensional inputs and outputs. While several studies have investigated the function estimation capabilities of deep learning, research on dilated convolutional neural networks (CNNs) has mainly focused on cases where input dimensions are infinite but output dimensions are one-dimensional, similar to many other studies. However, many practical deep learning tasks involve high-dimensional (or even infinite dimensional) inputs and outputs.\nIn this paper, we investigate the optimality of dilated CNNs for estimating a map between infinite-dimensional input and output spaces \nby analyzing their approximation and estimation abilities. \nFor that purpose, we first show that approximation and estimation errors depend only on the smoothness and decay rate with respect to the infinity norm of the output, and their estimation accuracy actually achieve the {\\it minimax optimal} rate of convergence.\nSecond, we demonstrate that the dilated CNNs outperform {\\it any} linear estimators including kernel ridge regression and $k$-NN estimators in a minimax error sense, highlighting the usefulness of feature learning realized by deep neural networks.\nOur theoretical analysis particularly explains the success of deep learning in recent high-dimensional input-output tasks."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4b7946387cd61ff2ae4a8ba6793aed54e90f4b5d.pdf"}, "supplementary_material": {"value": "/attachment/cf43fff57246ed4b7062ed641df5c64464771c7a.pdf"}, "_bibtex": {"value": "@inproceedings{\nnishimura2024minimax,\ntitle={Minimax optimality of convolutional neural networks for infinite dimensional input-output problems and separation from kernel methods},\nauthor={Yuto Nishimura and Taiji Suzuki},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EW8ZExRZkJ}\n}"}, "paperhash": {"value": "nishimura|minimax_optimality_of_convolutional_neural_networks_for_infinite_dimensional_inputoutput_problems_and_separation_from_kernel_methods"}}, "number": 7702, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7702/-/Revision", "ICLR.cc/2024/Conference/Submission7702/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7702/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483201598, "cdate": 1695483201598, "tmdate": 1710956350292, "mdate": 1710956350292, "pdate": 1705411017734, "version": 2}, {"id": "XOnya9gSdF", "forum": "XOnya9gSdF", "signatures": ["ICLR.cc/2024/Conference/Submission7700/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7700/Authors"], "content": {"title": {"value": "Consistent algorithms for multi-label classification with macro-at-$k$ metrics"}, "authors": {"value": ["Erik Schultheis", "Wojciech Kotlowski", "Marek Wydmuch", "Rohit Babbar", "Strom Borman", "Krzysztof Dembczynski"]}, "authorids": {"value": ["~Erik_Schultheis1", "~Wojciech_Kotlowski1", "~Marek_Wydmuch1", "~Rohit_Babbar1", "~Strom_Borman1", "~Krzysztof_Dembczynski1"]}, "keywords": {"value": ["multi-label classification", "complex performance metrics", "macro-at-k", "extreme classification"]}, "abstract": {"value": "We consider the optimization of complex performance metrics in multi-label classification under the population utility framework. We mainly focus on metrics linearly decomposable into a sum of binary classification utilities applied separately to each label with an additional requirement of exactly $k$ labels predicted for each instance. These \"macro-at-$k$\" metrics possess desired properties for extreme classification problems with long tail labels. Unfortunately, the at-$k$ constraint couples the otherwise independent binary classification tasks, leading to a much more challenging optimization problem than standard macro-averages. We provide a statistical framework to study this problem, prove the existence and the form of the optimal classifier, and propose a statistically consistent and practical learning algorithm based on the Frank-Wolfe method. Interestingly, our main results concern even more general metrics being non-linear functions of label-wise confusion matrices. Empirical results provide evidence for the competitive performance of the proposed approach."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8c5e51c7184328839fb5ad7fbbdc547b7724d266.pdf"}, "_bibtex": {"value": "@inproceedings{\nschultheis2024consistent,\ntitle={Consistent algorithms for multi-label classification with macro-at-\\$k\\$ metrics},\nauthor={Erik Schultheis and Wojciech Kotlowski and Marek Wydmuch and Rohit Babbar and Strom Borman and Krzysztof Dembczynski},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XOnya9gSdF}\n}"}, "paperhash": {"value": "schultheis|consistent_algorithms_for_multilabel_classification_with_macroatk_metrics"}}, "number": 7700, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7700/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7700/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483161825, "cdate": 1695483161825, "tmdate": 1713130858541, "mdate": 1713130858541, "pdate": 1705411017626, "version": 2}, {"id": "d4uL2MSe0z", "forum": "d4uL2MSe0z", "signatures": ["ICLR.cc/2024/Conference/Submission7696/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7696/Authors"], "content": {"title": {"value": "Dynamic Layer Tying for Parameter-Efficient Transformers"}, "authors": {"value": ["Tamir David Hay", "Lior Wolf"]}, "authorids": {"value": ["~Tamir_David_Hay1", "~Lior_Wolf1"]}, "keywords": {"value": ["NLP", "Transformer", "Reinforcement Learning"]}, "abstract": {"value": "In the pursuit of reducing the number of trainable parameters in deep transformer networks, we employ Reinforcement Learning to dynamically select layers during training and tie them together. Every few iterations, the RL agent is asked whether to train each layer $i$ independently or to copy the weights of a previous layer $j<i$. This facilitates weight sharing, reduces the number of trainable parameters, and also serves as an effective regularization technique. Experimental evaluations validate that our model modestly outperforms the baseline transformer model with regard to perplexity and drastically reduces the number of trainable parameters. In particular, the memory consumption during training is up to one order of magnitude less than the conventional training method."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c26efad7ae662b09d7ad8d828fce467759a8686f.pdf"}, "supplementary_material": {"value": "/attachment/448b17a582c978ee8369ca2926fc01a7901a551f.zip"}, "_bibtex": {"value": "@inproceedings{\nhay2024dynamic,\ntitle={Dynamic Layer Tying for Parameter-Efficient Transformers},\nauthor={Tamir David Hay and Lior Wolf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d4uL2MSe0z}\n}"}, "paperhash": {"value": "hay|dynamic_layer_tying_for_parameterefficient_transformers"}}, "number": 7696, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7696/-/Revision", "ICLR.cc/2024/Conference/Submission7696/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7696/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695483133125, "cdate": 1695483133125, "tmdate": 1709661542083, "mdate": 1709661542083, "pdate": 1705411017440, "version": 2}, {"id": "ymjI8feDTD", "forum": "ymjI8feDTD", "signatures": ["ICLR.cc/2024/Conference/Submission7687/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7687/Authors"], "content": {"title": {"value": "Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion"}, "authors": {"value": ["Dongjun Kim", "Chieh-Hsin Lai", "Wei-Hsiang Liao", "Naoki Murata", "Yuhta Takida", "Toshimitsu Uesaka", "Yutong He", "Yuki Mitsufuji", "Stefano Ermon"]}, "authorids": {"value": ["~Dongjun_Kim1", "~Chieh-Hsin_Lai2", "~Wei-Hsiang_Liao1", "~Naoki_Murata1", "~Yuhta_Takida1", "~Toshimitsu_Uesaka1", "~Yutong_He1", "~Yuki_Mitsufuji1", "~Stefano_Ermon1"]}, "keywords": {"value": ["Diffusion Models; Score-based Models; Generative Models; Generative AI; Deep Generative Models; Distillation Models"]}, "TLDR": {"value": "Our model integrates score-based models and distillation models by learning the entire ODE trajectory, resulting in SOTA FID for CIFAR-10 and ImageNet."}, "abstract": {"value": "Consistency Models (CM) (Song et al., 2023) accelerate score-based diffusion model sampling at the cost of sample quality but lack a natural way to trade-off quality for speed. To address this limitation, we propose Consistency Trajectory Model (CTM), a generalization encompassing CM and score-based models as special cases. CTM trains a single neural network that can -- in a single forward pass -- output scores (i.e., gradients of log-density) and enables unrestricted traversal between any initial and final time along the Probability Flow Ordinary Differential Equation (ODE) in a diffusion process. CTM enables the efficient combination of adversarial training and denoising score matching loss to enhance performance and achieves new state-of-the-art FIDs for single-step diffusion model sampling on CIFAR-10 (FID 1.73) and ImageNet at 64X64 resolution (FID 1.92). CTM also enables a new family of sampling schemes, both deterministic and stochastic, involving long jumps along the ODE solution trajectories. It consistently improves sample quality as computational budgets increase, avoiding the degradation seen in CM. Furthermore, unlike CM, CTM's access to the score function can streamline the adoption of established controllable/conditional generation methods from the diffusion community. This access also enables the computation of likelihood. The code is available at https://github.com/sony/ctm."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f46141686c6fc27b73793bb443c11c61e7dc87b8.pdf"}, "supplementary_material": {"value": "/attachment/2a54591f4ef51579de69ab7331179c5bd6e9f8df.zip"}, "_bibtex": {"value": "@inproceedings{\nkim2024consistency,\ntitle={Consistency Trajectory Models: Learning Probability Flow {ODE} Trajectory of Diffusion},\nauthor={Dongjun Kim and Chieh-Hsin Lai and Wei-Hsiang Liao and Naoki Murata and Yuhta Takida and Toshimitsu Uesaka and Yutong He and Yuki Mitsufuji and Stefano Ermon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ymjI8feDTD}\n}"}, "paperhash": {"value": "kim|consistency_trajectory_models_learning_probability_flow_ode_trajectory_of_diffusion"}}, "number": 7687, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7687/-/Revision", "ICLR.cc/2024/Conference/Submission7687/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7687/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695482803454, "cdate": 1695482803454, "tmdate": 1711748990522, "mdate": 1711748990522, "pdate": 1705411017179, "version": 2}, {"id": "icTZCUbtD6", "forum": "icTZCUbtD6", "signatures": ["ICLR.cc/2024/Conference/Submission7682/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7682/Authors"], "content": {"title": {"value": "Dissecting Sample Hardness: A Fine-Grained Analysis of Hardness Characterization Methods for Data-Centric AI"}, "authors": {"value": ["Nabeel Seedat", "Fergus Imrie", "Mihaela van der Schaar"]}, "authorids": {"value": ["~Nabeel_Seedat1", "~Fergus_Imrie1", "~Mihaela_van_der_Schaar2"]}, "keywords": {"value": ["data-centric AI", "hardness characterization", "data-centric ML", "DMLR", "benchmarking"]}, "TLDR": {"value": "A fine-grained analysis of Hardness Characterization Methods across multiple hardness types"}, "abstract": {"value": "Characterizing samples that are difficult to learn from is crucial to developing highly performant ML models. This has led to numerous Hardness Characterization Methods (HCMs) that aim to identify ''hard'' samples. However, there is a lack of consensus regarding the definition and evaluation of ''hardness''. Unfortunately, current HCMs have only been evaluated on specific types of hardness and often only qualitatively or with respect to downstream performance, overlooking the fundamental quantitative identification task. We address this gap by presenting a fine-grained taxonomy of hardness types. Additionally, we propose the Hardness Characterization Analysis Toolkit (H-CAT), which supports comprehensive and quantitative benchmarking of HCMs across the hardness taxonomy and can easily be extended to new HCMs, hardness types, and datasets. We use H-CAT to evaluate 13 different HCMs across 8 hardness types. This comprehensive evaluation encompassing over 14K setups uncovers strengths and weaknesses of different HCMs, leading to practical tips to guide HCM selection and future development. Our findings highlight the need for more comprehensive HCM evaluation, while we hope our hardness taxonomy and toolkit will advance the principled evaluation and uptake of data-centric AI methods."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/93ef1eed403de9b38d8f5e449bb2686deceec150.pdf"}, "supplementary_material": {"value": "/attachment/f6646837921bc5e67e60c0f0aff42cca93d5cc3e.pdf"}, "_bibtex": {"value": "@inproceedings{\nseedat2024dissecting,\ntitle={Dissecting sample hardness: Fine-grained analysis of Hardness Characterization Methods},\nauthor={Nabeel Seedat and Fergus Imrie and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=icTZCUbtD6}\n}"}, "paperhash": {"value": "seedat|dissecting_sample_hardness_a_finegrained_analysis_of_hardness_characterization_methods_for_datacentric_ai"}}, "number": 7682, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7682/-/Revision", "ICLR.cc/2024/Conference/Submission7682/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7682/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695482639731, "cdate": 1695482639731, "tmdate": 1710339993402, "mdate": 1710339993402, "pdate": 1705411017008, "version": 2}, {"id": "1OfAO2mes1", "forum": "1OfAO2mes1", "signatures": ["ICLR.cc/2024/Conference/Submission7677/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7677/Authors"], "content": {"title": {"value": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"}, "authors": {"value": ["Soumyadeep Pal", "Yuguang Yao", "Ren Wang", "Bingquan Shen", "Sijia Liu"]}, "authorids": {"value": ["~Soumyadeep_Pal1", "~Yuguang_Yao1", "~Ren_Wang1", "~Bingquan_Shen1", "~Sijia_Liu1"]}, "keywords": {"value": ["Backdoor Detection", "Backdoor Attack", "Data Poisoning", "AI Security", "Deep learning"]}, "abstract": {"value": "Modern machine learning (ML) systems demand substantial training data, often resorting to external sources. Nevertheless, this practice renders them vulnerable to backdoor poisoning attacks. Prior backdoor defense strategies have primarily focused on the identification of backdoored models or poisoned data characteristics, typically operating under the assumption of access to clean data. In this work, we delve into a relatively underexplored challenge: the automatic identification of backdoor data within a poisoned dataset, all under realistic conditions, *i.e.*,  without the need for additional clean data or without manually defining a threshold for backdoor detection. We draw an inspiration from the scaled prediction consistency (SPC) technique, which exploits the prediction invariance of poisoned data to an input scaling factor. Based on this, we pose the backdoor data identification problem as a hierarchical data splitting optimization problem, leveraging a novel SPC-based loss function as the primary optimization objective. Our innovation unfolds in several key aspects. First, we revisit the vanilla SPC method, unveiling its limitations in addressing the proposed backdoor identification problem. Subsequently, we develop a bi-level optimization-based approach to precisely identify backdoor data by minimizing the advanced SPC loss. Finally, we demonstrate the efficacy of our proposal against a spectrum of backdoor attacks, encompassing basic label-corrupted attacks as well as more sophisticated clean-label attacks, evaluated across various benchmark datasets. Experiment results show that our approach often surpasses the performance of current baselines in identifying backdoor data points, resulting in about 4\\%-36\\% improvement in average AUROC. Codes are available at https://github.com/OPTML-Group/BackdoorMSPC."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/65154e63dca5bc5a618863dc344eaf6912916794.pdf"}, "supplementary_material": {"value": "/attachment/d2c5665558b4c332568545796e2d21302eb03e53.zip"}, "_bibtex": {"value": "@inproceedings{\npal2024backdoor,\ntitle={Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency},\nauthor={Soumyadeep Pal and Yuguang Yao and Ren Wang and Bingquan Shen and Sijia Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1OfAO2mes1}\n}"}, "paperhash": {"value": "pal|backdoor_secrets_unveiled_identifying_backdoor_data_with_optimized_scaled_prediction_consistency"}}, "number": 7677, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7677/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7677/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695482538319, "cdate": 1695482538319, "tmdate": 1710539343512, "mdate": 1710539343512, "pdate": 1705411016909, "version": 2}, {"id": "Ch7WqGcGmb", "forum": "Ch7WqGcGmb", "signatures": ["ICLR.cc/2024/Conference/Submission7658/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7658/Authors"], "content": {"title": {"value": "Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants"}, "authors": {"value": ["Peter Richt\u00e1rik", "Elnur Gasanov", "Konstantin Pavlovich Burlachenko"]}, "authorids": {"value": ["~Peter_Richt\u00e1rik1", "~Elnur_Gasanov1", "~Konstantin_Pavlovich_Burlachenko1"]}, "keywords": {"value": ["error feedback", "greedy sparsification", "distributed optimization", "communication complexity", "machine cloning", "weighted error feedback", "quadratic mean", "arithmetic mean", "large stepsizes"]}, "abstract": {"value": "Error feedback (EF) is a highly popular and immensely effective mechanism for fixing convergence issues which arise in distributed training methods (such as distributed GD or SGD) when these are enhanced with greedy communication compression techniques such as Top-k. While EF was proposed almost a decade ago (Seide et al, 2014), and despite concentrated effort by the community to advance the theoretical understanding of this mechanism, there is still a lot to explore. In this work we study a modern form of error feedback called EF21 (Richt\u00e1rik et al, 2021) which offers the currently best-known theoretical guarantees, under the weakest assumptions, and also works well in practice. In particular, while the theoretical communication complexity of EF21 depends on the quadratic mean of certain smoothness parameters, we improve this dependence to their arithmetic mean, which is always smaller, and can be substantially smaller, especially in heterogeneous data regimes. We take the reader on a journey of our discovery process. Starting with the idea of applying EF21 to an equivalent reformulation of the underlying problem which (unfortunately) requires (often impractical) machine cloning, we continue to the discovery of a new weighted version of EF21 which can (fortunately) be executed without any cloning, and finally circle back to an improved analysis of the original EF21 method. While this development applies to the simplest form of EF21, our approach naturally extends to more elaborate variants involving stochastic gradients and partial participation. Further, our technique improves the best-known theory of EF21 in the rare features regime (Richt\u00e1rik et al, 2023). Finally, we validate our theoretical findings with suitable experiments."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4646272f3ec362b2dc58601156130afb86614d72.pdf"}, "supplementary_material": {"value": "/attachment/a8bf5d77da65d4c9a835ff63dfb4687ca5e39a5f.zip"}, "_bibtex": {"value": "@inproceedings{\nricht{\\'a}rik2024error,\ntitle={Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants},\nauthor={Peter Richt{\\'a}rik and Elnur Gasanov and Konstantin Pavlovich Burlachenko},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ch7WqGcGmb}\n}"}, "paperhash": {"value": "richt\u00e1rik|error_feedback_reloaded_from_quadratic_to_arithmetic_mean_of_smoothness_constants"}}, "number": 7658, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7658/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7658/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695482012891, "cdate": 1695482012891, "tmdate": 1710403208169, "mdate": 1710403208169, "pdate": 1705411016456, "version": 2}, {"id": "2inBuwTyL2", "forum": "2inBuwTyL2", "signatures": ["ICLR.cc/2024/Conference/Submission7654/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7654/Authors"], "content": {"title": {"value": "Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks"}, "authors": {"value": ["Ben Eisner", "Yi Yang", "Todor Davchev", "Mel Vecerik", "Jonathan Scholz", "David Held"]}, "authorids": {"value": ["~Ben_Eisner1", "~Yi_Yang10", "~Todor_Davchev1", "~Mel_Vecerik1", "~Jonathan_Scholz2", "~David_Held1"]}, "keywords": {"value": ["Learning from Demonstration", "Manipulation", "3D Learning", "SE(3) Equivariance"]}, "abstract": {"value": "Many robot manipulation tasks can be framed as geometric reasoning tasks, where an agent must be able to precisely manipulate an object into a position that satisfies the task from a set of initial conditions. Often, task success is defined based on the relationship between two objects - for instance, hanging a mug on a rack.  In such cases, the solution should be equivariant to the initial position of the objects as well as the agent, and invariant to the pose of the camera. This poses a challenge for learning systems which attempt to solve this task by learning directly from high-dimensional demonstrations: the agent must learn to be both equivariant as well as precise, which can be challenging without any inductive biases about the problem. In this work, we propose a method for precise relative pose prediction which is provably SE(3)-equivariant, can be learned from only a few demonstrations, and can generalize across variations in a class of objects. We accomplish this by factoring the problem into learning an SE(3) invariant task-specific representation of the scene and then interpreting this representation with novel geometric reasoning layers which are provably SE(3) equivariant. We demonstrate that our method can yield substantially more precise placement predictions in simulated placement tasks than previous methods trained with the same amount of data, and can accurately represent relative placement relationships data collected from real-world demonstrations. Supplementary information and videos can be found at https://sites.google.com/view/reldist-iclr-2023."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dd9df4ab36e1ad9afd17e997264a7c5f12256975.pdf"}, "_bibtex": {"value": "@inproceedings{\neisner2024deep,\ntitle={Deep {SE}(3)-Equivariant Geometric Reasoning for Precise Placement Tasks},\nauthor={Ben Eisner and Yi Yang and Todor Davchev and Mel Vecerik and Jonathan Scholz and David Held},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2inBuwTyL2}\n}"}, "paperhash": {"value": "eisner|deep_se3equivariant_geometric_reasoning_for_precise_placement_tasks"}}, "number": 7654, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7654/-/Revision", "ICLR.cc/2024/Conference/Submission7654/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7654/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481907038, "cdate": 1695481907038, "tmdate": 1711406160461, "mdate": 1711406160461, "pdate": 1705411016356, "version": 2}, {"id": "Q3YaCghZNt", "forum": "Q3YaCghZNt", "signatures": ["ICLR.cc/2024/Conference/Submission7652/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7652/Authors"], "content": {"title": {"value": "Lemur: Integrating Large Language Models in Automated Program Verification"}, "authors": {"value": ["Haoze Wu", "Clark Barrett", "Nina Narodytska"]}, "authorids": {"value": ["~Haoze_Wu1", "~Clark_Barrett1", "~Nina_Narodytska1"]}, "keywords": {"value": ["Large Language Models", "Formal verification"]}, "abstract": {"value": "The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that demands high-level abstract reasoning about program properties that is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of derivation rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure, which led to practical improvements on a set of synthetic and competition benchmarks."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/532a430297b4420f65a27bc013065c3994ac9774.pdf"}, "supplementary_material": {"value": "/attachment/5bd7e492e0c3434e57acc9d9bcacbe75f04992c8.zip"}, "_bibtex": {"value": "@inproceedings{\nwu2024lemur,\ntitle={Lemur: Integrating Large Language Models in Automated Program Verification},\nauthor={Haoze Wu and Clark Barrett and Nina Narodytska},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Q3YaCghZNt}\n}"}, "TLDR": {"value": "We present a general methodology for combining LLMs and formal verifiers for automated program verification."}, "paperhash": {"value": "wu|lemur_integrating_large_language_models_in_automated_program_verification"}}, "number": 7652, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7652/-/Revision", "ICLR.cc/2024/Conference/Submission7652/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7652/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481853819, "cdate": 1695481853819, "tmdate": 1710544449116, "mdate": 1710544449116, "pdate": 1705411016238, "version": 2}, {"id": "liuqDwmbQJ", "forum": "liuqDwmbQJ", "signatures": ["ICLR.cc/2024/Conference/Submission7649/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7649/Authors"], "content": {"title": {"value": "ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models"}, "authors": {"value": ["Ilker Kesen", "Andrea Pedrotti", "Mustafa Dogan", "Michele Cafagna", "Emre Can Acikgoz", "Letitia Parcalabescu", "Iacer Calixto", "Anette Frank", "Albert Gatt", "Aykut Erdem", "Erkut Erdem"]}, "authorids": {"value": ["~Ilker_Kesen1", "~Andrea_Pedrotti1", "~Mustafa_Dogan1", "~Michele_Cafagna1", "~Emre_Can_Acikgoz1", "~Letitia_Parcalabescu1", "~Iacer_Calixto2", "~Anette_Frank1", "~Albert_Gatt2", "~Aykut_Erdem1", "~Erkut_Erdem1"]}, "keywords": {"value": ["vision-language benchmark", "spatio-temporal grounding", "video-language models", "benchmark", "evaluation", "zero-shot"]}, "abstract": {"value": "With the ever-increasing popularity of pretrained Video-Language Models (VidLMs), there is a pressing need to develop robust evaluation methodologies that delve deeper into their visio-linguistic capabilities. To address this challenge, we present ViLMA (Video Language Model Assessment), a task-agnostic benchmark that places the assessment of fine-grained capabilities of these models on a firm footing. Task-based evaluations, while valuable, fail to capture the complexities and specific temporal aspects of moving images that VidLMs need to process. Through carefully curated counterfactuals, ViLMA offers a controlled evaluation suite that sheds light on the true potential of these models, as well as their performance gaps compared to human-level understanding. ViLMA also includes proficiency tests, which assess basic capabilities deemed essential to solving the main counterfactual tests. We show that current VidLMs\u2019 grounding abilities are no better than those of vision-language models which use static images. This is especially striking once the performance on proficiency tests is factored in. Our benchmark serves as a catalyst for future research on VidLMs, helping to highlight areas that still need to be explored."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2ec7e7c715d59b101102ec7f464e513f8762ac38.pdf"}, "_bibtex": {"value": "@inproceedings{\nkesen2024vilma,\ntitle={Vi{LMA}: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models},\nauthor={Ilker Kesen and Andrea Pedrotti and Mustafa Dogan and Michele Cafagna and Emre Can Acikgoz and Letitia Parcalabescu and Iacer Calixto and Anette Frank and Albert Gatt and Aykut Erdem and Erkut Erdem},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=liuqDwmbQJ}\n}"}, "paperhash": {"value": "kesen|vilma_a_zeroshot_benchmark_for_linguistic_and_temporal_grounding_in_videolanguage_models"}}, "number": 7649, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7649/-/Revision", "ICLR.cc/2024/Conference/Submission7649/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7649/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481740522, "cdate": 1695481740522, "tmdate": 1710495676007, "mdate": 1710495676007, "pdate": 1705411016121, "version": 2}, {"id": "UMOlFJzLfL", "forum": "UMOlFJzLfL", "signatures": ["ICLR.cc/2024/Conference/Submission7646/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7646/Authors"], "content": {"title": {"value": "A Precise Characterization of SGD Stability Using Loss Surface Geometry"}, "authors": {"value": ["Gregory Dexter", "Borja Ocejo", "Sathiya Keerthi", "Aman Gupta", "Ayan Acharya", "Rajiv Khanna"]}, "authorids": {"value": ["~Gregory_Dexter1", "bocejo@linkedin.com", "~Sathiya_Keerthi1", "~Aman_Gupta1", "~Ayan_Acharya1", "~Rajiv_Khanna1"]}, "keywords": {"value": ["SGD", "linear dynamics", "sharpness", "implicit regularization"]}, "TLDR": {"value": "Improved necessary and sufficient conditions for SGD to be linearly stable at a point when minimizing additively decomposable loss functions."}, "abstract": {"value": "Stochastic Gradient Descent (SGD) stands as a cornerstone optimization algorithm with proven real-world empirical successes but relatively limited theoretical understanding. Recent research has illuminated a key factor contributing to its practical efficacy: the implicit regularization it instigates. Several studies have investigated the linear stability property of SGD in the vicinity of a stationary point as a predictive proxy for sharpness and generalization error in overparameterized neural networks (Wu et al., 2022; Jastrzebski et al., 2019; Cohen et al., 2021). In this paper, we delve deeper into the relationship between linear stability and sharpness. More specifically, we meticulously delineate the necessary and sufficient conditions for linear stability, contingent on hyperparameters of SGD and the sharpness at the optimum. Towards this end, we introduce a novel coherence measure of the loss Hessian that encapsulates pertinent geometric properties of the loss function that are relevant to the linear stability of SGD. It enables us to provide a simplified sufficient condition for identifying linear instability at an optimum. Notably, compared to previous works, our analysis relies on significantly milder assumptions and is applicable for a broader class of loss functions than known before, encompassing not only mean-squared error but also cross-entropy loss."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/67f0489c82ce9ff96ad27b73625b0ef149c2b35c.pdf"}, "supplementary_material": {"value": "/attachment/810125a9247ea43f8ad272eac7c80b55389d14d0.zip"}, "_bibtex": {"value": "@inproceedings{\ndexter2024a,\ntitle={A Precise Characterization of {SGD} Stability Using Loss Surface Geometry},\nauthor={Gregory Dexter and Borja Ocejo and Sathiya Keerthi and Aman Gupta and Ayan Acharya and Rajiv Khanna},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UMOlFJzLfL}\n}"}, "paperhash": {"value": "dexter|a_precise_characterization_of_sgd_stability_using_loss_surface_geometry"}}, "number": 7646, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7646/-/Revision", "ICLR.cc/2024/Conference/Submission7646/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481656426, "cdate": 1695481656426, "tmdate": 1707625641605, "mdate": 1707625641605, "pdate": 1705411015996, "version": 2}, {"id": "86NGO8qeWs", "forum": "86NGO8qeWs", "signatures": ["ICLR.cc/2024/Conference/Submission7640/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7640/Authors"], "content": {"title": {"value": "CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models"}, "authors": {"value": ["Sreyan Ghosh", "Ashish Seth", "Sonal Kumar", "Utkarsh Tyagi", "Chandra Kiran Reddy Evuru", "Ramaneswaran S", "S Sakshi", "Oriol Nieto", "Ramani Duraiswami", "Dinesh Manocha"]}, "authorids": {"value": ["~Sreyan_Ghosh1", "~Ashish_Seth1", "~Sonal_Kumar1", "~Utkarsh_Tyagi1", "~Chandra_Kiran_Reddy_Evuru1", "~Ramaneswaran_S1", "~S_Sakshi1", "~Oriol_Nieto1", "~Ramani_Duraiswami1", "~Dinesh_Manocha3"]}, "keywords": {"value": ["audio", "audio-language", "compositional reasoning"]}, "abstract": {"value": "A fundamental characteristic of audio is its compositional nature. Audio-language models (ALMs) trained using a contrastive approach (e.g., CLAP) that learns a shared representation between audio and language modalities have improved performance in many downstream applications, including zero-shot audio classification, audio retrieval, etc. However, the ability of these models to effectively perform compositional reasoning remains largely unexplored and necessitates additional research. In this paper, we propose CompA, a collection of two expert-annotated benchmarks with a majority of real-world audio samples, to evaluate compositional reasoning in ALMs. Our proposed CompA-order evaluates how well an ALM understands the order or occurrence of acoustic events in audio, and CompA-attribute evaluates attribute-binding of acoustic events. An instance from either benchmark consists of two audio-caption pairs, where both audios have the same acoustic events but with different compositions. An ALM is evaluated on how well it matches the right audio to the right caption. Using this benchmark, we first show that current ALMs perform only marginally better than random chance, thereby struggling with compositional reasoning. Next, we propose CompA-CLAP, where we fine-tune CLAP using a novel learning method to improve its compositional reasoning abilities. To train CompA-CLAP, we first propose improvements to contrastive training with composition-aware hard negatives, allowing for more focused training. Next, we propose a novel modular contrastive loss that helps the model learn fine-grained compositional understanding and overcomes the acute scarcity of openly available compositional audios. CompA-CLAP significantly improves over all our baseline models on the CompA benchmark, indicating its superior compositional reasoning capabilities."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e5feca0372d1f79d858cdfff53017b76515b203e.pdf"}, "supplementary_material": {"value": "/attachment/8a89ee1502f56c41795ace8c403fa62fedc8d16c.zip"}, "_bibtex": {"value": "@inproceedings{\nghosh2024compa,\ntitle={CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models},\nauthor={Sreyan Ghosh and Ashish Seth and Sonal Kumar and Utkarsh Tyagi and Chandra Kiran Reddy Evuru and Ramaneswaran S and S Sakshi and Oriol Nieto and Ramani Duraiswami and Dinesh Manocha},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=86NGO8qeWs}\n}"}, "paperhash": {"value": "ghosh|compa_addressing_the_gap_in_compositional_reasoning_in_audiolanguage_models"}}, "number": 7640, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7640/-/Revision", "ICLR.cc/2024/Conference/Submission7640/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7640/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481440550, "cdate": 1695481440550, "tmdate": 1711664105585, "mdate": 1711664105585, "pdate": 1705411015818, "version": 2}, {"id": "ulaUJFd96G", "forum": "ulaUJFd96G", "signatures": ["ICLR.cc/2024/Conference/Submission7631/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7631/Authors"], "content": {"title": {"value": "Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs"}, "authors": {"value": ["Woomin Song", "Seunghyuk Oh", "Sangwoo Mo", "Jaehyung Kim", "Sukmin Yun", "Jung-Woo Ha", "Jinwoo Shin"]}, "authorids": {"value": ["~Woomin_Song1", "~Seunghyuk_Oh1", "~Sangwoo_Mo1", "~Jaehyung_Kim1", "~Sukmin_Yun1", "~Jung-Woo_Ha1", "~Jinwoo_Shin1"]}, "keywords": {"value": ["Large language models", "Long context handling", "Token pruning"]}, "abstract": {"value": "Large language models (LLMs) have shown remarkable performance in various natural language processing tasks. However, a primary constraint they face is the context limit, i.e., the maximum number of tokens they can process. Previous works have explored architectural changes and modifications in positional encoding to relax the constraint, but they often require expensive training or do not address the computational demands of self-attention. In this paper, we present Hierarchical cOntext MERging (HOMER), a new training-free scheme designed to overcome the limitations. HOMER uses a divide-and-conquer algorithm, dividing long inputs into manageable chunks. Each chunk is then processed collectively, employing a hierarchical strategy that merges adjacent chunks at progressive transformer layers. A token reduction technique precedes each merging, ensuring memory usage efficiency. We also propose an optimized computational order reducing the memory requirement to logarithmically scale with respect to input length, making it especially favorable for environments with tight memory restrictions.  Our experiments demonstrate the proposed method's superior performance and memory efficiency, enabling the broader use of LLMs in contexts requiring extended context. Code is available at https://github.com/alinlab/HOMER."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cafcfd44a57e7102d87817b5600de58b7e424756.pdf"}, "TLDR": {"value": "We propose a computationally efficient method to extend the context limit of large language models."}, "_bibtex": {"value": "@inproceedings{\nsong2024hierarchical,\ntitle={Hierarchical Context Merging: Better Long Context Understanding for Pre-trained {LLM}s},\nauthor={Woomin Song and Seunghyuk Oh and Sangwoo Mo and Jaehyung Kim and Sukmin Yun and Jung-Woo Ha and Jinwoo Shin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ulaUJFd96G}\n}"}, "paperhash": {"value": "song|hierarchical_context_merging_better_long_context_understanding_for_pretrained_llms"}}, "number": 7631, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7631/-/Revision", "ICLR.cc/2024/Conference/Submission7631/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7631/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481225606, "cdate": 1695481225606, "tmdate": 1713170392655, "mdate": 1713170392655, "pdate": 1705411015423, "version": 2}, {"id": "ePOjNlOjLC", "forum": "ePOjNlOjLC", "signatures": ["ICLR.cc/2024/Conference/Submission7628/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7628/Authors"], "content": {"title": {"value": "Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation"}, "authors": {"value": ["Ruoyu Wang", "Yongqi Yang", "Zhihao Qian", "Ye Zhu", "Yu Wu"]}, "authorids": {"value": ["~Ruoyu_Wang6", "~Yongqi_Yang1", "~Zhihao_Qian1", "~Ye_Zhu3", "~Yu_Wu3"]}, "keywords": {"value": ["Diffusion Models\uff1btext-vision Condition\uff1b"]}, "abstract": {"value": "Originating from the diffusion phenomenon in physics that describes particle movement, the diffusion generative models inherit the characteristics of stochastic random walk in the data space along the denoising trajectory. However, the intrinsic mutual interference among image regions contradicts the need for practical downstream application scenarios where the preservation of low-level pixel information from given conditioning is desired (e.g., customization tasks like personalized generation and inpainting based on a user-provided single image). In this work, we investigate the diffusion (physics) in diffusion (machine learning) properties and propose our Cyclic One-Way Diffusion (COW) method to control the direction of diffusion phenomenon given a pre-trained frozen diffusion model for versatile customization application scenarios, where the low-level pixel information from the conditioning needs to be preserved. Notably, unlike most current methods that incorporate additional conditions by fine-tuning the base text-to-image diffusion model or learning auxiliary networks, our method provides a novel perspective to understand the task needs and is applicable to a wider range of customization scenarios in a learning-free manner. Extensive experiment results show that our proposed COW can achieve more flexible customization based on strict visual conditions in different application settings. Project page: https://wangruoyu02.github.io/cow.github.io/."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1ed153e30901516c66436cf1fc6202ddeebe5ce3.pdf"}, "supplementary_material": {"value": "/attachment/355ec8e4c90b7d266e47f26438ac63438d399276.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024diffusion,\ntitle={Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation},\nauthor={Ruoyu Wang and Yongqi Yang and Zhihao Qian and Ye Zhu and Yu Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ePOjNlOjLC}\n}"}, "paperhash": {"value": "wang|diffusion_in_diffusion_cyclic_oneway_diffusion_for_textvisionconditioned_generation"}}, "number": 7628, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7628/-/Revision", "ICLR.cc/2024/Conference/Submission7628/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7628/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481146126, "cdate": 1695481146126, "tmdate": 1710566336425, "mdate": 1710566336425, "pdate": 1705411015398, "version": 2}, {"id": "DfPtC8uSot", "forum": "DfPtC8uSot", "signatures": ["ICLR.cc/2024/Conference/Submission7624/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7624/Authors"], "content": {"title": {"value": "Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks"}, "authors": {"value": ["Yassine ABBAHADDOU", "Sofiane ENNADIR", "Johannes F. Lutzeyer", "Michalis Vazirgiannis", "Henrik Bostr\u00f6m"]}, "authorids": {"value": ["~Yassine_ABBAHADDOU1", "~Sofiane_ENNADIR1", "~Johannes_F._Lutzeyer1", "~Michalis_Vazirgiannis1", "~Henrik_Bostr\u00f6m1"]}, "keywords": {"value": ["Graph Neural Networks", "Adversarial Robustness"]}, "TLDR": {"value": "We define and upper-bound the expected adversarial robustness of Graph Neural Networks, which allows us to propose the more robust Graph Convolutional Orthogonal Robust Networks (GCORN)."}, "abstract": {"value": "Graph Neural Networks (GNNs) have demonstrated state-of-the-art performance in various graph representation learning tasks. Recently, studies revealed their vulnerability to adversarial attacks. In this work, we theoretically define the concept of expected robustness in the context of attributed graphs and relate it to the classical definition of adversarial robustness in the graph representation learning literature. Our definition allows us to derive an upper bound of the expected robustness of Graph Convolutional Networks (GCNs) and Graph Isomorphism Networks subject to node feature attacks. Building on these findings, we connect the expected robustness of GNNs to the orthonormality of their weight matrices and consequently propose an attack-independent, more robust variant of the GCN, called the Graph Convolutional Orthogonal Robust Networks (GCORNs). We further introduce a probabilistic method to estimate the expected robustness, which allows us to evaluate the effectiveness of GCORN on several real-world datasets. Experimental experiments showed that GCORN outperforms available defense methods. Our code is publicly available at: https://github.com/Sennadir/GCORN ."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f5a6ccde1dc15dde4b1f6709710b8de93622e851.pdf"}, "supplementary_material": {"value": "/attachment/f25b91b5158838a4032e88f0752c37a659f5da61.zip"}, "_bibtex": {"value": "@inproceedings{\nabbahaddou2024bounding,\ntitle={Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks},\nauthor={Yassine ABBAHADDOU and Sofiane ENNADIR and Johannes F. Lutzeyer and Michalis Vazirgiannis and Henrik Bostr{\\\"o}m},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DfPtC8uSot}\n}"}, "paperhash": {"value": "abbahaddou|bounding_the_expected_robustness_of_graph_neural_networks_subject_to_node_feature_attacks"}}, "number": 7624, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7624/-/Revision", "ICLR.cc/2024/Conference/Submission7624/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7624/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695481005110, "cdate": 1695481005110, "tmdate": 1713133405802, "mdate": 1713133405802, "pdate": 1705411015253, "version": 2}, {"id": "oXjnwQLcTA", "forum": "oXjnwQLcTA", "signatures": ["ICLR.cc/2024/Conference/Submission7619/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7619/Authors"], "content": {"title": {"value": "Score Models for Offline Goal-Conditioned Reinforcement Learning"}, "authors": {"value": ["Harshit Sikchi", "Rohan Chitnis", "Ahmed Touati", "Alborz Geramifard", "Amy Zhang", "Scott Niekum"]}, "authorids": {"value": ["~Harshit_Sikchi1", "~Rohan_Chitnis1", "~Ahmed_Touati1", "~Alborz_Geramifard1", "~Amy_Zhang1", "~Scott_Niekum1"]}, "keywords": {"value": ["Robot Learning", "Goal-Conditioned Reinforcement Learning", "Deep Reinforcement Learning"]}, "TLDR": {"value": "A discriminator-free occupancy matching approach for performant offline goal-conditioned reinforcement learning."}, "abstract": {"value": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a convex dual formulation to derive a learning objective that can better leverage suboptimal offline data. SMORe learns *scores* or unnormalized densities representing the importance of taking an action at a state for reaching a particular goal. SMORe is principled and our extensive experiments on the fully offline GCRL benchmark composed of robot manipulation and locomotion tasks, including high-dimensional observations, show that SMORe can outperform state-of-the-art baselines by a significant margin."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e910f7909d83805095dc5214228a3ec894a22038.pdf"}, "supplementary_material": {"value": "/attachment/2811914e2c6f0f2ce7daf54f16c0f209ca91b8ba.pdf"}, "_bibtex": {"value": "@inproceedings{\nsikchi2024score,\ntitle={Score Models for Offline Goal-Conditioned Reinforcement Learning},\nauthor={Harshit Sikchi and Rohan Chitnis and Ahmed Touati and Alborz Geramifard and Amy Zhang and Scott Niekum},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oXjnwQLcTA}\n}"}, "paperhash": {"value": "sikchi|score_models_for_offline_goalconditioned_reinforcement_learning"}}, "number": 7619, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7619/-/Revision", "ICLR.cc/2024/Conference/Submission7619/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7619/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480911444, "cdate": 1695480911444, "tmdate": 1709661541454, "mdate": 1709661541454, "pdate": 1705411015124, "version": 2}, {"id": "krx55l2A6G", "forum": "krx55l2A6G", "signatures": ["ICLR.cc/2024/Conference/Submission7616/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7616/Authors"], "content": {"title": {"value": "Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning"}, "authors": {"value": ["Kostadin Garov", "Dimitar Iliev Dimitrov", "Nikola Jovanovi\u0107", "Martin Vechev"]}, "authorids": {"value": ["~Kostadin_Garov1", "~Dimitar_Iliev_Dimitrov2", "~Nikola_Jovanovi\u01071", "~Martin_Vechev1"]}, "keywords": {"value": ["Privacy", "Federated Learning", "Gradient Leakage"]}, "TLDR": {"value": "We study detectability of malicious server attacks in federated learning, show that prior attacks are detectable, and propose SEER, a novel attack framework that reconstructs data from large batch sizes and is by design harder to detect."}, "abstract": {"value": "Malicious server (MS) attacks have enabled the scaling of data stealing in federated learning to large batch sizes and secure aggregation, settings previously considered private. However, many concerns regarding the client-side detectability of MS attacks were raised, questioning their practicality. In this work, for the first time, we thoroughly study client-side detectability. We first demonstrate that all prior MS attacks are detectable by principled checks, and formulate a necessary set of requirements that a practical MS attack must satisfy. Next, we propose SEER, a novel attack framework that satisfies these requirements. The key insight of SEER is the use of a secret decoder, jointly trained with the shared model. We show that SEER can steal user data from gradients of realistic networks, even for large batch sizes of up to 512 and under secure aggregation. Our work is a promising step towards assessing the true vulnerability of federated learning in real-world settings."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/13aec170e01b9671539a236fa14e39332639360b.pdf"}, "supplementary_material": {"value": "/attachment/927408f6251e7e83daa02a971c8edb6ebf6eac52.zip"}, "_bibtex": {"value": "@inproceedings{\ngarov2024hiding,\ntitle={Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning},\nauthor={Kostadin Garov and Dimitar Iliev Dimitrov and Nikola Jovanovi{\\'c} and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=krx55l2A6G}\n}"}, "paperhash": {"value": "garov|hiding_in_plain_sight_disguising_data_stealing_attacks_in_federated_learning"}}, "number": 7616, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7616/-/Revision", "ICLR.cc/2024/Conference/Submission7616/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7616/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480839770, "cdate": 1695480839770, "tmdate": 1713171533943, "mdate": 1713171533943, "pdate": 1705411014992, "version": 2}, {"id": "igfDXfMvm5", "forum": "igfDXfMvm5", "signatures": ["ICLR.cc/2024/Conference/Submission7614/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7614/Authors"], "content": {"title": {"value": "USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields"}, "authors": {"value": ["Moyang Li", "Peng Wang", "Lingzhe Zhao", "Bangyan Liao", "Peidong Liu"]}, "authorids": {"value": ["~Moyang_Li1", "~Peng_Wang29", "~Lingzhe_Zhao1", "~Bangyan_Liao1", "~Peidong_Liu3"]}, "keywords": {"value": ["Neural Radiance Fields", "Bundle Adjustment", "Rolling Shutter"]}, "abstract": {"value": "Neural Radiance Fields (NeRF) has received much attention recently due to its impressive capability to represent 3D scene and synthesize novel view images. Existing works usually assume that the input images are captured by a global shutter camera. Thus, rolling shutter (RS) images cannot be trivially applied to an off-the-shelf NeRF algorithm for novel view synthesis. Rolling shutter effect would also affect the accuracy of the camera pose estimation (e.g. via COLMAP), which further prevents the success of NeRF algorithm with RS images.\nIn this paper, we propose Unrolling Shutter Bundle Adjusted Neural Radiance Fields (USB-NeRF). USB-NeRF is able to correct rolling shutter distortions and recover accurate camera motion trajectory simultaneously under the framework of NeRF, by modeling the physical image formation process of a RS camera.\nExperimental results demonstrate that USB-NeRF achieves better performance compared to prior works, in terms of RS effect removal, novel view image synthesis as well as camera motion estimation. Furthermore, our algorithm can also be used to recover high-fidelity high frame-rate global shutter video from a sequence of RS images."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4612afe3654a547a44dc4e5e94071ad6b9f1e4b2.pdf"}, "supplementary_material": {"value": "/attachment/70d15e784e959725f70523e56a8b6ff6b0b5a6f0.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024usbnerf,\ntitle={{USB}-Ne{RF}: Unrolling Shutter Bundle Adjusted Neural Radiance Fields},\nauthor={Moyang Li and Peng Wang and Lingzhe Zhao and Bangyan Liao and Peidong Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=igfDXfMvm5}\n}"}, "paperhash": {"value": "li|usbnerf_unrolling_shutter_bundle_adjusted_neural_radiance_fields"}}, "number": 7614, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7614/-/Revision", "ICLR.cc/2024/Conference/Submission7614/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7614/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480811762, "cdate": 1695480811762, "tmdate": 1710259847043, "mdate": 1710259847043, "pdate": 1705411014979, "version": 2}, {"id": "bAMPOUF227", "forum": "bAMPOUF227", "signatures": ["ICLR.cc/2024/Conference/Submission7605/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7605/Authors"], "content": {"title": {"value": "Supervised Knowledge Makes Large Language Models Better In-context Learners"}, "authors": {"value": ["Linyi Yang", "Shuibai Zhang", "Zhuohao Yu", "Guangsheng Bao", "Yidong Wang", "Jindong Wang", "Ruochen Xu", "Wei Ye", "Xing Xie", "Weizhu Chen", "Yue Zhang"]}, "authorids": {"value": ["~Linyi_Yang1", "zhangshuibai@westlake.edu.cn", "~Zhuohao_Yu1", "~Guangsheng_Bao1", "~Yidong_Wang1", "~Jindong_Wang1", "~Ruochen_Xu2", "~Wei_Ye2", "~Xing_Xie3", "~Weizhu_Chen1", "~Yue_Zhang7"]}, "keywords": {"value": ["In-context Learning; Out-of-distribution Generalization; Reliability"]}, "abstract": {"value": "Large Language Models (LLMs) exhibit emerging in-context learning abilities through prompt engineering. The recent progress in large-scale generative models has further expanded their use in real-world language applications. However, the critical challenge of improving the generalizability and factuality of LLMs in natural language understanding and question answering remains under-explored. While previous in-context learning research has focused on enhancing models to adhere to users' specific instructions and quality expectations, and to avoid undesired outputs, little to no work has explored the use of task-specific fine-tuned Language Models (SLMs) to improve LLMs' in-context learning during the inference stage. Our primary contribution is the establishment of a simple yet effective framework that enhances the reliability of LLMs as it: 1) generalizes out-of-distribution data, 2) elucidates how LLMs benefit from discriminative models, and 3) minimizes hallucinations in generative tasks. Using our proposed plug-in method, enhanced versions of Llama 2 and ChatGPT surpass their original versions regarding generalizability and factuality. We offer a comprehensive suite of resources, including 16 curated datasets, prompts, model checkpoints, and LLM outputs across 9 distinct tasks. Our empirical analysis sheds light on the advantages of incorporating discriminative models into LLMs and highlights the potential of our methodology in fostering more reliable LLMs."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d77e7240711e2000ec4b22293ad713ad0b91e732.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024supervised,\ntitle={Supervised Knowledge Makes Large Language Models Better In-context Learners},\nauthor={Linyi Yang and Shuibai Zhang and Zhuohao Yu and Guangsheng Bao and Yidong Wang and Jindong Wang and Ruochen Xu and Wei Ye and Xing Xie and Weizhu Chen and Yue Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bAMPOUF227}\n}"}, "TLDR": {"value": "We shed light on the advantages of incorporating discriminative models into LLMs and highlight the potential of our methodology in fostering more reliable LLMs."}, "paperhash": {"value": "yang|supervised_knowledge_makes_large_language_models_better_incontext_learners"}}, "number": 7605, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7605/-/Revision", "ICLR.cc/2024/Conference/Submission7605/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7605/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480507702, "cdate": 1695480507702, "tmdate": 1711516569925, "mdate": 1711516569925, "pdate": 1705411014726, "version": 2}, {"id": "XN6ZPINdSg", "forum": "XN6ZPINdSg", "signatures": ["ICLR.cc/2024/Conference/Submission7604/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7604/Authors"], "content": {"title": {"value": "COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits"}, "authors": {"value": ["Mintong Kang", "Nezihe Merve G\u00fcrel", "Linyi Li", "Bo Li"]}, "authorids": {"value": ["~Mintong_Kang1", "~Nezihe_Merve_G\u00fcrel2", "~Linyi_Li1", "~Bo_Li19"]}, "keywords": {"value": ["conformal prediction", "adversarial robustness", "probabilistic circuits"]}, "abstract": {"value": "Conformal prediction has shown spurring performance in constructing statistically rigorous prediction sets for arbitrary black-box machine learning models, assuming the data is exchangeable. However, even small adversarial perturbations during the inference can violate the exchangeability assumption, challenge the coverage guarantees, and result in a subsequent decline in empirical coverage. In this work, we propose a certifiably robust learning-reasoning conformal prediction framework (COLEP) via probabilistic circuits, which comprise a data-driven learning component that trains statistical models to learn different semantic concepts, and a reasoning component that encodes knowledge and characterizes the relationships among the trained models for logic reasoning. To achieve exact and efficient reasoning, we employ probabilistic circuits (PCs) within the reasoning component. Theoretically, we provide end-to-end certification of prediction coverage for COLEP in the presence of $\\ell_2$ bounded adversarial perturbations. We also provide certified coverage considering the finite size of the calibration set. Furthermore, we prove that COLEP achieves higher prediction coverage and accuracy over a single model as long as the utilities of knowledge models are non-trivial. Empirically, we show the validity and tightness of our certified coverage, demonstrating the robust conformal prediction of COLEP on various datasets, including GTSRB, CIFAR10, and AwA2. We show that COLEP achieves up to 12% improvement in certified coverage on GTSRB, 9% on CIFAR-10, and 14% on AwA2."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6860fb9b71cc9f6f7a0d89d24aeab9312e53e7d9.pdf"}, "TLDR": {"value": "We propose a certifiably robust learning-reasoning pipeline for conformal prediction."}, "_bibtex": {"value": "@inproceedings{\nkang2024colep,\ntitle={{COLEP}: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits},\nauthor={Mintong Kang and Nezihe Merve G{\\\"u}rel and Linyi Li and Bo Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XN6ZPINdSg}\n}"}, "paperhash": {"value": "kang|colep_certifiably_robust_learningreasoning_conformal_prediction_via_probabilistic_circuits"}}, "number": 7604, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7604/-/Revision", "ICLR.cc/2024/Conference/Submission7604/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7604/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480499635, "cdate": 1695480499635, "tmdate": 1710560595450, "mdate": 1710560595450, "pdate": 1705411014700, "version": 2}, {"id": "0akLDTFR9x", "forum": "0akLDTFR9x", "signatures": ["ICLR.cc/2024/Conference/Submission7601/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7601/Authors"], "content": {"title": {"value": "Contrastive Difference Predictive Coding"}, "authors": {"value": ["Chongyi Zheng", "Ruslan Salakhutdinov", "Benjamin Eysenbach"]}, "authorids": {"value": ["~Chongyi_Zheng1", "~Ruslan_Salakhutdinov1", "~Benjamin_Eysenbach1"]}, "keywords": {"value": ["contrastive learning", "reinforcement learning", "goal-reaching", "goal-conditioned RL", "temporal difference"]}, "TLDR": {"value": "a temporal difference version of contrastive predictive coding"}, "abstract": {"value": "Predicting and reasoning about the future lie at the heart of many time-series questions. For example, goal-conditioned reinforcement learning can be viewed as learning representations to predict which states are likely to be visited in the future. While prior methods have used contrastive predictive coding to model time series data, learning representations that encode long-term dependencies usually requires large amounts of data. In this paper, we introduce a temporal difference version of contrastive predictive coding that stitches together pieces of different time series data to decrease the amount of data required to learn predictions of future events. We apply this representation learning method to derive an off-policy algorithm for goal-conditioned RL. Experiments demonstrate that, compared with prior RL methods, ours achieves $2 \\times$ median improvement in success rates and can better cope with stochastic environments. In tabular settings, we show that our method is about $20\\times$ more sample efficient than the successor representation and $1500 \\times$ more sample efficient than the standard (Monte Carlo) version of contrastive predictive coding."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/55decc67951f082fd52c8de14ddacb53203f15a9.pdf"}, "supplementary_material": {"value": ""}, "_bibtex": {"value": "@inproceedings{\nzheng2024contrastive,\ntitle={Contrastive Difference Predictive Coding},\nauthor={Chongyi Zheng and Ruslan Salakhutdinov and Benjamin Eysenbach},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0akLDTFR9x}\n}"}, "paperhash": {"value": "zheng|contrastive_difference_predictive_coding"}}, "number": 7601, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7601/-/Revision", "ICLR.cc/2024/Conference/Submission7601/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7601/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480434284, "cdate": 1695480434284, "tmdate": 1710103871152, "mdate": 1710103871152, "pdate": 1705411014601, "version": 2}, {"id": "LNLjU5C5dK", "forum": "LNLjU5C5dK", "signatures": ["ICLR.cc/2024/Conference/Submission7591/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7591/Authors"], "content": {"title": {"value": "Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"}, "authors": {"value": ["Geyang Guo", "Ranchi Zhao", "Tianyi Tang", "Xin Zhao", "Ji-Rong Wen"]}, "authorids": {"value": ["~Geyang_Guo2", "~Ranchi_Zhao1", "~Tianyi_Tang1", "~Xin_Zhao10", "~Ji-Rong_Wen1"]}, "keywords": {"value": ["large language models", "alignment", "fine-grained SFT"]}, "abstract": {"value": "Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which can't fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named $\\textbf{FIGA}$. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quailty signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7e691e0fc92959027977a190a73e2f84c0484e77.pdf"}, "_bibtex": {"value": "@inproceedings{\nguo2024beyond,\ntitle={Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment},\nauthor={Geyang Guo and Ranchi Zhao and Tianyi Tang and Xin Zhao and Ji-Rong Wen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LNLjU5C5dK}\n}"}, "paperhash": {"value": "guo|beyond_imitation_leveraging_finegrained_quality_signals_for_alignment"}}, "number": 7591, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7591/-/Revision", "ICLR.cc/2024/Conference/Submission7591/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7591/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480153291, "cdate": 1695480153291, "tmdate": 1713013335671, "mdate": 1713013335671, "pdate": 1705411014278, "version": 2}, {"id": "ZWzUA9zeAg", "forum": "ZWzUA9zeAg", "signatures": ["ICLR.cc/2024/Conference/Submission7589/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7589/Authors"], "content": {"title": {"value": "Effective Data Augmentation With Diffusion Models"}, "authors": {"value": ["Brandon Trabucco", "Kyle Doherty", "Max A Gurinas", "Ruslan Salakhutdinov"]}, "authorids": {"value": ["~Brandon_Trabucco1", "~Kyle_Doherty1", "~Max_A_Gurinas1", "~Ruslan_Salakhutdinov1"]}, "keywords": {"value": ["Deep Learning"]}, "abstract": {"value": "Data augmentation is one of the most prevalent tools in deep learning, underpinning many recent advances, including those from classification, generative models, and representation learning. The standard approach to data augmentation combines simple transformations like rotations and flips to generate new images from existing ones. However, these new images lack diversity along key semantic axes present in the data. Current augmentations cannot alter the high-level semantic attributes, such as animal species present in a scene, to enhance the diversity of data. We address the lack of diversity in data augmentation with image-to-image transformations parameterized by pre-trained text-to-image diffusion models. Our method edits images to change their semantics using an off-the-shelf diffusion model, and generalizes to novel visual concepts from a few labelled examples. We evaluate our approach on few-shot image classification tasks, and on a real-world weed recognition task, and observe an improvement in accuracy in tested domains."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/34c4bb38ef126d947a7a2353731d896d02f52d84.pdf"}, "_bibtex": {"value": "@inproceedings{\ntrabucco2024effective,\ntitle={Effective Data Augmentation With Diffusion Models},\nauthor={Brandon Trabucco and Kyle Doherty and Max A Gurinas and Ruslan Salakhutdinov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZWzUA9zeAg}\n}"}, "paperhash": {"value": "trabucco|effective_data_augmentation_with_diffusion_models"}}, "number": 7589, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7589/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7589/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480130681, "cdate": 1695480130681, "tmdate": 1713039924109, "mdate": 1713039924109, "pdate": 1705411014165, "version": 2}, {"id": "TYXtXLYHpR", "forum": "TYXtXLYHpR", "signatures": ["ICLR.cc/2024/Conference/Submission7585/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7585/Authors"], "content": {"title": {"value": "Towards Transparent Time Series Forecasting"}, "authors": {"value": ["Krzysztof Kacprzyk", "Tennison Liu", "Mihaela van der Schaar"]}, "authorids": {"value": ["~Krzysztof_Kacprzyk1", "~Tennison_Liu1", "~Mihaela_van_der_Schaar2"]}, "keywords": {"value": ["transparency", "interpretability", "time series"]}, "abstract": {"value": "Transparent machine learning (ML) models are essential for ensuring interpretability and trustworthiness in decision-making systems, particularly in high-stakes domains such as healthcare, finance, and criminal justice. While transparent machine learning models have been proposed for classification and regression, time series forecasting presents some unique challenges for ensuring transparency. In particular, currently used bottom-up approaches that focus on the values of the time series at specific time points (usually regularly spaced) do not provide a holistic understanding of the entire time series. This limits the applicability of ML in many critical areas. To open up these domains for ML, we propose a top-down framework of bi-level transparency, which involves understanding the higher-level trends and the lower-level properties of the predicted time series. Applying this framework, we develop TIMEVIEW, a transparent ML model for time series forecasting based on static features, complemented with an interactive visualization tool. Through a series of experiments, we demonstrate the efficacy and interpretability of our approach, paving the way for more transparent and reliable applications of ML in various domains."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7b4d31c5923b2c590fdf82c4c7695fade13a4fd0.pdf"}, "_bibtex": {"value": "@inproceedings{\nkacprzyk2024towards,\ntitle={Towards Transparent Time Series Forecasting},\nauthor={Krzysztof Kacprzyk and Tennison Liu and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TYXtXLYHpR}\n}"}, "paperhash": {"value": "kacprzyk|towards_transparent_time_series_forecasting"}}, "number": 7585, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7585/-/Revision", "ICLR.cc/2024/Conference/Submission7585/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7585/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695480010559, "cdate": 1695480010559, "tmdate": 1710424645234, "mdate": 1710424645234, "pdate": 1705411013976, "version": 2}, {"id": "BlkxbI6vzl", "forum": "BlkxbI6vzl", "signatures": ["ICLR.cc/2024/Conference/Submission7574/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7574/Authors"], "content": {"title": {"value": "A Fast and Provable Algorithm for Sparse Phase Retrieval"}, "authors": {"value": ["Jian-Feng CAI", "Yu Long", "Ruixue WEN", "Jiaxi Ying"]}, "authorids": {"value": ["~Jian-Feng_CAI1", "~Yu_Long2", "~Ruixue_WEN1", "~Jiaxi_Ying1"]}, "keywords": {"value": ["Sparse Phase Retrieval", "Quadratic Convergence", "Newton-type Method", "Hard Thresholding", "Nonconvex Optimization"]}, "abstract": {"value": "We study the sparse phase retrieval problem, which seeks to recover a sparse signal from a limited set of magnitude-only measurements. In contrast to prevalent sparse phase retrieval algorithms that primarily use first-order methods, we propose an innovative second-order algorithm that employs a Newton-type method with hard thresholding. This algorithm overcomes the linear convergence limitations of first-order methods while preserving their hallmark per-iteration computational efficiency. We provide theoretical guarantees that our algorithm converges to the $s$-sparse ground truth signal $\\boldsymbol{x}^{\\natural} \\in \\mathbb{R}^n$ (up to a global sign) at a quadratic convergence rate after at most $O(\\log (\\Vert\\boldsymbol{x}^{\\natural} \\Vert /x_{\\min}^{\\natural}))$ iterations, using $\\Omega(s^2\\log n)$ Gaussian random samples. Numerical experiments show that our algorithm achieves a significantly faster convergence rate than state-of-the-art methods."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fcd0220a2102b9b85af6f602606be5f55f4c223b.pdf"}, "_bibtex": {"value": "@inproceedings{\ncai2024a,\ntitle={A Fast and Provable Algorithm for Sparse Phase Retrieval},\nauthor={Jian-Feng CAI and Yu Long and Ruixue WEN and Jiaxi Ying},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BlkxbI6vzl}\n}"}, "paperhash": {"value": "cai|a_fast_and_provable_algorithm_for_sparse_phase_retrieval"}}, "number": 7574, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7574/-/Revision", "ICLR.cc/2024/Conference/Submission7574/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7574/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695479546515, "cdate": 1695479546515, "tmdate": 1710858377324, "mdate": 1710858377324, "pdate": 1705411013744, "version": 2}, {"id": "lNZJyEDxy4", "forum": "lNZJyEDxy4", "signatures": ["ICLR.cc/2024/Conference/Submission7570/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7570/Authors"], "content": {"title": {"value": "MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data"}, "authors": {"value": ["Jiaxin Yin", "Yuanyuan Qiao", "Zitang Zhou", "Xiangchao Wang", "Jie Yang"]}, "authorids": {"value": ["~Jiaxin_Yin1", "~Yuanyuan_Qiao1", "~Zitang_Zhou1", "~Xiangchao_Wang1", "~Jie_Yang30"]}, "keywords": {"value": ["anomaly detection", "tabular data", "self-supervised learning"]}, "abstract": {"value": "This paper addresses the problem of anomaly detection in tabular data, which is usually implemented in an one-class classification setting where the training set only contains normal samples. Inspired by the success of masked image/language modeling in vision and natural language domains, we extend masked modeling methods to address this problem by capturing intrinsic correlations between features in training set. Thus, a sample deviate from such correlations is related to a high possibility of anomaly. To obtain multiple and diverse correlations, we propose a novel masking strategy which generates multiple masks by learning, and design a diversity loss to reduce the similarity of different masks. Extensive experiments show our method achieves state-of-the-art performance. We also discuss the interpretability from the perspective of each individual feature and correlations between features."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/64049067598c9873e6b5359e0456c55572fa2133.pdf"}, "supplementary_material": {"value": "/attachment/8be1c2b5eb05316275cb539b78aa1e2fb29f015c.zip"}, "_bibtex": {"value": "@inproceedings{\nyin2024mcm,\ntitle={{MCM}: Masked Cell Modeling for Anomaly Detection in Tabular Data},\nauthor={Jiaxin Yin and Yuanyuan Qiao and Zitang Zhou and Xiangchao Wang and Jie Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lNZJyEDxy4}\n}"}, "paperhash": {"value": "yin|mcm_masked_cell_modeling_for_anomaly_detection_in_tabular_data"}}, "number": 7570, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7570/-/Revision", "ICLR.cc/2024/Conference/Submission7570/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7570/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695479451322, "cdate": 1695479451322, "tmdate": 1710934863628, "mdate": 1710934863628, "pdate": 1705411013639, "version": 2}, {"id": "KNvubydSB5", "forum": "KNvubydSB5", "signatures": ["ICLR.cc/2024/Conference/Submission7566/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7566/Authors"], "content": {"title": {"value": "HiGen: Hierarchical Graph Generative Networks"}, "authors": {"value": ["Mahdi Karami"]}, "authorids": {"value": ["~Mahdi_Karami2"]}, "keywords": {"value": ["Generative Models", "Graph Generative Network", "Graph Neural Network", "Probabilistic Model"]}, "abstract": {"value": "Most real-world graphs exhibit a hierarchical structure, which is often overlooked by existing graph generation methods. To address this limitation, we propose a novel graph generative network that captures the hierarchical nature of graphs and successively generates the graph sub-structures in a coarse-to-fine fashion. At each level of hierarchy, this model generates communities in parallel, followed by the prediction of cross-edges between communities using separate neural networks. This modular approach enables scalable graph generation for large and complex graphs.  Moreover, we model the output distribution of edges in the hierarchical graph with a multinomial distribution and derive a recursive factorization for this distribution. This enables us to generate  community graphs with integer-valued edge weights in an autoregressive manner. Empirical studies demonstrate the effectiveness and scalability of our proposed generative model, achieving state-of-the-art performance in terms of graph quality across various benchmark datasets. \nCode available at https://github.com/Karami-m/HiGen_main."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/deabb647b820118241cb70e7719824b6d6f6cd8c.pdf"}, "TLDR": {"value": "We propose a novel graph generative network that captures the hierarchical nature of graphs and successively generates the graph sub-structures in a coarse-to-fine fashion."}, "_bibtex": {"value": "@inproceedings{\nkarami2024higen,\ntitle={HiGen: Hierarchical Graph Generative Networks},\nauthor={Mahdi Karami},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KNvubydSB5}\n}"}, "paperhash": {"value": "karami|higen_hierarchical_graph_generative_networks"}}, "number": 7566, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7566/-/Revision", "ICLR.cc/2024/Conference/Submission7566/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7566/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695479222928, "cdate": 1695479222928, "tmdate": 1710517678350, "mdate": 1710517678350, "pdate": 1705411013595, "version": 2}, {"id": "8BAkNCqpGW", "forum": "8BAkNCqpGW", "signatures": ["ICLR.cc/2024/Conference/Submission7564/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7564/Authors"], "content": {"title": {"value": "A Policy Gradient Method for Confounded POMDPs"}, "authors": {"value": ["Mao Hong", "Zhengling Qi", "Yanxun Xu"]}, "authorids": {"value": ["~Mao_Hong1", "~Zhengling_Qi1", "~Yanxun_Xu1"]}, "keywords": {"value": ["Offline Reinforcement Learning", "Confounded POMDP", "Policy Gradient", "Statistical Guarantee", "Function Approximation"]}, "TLDR": {"value": "We propose a policy gradient method for Confounded POMDPs with theoretical guarantees."}, "abstract": {"value": "In this paper, we propose a policy gradient method for confounded partially observable Markov decision processes (POMDPs) with continuous state and observation spaces in the offline setting. We first establish a novel identification result to non-parametrically estimate any history-dependent policy gradient under POMDPs using the offline data. The identification enables us to solve a sequence of conditional moment restrictions and adopt the min-max learning procedure with general function approximation for estimating the policy gradient. We then provide a finite-sample non-asymptotic bound for estimating the gradient uniformly over a pre-specified policy class in terms of the sample size, length of horizon, concentratability coefficient and the measure of ill-posedness in solving the conditional moment restrictions. Lastly, by deploying the proposed gradient estimation in the gradient ascent algorithm, we show the global convergence of the proposed algorithm in finding the history-dependent optimal policy under some technical conditions. To the best of our knowledge, this is the first work studying the policy gradient method for POMDPs under the offline setting."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1c80c0bc0c9f0bc9838d559228a47e3305a40a6f.pdf"}, "_bibtex": {"value": "@inproceedings{\nhong2024a,\ntitle={A Policy Gradient Method for Confounded {POMDP}s},\nauthor={Mao Hong and Zhengling Qi and Yanxun Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8BAkNCqpGW}\n}"}, "paperhash": {"value": "hong|a_policy_gradient_method_for_confounded_pomdps"}}, "number": 7564, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7564/-/Revision", "ICLR.cc/2024/Conference/Submission7564/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7564/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695479177975, "cdate": 1695479177975, "tmdate": 1710553085777, "mdate": 1710553085777, "pdate": 1705411013476, "version": 2}, {"id": "yoVq2BGQdP", "forum": "yoVq2BGQdP", "signatures": ["ICLR.cc/2024/Conference/Submission7562/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7562/Authors"], "content": {"title": {"value": "Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning"}, "authors": {"value": ["Peizhong Ju", "Arnob Ghosh", "Ness Shroff"]}, "authorids": {"value": ["~Peizhong_Ju1", "~Arnob_Ghosh3", "~Ness_Shroff1"]}, "keywords": {"value": ["Fairness", "Multi-Agent Reinforcement Learning", "Markov Decision Process"]}, "abstract": {"value": "Fairness plays a crucial role in various multi-agent systems (e.g., communication networks, financial markets, etc.). Many multi-agent dynamical interactions can be cast as Markov Decision Processes (MDPs). While existing research has focused on studying fairness in known environments, the exploration of fairness in such systems for unknown environments remains open. In this paper, we propose a  Reinforcement Learning (RL) approach to achieve fairness in multi-agent finite-horizon episodic MDPs. Instead of maximizing the sum of individual agents' value functions, we introduce a fairness function that ensures equitable rewards across agents. Since the classical Bellman's equation does not hold when the sum of individual value functions is not maximized, we cannot use traditional approaches. Instead, in order to explore, we maintain a confidence bound of the unknown environment and then propose an online convex optimization based approach to obtain a policy constrained to this confidence region. We show that such an approach achieves sub-linear regret in terms of the number of episodes. Additionally, we provide a probably approximately correct (PAC) guarantee based on the obtained regret bound. We also propose an offline RL algorithm and bound the optimality gap with respect to the optimal fair solution. To mitigate computational complexity, we introduce a policy-gradient type method for the fair objective. Simulation experiments also demonstrate the efficacy of our approach."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/832d7ea57a154b15de9382f6f8db49dad34bc05e.pdf"}, "_bibtex": {"value": "@inproceedings{\nju2024achieving,\ntitle={Achieving Fairness in Multi-Agent {MDP} Using Reinforcement Learning},\nauthor={Peizhong Ju and Arnob Ghosh and Ness Shroff},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yoVq2BGQdP}\n}"}, "paperhash": {"value": "ju|achieving_fairness_in_multiagent_mdp_using_reinforcement_learning"}}, "number": 7562, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7562/-/Revision", "ICLR.cc/2024/Conference/Submission7562/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7562/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695479108675, "cdate": 1695479108675, "tmdate": 1710182829027, "mdate": 1710182829027, "pdate": 1705411013285, "version": 2}, {"id": "ndR8Ytrzhh", "forum": "ndR8Ytrzhh", "signatures": ["ICLR.cc/2024/Conference/Submission7556/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7556/Authors"], "content": {"title": {"value": "Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning"}, "authors": {"value": ["Yiwei Li", "Peiwen Yuan", "Shaoxiong Feng", "Boyuan Pan", "Xinglin Wang", "Bin Sun", "Heda Wang", "Kan Li"]}, "authorids": {"value": ["~Yiwei_Li1", "~Peiwen_Yuan1", "~Shaoxiong_Feng1", "~Boyuan_Pan1", "~Xinglin_Wang1", "~Bin_Sun3", "~Heda_Wang1", "~Kan_Li3"]}, "keywords": {"value": ["Self-consistency", "Chain-of-Thoughts", "Multi-Step Reasoning", "Large Language Models"]}, "TLDR": {"value": "We propose early-stopping self-consistency (ESC), a simple and scalable process which is capable of greatly reducing the cost of SC while maintaining performance."}, "abstract": {"value": "Self-consistency (SC) has been a widely used decoding strategy for chain-of-thought reasoning. Despite bringing significant performance improvements across a variety of multi-step reasoning tasks, it is a high-cost method that requires multiple sampling with the preset size. In this paper, we propose a simple and scalable sampling process, Early-Stopping Self-Consistency (ESC), to greatly reduce the cost of SC without sacrificing performance. On this basis, one control scheme for ESC is further derivated to dynamically choose the performance-cost balance for different tasks and models. To demonstrate ESC's effectiveness, we conducted extensive experiments on three popular categories of reasoning tasks: arithmetic, commonsense and symbolic reasoning over language models with varying scales. The empirical results show that ESC reduces the average number of sampling of chain-of-thought reasoning by a significant margin on six benchmarks, including MATH (-33.8%), GSM8K (-80.1%), StrategyQA (-76.8%), CommonsenseQA (-78.5%), Coin Flip (-84.2%) and Last Letters (-67.4%), while attaining comparable performances."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cb1e865be5cc18836e1f61dc8d857a0e438c9911.pdf"}, "supplementary_material": {"value": "/attachment/35eeba346f7fd550814066e1ed0c57445c026217.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024escape,\ntitle={Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning},\nauthor={Yiwei Li and Peiwen Yuan and Shaoxiong Feng and Boyuan Pan and Xinglin Wang and Bin Sun and Heda Wang and Kan Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ndR8Ytrzhh}\n}"}, "paperhash": {"value": "li|escape_skyhigh_cost_earlystopping_selfconsistency_for_multistep_reasoning"}}, "number": 7556, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7556/-/Revision", "ICLR.cc/2024/Conference/Submission7556/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7556/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478841291, "cdate": 1695478841291, "tmdate": 1710404347854, "mdate": 1710404347854, "pdate": 1705411013032, "version": 2}, {"id": "3zQo5oUvia", "forum": "3zQo5oUvia", "signatures": ["ICLR.cc/2024/Conference/Submission7550/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7550/Authors"], "content": {"title": {"value": "REBAR: Retrieval-Based Reconstruction for Time-series Contrastive Learning"}, "authors": {"value": ["Maxwell Xu", "Alexander Moreno", "Hui Wei", "Benjamin Marlin", "James Matthew Rehg"]}, "authorids": {"value": ["~Maxwell_Xu1", "~Alexander_Moreno1", "~Hui_Wei3", "~Benjamin_Marlin1", "~James_Matthew_Rehg1"]}, "keywords": {"value": ["time-series", "contrastive learning", "masked reconstruction", "self-supervised learning", "imputation", "unsupervised learning"]}, "TLDR": {"value": "We introduce a novel method of identifying positives and negatives for time-series contrastive learning with Retrieval-Based Reconstruction (REBAR)"}, "abstract": {"value": "The success of self-supervised contrastive learning hinges on identifying positive data pairs, such that when they are pushed together in embedding space, the space encodes useful information for subsequent downstream tasks. Constructing positive pairs is non-trivial as the pairing must be similar enough to reflect a shared semantic meaning, but different enough to capture within-class variation. Classical approaches in vision use augmentations to exploit well-established invariances to construct positive pairs, but invariances in the time-series domain are much less obvious. In our work, we propose a novel method of using a learned measure for identifying positive pairs. Our Retrieval-Based Reconstruction (REBAR) measure measures the similarity between two sequences as the reconstruction error that results from reconstructing one sequence with retrieved information from the other. Then, if the two sequences have high REBAR similarity, we label them as a positive pair. Through validation experiments, we show that the REBAR error is a predictor of mutual class membership. Once integrated into a contrastive learning framework, our REBAR method learns an embedding that achieves state-of-the-art performance on downstream tasks across various modalities."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/83c59b117a7df04c999b82b4c9105cb0eb96c7ea.pdf"}, "supplementary_material": {"value": "/attachment/c86726dbbfe0b277c6a2e05cefadb1c1da643426.pdf"}, "_bibtex": {"value": "@inproceedings{\nxu2024retrievalbased,\ntitle={Retrieval-Based Reconstruction For Time-series Contrastive Learning},\nauthor={Maxwell Xu and Alexander Moreno and Hui Wei and Benjamin Marlin and James Matthew Rehg},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3zQo5oUvia}\n}"}, "paperhash": {"value": "xu|rebar_retrievalbased_reconstruction_for_timeseries_contrastive_learning"}}, "number": 7550, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7550/-/Revision", "ICLR.cc/2024/Conference/Submission7550/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7550/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478642721, "cdate": 1695478642721, "tmdate": 1713164694032, "mdate": 1713164694032, "pdate": 1705411012873, "version": 2}, {"id": "fGAIgO75dG", "forum": "fGAIgO75dG", "signatures": ["ICLR.cc/2024/Conference/Submission7539/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7539/Authors"], "content": {"title": {"value": "CoLiDE: Concomitant Linear DAG Estimation"}, "authors": {"value": ["Seyed Saman Saboksayr", "Gonzalo Mateos", "Mariano Tepper"]}, "authorids": {"value": ["~Seyed_Saman_Saboksayr1", "~Gonzalo_Mateos1", "~Mariano_Tepper2"]}, "keywords": {"value": ["directed acyclic graph", "concomitant scale estimation", "causal discovery", "graph structure learning"]}, "TLDR": {"value": "We bring to bear ideas from concomitant scale estimation in linear regression and propose a novel score function for regression-based inference of linear DAGs, demonstrating significant improvements relative to existing state-of-the-art methods."}, "abstract": {"value": "We deal with the combinatorial problem of learning directed acyclic graph (DAG) structure from observational data adhering to a linear structural equation model (SEM). Leveraging advances in differentiable, nonconvex characterizations of acyclicity, recent efforts have advocated a continuous constrained optimization paradigm to efficiently explore the space of DAGs. Most existing methods employ lasso-type score functions to guide this search, which (i) require expensive penalty parameter retuning when the $\\textit{unknown}$ SEM noise variances change across problem instances; and (ii) implicitly rely on limiting homoscedasticity assumptions. In this work, we propose a new convex score function for sparsity-aware learning of linear DAGs, which incorporates concomitant estimation of scale and thus effectively decouples the sparsity parameter from noise levels. Regularization via a smooth, nonconvex acyclicity penalty term yields CoLiDE ($\\textbf{Co}$ncomitant $\\textbf{Li}$near $\\textbf{D}$AG $\\textbf{E}$stimation), a regression-based criterion amenable to efficient gradient computation and closed-form estimation of exogenous noise levels in heteroscedastic scenarios. Our algorithm outperforms state-of-the-art methods without incurring added complexity, especially when the DAGs are larger and the noise level profile is heterogeneous. We also find CoLiDE exhibits enhanced stability manifested via reduced standard deviations in several domain-specific metrics, underscoring the robustness of our novel linear DAG estimator."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/aa3fa937917ed9b3c6f891c1080689cdf78c72e8.pdf"}, "supplementary_material": {"value": "/attachment/61f224de40a83e3e6f224f88faf4f7eb12e0428e.zip"}, "_bibtex": {"value": "@inproceedings{\nsaboksayr2024colide,\ntitle={CoLi{DE}: Concomitant Linear {DAG} Estimation},\nauthor={Seyed Saman Saboksayr and Gonzalo Mateos and Mariano Tepper},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fGAIgO75dG}\n}"}, "paperhash": {"value": "saboksayr|colide_concomitant_linear_dag_estimation"}}, "number": 7539, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7539/-/Revision", "ICLR.cc/2024/Conference/Submission7539/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7539/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478161585, "cdate": 1695478161585, "tmdate": 1710296954923, "mdate": 1710296954923, "pdate": 1705411012341, "version": 2}, {"id": "ikmuHqugN7", "forum": "ikmuHqugN7", "signatures": ["ICLR.cc/2024/Conference/Submission7535/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7535/Authors"], "content": {"title": {"value": "Scaling Convex Neural Networks with Burer-Monteiro Factorization"}, "authors": {"value": ["Arda Sahiner", "Tolga Ergen", "Batu Ozturkler", "John M. Pauly", "Morteza Mardani", "Mert Pilanci"]}, "authorids": {"value": ["~Arda_Sahiner1", "~Tolga_Ergen1", "~Batu_Ozturkler1", "~John_M._Pauly1", "~Morteza_Mardani1", "~Mert_Pilanci3"]}, "keywords": {"value": ["burer-monteiro", "convex optimization", "neural networks", "stationary points", "global optima", "relu activation"]}, "TLDR": {"value": "We apply the Burer-Monteiro factorization to two-layer ReLU (fully-connected, convolutional, self-attention) neural networks by leveraging their implicit convexity, and provide insights into stationary points and local optima of these networks."}, "abstract": {"value": "It has been demonstrated that the training problem for a variety of (non) linear two-layer neural networks (such as two-layer perceptrons, convolutional networks, and self-attention) can be posed as equivalent convex optimization problems, with an induced regularizer which encourages low rank. However, this regularizer becomes prohibitively expensive to compute at moderate scales, impeding training convex neural networks. To this end, we propose applying the Burer-Monteiro factorization to convex neural networks, which for the first time enables a Burer-Monteiro perspective on neural networks with non-linearities. This factorization leads to an equivalent yet computationally tractable non-convex alternative with no spurious local minima. We develop a novel relative optimality bound of stationary points of the Burer-Monteiro factorization, providing verifiable conditions under which any stationary point is a global optimum. Further, for the first time, we show that linear self-attention with sufficiently many heads has no spurious local minima. Our experiments validate the novel relative optimality bound and the utility of the Burer-Monteiro factorization for scaling convex neural networks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2a8bb9c7bc31118166cd6821cebc31d9d2748160.pdf"}, "supplementary_material": {"value": "/attachment/e7b3b544e859df2c67a6c062cb75b76495cc8a6e.zip"}, "_bibtex": {"value": "@inproceedings{\nsahiner2024scaling,\ntitle={Scaling Convex Neural Networks with Burer-Monteiro Factorization},\nauthor={Arda Sahiner and Tolga Ergen and Batu Ozturkler and John M. Pauly and Morteza Mardani and Mert Pilanci},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ikmuHqugN7}\n}"}, "paperhash": {"value": "sahiner|scaling_convex_neural_networks_with_burermonteiro_factorization"}}, "number": 7535, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7535/-/Revision", "ICLR.cc/2024/Conference/Submission7535/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7535/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478132877, "cdate": 1695478132877, "tmdate": 1710556343617, "mdate": 1710556343617, "pdate": 1705411012203, "version": 2}, {"id": "6LLho5X6xV", "forum": "6LLho5X6xV", "signatures": ["ICLR.cc/2024/Conference/Submission7524/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7524/Authors"], "content": {"title": {"value": "UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science"}, "authors": {"value": ["Yazheng Yang", "Yuqi Wang", "Guang Liu", "Ledell Wu", "Qi Liu"]}, "authorids": {"value": ["~Yazheng_Yang2", "~Yuqi_Wang5", "~Guang_Liu2", "~Ledell_Wu1", "~Qi_Liu5"]}, "keywords": {"value": ["Pre-training Tabular Encoder", "Pre-training", "Heterogeneous Tabular Data", "Classification and Regression", "Deep Learning"]}, "TLDR": {"value": "This study explores pre-training over tabular data with the proposed UniTabE method, addressing challenges in diverse table structures and knowledge transfer."}, "abstract": {"value": "Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks. This study seeks to extend the power of pretraining methodologies to facilitating the prediction over tables in data science, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks. The primary research questions underpinning this work revolve around the establishment of a universal pretraining protocol for tables with varied structures, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time. In response to these challenges, we introduce UniTabE, a straightforward yet effective method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures. UniTabE's core concept relies on representing each basic table element with a module, termed TabUnit. This is subsequently followed by a Transformer encoder to refine the representation. Moreover, our model is designed to facilitate pretraining and finetuning through the utilization of free-form prompts. In order to implement the pretraining phase, we curated an expansive tabular dataset comprising approximately 13 billion samples, meticulously gathered from the Kaggle platform. This research primarily centers on classification and regression tasks involving tabular data, and conducts rigorous experimental testing and analyses to validate the effectiveness of our methodology. The experimental results demonstrate UniTabE's superior performance against several baseline models across a multitude of benchmark datasets. This, therefore, underscores UniTabE's potential to significantly enhance the semantic representation of tabular data, thereby marking a significant stride for tabular data analysis."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c4c9e872d51930ec24a408aba0f94adc0b6c97ac.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024unitabe,\ntitle={UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science},\nauthor={Yazheng Yang and Yuqi Wang and Guang Liu and Ledell Wu and Qi Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6LLho5X6xV}\n}"}, "paperhash": {"value": "yang|unitabe_a_universal_pretraining_protocol_for_tabular_foundation_model_in_data_science"}}, "number": 7524, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7524/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7524/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695477814811, "cdate": 1695477814811, "tmdate": 1710317326661, "mdate": 1710317326661, "pdate": 1705411011782, "version": 2}, {"id": "hCrFG9cyuC", "forum": "hCrFG9cyuC", "signatures": ["ICLR.cc/2024/Conference/Submission7518/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7518/Authors"], "content": {"title": {"value": "PolyVoice: Language Models for Speech to Speech Translation"}, "authors": {"value": ["Qian qian Dong", "Zhiying Huang", "Qiao Tian", "Chen Xu", "Tom Ko", "yunlong zhao", "Siyuan Feng", "Tang Li", "Kexin Wang", "Xuxin Cheng", "Fengpeng Yue", "Ye Bai", "Xi Chen", "Lu Lu", "Zejun MA", "Yuping Wang", "Mingxuan Wang", "Yuxuan Wang"]}, "authorids": {"value": ["~Qian_qian_Dong1", "~Zhiying_Huang1", "~Qiao_Tian1", "~Chen_Xu9", "~Tom_Ko2", "~yunlong_zhao4", "~Siyuan_Feng3", "~Tang_Li2", "~Kexin_Wang5", "~Xuxin_Cheng3", "~Fengpeng_Yue1", "~Ye_Bai1", "~Xi_Chen46", "~Lu_Lu6", "~Zejun_MA1", "~Yuping_Wang3", "~Mingxuan_Wang1", "~Yuxuan_Wang1"]}, "keywords": {"value": ["Speech-to-Speecn Translatiom", "Audio Language Model", "Voice Clone"]}, "abstract": {"value": "With the huge success of GPT models in natural language processing, there is a growing interest in applying language modeling approaches to speech tasks.\nCurrently, the dominant architecture in speech-to-speech translation (S2ST) remains the encoder-decoder paradigm, creating a need to investigate the impact of language modeling approaches in this area. \nIn this study, we introduce PolyVoice, a language model-based framework designed for S2ST systems. Our framework comprises three decoder-only language models: a translation language model, a duration language model, and a speech synthesis language model. \nThese language models employ different types of prompts to extract learned information effectively. By utilizing unsupervised semantic units, our framework can transfer semantic information across these models, making it applicable even to unwritten languages. \nWe evaluate our system on Chinese $\\rightarrow$ English and English $\\rightarrow$ Spanish language pairs. Experimental results demonstrate that \\method outperforms the state-of-the-art encoder-decoder model, producing voice-cloned speech with high translation and audio quality.\nSpeech samples are available at https://polyvoice.github.io."}, "pdf": {"value": "/pdf/65d45b57c8e451cf38da2f641f20ffa4065c3ab9.pdf"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\ndong2024polyvoice,\ntitle={PolyVoice: Language Models for Speech to Speech Translation},\nauthor={Qian qian Dong and Zhiying Huang and Qiao Tian and Chen Xu and Tom Ko and yunlong zhao and Siyuan Feng and Tang Li and Kexin Wang and Xuxin Cheng and Fengpeng Yue and Ye Bai and Xi Chen and Lu Lu and Zejun MA and Yuping Wang and Mingxuan Wang and Yuxuan Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hCrFG9cyuC}\n}"}, "TLDR": {"value": "In this study, we introduce PolyVoice, a language model-based framework designed for S2ST systems."}, "paperhash": {"value": "dong|polyvoice_language_models_for_speech_to_speech_translation"}}, "number": 7518, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7518/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7518/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695477397209, "cdate": 1695477397209, "tmdate": 1713016823626, "mdate": 1713016823626, "pdate": 1705411011616, "version": 2}, {"id": "IOEEDkla96", "forum": "IOEEDkla96", "signatures": ["ICLR.cc/2024/Conference/Submission7515/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7515/Authors"], "content": {"title": {"value": "Adversarial Feature Map Pruning for Backdoor"}, "authors": {"value": ["Dong HUANG", "Qingwen Bu"]}, "authorids": {"value": ["~Dong_HUANG4", "~Qingwen_Bu1"]}, "keywords": {"value": ["Backdoor Defense", "Data Poisoning"]}, "abstract": {"value": "Deep neural networks have been widely used in many critical applications, such as autonomous vehicles and medical diagnosis. However, their security is threatened by backdoor attacks, which are achieved by adding artificial patterns to specific training data. Existing defense strategies primarily focus on using reverse engineering to reproduce the backdoor trigger generated by attackers and subsequently repair the DNN model by adding the trigger into inputs and fine-tuning the model with ground truth labels. However, once the trigger generated by the attackers is complex and invisible, the defender cannot reproduce the trigger successfully then the DNN model will not be repaired, as the trigger is not effectively removed. \n\nIn this work, we propose Adversarial Feature Map Pruning for Backdoor (FMP) to mitigate backdoor from the DNN. Unlike existing defense strategies, which focus on reproducing backdoor triggers, FMP attempts to prune backdoor feature maps, which are trained to extract backdoor information from inputs. After pruning these backdoor feature maps, FMP will fine-tune the model with a secure subset of training data. Our experiments demonstrate that, compared to existing defense strategies, FMP can effectively reduce the Attack Success Rate (ASR) even against the most complex and invisible attack triggers (e.g., FMP decreases the ASR to 2.86% in CIFAR10, which is 19.2% to 65.41% lower than baselines). Second, unlike conventional defense methods that tend to exhibit low robust accuracy (that is, the accuracy of the model on poisoned data), FMP achieves a higher RA, indicating its superiority in maintaining model performance while mitigating the effects of backdoor attacks (e.g., FMP obtains 87.40% RA in CIFAR10). Our code is publicly available at: https://github.com/hku-systems/FMP."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e950686985c71b8def382e18d59ba3a96431b8a9.pdf"}, "supplementary_material": {"value": "/attachment/68eeac584ac34fbbaef0a65c05f54b5b92a52b2a.zip"}, "_bibtex": {"value": "@inproceedings{\nbu2024adversarial,\ntitle={Adversarial Feature Map Pruning for Backdoor},\nauthor={Qingwen Bu and Dong HUANG},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IOEEDkla96}\n}"}, "TLDR": {"value": "We propose a backdoor defense method that effectively detect and pruning feature maps that propagate backdoor information."}, "paperhash": {"value": "huang|adversarial_feature_map_pruning_for_backdoor"}}, "number": 7515, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7515/-/Revision", "ICLR.cc/2024/Conference/Submission7515/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7515/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695477261138, "cdate": 1695477261138, "tmdate": 1712024379252, "mdate": 1712024379252, "pdate": 1705411011561, "version": 2}, {"id": "awHTL3Hpto", "forum": "awHTL3Hpto", "signatures": ["ICLR.cc/2024/Conference/Submission7513/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7513/Authors"], "content": {"title": {"value": "Expressivity of ReLU-Networks under Convex Relaxations"}, "authors": {"value": ["Maximilian Baader", "Mark Niklas Mueller", "Yuhao Mao", "Martin Vechev"]}, "authorids": {"value": ["~Maximilian_Baader1", "~Mark_Niklas_Mueller2", "~Yuhao_Mao1", "~Martin_Vechev1"]}, "keywords": {"value": ["Convex Relaxations", "Neural Network Verification", "Certified Robustness", "Adversarial Robustness", "Universal Approximation"]}, "TLDR": {"value": "ReLU networks cannot encode multivariate, convex, monotone, continuous piecewise linear functions such that single-neuron convex relaxations yield precise bounds and more results on the expressiveness of ReLU networks under convex relaxation."}, "abstract": {"value": "Convex relaxations are a key component of training and certifying provably safe neural networks. However, despite substantial progress, a wide and poorly understood accuracy gap to standard networks remains, raising the question of whether this is due to fundamental limitations of convex relaxations. Initial work investigating this question focused on the simple and widely used IBP relaxation. It revealed that some univariate, convex, continuous piecewise linear (CPWL) functions cannot be encoded by any ReLU network such that its IBP-analysis is precise.\nTo explore whether this limitation is shared by more advanced convex relaxations, we conduct the first in-depth study on the expressive power of ReLU networks across all commonly used convex relaxations. We show that: (i) more advanced relaxations allow a larger class of univariate functions to be expressed as precisely analyzable ReLU networks, (ii) more precise relaxations can allow exponentially larger solution spaces of ReLU networks encoding the same functions, and (iii) even using the most precise single-neuron relaxations, it is impossible to construct precisely analyzable ReLU networks that express multivariate, convex, monotone CPWL functions."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b97b6766d2a0d67594150433f93ce916163a0039.pdf"}, "_bibtex": {"value": "@inproceedings{\nbaader2024expressivity,\ntitle={Expressivity of Re{LU}-Networks under Convex Relaxations},\nauthor={Maximilian Baader and Mark Niklas Mueller and Yuhao Mao and Martin Vechev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=awHTL3Hpto}\n}"}, "paperhash": {"value": "baader|expressivity_of_relunetworks_under_convex_relaxations"}}, "number": 7513, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7513/-/Revision", "ICLR.cc/2024/Conference/Submission7513/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7513/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695476993080, "cdate": 1695476993080, "tmdate": 1710172447623, "mdate": 1710172447623, "pdate": 1705411011478, "version": 2}, {"id": "YqyTXmF8Y2", "forum": "YqyTXmF8Y2", "signatures": ["ICLR.cc/2024/Conference/Submission7508/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7508/Authors"], "content": {"title": {"value": "EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models"}, "authors": {"value": ["Koichi Namekata", "Amirmojtaba Sabour", "Sanja Fidler", "Seung Wook Kim"]}, "authorids": {"value": ["~Koichi_Namekata1", "~Amirmojtaba_Sabour1", "~Sanja_Fidler1", "~Seung_Wook_Kim1"]}, "keywords": {"value": ["Latent Diffusion Models", "Diffusion Models", "Generative Models", "Unsupervised Semantic Segmentation"]}, "abstract": {"value": "Diffusion models have recently received increasing research attention for their remarkable transfer abilities in semantic segmentation tasks. However, generating fine-grained segmentation masks with diffusion models often requires additional training on annotated datasets, leaving it unclear to what extent pre-trained diffusion models alone understand the semantic relations of their generated images. To address this question, we leverage the semantic knowledge extracted from Stable Diffusion (SD) and aim to develop an image segmentor capable of generating fine-grained segmentation maps without any additional training. The primary difficulty stems from the fact that semantically meaningful feature maps typically exist only in the spatially lower-dimensional layers, which poses a challenge in directly extracting pixel-level semantic relations from these feature maps. To overcome this issue, our framework identifies semantic correspondences between image pixels and spatial locations of low-dimensional feature maps by exploiting SD's generation process and utilizes them for constructing image-resolution segmentation maps. In extensive experiments, the produced segmentation maps are demonstrated to be well delineated and capture detailed parts of the images, indicating the existence of highly accurate pixel-level semantic knowledge in diffusion models. \nProject page: https://kmcode1.github.io/Projects/EmerDiff/"}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/06738398098994bbb82b8cc820225d87217081e7.pdf"}, "_bibtex": {"value": "@inproceedings{\nnamekata2024emerging,\ntitle={Emerging Pixel-level Semantic Knowledge in Diffusion Models},\nauthor={Koichi Namekata and Amirmojtaba Sabour and Sanja Fidler and Seung Wook Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YqyTXmF8Y2}\n}"}, "paperhash": {"value": "namekata|emerdiff_emerging_pixellevel_semantic_knowledge_in_diffusion_models"}}, "number": 7508, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7508/-/Revision", "ICLR.cc/2024/Conference/Submission7508/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7508/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695476846248, "cdate": 1695476846248, "tmdate": 1709661540376, "mdate": 1709661540376, "pdate": 1705411011240, "version": 2}, {"id": "wXpSidPpc5", "forum": "wXpSidPpc5", "signatures": ["ICLR.cc/2024/Conference/Submission7503/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7503/Authors"], "content": {"title": {"value": "CLEX: Continuous  Length Extrapolation for Large Language Models"}, "authors": {"value": ["Guanzheng Chen", "Xin Li", "Zaiqiao Meng", "Shangsong Liang", "Lidong Bing"]}, "authorids": {"value": ["~Guanzheng_Chen1", "~Xin_Li40", "~Zaiqiao_Meng1", "~Shangsong_Liang1", "~Lidong_Bing2"]}, "keywords": {"value": ["Length Extrapolation", "Long Context", "Large Language Model (LLM)", "Neural Ordinary Differential Equation (ODE)"]}, "abstract": {"value": "Transformer-based Large Language Models (LLMs) are pioneering advances in many natural language processing tasks, however, their exceptional capabilities are restricted within the preset context window of Transformer. Position Embedding (PE) scaling methods, while effective in extending the context window to a specific length, demonstrate either notable limitations in their extrapolation abilities or sacrificing partial performance within the context window. Length extrapolation methods, although theoretically capable of extending the context window beyond the training sequence length, often underperform in practical long-context applications. To address these challenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We generalise the PE scaling approaches to model the continuous dynamics by ordinary differential equations over the length scaling factor, thereby overcoming the constraints of current PE scaling methods designed for specific lengths. Moreover, by extending the dynamics to desired context lengths beyond the training sequence length, CLEX facilitates the length extrapolation with impressive performance in practical tasks. We demonstrate that CLEX can be seamlessly incorporated into LLMs equipped with Rotary Position Embedding, such as LLaMA and GPT-NeoX, with negligible impact on training and inference latency. Experimental results reveal that CLEX can effectively extend the context window to over 4\u00d7 or almost 8\u00d7 training length, with no deterioration in performance. Furthermore, when evaluated on the practical LongBench benchmark, our model trained on a 4k length exhibits competitive performance against state-of-the-art open-source models trained on context lengths up to 32k. Our code is available at https://github.com/DAMO-NLP-SG/CLEX."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ed775e08f207a91db5b9b4135b7f1b41420adb39.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024clex,\ntitle={{CLEX}: Continuous  Length Extrapolation for Large Language Models},\nauthor={Guanzheng Chen and Xin Li and Zaiqiao Meng and Shangsong Liang and Lidong Bing},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wXpSidPpc5}\n}"}, "TLDR": {"value": "Extrapolating the context length of LLMs to lengths 4x~ 8x times beyond training length via continual and trainable RoPE scaling."}, "paperhash": {"value": "chen|clex_continuous_length_extrapolation_for_large_language_models"}}, "number": 7503, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7503/-/Revision", "ICLR.cc/2024/Conference/Submission7503/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7503/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695476414490, "cdate": 1695476414490, "tmdate": 1711300318384, "mdate": 1711300318384, "pdate": 1705411011076, "version": 2}, {"id": "YEPlTU5mZC", "forum": "YEPlTU5mZC", "signatures": ["ICLR.cc/2024/Conference/Submission7490/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7490/Authors"], "content": {"title": {"value": "Implicit Gaussian process representation of vector fields over arbitrary latent manifolds"}, "authors": {"value": ["Robert Peach", "Matteo Vinao-Carl", "Nir Grossman", "Michael David", "Emma Mallas", "David J. Sharp", "Paresh A. Malhotra", "Pierre Vandergheynst", "Adam Gosztolai"]}, "authorids": {"value": ["~Robert_Peach1", "~Matteo_Vinao-Carl1", "nirg@imperial.ac.uk", "michael.david12@imperial.ac.uk", "e.mallas@imperial.ac.uk", "~David_J._Sharp1", "p.malhotra@imperial.ac.uk", "~Pierre_Vandergheynst1", "~Adam_Gosztolai1"]}, "keywords": {"value": ["Gaussian processes", "neuroscience", "vector field", "tangent bundle", "connection Laplacian", "EEG", "Alzheimer's disease"]}, "abstract": {"value": "Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds, appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-density neural dynamics derived from low-density EEG recordings in healthy individuals and Alzheimer's patients. We show that vector field singularities are important disease markers and that their reconstruction leads to a comparable classification accuracy of disease states to high-density recordings. Thus, our method overcomes a significant practical limitation in experimental and clinical applications."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/67fb456606ec64e3609b6ff016417f5926926ed9.pdf"}, "_bibtex": {"value": "@inproceedings{\npeach2024implicit,\ntitle={Implicit Gaussian process representation of vector fields over arbitrary latent manifolds},\nauthor={Robert Peach and Matteo Vinao-Carl and Nir Grossman and Michael David and Emma Mallas and David J. Sharp and Paresh A. Malhotra and Pierre Vandergheynst and Adam Gosztolai},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YEPlTU5mZC}\n}"}, "paperhash": {"value": "peach|implicit_gaussian_process_representation_of_vector_fields_over_arbitrary_latent_manifolds"}}, "number": 7490, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7490/-/Revision", "ICLR.cc/2024/Conference/Submission7490/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7490/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695475978590, "cdate": 1695475978590, "tmdate": 1709730885310, "mdate": 1709730885310, "pdate": 1705411010909, "version": 2}, {"id": "gbrHZq07mq", "forum": "gbrHZq07mq", "signatures": ["ICLR.cc/2024/Conference/Submission7474/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7474/Authors"], "content": {"title": {"value": "Logical Languages Accepted by Transformer Encoders with Hard Attention"}, "authors": {"value": ["Pablo Barcelo", "Alexander Kozachinskiy", "Anthony Widjaja Lin", "Vladimir Podolskii"]}, "authorids": {"value": ["~Pablo_Barcelo1", "~Alexander_Kozachinskiy1", "~Anthony_Widjaja_Lin1", "podolskii.vv@gmail.com"]}, "keywords": {"value": ["transformer encoders", "languages", "AC0", "first order logic", "linear temporal logic", "counting terms", "parity", "majority"]}, "TLDR": {"value": "We show that all languages definable in first-order logic with arbitrary unary numerical predicates can be recognized by transformer encoders with unique hard attention"}, "abstract": {"value": "We contribute to the study of formal languages that can be recognized by transformer encoders. We focus on two self-attention mechanisms: (1) UHAT (Unique Hard Attention Transformers) and (2) AHAT (Average Hard Attention Transformers). UHAT encoders are known to  recognize only languages inside the circuit complexity class ${\\sf AC}^0$, i.e., accepted by a family of poly-sized and depth-bounded boolean circuits with unbounded fan-ins. On the other hand, AHAT encoders can recognize languages outside ${\\sf AC}^0$), but their expressive power still lies within the bigger circuit complexity class ${\\sf TC}^0$, i.e., ${\\sf AC}^0$-circuits extended by majority gates.\nWe first show a negative result that there is an  ${\\sf AC}^0$-language that cannot be recognized by an UHAT encoder. On the positive side, we show that UHAT encoders can recognize a rich fragment of ${\\sf AC}^0$-languages, namely, all languages definable in first-order logic with arbitrary unary numerical predicates. This logic, includes, for example, all regular languages from  ${\\sf AC}^0$. We then show that AHAT encoders can recognize all languages of our logic even when we enrich it with counting terms. Using these results, we obtain a characterization of which counting properties are expressible by UHAT and AHAT, in relation to regular languages."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bde9e683d85c361b4e67d54e63bb0300a10ffcdd.pdf"}, "supplementary_material": {"value": "/attachment/5630524797871c905ca27daf2cd1114719f1f16d.pdf"}, "_bibtex": {"value": "@inproceedings{\nbarcelo2024logical,\ntitle={Logical Languages Accepted by Transformer Encoders with Hard Attention},\nauthor={Pablo Barcelo and Alexander Kozachinskiy and Anthony Widjaja Lin and Vladimir Podolskii},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gbrHZq07mq}\n}"}, "paperhash": {"value": "barcelo|logical_languages_accepted_by_transformer_encoders_with_hard_attention"}}, "number": 7474, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7474/-/Revision", "ICLR.cc/2024/Conference/Submission7474/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7474/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695475188635, "cdate": 1695475188635, "tmdate": 1710515452219, "mdate": 1710515452219, "pdate": 1705411010585, "version": 2}, {"id": "qNrJJZAKI3", "forum": "qNrJJZAKI3", "signatures": ["ICLR.cc/2024/Conference/Submission7468/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7468/Authors"], "content": {"title": {"value": "FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling"}, "authors": {"value": ["Yu Tian", "Min Shi", "Yan Luo", "Ava Kouhana", "Tobias Elze", "Mengyu Wang"]}, "authorids": {"value": ["~Yu_Tian8", "~Min_Shi4", "~Yan_Luo2", "akouhana@meei.harvard.edu", "~Tobias_Elze1", "~Mengyu_Wang4"]}, "keywords": {"value": ["Medical Segmentation", "Medical Imaging", "Fairness Learning", "Health Equity", "Deep Learning", "Trustworthy AI"]}, "abstract": {"value": "Fairness in artificial intelligence models has gained significantly more attention in recent years, especially in the area of medicine, as fairness in medical models is critical to people's well-being and lives. High-quality medical fairness datasets are needed to promote fairness learning research. Existing medical fairness datasets are all for classification tasks, and no fairness datasets are available for medical segmentation, while medical segmentation is an equally important clinical task as classifications, which can provide detailed spatial information on organ abnormalities ready to be assessed by clinicians. In this paper, we propose the first fairness dataset for medical segmentation named Harvard-FairSeg with 10,000 subject samples. In addition, we propose a fair error-bound scaling approach to reweight the loss function with the upper error-bound in each identity group, using the segment anything model (SAM). We anticipate that the segmentation performance equity can be improved by explicitly tackling the hard cases with high training errors in each identity group. To facilitate fair comparisons, we utilize a novel equity-scaled segmentation performance metric to compare segmentation metrics in the context of fairness, such as the equity-scaled Dice coefficient. Through comprehensive experiments, we demonstrate that our fair error-bound scaling approach either has superior or comparable fairness performance to the state-of-the-art fairness learning models. The dataset and code are publicly accessible via https://ophai.hms.harvard.edu/datasets/harvard-fairseg10k."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/001b547d0bb2c924748df74bdd8de4a7b4d69e05.pdf"}, "TLDR": {"value": "We curate and release the first large-scale fairness dataset for medical segmentation."}, "_bibtex": {"value": "@inproceedings{\ntian2024fairseg,\ntitle={FairSeg: A Large-scale Medical Image Segmentation Dataset for Fairness Learning with Fair Error-Bound Scaling},\nauthor={Yu Tian and Min Shi and Yan Luo and Ava Kouhana and Tobias Elze and Mengyu Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qNrJJZAKI3}\n}"}, "paperhash": {"value": "tian|fairseg_a_largescale_medical_image_segmentation_dataset_for_fairness_learning_using_segment_anything_model_with_fair_errorbound_scaling"}}, "number": 7468, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7468/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7468/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695474826704, "cdate": 1695474826704, "tmdate": 1710081843995, "mdate": 1710081843995, "pdate": 1705411010444, "version": 2}, {"id": "G1Hlubz1fR", "forum": "G1Hlubz1fR", "signatures": ["ICLR.cc/2024/Conference/Submission7467/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7467/Authors"], "content": {"title": {"value": "Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning"}, "authors": {"value": ["Haowen Wang", "Tao Sun", "Congyun Jin", "Yingbo Wang", "Yibo Fan", "Yunqi Xu", "Yuliang Du", "Cong Fan"]}, "authorids": {"value": ["~Haowen_Wang1", "~Tao_Sun15", "~Congyun_Jin1", "~Yingbo_Wang3", "~Yibo_Fan1", "~Yunqi_Xu1", "~Yuliang_Du1", "~Cong_Fan1"]}, "keywords": {"value": ["Modular skill learning", "Multi-task learning", "Parameter-Efficient", "Fine-Tuning"]}, "TLDR": {"value": "A novel paradigm of Parameter Efficient Fine-Tuning (PEFT) for multi-task learning, harnessing specialized and shared domain skills."}, "abstract": {"value": "Modular and composable transfer learning is an emerging direction in the field of Parameter Efficient Fine-Tuning, as it enables neural networks to better organize various aspects of knowledge, leading to improved cross-task generalization.\nIn this paper, we introduce a novel approach Customized Polytropon ($\\texttt{C-Poly}$) that combines task-common skills and task-specific skills, while the skill parameters being highly parameterized using low-rank techniques.\nEach task is associated with a customizable number of exclusive specialized skills and also benefits from skills shared with peer tasks. A skill assignment matrix is jointly learned. To evaluate our approach, we conducted extensive experiments on the Super-NaturalInstructions and the SuperGLUE benchmarks.\nOur findings demonstrate that $\\texttt{C-Poly}$ outperforms fully-shared, task-specific, and skill-indistinguishable baselines, significantly enhancing the sample efficiency in multi-task learning scenarios."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d29096bf4d18202556151b6f81d96c80c8e0d188.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024customizable,\ntitle={Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning},\nauthor={Haowen Wang and Tao Sun and Congyun Jin and Yingbo Wang and Yibo Fan and Yunqi Xu and Yuliang Du and Cong Fan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=G1Hlubz1fR}\n}"}, "paperhash": {"value": "wang|customizable_combination_of_parameterefficient_modules_for_multitask_learning"}}, "number": 7467, "odate": 1697213872796, "pdate": 1705411010346, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7467/-/Revision", "ICLR.cc/2024/Conference/Submission7467/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7467/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695474776570, "cdate": 1695474776570, "tmdate": 1713066993666, "mdate": 1713066993666, "version": 2}, {"id": "Nu9mOSq7eH", "forum": "Nu9mOSq7eH", "signatures": ["ICLR.cc/2024/Conference/Submission7458/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7458/Authors"], "content": {"title": {"value": "InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists"}, "authors": {"value": ["Yulu Gan", "Sungwoo Park", "Alexander Marcel Schubert", "Anthony Philippakis", "Ahmed Alaa"]}, "authorids": {"value": ["~Yulu_Gan1", "~Sungwoo_Park3", "~Alexander_Marcel_Schubert1", "~Anthony_Philippakis1", "~Ahmed_Alaa1"]}, "keywords": {"value": ["Vision generalists", "Text-to-image models", "Multi-task learning"]}, "abstract": {"value": "Recent advances in generative diffusion models have enabled text-controlled synthesis of realistic and diverse images with impressive quality. Despite these remarkable advances, the application of text-to-image generative models in computer vision for standard visual recognition tasks remains limited. The current de facto approach for these tasks is to design model architectures and loss functions that are tailored to the task at hand. In this paper, we develop a unified language interface for computer vision tasks that abstracts away task specific design choices and enables task execution by following natural language instructions. Our approach involves casting multiple computer vision tasks as text-to-image generation problems. Here, the text represents an instruction describing the task, and the resulting image is a visually-encoded task output. To train our model, we pool commonly-used computer vision datasets covering a range of tasks, including segmentation, object detection, depth estimation, and classification. We then use a large language model to paraphrase prompt templates that convey the specific tasks to be conducted on each image, and through this process, we create a multi-modal and multi-task training dataset comprising input and output images along with annotated instructions. Following the InstructPix2Pix architecture, we apply instruction-tuning to a text-to-image diffusion model using our constructed dataset, steering its functionality from a generative model to an instruction-guided multi-task vision learner. Experiments demonstrate that our model, dubbed InstructCV, performs competitively compared to other generalist and task-specific vision models. Moreover, it exhibits compelling generalization capabilities to unseen data, categories, and user instructions."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/813f711597d117a14b81689c5b3a6724d70b1c8b.pdf"}, "_bibtex": {"value": "@inproceedings{\ngan2024instructcv,\ntitle={Instruct{CV}: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists},\nauthor={Yulu Gan and Sungwoo Park and Alexander Marcel Schubert and Anthony Philippakis and Ahmed Alaa},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Nu9mOSq7eH}\n}"}, "supplementary_material": {"value": "/attachment/85b09293971fcc775541cb57c97ed79ff83daabc.pdf"}, "paperhash": {"value": "gan|instructcv_instructiontuned_texttoimage_diffusion_models_as_vision_generalists"}}, "number": 7458, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7458/-/Revision", "ICLR.cc/2024/Conference/Submission7458/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7458/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695474312459, "cdate": 1695474312459, "tmdate": 1712351352458, "mdate": 1712351352458, "pdate": 1705411010151, "version": 2}, {"id": "Koh0i2u8qX", "forum": "Koh0i2u8qX", "signatures": ["ICLR.cc/2024/Conference/Submission7453/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7453/Authors"], "content": {"title": {"value": "Mitigating Emergent Robustness Degradation while Scaling Graph Learning"}, "authors": {"value": ["Xiangchi Yuan", "Chunhui Zhang", "Yijun Tian", "Yanfang Ye", "Chuxu Zhang"]}, "authorids": {"value": ["~Xiangchi_Yuan1", "~Chunhui_Zhang1", "~Yijun_Tian1", "~Yanfang_Ye1", "~Chuxu_Zhang2"]}, "keywords": {"value": ["Graph neural network"]}, "abstract": {"value": "Although graph neural networks have exhibited remarkable performance in various graph tasks, a significant concern is their vulnerability to adversarial attacks. Consequently, many defense methods have been proposed to alleviate the deleterious effects of adversarial attacks and learn robust graph representations. However, most of them are difficult to *simultaneously* avoid two major limitations: (i) an emergent and severe degradation in robustness when exposed to very intense attacks, and (ii) heavy computation complexity hinders them from scaling to large graphs. In response to these challenges, we introduce an innovative graph defense method for unpredictable real-world scenarios by *designing a graph robust learning framework that is resistant to robustness degradation* and *refraining from unscalable designs with heavy computation*: specifically, our method employs a denoising module, which eliminates edges that are associated with attacked nodes to reconstruct a cleaner graph; Then, it applies Mixture-of-Experts to select differentially private noises with varying magnitudes to counteract the hidden features attacked at different intensities toward robust predictions; Moreover, our overall design avoids the reliance on heavy adjacency matrix computations, such as SVD, thus facilitating its applicability even on large graphs. Comprehensive experiments have been conducted to demonstrate the anti-degraded robustness and scalability of our method, as compared to popular graph adversarial learning methods, under diverse attack intensities and various datasets of different sizes."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4949e1910503fe9266e08eae2f464ca893e811af.pdf"}, "_bibtex": {"value": "@inproceedings{\nyuan2024mitigating,\ntitle={Mitigating Severe Robustness Degradation on Graphs},\nauthor={Xiangchi Yuan and Chunhui Zhang and Yijun Tian and Yanfang Ye and Chuxu Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Koh0i2u8qX}\n}"}, "TLDR": {"value": "When scaling up graph learning, we are the first to observe and then mitigate the emergent robustness degradation."}, "paperhash": {"value": "yuan|mitigating_emergent_robustness_degradation_while_scaling_graph_learning"}}, "number": 7453, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7453/-/Revision", "ICLR.cc/2024/Conference/Submission7453/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7453/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695474195371, "cdate": 1695474195371, "tmdate": 1710534451820, "mdate": 1710534451820, "pdate": 1705411010057, "version": 2}, {"id": "p4S5Z6Sah4", "forum": "p4S5Z6Sah4", "signatures": ["ICLR.cc/2024/Conference/Submission7452/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7452/Authors"], "content": {"title": {"value": "Traveling Waves Encode The Recent Past and Enhance Sequence Learning"}, "authors": {"value": ["T. Anderson Keller", "Lyle Muller", "Terrence Sejnowski", "Max Welling"]}, "authorids": {"value": ["~T._Anderson_Keller1", "~Lyle_Muller1", "~Terrence_Sejnowski2", "~Max_Welling1"]}, "keywords": {"value": ["RNNs", "Traveling Waves", "Memory", "Sequence Modeling"]}, "TLDR": {"value": "We demonstrate that traveling waves are an efficient and effective mechanism for storing long term memories in recurrent neural networks."}, "abstract": {"value": "Traveling waves of neural activity have been observed throughout the brain at a diversity of regions and scales; however, their precise computational role is still debated. One physically inspired hypothesis suggests that the cortical sheet may act like a wave-propagating system capable of invertibly storing a short-term memory of sequential stimuli through induced waves traveling across the cortical surface, and indeed many experimental results from neuroscience correlate wave activity with memory tasks. To date, however, the computational implications of this idea have remained hypothetical due to the lack of a simple recurrent neural network architecture capable of exhibiting such waves. In this work, we introduce a model to fill this gap, which we denote the Wave-RNN (wRNN), and demonstrate how such an architecture indeed efficiently encodes the recent past through a suite of synthetic memory tasks where wRNNs learn faster and reach significantly lower error than wave-free counterparts. We further explore the implications of this memory storage system on more complex sequence modeling tasks such as sequential image classification and find that wave-based models not only again outperform comparable wave-free RNNs while using significantly fewer parameters, but additionally perform comparably to more complex gated architectures such as LSTMs and GRUs."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/875de4ed3f20200b62e1de9da79bf3a2aae7068f.pdf"}, "_bibtex": {"value": "@inproceedings{\nkeller2024traveling,\ntitle={Traveling Waves Encode The Recent Past and Enhance Sequence Learning},\nauthor={T. Anderson Keller and Lyle Muller and Terrence Sejnowski and Max Welling},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=p4S5Z6Sah4}\n}"}, "paperhash": {"value": "keller|traveling_waves_encode_the_recent_past_and_enhance_sequence_learning"}}, "number": 7452, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7452/-/Revision", "ICLR.cc/2024/Conference/Submission7452/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7452/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695474134796, "cdate": 1695474134796, "tmdate": 1710467521714, "mdate": 1710467521714, "pdate": 1705411010007, "version": 2}, {"id": "6IjN7oxjXt", "forum": "6IjN7oxjXt", "signatures": ["ICLR.cc/2024/Conference/Submission7445/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7445/Authors"], "content": {"title": {"value": "Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training"}, "authors": {"value": ["Shruthi Gowda", "Bahram Zonooz", "Elahe Arani"]}, "authorids": {"value": ["~Shruthi_Gowda1", "~Bahram_Zonooz1", "~Elahe_Arani1"]}, "keywords": {"value": ["Adversarial training", "Adversarial Robustness", "Generalization", "Robustness", "Robust overfitting", "Selective training"]}, "TLDR": {"value": "A selective adversarial training method that enhances the trade-off between standard and robust generalization while also mitigating robust overfitting."}, "abstract": {"value": "Adversarial training improves the robustness of neural networks against adversarial attacks, albeit at the expense of the trade-off between standard and robust generalization. To unveil the underlying factors driving this phenomenon, we examine the layer-wise learning capabilities of neural networks during the transition from a standard to an adversarial setting. Our empirical findings demonstrate that selectively updating specific layers while preserving others can substantially enhance the network's learning capacity. We, therefore, propose CURE, a novel training framework that leverages a gradient prominence criterion to perform selective conservation, updating, and revision of weights. Importantly, CURE is designed to be dataset- and architecture-agnostic, ensuring its applicability across various scenarios. It effectively tackles both memorization and overfitting issues, thus enhancing the trade-off between robustness and generalization and additionally, this training approach also aids in mitigating \"robust overfitting\". Furthermore, our study provides valuable insights into the mechanisms of selective adversarial training and offers a promising avenue for future research."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ac5d180422b747207623bb24b37684f7629eecbf.pdf"}, "_bibtex": {"value": "@inproceedings{\ngowda2024conserveupdaterevise,\ntitle={Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training},\nauthor={Shruthi Gowda and Bahram Zonooz and Elahe Arani},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6IjN7oxjXt}\n}"}, "paperhash": {"value": "gowda|conserveupdaterevise_to_cure_generalization_and_robustness_tradeoff_in_adversarial_training"}}, "number": 7445, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7445/-/Revision", "ICLR.cc/2024/Conference/Submission7445/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7445/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695473863409, "cdate": 1695473863409, "tmdate": 1709933310479, "mdate": 1709933310479, "pdate": 1705411009814, "version": 2}, {"id": "NLevOah0CJ", "forum": "NLevOah0CJ", "signatures": ["ICLR.cc/2024/Conference/Submission7430/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7430/Authors"], "content": {"title": {"value": "Hindsight PRIORs for Reward Learning from Human Preferences"}, "authors": {"value": ["Mudit Verma", "Katherine Metcalf"]}, "authorids": {"value": ["~Mudit_Verma2", "~Katherine_Metcalf1"]}, "keywords": {"value": ["preference based reinforcement learning", "world models", "return redistribution"]}, "TLDR": {"value": "Presents a method to address credit assignment problem in preference-based reinforcement learning by guiding rewards to key states according to relative state importance."}, "abstract": {"value": "Preference based Reinforcement Learning (PbRL) removes the need to hand specify a reward function by learning one from preference feedback over policy behaviors. Current approaches to PbRL do not address the credit assignment problem inherent in determining which parts of a behavior most contributed to a preference resulting in data intensive approaches and subpar reward models. We address such limitations by introducing a credit assignment strategy (PRIOR) that uses a forward dynamics world model to approximate state importance within a trajectory and then guides rewards to be proportional to state importance through an auxiliary predicted return redistribution objective. Incorporating state importance into reward learning improves the speed of policy learning, overall policy performance, and reward recovery on both locomotion and manipulation tasks. For example, PRIOR achieves 80% success rate with half the amount of data compared to baselines. The performance gains and our ablations demonstrate the benefits even a simple credit assignment strategy can have on reward learning and that state importance in forward dynamics prediction is a strong proxy for a state's contribution to a preference decision."}, "pdf": {"value": "/pdf/83a2844bd7349c71ea3533dc2bea9b7fa6d0018f.pdf"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "supplementary_material": {"value": "/attachment/17208f20711a518faba9e198a3f5c6e5d2bcac0c.pdf"}, "_bibtex": {"value": "@inproceedings{\nverma2024hindsight,\ntitle={Hindsight {PRIOR}s for Reward Learning from Human Preferences},\nauthor={Mudit Verma and Katherine Metcalf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NLevOah0CJ}\n}"}, "paperhash": {"value": "verma|hindsight_priors_for_reward_learning_from_human_preferences"}}, "number": 7430, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7430/-/Revision", "ICLR.cc/2024/Conference/Submission7430/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7430/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695473383126, "cdate": 1695473383126, "tmdate": 1710570617708, "mdate": 1710570617708, "pdate": 1705411009468, "version": 2}, {"id": "kzGuiRXZrQ", "forum": "kzGuiRXZrQ", "signatures": ["ICLR.cc/2024/Conference/Submission7425/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7425/Authors"], "content": {"title": {"value": "Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation"}, "authors": {"value": ["Tuan Le", "Julian Cremer", "Frank Noe", "Djork-Arn\u00e9 Clevert", "Kristof T Sch\u00fctt"]}, "authorids": {"value": ["~Tuan_Le2", "~Julian_Cremer1", "~Frank_Noe1", "~Djork-Arn\u00e9_Clevert2", "~Kristof_T_Sch\u00fctt1"]}, "keywords": {"value": ["Generative Modelling", "Molecule Design", "Denoising Diffusion Probabilistic Models", "Ablation Study", "Equivariant Graph Neural Network", "3D Molecule Generation", "Diffusion Model"]}, "TLDR": {"value": "We explore the design space of diffusion models for 3D molecular modelling. Based on our findings we provide an equivariant diffusion model that outperforms the current state-of-the-art models in the domain by a large margin."}, "abstract": {"value": "Deep generative diffusion models are a promising avenue for 3D de novo molecular design in materials science and drug discovery.\nHowever, their utility is still limited by suboptimal performance on large molecular structures and limited training data.\nTo address this gap, we explore the design space of E(3)-equivariant diffusion models, focusing on previously unexplored areas.  \nOur extensive comparative analysis evaluates the interplay between continuous and discrete state spaces.\nFrom this investigation, we present the EQGAT-diff model, which consistently outperforms established models for the QM9 and GEOM-Drugs datasets.  \nSignificantly, EQGAT-diff takes continuous atom positions, while chemical elements and bond types are categorical and uses time-dependent loss weighting, substantially increasing training convergence, the quality of generated samples, and inference time. We also showcase that including chemically motivated additional features like hybridization states in the diffusion process enhances the validity of generated molecules.  \nTo further strengthen the applicability of diffusion models to limited training data, we investigate the transferability of EQGAT-diff trained on the large PubChem3D dataset with implicit hydrogen atoms to target different data distributions. Fine-tuning EQGAT-diff for just a few iterations shows an efficient distribution shift, further improving performance throughout data sets.   \nFinally, we test our model on the Crossdocked data set for structure-based de novo ligand generation, underlining the importance of our findings showing state-of-the-art performance on Vina docking scores."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c9a775e621bc51fdc5f935c63439eff6b0d94a25.pdf"}, "_bibtex": {"value": "@inproceedings{\nle2024navigating,\ntitle={Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation},\nauthor={Tuan Le and Julian Cremer and Frank Noe and Djork-Arn{\\'e} Clevert and Kristof T Sch{\\\"u}tt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kzGuiRXZrQ}\n}"}, "paperhash": {"value": "le|navigating_the_design_space_of_equivariant_diffusionbased_generative_models_for_de_novo_3d_molecule_generation"}}, "number": 7425, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7425/-/Revision", "ICLR.cc/2024/Conference/Submission7425/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7425/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695473078598, "cdate": 1695473078598, "tmdate": 1710292798510, "mdate": 1710292798510, "pdate": 1705411009256, "version": 2}, {"id": "BqHaLnans2", "forum": "BqHaLnans2", "signatures": ["ICLR.cc/2024/Conference/Submission7413/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7413/Authors"], "content": {"title": {"value": "LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation"}, "authors": {"value": ["Suhyeon Lee", "Won Jun Kim", "Jinho Chang", "Jong Chul Ye"]}, "authorids": {"value": ["~Suhyeon_Lee2", "~Won_Jun_Kim1", "~Jinho_Chang1", "~Jong_Chul_Ye1"]}, "keywords": {"value": ["large language model", "multimodal", "medical imaging", "chest X-ray", "bidirectional", "instruction-tuning", "vision-question answering"]}, "abstract": {"value": "Following the impressive development of LLMs, vision-language alignment in LLMs is actively being researched to enable multimodal reasoning and visual input/output. This direction of research is particularly relevant to medical imaging because accurate medical image analysis and generation consist of a combination of reasoning based on visual features and prior knowledge. Many recent works have focused on training adapter networks that serve as an information bridge between image processing (encoding or generating) networks and LLMs; but presumably, in order to achieve maximum reasoning potential of LLMs on visual information as well, visual and language features should be allowed to interact more freely. This is especially important in the medical domain because understanding and generating medical images such as chest X-rays (CXR) require not only accurate visual and language-based reasoning but also a more intimate mapping between the two modalities. Thus, taking inspiration from previous work on the transformer and VQ-GAN combination for bidirectional image and text generation, we build upon this approach and develop a method for instruction-tuning an LLM pre-trained only on text to gain vision-language capabilities for medical images. Specifically, we leverage a pretrained LLM\u2019s existing question-answering and instruction-following abilities to teach it to understand visual inputs by instructing it to answer questions about image inputs and, symmetrically, output both text and image responses appropriate to a given query by tuning the LLM with diverse tasks that encompass image-based text-generation and text-based image-generation. We show that our LLM-CXR trained in this approach shows better image-text alignment in both CXR understanding and generation tasks while being smaller in size compared to previously developed models that perform a narrower range of tasks."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/495e4c5290e90fa4b234772ff8cd9a1d493a60a5.pdf"}, "TLDR": {"value": "We present a state-of-the-art multimodal LLM for chest X-ray understanding and generation, developed using a method that builds upon the transformer+VQGAN architecture and adapts it for instruction-finetuning of an LLM pretrained only on text."}, "_bibtex": {"value": "@inproceedings{\nlee2024llmcxr,\ntitle={{LLM}-{CXR}: Instruction-Finetuned {LLM} for {CXR} Image Understanding and Generation},\nauthor={Suhyeon Lee and Won Jun Kim and Jinho Chang and Jong Chul Ye},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BqHaLnans2}\n}"}, "paperhash": {"value": "lee|llmcxr_instructionfinetuned_llm_for_cxr_image_understanding_and_generation"}}, "number": 7413, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7413/-/Revision", "ICLR.cc/2024/Conference/Submission7413/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7413/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695472568972, "cdate": 1695472568972, "tmdate": 1710488694895, "mdate": 1710488694895, "pdate": 1705411008967, "version": 2}, {"id": "fszrlQ2DuP", "forum": "fszrlQ2DuP", "signatures": ["ICLR.cc/2024/Conference/Submission7412/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7412/Authors"], "content": {"title": {"value": "Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?"}, "authors": {"value": ["Jianfei Yang", "Hanjie Qian", "Yuecong Xu", "Kai Wang", "Lihua Xie"]}, "authorids": {"value": ["~Jianfei_Yang4", "~Hanjie_Qian1", "~Yuecong_Xu1", "~Kai_Wang8", "~Lihua_Xie2"]}, "keywords": {"value": ["domain adaptation; feature transferability;"]}, "TLDR": {"value": "A metric to evaluate domain adaptation models in an unsupervised manner, contributing to model selection and tuning"}, "abstract": {"value": "Unsupervised domain adaptation (UDA) involves adapting a model trained on a label-rich source domain to an unlabeled target domain. However, in real-world scenarios, the absence of target-domain labels makes it challenging to evaluate the performance of UDA models. Furthermore, prevailing UDA methods relying on adversarial training and self-training could lead to model degeneration and negative transfer, further exacerbating the evaluation problem. In this paper, we propose a novel metric called the Transfer Score to address these issues. The proposed metric enables the unsupervised evaluation of UDA models by assessing the spatial uniformity of the classifier via model parameters, as well as the transferability and discriminability of deep representations. Based on the metric, we achieve three novel objectives without target-domain labels: (1) selecting the best UDA method from a range of available options, (2) optimizing hyperparameters of UDA models to prevent model degeneration, and (3) identifying which checkpoint of UDA model performs optimally. Our work bridges the gap between data-level UDA research and practical UDA scenarios, enabling a realistic assessment of UDA model performance. We validate the effectiveness of our metric through extensive empirical studies on UDA datasets of different scales and imbalanced distributions. The results demonstrate that our metric robustly achieves the aforementioned goals."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2ed2215f72252b6e197760092cc7376fb734086b.pdf"}, "supplementary_material": {"value": "/attachment/3578989e822015b7fe775da1cacd918407099647.zip"}, "_bibtex": {"value": "@inproceedings{\nyang2024can,\ntitle={Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?},\nauthor={Jianfei Yang and Hanjie Qian and Yuecong Xu and Kai Wang and Lihua Xie},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fszrlQ2DuP}\n}"}, "paperhash": {"value": "yang|can_we_evaluate_domain_adaptation_models_without_targetdomain_labels"}}, "number": 7412, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7412/-/Revision", "ICLR.cc/2024/Conference/Submission7412/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7412/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695472559656, "cdate": 1695472559656, "tmdate": 1710155091627, "mdate": 1710155091627, "pdate": 1705411008910, "version": 2}, {"id": "fyTPWfXtcc", "forum": "fyTPWfXtcc", "signatures": ["ICLR.cc/2024/Conference/Submission7401/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7401/Authors"], "content": {"title": {"value": "Global Optimality for Non-linear Constrained Restoration Problems via Invexity"}, "authors": {"value": ["Samuel Pinilla", "Jeyan Thiyagalingam"]}, "authorids": {"value": ["~Samuel_Pinilla1", "~Jeyan_Thiyagalingam1"]}, "keywords": {"value": ["Constrained optimization", "Invexity", "Quasi-invexity", "Global optima"]}, "abstract": {"value": "Signal restoration is an important constrained optimization problem with significant applications in various domains. Although non-convex constrained optimization problems have been shown to perform better than convex counterparts in terms of reconstruction quality, convex constrained optimization problems have been preferably for its global optima guarantees. Despite the success of non-convex methods in a large number of applications, it is not an overstatement to say that there is little or no hope for non-convex problems to ensure global optima. In this paper, for the first time, we develop invex constrained optimization theory to mitigate the loss of guarantees for global optima in non-convex constrained inverse problems, where the invex function is a mapping where any critical point is a global minimizer. We also develop relevant theories to extend the global optima guarantee to a set of quasi-invex functions - the largest optimizable mappings. More specifically, we propose a family of invex/quasi-invex of functions for handling constrained inverse problems using the non-convex setting along with guarantees for their global optima. Our experimental evaluation shows that the proposed approach is very promising and can aid in extending existing convex optimization algorithms, such as the alternating direction method of multipliers, and accelerated proximal gradient methods."}, "pdf": {"value": "/pdf/a837bfc9b8965ae07fab929db2baf1843f43c2f1.pdf"}, "supplementary_material": {"value": "/attachment/01f8c2aef73f47a494f24b4b21c7c6500645107f.pdf"}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\npinilla2024global,\ntitle={Global Optimality for Non-linear Constrained Restoration Problems via Invexity},\nauthor={Samuel Pinilla and Jeyan Thiyagalingam},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fyTPWfXtcc}\n}"}, "paperhash": {"value": "pinilla|global_optimality_for_nonlinear_constrained_restoration_problems_via_invexity"}}, "number": 7401, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7401/-/Revision", "ICLR.cc/2024/Conference/Submission7401/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7401/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695471823723, "cdate": 1695471823723, "tmdate": 1712190041329, "mdate": 1712190041329, "pdate": 1705411008662, "version": 2}, {"id": "iriEqxFB4y", "forum": "iriEqxFB4y", "signatures": ["ICLR.cc/2024/Conference/Submission7386/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7386/Authors"], "content": {"title": {"value": "DOS: Diverse Outlier Sampling for Out-of-Distribution Detection"}, "authors": {"value": ["Wenyu Jiang", "Hao Cheng", "MingCai Chen", "Chongjun Wang", "Hongxin Wei"]}, "authorids": {"value": ["~Wenyu_Jiang1", "~Hao_Cheng14", "~MingCai_Chen1", "~Chongjun_Wang1", "~Hongxin_Wei1"]}, "keywords": {"value": ["out-of-distribution detection", "data-centric artificial intelligence"]}, "TLDR": {"value": "We empirically show that diversity is critical in sampling, and thereby propose a clustering-based sampling strategy."}, "abstract": {"value": "Modern neural networks are known to give overconfident predictions for out-of-distribution inputs when deployed in the open world. It is common practice to leverage a surrogate outlier dataset to regularize the model during training, and recent studies emphasize the role of uncertainty in designing the sampling strategy for outlier datasets. However, the OOD samples selected solely based on predictive uncertainty can be biased towards certain types, which may fail to capture the full outlier distribution. In this work, we empirically show that diversity is critical in sampling outliers for OOD detection performance. Motivated by the observation, we propose a straightforward and novel sampling strategy named DOS (Diverse Outlier Sampling) to select diverse and informative outliers. Specifically, we cluster the normalized features at each iteration, and the most informative outlier from each cluster is selected for model training with absent category loss. With DOS, the sampled outliers efficiently shape a globally compact decision boundary between ID and OOD data. Extensive experiments demonstrate the superiority of DOS, reducing the average FPR95 by up to 25.79% on CIFAR-100 with TI-300K."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/311d49eb76f1521149b1534c7a6414405f1dedb7.pdf"}, "supplementary_material": {"value": "/attachment/530e2c1bdc10b2339a08bf05dae7e4dae3880962.zip"}, "_bibtex": {"value": "@inproceedings{\njiang2024dos,\ntitle={{DOS}: Diverse Outlier Sampling for Out-of-Distribution Detection},\nauthor={Wenyu Jiang and Hao Cheng and MingCai Chen and Chongjun Wang and Hongxin Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iriEqxFB4y}\n}"}, "paperhash": {"value": "jiang|dos_diverse_outlier_sampling_for_outofdistribution_detection"}}, "number": 7386, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7386/-/Revision", "ICLR.cc/2024/Conference/Submission7386/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7386/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470980396, "cdate": 1695470980396, "tmdate": 1709661539475, "mdate": 1709661539475, "pdate": 1705411008159, "version": 2}, {"id": "MY0qlcFcUg", "forum": "MY0qlcFcUg", "signatures": ["ICLR.cc/2024/Conference/Submission7379/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7379/Authors"], "content": {"title": {"value": "Denoising Task Routing for Diffusion Models"}, "authors": {"value": ["Byeongjun Park", "Sangmin Woo", "Hyojun Go", "Jin-Young Kim", "Changick Kim"]}, "authorids": {"value": ["~Byeongjun_Park1", "~Sangmin_Woo1", "~Hyojun_Go2", "~Jin-Young_Kim1", "~Changick_Kim1"]}, "keywords": {"value": ["Diffusion Model Architecture", "Multi-Task Learning (MTL)", "Diffusion Models"]}, "TLDR": {"value": "Simple add-on strategy improves diffusion model architectures by explicitly routing denoising tasks in diffusion models."}, "abstract": {"value": "Diffusion models generate highly realistic images by learning a multi-step denoising process, naturally embodying the principles of multi-task learning (MTL). Despite the inherent connection between diffusion models and MTL, there remains an unexplored area in designing neural architectures that explicitly incorporate MTL into the framework of diffusion models. In this paper, we present Denoising Task Routing (DTR), a simple add-on strategy for existing diffusion model architectures to establish distinct information pathways for individual tasks within a single architecture by selectively activating subsets of channels in the model. What makes DTR particularly compelling is its seamless integration of prior knowledge of denoising tasks into the framework: (1) Task Affinity: DTR activates similar channels for tasks at adjacent timesteps and shifts activated channels as sliding windows through timesteps, capitalizing on the inherent strong affinity between tasks at adjacent timesteps. (2) Task Weights: During the early stages (higher timesteps) of the denoising process, DTR assigns a greater number of task-specific channels, leveraging the insight that diffusion models prioritize reconstructing global structure and perceptually rich contents in earlier stages, and focus on simple noise removal in later stages. Our experiments reveal that DTR not only consistently boosts diffusion models' performance across different evaluation protocols without adding extra parameters but also accelerates training convergence. Finally, we show the complementarity between our architectural approach and existing MTL optimization techniques, providing a more complete view of MTL in the context of diffusion training. Significantly, by leveraging this complementarity, we attain matched performance of DiT-XL using the smaller DiT-L with a reduction in training iterations from 7M to 2M. Our project page is available at https://byeongjun-park.github.io/DTR/"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a3a12031604726d721296996f2bfdbfa081bf598.pdf"}, "_bibtex": {"value": "@inproceedings{\npark2024denoising,\ntitle={Denoising Task Routing for Diffusion Models},\nauthor={Byeongjun Park and Sangmin Woo and Hyojun Go and Jin-Young Kim and Changick Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MY0qlcFcUg}\n}"}, "paperhash": {"value": "park|denoising_task_routing_for_diffusion_models"}}, "number": 7379, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7379/-/Revision", "ICLR.cc/2024/Conference/Submission7379/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7379/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470713179, "cdate": 1695470713179, "tmdate": 1709661539631, "mdate": 1709661539631, "pdate": 1705411007838, "version": 2}, {"id": "dcjtMYkpXx", "forum": "dcjtMYkpXx", "signatures": ["ICLR.cc/2024/Conference/Submission7374/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7374/Authors"], "content": {"title": {"value": "Reward Model Ensembles Help Mitigate Overoptimization"}, "authors": {"value": ["Thomas Coste", "Usman Anwar", "Robert Kirk", "David Krueger"]}, "authorids": {"value": ["~Thomas_Coste1", "~Usman_Anwar1", "~Robert_Kirk1", "~David_Krueger1"]}, "keywords": {"value": ["ensembles", "overoptimization", "RLHF", "reinforcement learning from human feedback", "language models", "uncertainty weighted optimization"]}, "TLDR": {"value": "Using an ensembles of (learned) reward models in RLHF helps mitigate overoptimization."}, "abstract": {"value": "Reinforcement learning from human feedback (RLHF) is a standard approach for fine-tuning large language models to follow instructions. As part of this process, learned reward models are used to approximately model human preferences. However, as imperfect representations of the \u201ctrue\u201d reward, these learned reward models are susceptible to overoptimization. Gao et al. (2023) studied this phenomenon in a synthetic human feedback setup with a significantly larger \u201cgold\u201d reward model acting as the true reward (instead of humans) and showed that overoptimization remains a persistent problem regardless of the size of the proxy reward model and training data used. Using a similar setup, we conduct a systematic study to evaluate the efficacy of using ensemble-based conservative optimization objectives, specifically worst-case optimization (WCO) and uncertainty-weighted optimization (UWO), for mitigating reward model overoptimization when using two optimization methods: (a) best-of-n sampling (BoN) (b) proximal policy optimization (PPO). We additionally extend the setup of Gao et al. (2023) to include 25% label noise to better mirror real-world conditions. Both with and without label noise we find that conservative optimization practically eliminates overoptimization and improves performance by up to 70% for BoN sampling. For PPO, ensemble-based conservative optimization always reduces overoptimization and outperforms single reward model optimization. Moreover, combining it with a small KL penalty successfully prevents overoptimization at no performance cost. Overall, our results demonstrate that ensemble-based conservative optimization can effectively counter overoptimization."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ef2bb264ca333c06129a9c23f5038f5566619ecb.pdf"}, "_bibtex": {"value": "@inproceedings{\ncoste2024reward,\ntitle={Reward Model Ensembles Help Mitigate Overoptimization},\nauthor={Thomas Coste and Usman Anwar and Robert Kirk and David Krueger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dcjtMYkpXx}\n}"}, "paperhash": {"value": "coste|reward_model_ensembles_help_mitigate_overoptimization"}}, "number": 7374, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7374/-/Revision", "ICLR.cc/2024/Conference/Submission7374/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7374/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470511815, "cdate": 1695470511815, "tmdate": 1710033982826, "mdate": 1710033982826, "pdate": 1705411007482, "version": 2}, {"id": "HKGQDDTuvZ", "forum": "HKGQDDTuvZ", "signatures": ["ICLR.cc/2024/Conference/Submission7366/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7366/Authors"], "content": {"title": {"value": "Frequency-Aware Transformer for Learned  Image Compression"}, "authors": {"value": ["Han Li", "Shaohui Li", "Wenrui Dai", "Chenglin Li", "Junni Zou", "Hongkai Xiong"]}, "authorids": {"value": ["~Han_Li8", "~Shaohui_Li3", "~Wenrui_Dai1", "~Chenglin_Li2", "~Junni_Zou1", "~Hongkai_Xiong1"]}, "keywords": {"value": ["learned image compression", "frequency-aware", "transformer", "entropy model"]}, "abstract": {"value": "Learned image compression (LIC) has gained traction as an effective solution for image storage and transmission in recent years. However, existing LIC methods are redundant in latent representation due to limitations in capturing anisotropic frequency components and preserving directional details. To overcome these challenges, we propose a novel frequency-aware transformer (FAT) block that for the first time achieves multiscale directional ananlysis for LIC. The FAT block comprises frequency-decomposition window attention (FDWA) modules to capture multiscale and directional frequency components of natural images. Additionally, we introduce frequency-modulation feed-forward network (FMFFN) to adaptively modulate different frequency components, improving rate-distortion performance. Furthermore, we present a transformer-based channel-wise autoregressive (T-CA) model that effectively exploits channel dependencies. Experiments show that our method achieves state-of-the-art rate-distortion performance compared to existing LIC methods, and evidently outperforms latest standardized codec VTM-12.1 by 14.5\\%, 15.1\\%, 13.0\\% in BD-rate on the Kodak, Tecnick, and CLIC datasets."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7d1a2f03544dfbb0c35c95ba82059f4a111fdcbc.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024frequencyaware,\ntitle={Frequency-Aware Transformer for Learned  Image Compression},\nauthor={Han Li and Shaohui Li and Wenrui Dai and Chenglin Li and Junni Zou and Hongkai Xiong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HKGQDDTuvZ}\n}"}, "paperhash": {"value": "li|frequencyaware_transformer_for_learned_image_compression"}}, "number": 7366, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7366/-/Revision", "ICLR.cc/2024/Conference/Submission7366/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7366/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470191477, "cdate": 1695470191477, "tmdate": 1710996286176, "mdate": 1710996286176, "pdate": 1705411007270, "version": 2}, {"id": "nMFSUjxMIl", "forum": "nMFSUjxMIl", "signatures": ["ICLR.cc/2024/Conference/Submission7365/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7365/Authors"], "content": {"title": {"value": "CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment"}, "authors": {"value": ["Xun Jiang", "zhuomin chai", "Yuxiang Zhao", "Yibo Lin", "Runsheng Wang", "Ru Huang"]}, "authorids": {"value": ["~Xun_Jiang2", "~zhuomin_chai1", "~Yuxiang_Zhao2", "~Yibo_Lin1", "~Runsheng_Wang3", "~Ru_Huang2"]}, "keywords": {"value": ["Chip Design", "Machine Learning", "Dataset"]}, "abstract": {"value": "Integrated circuits or chips are key to enable computing in modern industry. Designing a chip relies on human experts to produce chip data through professional electronic design automation (EDA) software and complicated procedures. Nowadays, prompted by the wide variety of machine learning (ML) datasets, we have witnessed great advancement of ML algorithms in computer vision, natural language processing, and other fields. However, in chip design, high human workload and data sensitivity cause the lack of public datasets, which hinders the progress of ML development for EDA. To this end, we introduce an advanced large-scale dataset, CircuitNet 2.0, which targets promoting ML innovations in a realistic chip design environment. In order to approach the realistic chip design space, we collect more than 10,000 samples with a variety of chip designs (e.g., CPU, GPU, and AI Chip). All the designs are conducted through complete commercial design flows in a widely-used technology node, 14nm FinFET. We collect comprehensive data, including routability, timing, and power, from the design flow to support versatile ML tasks in EDA. Besides, we also introduce some realistic ML tasks with CircuitNet 2.0 to verify the potential for boosting innovations."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/18243659a4c68baa73e34792453c17d63e6f68a3.pdf"}, "_bibtex": {"value": "@inproceedings{\njiang2024circuitnet,\ntitle={CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment},\nauthor={Xun Jiang and zhuomin chai and Yuxiang Zhao and Yibo Lin and Runsheng Wang and Ru Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nMFSUjxMIl}\n}"}, "paperhash": {"value": "jiang|circuitnet_20_an_advanced_dataset_for_promoting_machine_learning_innovations_in_realistic_chip_design_environment"}}, "number": 7365, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7365/-/Revision", "ICLR.cc/2024/Conference/Submission7365/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7365/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695470161446, "cdate": 1695470161446, "tmdate": 1709864550779, "mdate": 1709864550779, "pdate": 1705411007255, "version": 2}, {"id": "q9jQPA6zPK", "forum": "q9jQPA6zPK", "signatures": ["ICLR.cc/2024/Conference/Submission7350/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7350/Authors"], "content": {"title": {"value": "Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design"}, "authors": {"value": ["Heng Dong", "Junyu Zhang", "Chongjie Zhang"]}, "authorids": {"value": ["~Heng_Dong1", "~Junyu_Zhang3", "~Chongjie_Zhang1"]}, "keywords": {"value": ["Robot Design", "Hyperbolic Space", "Coarse-to-Fine", "Multi-Cellular"]}, "abstract": {"value": "Multi-cellular robot design aims to create robots comprised of numerous cells that can be efficiently controlled to perform diverse tasks. Previous research has demonstrated the ability to generate robots for various tasks, but these approaches often optimize robots directly in the vast design space, resulting in robots with complicated morphologies that are hard to control. In response, this paper presents a novel coarse-to-fine method for designing multi-cellular robots. Initially, this strategy seeks optimal coarse-grained robots and progressively refines them. To mitigate the challenge of determining the precise refinement juncture during the coarse-to-fine transition, we introduce the Hyperbolic Embeddings for Robot Design (HERD) framework. HERD unifies robots of various granularity within a shared hyperbolic space and leverages a refined Cross-Entropy Method for optimization. This framework enables our method to autonomously identify areas of exploration in hyperbolic space and concentrate on regions demonstrating promise.  Finally, the extensive empirical studies on various challenging tasks sourced from EvoGym show our approach's superior efficiency and generalization capability."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9f01d3b965f2c102a1d6332805027091b7f2a6c5.pdf"}, "TLDR": {"value": "We propose to design multi-cellular robots in a coarse-to-fine manner and leverage hyperbolic embeddings for realization."}, "_bibtex": {"value": "@inproceedings{\ndong2024leveraging,\ntitle={Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design},\nauthor={Heng Dong and Junyu Zhang and Chongjie Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=q9jQPA6zPK}\n}"}, "paperhash": {"value": "dong|leveraging_hyperbolic_embeddings_for_coarsetofine_robot_design"}}, "number": 7350, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7350/-/Revision", "ICLR.cc/2024/Conference/Submission7350/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7350/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695469397656, "cdate": 1695469397656, "tmdate": 1710580676313, "mdate": 1710580676313, "pdate": 1705411006903, "version": 2}, {"id": "Y3wpuxd7u9", "forum": "Y3wpuxd7u9", "signatures": ["ICLR.cc/2024/Conference/Submission7332/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7332/Authors"], "content": {"title": {"value": "GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction"}, "authors": {"value": ["Oscar Sainz", "Iker Garc\u00eda-Ferrero", "Rodrigo Agerri", "Oier Lopez de Lacalle", "German Rigau", "Eneko Agirre"]}, "authorids": {"value": ["~Oscar_Sainz1", "~Iker_Garc\u00eda-Ferrero1", "~Rodrigo_Agerri1", "~Oier_Lopez_de_Lacalle1", "~German_Rigau2", "~Eneko_Agirre1"]}, "keywords": {"value": ["Information Extraction", "Zero-Shot", "Annotation Guidelines", "Large Language Models", "LLM", "prompt"]}, "abstract": {"value": "Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines which describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out-of-the-box. In this paper we propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines is key for good results. Code, data and models will be made publicly available."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ea4325061f2afa23c19e388d3e36350c3950d72d.pdf"}, "TLDR": {"value": "We propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines."}, "_bibtex": {"value": "@inproceedings{\nsainz2024gollie,\ntitle={Go{LLIE}: Annotation Guidelines improve Zero-Shot Information-Extraction},\nauthor={Oscar Sainz and Iker Garc{\\'\\i}a-Ferrero and Rodrigo Agerri and Oier Lopez de Lacalle and German Rigau and Eneko Agirre},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Y3wpuxd7u9}\n}"}, "paperhash": {"value": "sainz|gollie_annotation_guidelines_improve_zeroshot_informationextraction"}}, "number": 7332, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7332/-/Revision", "ICLR.cc/2024/Conference/Submission7332/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7332/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695468337292, "cdate": 1695468337292, "tmdate": 1709742841417, "mdate": 1709742841417, "pdate": 1705411006484, "version": 2}, {"id": "vZ6r9GMT1n", "forum": "vZ6r9GMT1n", "signatures": ["ICLR.cc/2024/Conference/Submission7319/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7319/Authors"], "content": {"title": {"value": "Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks"}, "authors": {"value": ["Nguyen Hung-Quang", "Yingjie Lao", "Tung Pham", "Kok-Seng Wong", "Khoa D Doan"]}, "authorids": {"value": ["~Nguyen_Hung-Quang1", "~Yingjie_Lao1", "~Tung_Pham1", "~Kok-Seng_Wong1", "~Khoa_D_Doan1"]}, "keywords": {"value": ["adversarial attacks", "adversarial defense", "black-box attacks"]}, "TLDR": {"value": "We analyze and propose a randomized defense on latent space to query-based attacks."}, "abstract": {"value": "Recent works have shown that deep neural networks are vulnerable to adversarial examples that find samples close to the original image but can make the model misclassify. Even with access only to the model's output, an attacker can employ black-box attacks to generate such adversarial examples. In this work, we propose a simple and lightweight defense against black-box attacks by adding random noise to hidden features at intermediate layers of the model at inference time. Our theoretical analysis confirms that this method effectively enhances the model's resilience against both score-based and decision-based black-box attacks. Importantly, our defense does not necessitate adversarial training and has minimal impact on accuracy, rendering it applicable to any pre-trained model. Our analysis also reveals the significance of selectively adding noise to different parts of the model based on the gradient of the adversarial objective function, which can be varied during the attack. We demonstrate the robustness of our defense against multiple black-box attacks through extensive empirical experiments involving diverse models with various architectures."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/78c4e6b92b7962c8c39023a841fe9c4924716f93.pdf"}, "supplementary_material": {"value": "/attachment/fe9544aa26fc29d2558eed722945d5967e7ce9fb.zip"}, "_bibtex": {"value": "@inproceedings{\nhung-quang2024understanding,\ntitle={Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks},\nauthor={Nguyen Hung-Quang and Yingjie Lao and Tung Pham and Kok-Seng Wong and Khoa D Doan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vZ6r9GMT1n}\n}"}, "paperhash": {"value": "hungquang|understanding_the_robustness_of_randomized_feature_defense_against_querybased_adversarial_attacks"}}, "number": 7319, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7319/-/Revision", "ICLR.cc/2024/Conference/Submission7319/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7319/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695467361428, "cdate": 1695467361428, "tmdate": 1713029555014, "mdate": 1713029555014, "pdate": 1705411006131, "version": 2}, {"id": "02f3mUtqnM", "forum": "02f3mUtqnM", "signatures": ["ICLR.cc/2024/Conference/Submission7318/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7318/Authors"], "content": {"title": {"value": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"}, "authors": {"value": ["Dujian Ding", "Ankur Mallick", "Chi Wang", "Robert Sim", "Subhabrata Mukherjee", "Victor R\u00fchle", "Laks V. S. Lakshmanan", "Ahmed Hassan Awadallah"]}, "authorids": {"value": ["~Dujian_Ding1", "~Ankur_Mallick1", "~Chi_Wang3", "~Robert_Sim1", "~Subhabrata_Mukherjee2", "~Victor_R\u00fchle1", "~Laks_V._S._Lakshmanan1", "~Ahmed_Hassan_Awadallah1"]}, "keywords": {"value": ["Large language models", "Efficient ML", "Query Routing"]}, "abstract": {"value": "Large language models (LLMs) excel in most NLP tasks but also require expensive cloud servers for deployment due to their size, while smaller models that can be deployed on lower cost (e.g., edge) devices, tend to lag behind in terms of response quality. Therefore in this work we propose a hybrid inference approach which combines their respective strengths to save cost and maintain quality. Our approach uses a router that assigns queries to the small or large model based on the predicted query difficulty and the desired quality level. The desired quality level can be tuned dynamically at test time to seamlessly trade  quality for cost as per the scenario requirements. In experiments our approach allows us to make up to 40% fewer calls to the large model, with no drop in response quality."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0f54d4ba54cdc0d5560da1f4d2c6e03953dc2678.pdf"}, "_bibtex": {"value": "@inproceedings{\nding2024hybrid,\ntitle={Hybrid {LLM}: Cost-Efficient and Quality-Aware Query Routing},\nauthor={Dujian Ding and Ankur Mallick and Chi Wang and Robert Sim and Subhabrata Mukherjee and Victor R{\\\"u}hle and Laks V. S. Lakshmanan and Ahmed Hassan Awadallah},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=02f3mUtqnM}\n}"}, "paperhash": {"value": "ding|hybrid_llm_costefficient_and_qualityaware_query_routing"}}, "number": 7318, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7318/-/Revision", "ICLR.cc/2024/Conference/Submission7318/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7318/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695467332860, "cdate": 1695467332860, "tmdate": 1710443411500, "mdate": 1710443411500, "pdate": 1705411006082, "version": 2}, {"id": "3cuJwmPxXj", "forum": "3cuJwmPxXj", "signatures": ["ICLR.cc/2024/Conference/Submission7315/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7315/Authors"], "content": {"title": {"value": "Identifying Representations for Intervention Extrapolation"}, "authors": {"value": ["Sorawit Saengkyongam", "Elan Rosenfeld", "Pradeep Kumar Ravikumar", "Niklas Pfister", "Jonas Peters"]}, "authorids": {"value": ["~Sorawit_Saengkyongam1", "~Elan_Rosenfeld1", "~Pradeep_Kumar_Ravikumar1", "~Niklas_Pfister1", "~Jonas_Peters2"]}, "keywords": {"value": ["causality", "extrapolation", "exogenous variables", "causal representation learning", "identifiable representation learning", "control functions", "instrumental variables", "invariance"]}, "abstract": {"value": "The premise of identifiable and causal representation learning is to improve the current representation learning paradigm in terms of generalizability or robustness. Despite recent progress in questions of identifiability, more theoretical results demonstrating concrete advantages of these methods for downstream tasks are needed. In this paper, we consider the task of intervention extrapolation: predicting how interventions affect an outcome, even when those interventions are not observed at training time, and show that identifiable representations can provide an effective solution to this task even if the interventions affect the outcome non-linearly. Our setup includes an outcome variable $Y$, observed features $X$, which are generated as a non-linear transformation of latent features $Z$, and exogenous action variables $A$, which influence $Z$. The objective of intervention extrapolation is then to predict how interventions on $A$ that lie outside the training support of $A$ affect $Y$. Here, extrapolation becomes possible if the effect of $A$ on $Z$ is linear and the residual when regressing Z on A has full support. As $Z$ is latent, we combine the task of intervention extrapolation with identifiable representation learning, which we call $\\texttt{Rep4Ex}$: we aim to map the observed features $X$ into a subspace that allows for non-linear extrapolation in $A$. We show that the hidden representation is identifiable up to an affine transformation in $Z$-space, which, we prove, is sufficient for intervention extrapolation. The identifiability is characterized by a novel constraint describing the linearity assumption of $A$ on $Z$. Based on this insight, we propose a flexible method that enforces the linear invariance constraint and can be combined with any type of autoencoder. We validate our theoretical findings through a series of synthetic experiments and show that our approach can indeed succeed in predicting the effects of unseen interventions."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8a74f7b89a0cd7b490dcfefbdc766bd93dab115c.pdf"}, "supplementary_material": {"value": "/attachment/ca0776cd9e91d0b874238a4bfb5ae74e4b210e3f.zip"}, "_bibtex": {"value": "@inproceedings{\nsaengkyongam2024identifying,\ntitle={Identifying Representations for Intervention Extrapolation},\nauthor={Sorawit Saengkyongam and Elan Rosenfeld and Pradeep Kumar Ravikumar and Niklas Pfister and Jonas Peters},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3cuJwmPxXj}\n}"}, "paperhash": {"value": "saengkyongam|identifying_representations_for_intervention_extrapolation"}}, "number": 7315, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7315/-/Revision", "ICLR.cc/2024/Conference/Submission7315/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7315/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695467103193, "cdate": 1695467103193, "tmdate": 1710163520047, "mdate": 1710163520047, "pdate": 1705411006027, "version": 2}, {"id": "j5JvZCaDM0", "forum": "j5JvZCaDM0", "signatures": ["ICLR.cc/2024/Conference/Submission7310/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7310/Authors"], "content": {"title": {"value": "Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model"}, "authors": {"value": ["Yinan Zheng", "Jianxiong Li", "Dongjie Yu", "Yujie Yang", "Shengbo Eben Li", "Xianyuan Zhan", "Jingjing Liu"]}, "authorids": {"value": ["~Yinan_Zheng1", "~Jianxiong_Li1", "~Dongjie_Yu1", "~Yujie_Yang1", "~Shengbo_Eben_Li2", "~Xianyuan_Zhan1", "~Jingjing_Liu2"]}, "keywords": {"value": ["Safe offline reinforcement learning", "Hamilton-Jacobi reachability", "diffusion model"]}, "abstract": {"value": "Safe offline reinforcement learning is a promising way to bypass risky online interactions towards safe policy learning. Most existing methods only enforce soft constraints, i.e., constraining safety violations in expectation below thresholds predetermined. This can lead to potentially unsafe outcomes, thus unacceptable in safety-critical scenarios. An alternative is to enforce the hard constraint of zero violation. However, this can be challenging in offline setting, as it needs to strike the right balance among three highly intricate and correlated aspects: safety constraint satisfaction, reward maximization, and behavior regularization imposed by offline datasets. Interestingly, we discover that via reachability analysis of safe-control theory, the hard safety constraint can be equivalently translated to identifying the largest feasible region given the offline dataset. This seamlessly converts the original trilogy problem to a feasibility-dependent objective, i.e., maximizing reward value within the feasible region while minimizing safety risks in the infeasible region. Inspired by these, we propose FISOR (FeasIbility-guided Safe Offline RL), which allows safety constraint adherence, reward maximization, and offline policy learning to be realized via three decoupled processes, while offering strong safety performance and stability. In FISOR, the optimal policy for the translated optimization problem can be derived in a special form of weighted behavior cloning, which can be effectively extracted with a guided diffusion model thanks to its expressiveness.  We compare FISOR against baselines on DSRL benchmark for safe offline RL. Evaluation results show that FISOR is the only method that can guarantee safety satisfaction in all tasks, while achieving top returns in most tasks. Code: https://github.com/ZhengYinan-AIR/FISOR."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/084567b03de688b5db97ecc466c6faec23ce82e7.pdf"}, "TLDR": {"value": "We propose a safe offline RL method that considers hard safety constraint with superior safety performance and stability."}, "_bibtex": {"value": "@inproceedings{\nzheng2024feasibilityguided,\ntitle={Feasibility-Guided Safe Offline Reinforcement Learning},\nauthor={Yinan Zheng and Jianxiong Li and Dongjie Yu and Yujie Yang and Shengbo Eben Li and Xianyuan Zhan and Jingjing Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=j5JvZCaDM0}\n}"}, "paperhash": {"value": "zheng|safe_offline_reinforcement_learning_with_feasibilityguided_diffusion_model"}}, "number": 7310, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7310/-/Revision", "ICLR.cc/2024/Conference/Submission7310/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7310/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695466861202, "cdate": 1695466861202, "tmdate": 1709661538966, "mdate": 1709661538966, "pdate": 1705411005823, "version": 2}, {"id": "S5EqslEHnz", "forum": "S5EqslEHnz", "signatures": ["ICLR.cc/2024/Conference/Submission7302/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7302/Authors"], "content": {"title": {"value": "Do Generated Data Always Help Contrastive Learning?"}, "authors": {"value": ["Yifei Wang", "Jizhe Zhang", "Yisen Wang"]}, "authorids": {"value": ["~Yifei_Wang1", "~Jizhe_Zhang1", "~Yisen_Wang1"]}, "keywords": {"value": ["Contrastive Learning", "Diffusion Model", "Representation Learning", "Self-supervised Learning", "Deep Learning"]}, "abstract": {"value": "Contrastive Learning (CL) has emerged as one of the most successful paradigms for unsupervised visual representation learning, yet it often depends on intensive manual data augmentations. With the rise of generative models, especially diffusion models, the ability to generate realistic images close to the real data distribution has been well recognized. These generated high-equality images have been successfully applied to enhance contrastive representation learning, a technique termed ``data inflation''. However, we find that the generated data (even from a good diffusion model like DDPM) may sometimes even harm contrastive learning. We investigate the causes behind this failure from the perspective of both data inflation and data augmentation. For the first time, we reveal the complementary roles that stronger data inflation should be accompanied by weaker augmentations, and vice versa. We also provide rigorous theoretical explanations for these phenomena via deriving its generalization bounds under data inflation. Drawing from these insights, we propose **Adaptive Inflation (AdaInf)**, a purely data-centric strategy without introducing any extra computation cost. On benchmark datasets, AdaInf can bring significant improvements for various contrastive learning methods. Notably, without using external data, AdaInf obtains 94.70% linear accuracy on CIFAR-10 with SimCLR, setting a new record that surpasses many sophisticated methods. Code is available at https://github.com/PKU-ML/adainf."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3161a91d84c0512d865fe1cda7429479478968b6.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024do,\ntitle={Do Generated Data Always Help Contrastive Learning?},\nauthor={Yifei Wang and Jizhe Zhang and Yisen Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=S5EqslEHnz}\n}"}, "paperhash": {"value": "wang|do_generated_data_always_help_contrastive_learning"}}, "number": 7302, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7302/-/Revision", "ICLR.cc/2024/Conference/Submission7302/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7302/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695466356343, "cdate": 1695466356343, "tmdate": 1711543991255, "mdate": 1711543991255, "pdate": 1705411005685, "version": 2}, {"id": "kMp8zCsXNb", "forum": "kMp8zCsXNb", "signatures": ["ICLR.cc/2024/Conference/Submission7291/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7291/Authors"], "content": {"title": {"value": "ASMR: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference"}, "authors": {"value": ["Jason Chun Lok Li", "Steven Tin Sui Luo", "Le Xu", "Ngai Wong"]}, "authorids": {"value": ["~Jason_Chun_Lok_Li1", "~Steven_Tin_Sui_Luo1", "~Le_Xu3", "~Ngai_Wong1"]}, "keywords": {"value": ["Implicit Neural Representation", "Coordinate Network", "Multi-resolution", "Efficient Inference"]}, "abstract": {"value": "Coordinate network or implicit neural representation (INR) is a fast-emerging method for encoding natural signals (such as images and videos) with the benefits of a compact neural representation. While numerous methods have been proposed to increase the encoding capabilities of an INR, an often overlooked aspect is the inference efficiency, usually measured in multiply-accumulate (MAC) count. This is particularly critical in use cases where inference bandwidth is greatly limited by hardware constraints. To this end, we propose the Activation-Sharing Multi-Resolution (ASMR) coordinate network that combines multi-resolution coordinate decomposition with hierarchical modulations. Specifically, an ASMR model enables the sharing of activations across grids of the data. This largely decouples its inference cost from its depth which is directly correlated to its reconstruction capability, and renders a near $O(1)$ inference complexity irrespective of the number of layers. Experiments show that ASMR can reduce the MAC of a vanilla SIREN model by up to 500$\\times$ while achieving an even higher reconstruction quality than its SIREN baseline."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We propose the Activation-Sharing Multi-Resolution (ASMR) coordinate network to enhance the inference efficiency of INRs. ASMR achieves high-quality reconstruction results with a low MAC count in various signal-fitting tasks."}, "pdf": {"value": "/pdf/757c0875ab81cabf86d178335cacc08bc7290fa3.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024asmr,\ntitle={{ASMR}: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference},\nauthor={Jason Chun Lok Li and Steven Tin Sui Luo and Le Xu and Ngai Wong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kMp8zCsXNb}\n}"}, "paperhash": {"value": "li|asmr_activationsharing_multiresolution_coordinate_networks_for_efficient_inference"}}, "number": 7291, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7291/-/Revision", "ICLR.cc/2024/Conference/Submission7291/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7291/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695465838774, "cdate": 1695465838774, "tmdate": 1713113796678, "mdate": 1713113796678, "pdate": 1705411005515, "version": 2}, {"id": "JsnR0YO4Fq", "forum": "JsnR0YO4Fq", "signatures": ["ICLR.cc/2024/Conference/Submission7286/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7286/Authors"], "content": {"title": {"value": "Exploring Weight Balancing on Long-Tailed Recognition Problem"}, "authors": {"value": ["Naoya Hasegawa", "Issei Sato"]}, "authorids": {"value": ["~Naoya_Hasegawa1", "~Issei_Sato2"]}, "keywords": {"value": ["long-tailed recognition", "imbalanced learning", "weight decay", "regularization", "neural collapse", "simplex ETF", "machine learning", "learning theory"]}, "TLDR": {"value": "We theoretically and empirically analyze weight balancing in long-tailed recognition, which leads to the further improvement of performance."}, "abstract": {"value": "Recognition problems in long-tailed data, in which the sample size per class is heavily skewed, have gained importance because the distribution of the sample size per class in a dataset is generally exponential unless the sample size is intentionally adjusted. Various methods have been devised to address these problems.\nRecently, weight balancing, which combines well-known classical regularization techniques with two-stage training, has been proposed. Despite its simplicity, it is known for its high performance compared with existing methods devised in various ways.\nHowever, there is a lack of understanding as to why this method is effective for long-tailed data. In this study, we analyze weight balancing by focusing on neural collapse and the cone effect at each training stage and found that it can be decomposed into an increase in Fisher's discriminant ratio of the feature extractor caused by weight decay and cross entropy loss and implicit logit adjustment caused by weight decay and class-balanced loss. Our analysis enables the training method to be further simplified by reducing the number of training stages to one while increasing accuracy. Code is available at https://github.com/HN410/Exploring-Weight-Balancing-on-Long-Tailed-Recognition-Problem."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3ae2b38ba7dd01bddd55e50e50c6dd2c31ef5330.pdf"}, "supplementary_material": {"value": "/attachment/cb18be5b20f4233738a1c23a35320070c7568ba1.pdf"}, "_bibtex": {"value": "@inproceedings{\nhasegawa2024exploring,\ntitle={Exploring Weight Balancing on Long-Tailed Recognition Problem},\nauthor={Naoya Hasegawa and Issei Sato},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JsnR0YO4Fq}\n}"}, "paperhash": {"value": "hasegawa|exploring_weight_balancing_on_longtailed_recognition_problem"}}, "number": 7286, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7286/-/Revision", "ICLR.cc/2024/Conference/Submission7286/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7286/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695465576920, "cdate": 1695465576920, "tmdate": 1710139021485, "mdate": 1710139021485, "pdate": 1705411005207, "version": 2}, {"id": "tuzTN0eIO5", "forum": "tuzTN0eIO5", "signatures": ["ICLR.cc/2024/Conference/Submission7283/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7283/Authors"], "content": {"title": {"value": "Zero Bubble (Almost) Pipeline Parallelism"}, "authors": {"value": ["Penghui Qi", "Xinyi Wan", "Guangxing Huang", "Min Lin"]}, "authorids": {"value": ["~Penghui_Qi1", "~Xinyi_Wan1", "~Guangxing_Huang1", "~Min_Lin1"]}, "keywords": {"value": ["Pipeline Parallelism", "Zero Bubble"]}, "abstract": {"value": "Pipeline parallelism is one of the key components for large-scale distributed training, yet its efficiency suffers from pipeline bubbles which were deemed inevitable. In this work, we introduce a scheduling strategy that, to our knowledge, is the first to successfully achieve zero pipeline bubbles under synchronous training semantics. The key idea behind this improvement is to split the backward computation into two parts, one that computes gradient for the input and another that computes for the parameters. Based on this idea, we handcraft novel pipeline schedules that significantly outperform the baseline methods. We further develop an algorithm that automatically finds an optimal schedule based on specific model configuration and memory limit. Additionally, to truly achieve zero bubble, we introduce a novel technique to bypass synchronizations during the optimizer step. Experimental evaluations show that our method outperforms the 1F1B schedule up to 15\\% in throughput under a similar memory limit. This number can be further pushed to 30\\% when the memory constraint is relaxed. We believe our results mark a major step forward in harnessing the true potential of pipeline parallelism. The source code based on Megatron-LM is publicly avaiable at \\url{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}."}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d9d00992fd3f8c0dc211cd10e300604a32c0690b.pdf"}, "_bibtex": {"value": "@inproceedings{\nqi2024zero,\ntitle={Zero Bubble Pipeline Parallelism},\nauthor={Penghui Qi and Xinyi Wan and Guangxing Huang and Min Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tuzTN0eIO5}\n}"}, "paperhash": {"value": "qi|zero_bubble_almost_pipeline_parallelism"}}, "number": 7283, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7283/-/Revision", "ICLR.cc/2024/Conference/Submission7283/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7283/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695465294788, "cdate": 1695465294788, "tmdate": 1709661538787, "mdate": 1709661538787, "pdate": 1705411005165, "version": 2}, {"id": "vtyasLn4RM", "forum": "vtyasLn4RM", "signatures": ["ICLR.cc/2024/Conference/Submission7266/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7266/Authors"], "content": {"title": {"value": "CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs"}, "authors": {"value": ["Florian Gr\u00f6tschla", "Jo\u00ebl Mathys", "Robert Veres", "Roger Wattenhofer"]}, "authorids": {"value": ["~Florian_Gr\u00f6tschla1", "~Jo\u00ebl_Mathys1", "~Robert_Veres1", "~Roger_Wattenhofer1"]}, "keywords": {"value": ["Graph Visualization", "Optimization", "Scalability", "Graph Neural Networks"]}, "abstract": {"value": "Graph Visualization, also known as Graph Drawing, aims to find geometric embeddings of graphs that optimize certain criteria. Stress is a widely used metric; stress is minimized when every pair of nodes is positioned at their shortest path distance. However, stress optimization presents computational challenges due to its inherent complexity and is usually solved using heuristics in practice. We introduce a scalable Graph Neural Network (GNN) based Graph Drawing framework with sub-quadratic runtime that can learn to optimize stress. Inspired by classical stress optimization techniques and force-directed layout algorithms, we create a coarsening hierarchy for the input graph. Beginning at the coarsest level, we iteratively refine and un-coarsen the layout, until we generate an embedding for the original graph. To enhance information propagation within the network, we propose a novel positional rewiring technique based on intermediate node positions. Our empirical evaluation demonstrates that the framework achieves state-of-the-art performance while remaining scalable."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1baa52e4c9b73bc02c6545df2f607951f50e3327.pdf"}, "TLDR": {"value": "We present CoRe-GD, a scalable GNN-based graph visualization framework using hierarchical coarsenings and positional rewiring."}, "_bibtex": {"value": "@inproceedings{\ngr{\\\"o}tschla2024coregd,\ntitle={CoRe-{GD}: A Hierarchical Framework for Scalable Graph Visualization with {GNN}s},\nauthor={Florian Gr{\\\"o}tschla and Jo{\\\"e}l Mathys and Robert Veres and Roger Wattenhofer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vtyasLn4RM}\n}"}, "paperhash": {"value": "gr\u00f6tschla|coregd_a_hierarchical_framework_for_scalable_graph_visualization_with_gnns"}}, "number": 7266, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7266/-/Revision", "ICLR.cc/2024/Conference/Submission7266/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7266/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695464122177, "cdate": 1695464122177, "tmdate": 1710264612287, "mdate": 1710264612287, "pdate": 1705411004457, "version": 2}, {"id": "HRkyLbBRHI", "forum": "HRkyLbBRHI", "signatures": ["ICLR.cc/2024/Conference/Submission7262/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7262/Authors"], "content": {"title": {"value": "Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning"}, "authors": {"value": ["Yeda Song", "Dongwook Lee", "Gunhee Kim"]}, "authorids": {"value": ["~Yeda_Song1", "~Dongwook_Lee5", "~Gunhee_Kim1"]}, "keywords": {"value": ["offline reinforcement learning", "compositional generalization", "conservatism", "transduction"]}, "TLDR": {"value": "We encourage conservatism in the compositional input space of the policy and Q-function, independently to the prevalent behavioral conservatism."}, "abstract": {"value": "Offline reinforcement learning (RL) is a compelling framework for learning optimal policies from past experiences without additional interaction with the environment. Nevertheless, offline RL inevitably faces the problem of distributional shifts, where the states and actions encountered during policy execution may not be in the training dataset distribution. A common solution involves incorporating conservatism into the policy or the value function to safeguard against uncertainties and unknowns. In this work, we focus on achieving the same objectives of conservatism but from a different perspective. We propose COmpositional COnservatism with Anchor-seeking (COCOA) for offline RL, an approach that pursues conservatism in a _compositional_ manner on top of the transductive reparameterization (Netanyahu et al., 2023), which decomposes the input variable (the state in our case) into an anchor and its difference from the original input. Our COCOA seeks both in-distribution anchors and differences by utilizing the learned reverse dynamics model, encouraging conservatism in the compositional input space for the policy or value function. Such compositional conservatism is independent of and agnostic to the prevalent _behavioral_ conservatism in offline RL. We apply COCOA to four state-of-the-art offline RL algorithms and evaluate them on the D4RL benchmark, where COCOA generally improves the performance of each algorithm. The code is available at https://github.com/runamu/compositional-conservatism."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/755e3b8ba24dd68b2d2c777c7911c492b6c9f9d7.pdf"}, "supplementary_material": {"value": "/attachment/9f7760815f3469bbe12348c4695e1ab1870c17a7.zip"}, "_bibtex": {"value": "@inproceedings{\nsong2024compositional,\ntitle={Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning},\nauthor={Yeda Song and Dongwook Lee and Gunhee Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HRkyLbBRHI}\n}"}, "paperhash": {"value": "song|compositional_conservatism_a_transductive_approach_in_offline_reinforcement_learning"}}, "number": 7262, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7262/-/Revision", "ICLR.cc/2024/Conference/Submission7262/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7262/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695463939115, "cdate": 1695463939115, "tmdate": 1710589878816, "mdate": 1710589878816, "pdate": 1705411004276, "version": 2}, {"id": "EG68RSznLT", "forum": "EG68RSznLT", "signatures": ["ICLR.cc/2024/Conference/Submission7244/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7244/Authors"], "content": {"title": {"value": "Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation"}, "authors": {"value": ["Zhilong Zhang", "Yihao Sun", "Junyin Ye", "Tian-Shuo Liu", "Jiaji Zhang", "Yang Yu"]}, "authorids": {"value": ["~Zhilong_Zhang2", "~Yihao_Sun1", "~Junyin_Ye1", "~Tian-Shuo_Liu1", "~Jiaji_Zhang1", "~Yang_Yu5"]}, "keywords": {"value": ["Preference-based Reinforcement Learning", "Offline Reinforcement Learning", "Conditional Generative Modeling", "Diffusion Models"]}, "abstract": {"value": "Offline preference-based reinforcement learning (PbRL) offers an effective solution to overcome the challenges associated with designing rewards and the high costs of online interactions. In offline PbRL, agents are provided with a fixed dataset containing human preferences between pairs of trajectories. Previous studies mainly focus on recovering the rewards from the preferences, followed by policy optimization with an off-the-shelf offline RL algorithm. However, given that preference label in PbRL is inherently trajectory-based, accurately learning transition-wise rewards from such label can be challenging, potentially leading to misguidance during subsequent offline RL training. To address this issue, we introduce our method named $\\textit{Flow-to-Better (FTB)}$, which leverages the pairwise preference relationship to guide a generative model in producing preferred trajectories, avoiding Temporal Difference (TD) learning with inaccurate rewards. Conditioning on a low-preference trajectory, $\\textit{FTB}$ uses a diffusion model to generate a better one with a higher preference, achieving high-fidelity full-horizon trajectory improvement. During diffusion training, we propose a technique called $\\textit{Preference Augmentation}$ to alleviate the problem of insufficient preference data. As a result, we surprisingly find that the model-generated trajectories not only exhibit increased preference and consistency with the real transition but also introduce elements of $\\textit{novelty}$ and $\\textit{diversity}$, from which we can derive a desirable policy through imitation learning. Experimental results on D4RL benchmarks demonstrate that FTB achieves a remarkable improvement compared to state-of-the-art offline PbRL methods. Furthermore, we show that FTB can also serve as an effective data augmentation method for offline RL."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ad36303392c1744c9dfd19512e714d01be29d8a0.pdf"}, "supplementary_material": {"value": "/attachment/907d98394076a214dc2c82800a1b929d0d76b8b0.zip"}, "_bibtex": {"value": "@inproceedings{\nzhang2024flow,\ntitle={Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation},\nauthor={Zhilong Zhang and Yihao Sun and Junyin Ye and Tian-Shuo Liu and Jiaji Zhang and Yang Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EG68RSznLT}\n}"}, "paperhash": {"value": "zhang|flow_to_better_offline_preferencebased_reinforcement_learning_via_preferred_trajectory_generation"}}, "number": 7244, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7244/-/Revision", "ICLR.cc/2024/Conference/Submission7244/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7244/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462996246, "cdate": 1695462996246, "tmdate": 1710076083499, "mdate": 1710076083499, "pdate": 1705411003518, "version": 2}, {"id": "iTFdNLHE7k", "forum": "iTFdNLHE7k", "signatures": ["ICLR.cc/2024/Conference/Submission7240/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7240/Authors"], "content": {"title": {"value": "Kernelised Normalising Flows"}, "authors": {"value": ["Eshant English", "Matthias Kirchler", "Christoph Lippert"]}, "authorids": {"value": ["~Eshant_English1", "~Matthias_Kirchler1", "~Christoph_Lippert1"]}, "keywords": {"value": ["Machine Learning", "Maximum Likelihood", "Density Estimation", "Statistics", "Kernels"]}, "TLDR": {"value": "Replacing neural network with kernelised transforms can improve normalising flow likelihood fit, especially in low-data regime"}, "abstract": {"value": "Normalising Flows are non-parametric statistical models known for their dual capabilities of density estimation and generation. They are distinguished by their inherently invertible architecture. However, the requirement of invertibility imposes constraints on their expressiveness, necessitating a large number of parameters and innovative architectural designs to achieve satisfactory outcomes. Whilst flow-based models predominantly rely on neural-network-based transformations for expressive designs, alternative transformation methods have received limited attention. In this work, we present Ferumal flow, a novel kernelised normalising flow paradigm that integrates kernels into the framework. Our results demonstrate that a kernelised flow can yield competitive or superior results compared to neural network-based flows whilst maintaining parameter efficiency. Kernelised flows excel especially in the low-data regime, enabling flexible non-parametric density estimation in applications with sparse data availability."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1906e5c792c779da5ed670b79e59c84df5493dee.pdf"}, "_bibtex": {"value": "@inproceedings{\nenglish2024kernelised,\ntitle={Kernelised Normalising Flows},\nauthor={Eshant English and Matthias Kirchler and Christoph Lippert},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iTFdNLHE7k}\n}"}, "paperhash": {"value": "english|kernelised_normalising_flows"}}, "number": 7240, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7240/-/Revision", "ICLR.cc/2024/Conference/Submission7240/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7240/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462847152, "cdate": 1695462847152, "tmdate": 1710429531618, "mdate": 1710429531618, "pdate": 1705411003332, "version": 2}, {"id": "HdAoLSBYXj", "forum": "HdAoLSBYXj", "signatures": ["ICLR.cc/2024/Conference/Submission7239/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7239/Authors"], "content": {"title": {"value": "Topic Modeling as Multi-Objective Contrastive Optimization"}, "authors": {"value": ["Thong Thanh Nguyen", "Xiaobao Wu", "Xinshuai Dong", "Cong-Duy T Nguyen", "See-Kiong Ng", "Anh Tuan Luu"]}, "authorids": {"value": ["~Thong_Thanh_Nguyen1", "~Xiaobao_Wu1", "~Xinshuai_Dong1", "~Cong-Duy_T_Nguyen1", "~See-Kiong_Ng1", "~Anh_Tuan_Luu2"]}, "keywords": {"value": ["neural topic model; contrastive learning"]}, "abstract": {"value": "Recent representation learning approaches enhance neural topic models by optimizing the weighted linear combination of the evidence lower bound (ELBO) of the log-likelihood and the contrastive learning objective that contrasts pairs of input documents. However, document-level contrastive learning might capture low-level mutual information, such as word ratio, which disturbs topic modeling. Moreover, there is a potential conflict between the ELBO loss that memorizes input details for better reconstruction quality, and the contrastive loss which attempts to learn topic representations that generalize among input documents. To address these issues, we first introduce a novel contrastive learning method oriented towards sets of topic vectors to capture useful semantics that are shared among a set of input documents. Secondly, we explicitly cast contrastive topic modeling as a gradient-based multi-objective optimization problem, with the goal of achieving a Pareto stationary solution that balances the trade-off between the ELBO and the contrastive objective. Extensive experiments demonstrate that our framework consistently produces higher-performing neural topic models in terms of topic coherence, topic diversity, and downstream performance."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/03b72301631f2eb40f630f1962d11bfb77212d09.pdf"}, "supplementary_material": {"value": "/attachment/00b068dc16b69fb8f553aec25a3cf60e7a01e994.zip"}, "_bibtex": {"value": "@inproceedings{\nnguyen2024topic,\ntitle={Topic modeling as multi-objective optimization with Setwise Contrastive Learning},\nauthor={Thong Thanh Nguyen and Xiaobao Wu and Xinshuai Dong and Cong-Duy T Nguyen and See-Kiong Ng and Anh Tuan Luu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HdAoLSBYXj}\n}"}, "paperhash": {"value": "nguyen|topic_modeling_as_multiobjective_contrastive_optimization"}}, "number": 7239, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7239/-/Revision", "ICLR.cc/2024/Conference/Submission7239/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7239/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462767253, "cdate": 1695462767253, "tmdate": 1709962314894, "mdate": 1709962314894, "pdate": 1705411003258, "version": 2}, {"id": "9DvDRTTdlu", "forum": "9DvDRTTdlu", "signatures": ["ICLR.cc/2024/Conference/Submission7237/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7237/Authors"], "content": {"title": {"value": "ED-NeRF: Efficient Text-Guided Editing of 3D Scene With Latent Space NeRF"}, "authors": {"value": ["JangHo Park", "Gihyun Kwon", "Jong Chul Ye"]}, "authorids": {"value": ["~JangHo_Park2", "~Gihyun_Kwon1", "~Jong_Chul_Ye1"]}, "keywords": {"value": ["NeRF", "Diffusion model", "3D scene editing"]}, "abstract": {"value": "Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into  NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this,  here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss function tailored for editing by migrating the delta denoising score (DDS) distillation loss, originally used in 2D image editing to the three-dimensional domain. This novel loss function surpasses the well-known score distillation sampling (SDS) loss in terms of suitability for editing purposes. Our experimental results demonstrate that ED-NeRF achieves faster editing speed while producing improved output quality compared to state-of-the-art 3D editing models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/205bd118d65762aad19ebc54c6a767c9ea6e0a95.pdf"}, "supplementary_material": {"value": "/attachment/2c94c50c0d663aed124b968c3da8d7c433667995.zip"}, "_bibtex": {"value": "@inproceedings{\npark2024ednerf,\ntitle={{ED}-Ne{RF}: Efficient Text-Guided Editing of 3D Scene With Latent Space Ne{RF}},\nauthor={JangHo Park and Gihyun Kwon and Jong Chul Ye},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9DvDRTTdlu}\n}"}, "paperhash": {"value": "park|ednerf_efficient_textguided_editing_of_3d_scene_with_latent_space_nerf"}}, "number": 7237, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7237/-/Revision", "ICLR.cc/2024/Conference/Submission7237/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7237/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462711511, "cdate": 1695462711511, "tmdate": 1710241694648, "mdate": 1710241694648, "pdate": 1705411003211, "version": 2}, {"id": "8FHWkY0SwF", "forum": "8FHWkY0SwF", "signatures": ["ICLR.cc/2024/Conference/Submission7234/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7234/Authors"], "content": {"title": {"value": "Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients"}, "authors": {"value": ["Xueyang Tang", "Song Guo", "Jie ZHANG", "Jingcai Guo"]}, "authorids": {"value": ["~Xueyang_Tang1", "~Song_Guo5", "~Jie_ZHANG18", "~Jingcai_Guo1"]}, "keywords": {"value": ["Personalized Federated Learning", "Invariant Learning", "Causality", "Out-of-distribution Generalization", "Shortcut Learning"]}, "TLDR": {"value": "We propose a provable shortcut discovery and removal method under personalized federated learning to develop the optimal personalized invariant predictors that can generalize to unseen OOD data for the heterogeneous clients."}, "abstract": {"value": "Personalized federated learning (PFL) has gained great success in tackling the scenarios where target datasets are heterogeneous across the local clients. However, the application of the existing PFL methods to real-world setting is hindered by the common assumption that the test data on each client is in-distribution (IND) with respect to its training data. Due to the bias of training dataset, the modern machine learning model prefers to rely on shortcut which can perform well on the training data but fail to generalize to the unseen test data that is out-of-distribution (OOD). This pervasive phenomenon is called shortcut learning and has attracted plentiful efforts in centralized situations. In PFL, the limited data diversity on federated clients makes mitigating shortcut and meanwhile preserving personalization knowledge rather difficult. In this paper, we analyse this challenging problem by formulating the structural causal models (SCMs) for heterogeneous federated clients. From the proposed SCMs, we derive two significant causal signatures which inspire a provable shortcut discovery and removal method under federated learning, namely FedSDR. Specifically, FedSDR is divided into two steps: 1) utilizing the available training data distributed among local clients to discover all the shortcut features in a collaborative manner. 2) developing the optimal personalized causally invariant predictor for each client by eliminating the discovered shortcut features. We provide theoretical analysis to prove that our method can draw complete shortcut features and produce the optimal personalized invariant predictor that can generalize to unseen OOD data on each client. The experimental results on diverse datasets validate the superiority of FedSDR over the state-of-the-art PFL methods on OOD generalization performance."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ccb7d7779ba1a168b0d21858fe06b340a9ddf2e9.pdf"}, "_bibtex": {"value": "@inproceedings{\ntang2024learning,\ntitle={Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients},\nauthor={Xueyang Tang and Song Guo and Jie ZHANG and Jingcai Guo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8FHWkY0SwF}\n}"}, "paperhash": {"value": "tang|learning_personalized_causally_invariant_representations_for_heterogeneous_federated_clients"}}, "number": 7234, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7234/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7234/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695462617421, "cdate": 1695462617421, "tmdate": 1710588791318, "mdate": 1710588791318, "pdate": 1705411003094, "version": 2}, {"id": "R7rZUSGOPD", "forum": "R7rZUSGOPD", "signatures": ["ICLR.cc/2024/Conference/Submission7222/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7222/Authors"], "content": {"title": {"value": "PAE: Reinforcement Learning from External Knowledge for Efficient Exploration"}, "authors": {"value": ["Zhe Wu", "Haofei Lu", "Junliang Xing", "You Wu", "Renye Yan", "Yaozhong Gan", "Yuanchun Shi"]}, "authorids": {"value": ["~Zhe_Wu6", "~Haofei_Lu1", "~Junliang_Xing1", "~You_Wu5", "~Renye_Yan1", "~Yaozhong_Gan1", "~Yuanchun_Shi1"]}, "keywords": {"value": ["Reinforcement learning", "exploration", "intrinsic motivation", "knowledge"]}, "TLDR": {"value": "This paper introduces PAE: Planner-Actor-Evaluator, a novel framework for teaching agents to learn to absorb external knowledge."}, "abstract": {"value": "Human intelligence is adept at absorbing valuable insights from external knowledge.\nThis capability is equally crucial for artificial intelligence. \nIn contrast, classical reinforcement learning agents lack such capabilities and often resort to extensive trial and error to explore the environment. \nThis paper introduces $\\textbf{PAE}$: $\\textbf{P}$lanner-$\\textbf{A}$ctor-$\\textbf{E}$valuator, a novel framework for teaching agents to $\\textit{learn to absorb external knowledge}$. \nPAE integrates the Planner's knowledge-state alignment mechanism, the Actor's mutual information skill control, and the Evaluator's adaptive intrinsic exploration reward to achieve 1) effective cross-modal information fusion, 2) enhanced linkage between knowledge and state, and 3) hierarchical mastery of complex tasks.\nComprehensive experiments across\n 11 challenging tasks from the BabyAI and MiniHack environment suites demonstrate PAE's superior exploration efficiency with good interpretability."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f45d0322cc4876f6528ee34b54eb7381043f06b7.pdf"}, "supplementary_material": {"value": "/attachment/05e9456ab6e27ad1bfa86b07e3188c5f4eb5dcfb.zip"}, "_bibtex": {"value": "@inproceedings{\nwu2024pae,\ntitle={{PAE}: Reinforcement Learning from External Knowledge for Efficient Exploration},\nauthor={Zhe Wu and Haofei Lu and Junliang Xing and You Wu and Renye Yan and Yaozhong Gan and Yuanchun Shi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=R7rZUSGOPD}\n}"}, "paperhash": {"value": "wu|pae_reinforcement_learning_from_external_knowledge_for_efficient_exploration"}}, "number": 7222, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7222/-/Revision", "ICLR.cc/2024/Conference/Submission7222/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/Submission7222/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695461906953, "cdate": 1695461906953, "tmdate": 1710296500377, "mdate": 1710296500377, "pdate": 1705411002636, "version": 2}, {"id": "rHzapPnCgT", "forum": "rHzapPnCgT", "signatures": ["ICLR.cc/2024/Conference/Submission7214/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7214/Authors"], "content": {"title": {"value": "Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models"}, "authors": {"value": ["Fei Shen", "Hu Ye", "Jun Zhang", "Cong Wang", "Xiao Han", "Yang Wei"]}, "authorids": {"value": ["~Fei_Shen1", "huye@tencent.com", "~Jun_Zhang17", "~Cong_Wang8", "~Xiao_Han2", "~Yang_Wei2"]}, "keywords": {"value": ["Diffusion Model;  Pose-Guided Image Synthesis"]}, "abstract": {"value": "Recent work has showcased the significant potential of diffusion models in pose-guided person image synthesis.\nHowever, owing to the inconsistency in pose between the source and target images, synthesizing an image with a distinct pose, relying exclusively on the source image and target pose information, remains a formidable challenge.\nThis paper presents Progressive Conditional Diffusion Models (PCDMs) that incrementally bridge the gap between person images under the target and source poses through three stages.\nSpecifically, in the first stage, we design a simple prior conditional diffusion model that predicts the global features of the target image by mining the global alignment relationship between pose coordinates and image appearance.\nThen, the second stage establishes a dense correspondence between the source and target images using the global features from the previous stage, and an inpainting conditional diffusion model is proposed to further align and enhance the contextual features, generating a coarse-grained person image.\nIn the third stage, we propose a refining conditional diffusion model to utilize the coarsely generated image from the previous stage as a condition, achieving texture restoration and enhancing fine-detail consistency.\nThe three-stage PCDMs work progressively to generate the final high-quality and high-fidelity synthesized image.\nBoth qualitative and quantitative results demonstrate the consistency and photorealism of our proposed PCDMs under challenging scenarios.\nThe code and model will be available at https://github.com/tencent-ailab/PCDMs."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/226a8b55e6ef3b8f319c249ab0cf8e60273d1045.pdf"}, "_bibtex": {"value": "@inproceedings{\nshen2024advancing,\ntitle={Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models},\nauthor={Fei Shen and Hu Ye and Jun Zhang and Cong Wang and Xiao Han and Yang Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rHzapPnCgT}\n}"}, "paperhash": {"value": "shen|advancing_poseguided_image_synthesis_with_progressive_conditional_diffusion_models"}}, "number": 7214, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7214/-/Revision", "ICLR.cc/2024/Conference/Submission7214/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7214/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695461615460, "cdate": 1695461615460, "tmdate": 1710315227462, "mdate": 1710315227462, "pdate": 1705411002339, "version": 2}, {"id": "8p3fu56lKc", "forum": "8p3fu56lKc", "signatures": ["ICLR.cc/2024/Conference/Submission7195/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7195/Authors"], "content": {"title": {"value": "One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention"}, "authors": {"value": ["Arvind V. Mahankali", "Tatsunori Hashimoto", "Tengyu Ma"]}, "authorids": {"value": ["~Arvind_V._Mahankali1", "~Tatsunori_Hashimoto1", "~Tengyu_Ma1"]}, "keywords": {"value": ["Linear Self-Attention", "In-context learning", "Gradient Descent", "Theoretical Understanding"]}, "abstract": {"value": "Recent works have empirically analyzed in-context learning and shown that transformers trained on synthetic linear regression tasks can learn to implement ridge regression, which is the Bayes-optimal predictor, given sufficient capacity (Akyurek et al., 2023), while one-layer transformers with linear self-attention and no MLP layer will learn to implement one step of gradient descent (GD) on a least-squares linear regression objective (von Oswald et al., 2022). However, the theory behind these observations remains poorly understood. We theoretically study transformers with a single layer of linear self-attention, trained on synthetic noisy linear regression data. First, we mathematically show that when the covariates are drawn from a standard Gaussian distribution, the one-layer transformer which minimizes the pre-training loss will implement a single step of GD on the least-squares linear regression objective. Then, we find that changing the distribution of the covariates and weight vector to a non-isotropic Gaussian distribution has a strong impact on the learned algorithm: the global minimizer of the pre-training loss now implements a single step of $\\textit{pre-conditioned}$ GD. However, if only the distribution of the responses is changed, then this does not have a large effect on the learned algorithm: even when the response comes from a more general family of $\\textit{nonlinear}$ functions, the global minimizer of the pre-training loss still implements a single step of GD on a least-squares linear regression objective."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c56e892fe43263e21b243db50afac6ff6b53fe4d.pdf"}, "supplementary_material": {"value": "/attachment/2a9f6630ad97e11aca89759cde4ceb153d835363.zip"}, "_bibtex": {"value": "@inproceedings{\nmahankali2024one,\ntitle={One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention},\nauthor={Arvind V. Mahankali and Tatsunori Hashimoto and Tengyu Ma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8p3fu56lKc}\n}"}, "paperhash": {"value": "mahankali|one_step_of_gradient_descent_is_provably_the_optimal_incontext_learner_with_one_layer_of_linear_selfattention"}}, "number": 7195, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7195/-/Revision", "ICLR.cc/2024/Conference/Submission7195/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7195/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695460535763, "cdate": 1695460535763, "tmdate": 1710567873830, "mdate": 1710567873830, "pdate": 1705411001626, "version": 2}, {"id": "8euJaTveKw", "forum": "8euJaTveKw", "signatures": ["ICLR.cc/2024/Conference/Submission7178/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7178/Authors"], "content": {"title": {"value": "Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models"}, "authors": {"value": ["Seungone Kim", "Jamin Shin", "Yejin Cho", "Joel Jang", "Shayne Longpre", "Hwaran Lee", "Sangdoo Yun", "Seongjin Shin", "Sungdong Kim", "James Thorne", "Minjoon Seo"]}, "authorids": {"value": ["~Seungone_Kim1", "~Jamin_Shin1", "~Yejin_Cho2", "~Joel_Jang1", "~Shayne_Longpre1", "~Hwaran_Lee1", "~Sangdoo_Yun1", "~Seongjin_Shin1", "~Sungdong_Kim1", "~James_Thorne1", "~Minjoon_Seo1"]}, "keywords": {"value": ["automatic evaluation", "large language models", "llm-as-a-judge"]}, "abstract": {"value": "Recently, GPT-4 has become the de facto evaluator for long-form text generated by large language models (LLMs). However, for practitioners and researchers with large and custom evaluation tasks, GPT-4 is unreliable due to its closed-source nature, uncontrolled versioning, and prohibitive costs. In this work, we propose PROMETHEUS a fully open-source LLM that is on par with GPT-4\u2019s evaluation capabilities when the appropriate reference materials (reference answer, score rubric) are accompanied. For this purpose, we construct a new dataset \u2013 FEEDBACK COLLECTION \u2013 that consists of 1K fine-grained score rubrics, 20K instructions, and 100K natural language feedback generated by GPT-4. Using the FEEDBACK COLLECTION, we train PROMETHEUS, a 13B evaluation-specific LLM that can assess any given response based on novel and unseen score rubrics and reference materials provided by the user. Our dataset\u2019s versatility and diversity make our model generalize to challenging real-world criteria, such as prioritizing conciseness, child-readability, or varying levels of formality. We show that PROMETHEUS shows a stronger correlation with GPT-4 evaluation compared to ChatGPT on seven evaluation benchmarks (Two Feedback Collection testsets, MT Bench, Vicuna Bench, Flask Eval, MT Bench Human Judgment, and HHH Alignment), showing the efficacy of our model and dataset design. During human evaluation with hand-crafted score rubrics, PROMETHEUS shows a Pearson correlation of 0.897 with human evaluators, which is on par with GPT-4-0613 (0.882), and greatly outperforms ChatGPT (0.392). Remarkably, when assessing the quality of the generated feedback, PROMETHEUS demonstrates a win rate of 58.62% when compared to GPT-4 evaluation and a win rate of 79.57% when compared to ChatGPT evaluation. Our findings suggests that by adding reference materials and training on GPT-4 feedback, we can obtain effective open-source evaluator LMs."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4dc010ade5e862ca7204d8a15c7306aa009d5bd2.pdf"}, "supplementary_material": {"value": "/attachment/fba32c838c8e8307f5560e1966c2a1c1b9cd1c4e.zip"}, "TLDR": {"value": "We are the first to train a model specifically for fine-grained evaluation capabilities that performs on-par with GPT-4."}, "_bibtex": {"value": "@inproceedings{\nkim2024prometheus,\ntitle={Prometheus: Inducing Evaluation Capability in Language Models},\nauthor={Seungone Kim and Jamin Shin and Yejin Cho and Joel Jang and Shayne Longpre and Hwaran Lee and Sangdoo Yun and Seongjin Shin and Sungdong Kim and James Thorne and Minjoon Seo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8euJaTveKw}\n}"}, "paperhash": {"value": "kim|prometheus_inducing_finegrained_evaluation_capability_in_language_models"}}, "number": 7178, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7178/-/Revision", "ICLR.cc/2024/Conference/Submission7178/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7178/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695459491424, "cdate": 1695459491424, "tmdate": 1709977393399, "mdate": 1709977393399, "pdate": 1705411001224, "version": 2}, {"id": "THUBTfSAS2", "forum": "THUBTfSAS2", "signatures": ["ICLR.cc/2024/Conference/Submission7173/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7173/Authors"], "content": {"title": {"value": "Querying Easily Flip-flopped Samples for Deep Active Learning"}, "authors": {"value": ["Seong Jin Cho", "Gwangsu Kim", "Junghyun Lee", "Jinwoo Shin", "Chang D. Yoo"]}, "authorids": {"value": ["~Seong_Jin_Cho1", "~Gwangsu_Kim1", "~Junghyun_Lee1", "~Jinwoo_Shin1", "~Chang_D._Yoo1"]}, "keywords": {"value": ["active learning", "uncertainty", "closeness", "disagree metric", "diversity"]}, "TLDR": {"value": "The uncertainty-based active learning algorithm that queries samples easily flip-flopped by a small perturbation of the decision boundary."}, "abstract": {"value": "Active learning, a paradigm within machine learning, aims to select and query unlabeled data to enhance model performance strategically. A crucial selection strategy leverages the model's predictive uncertainty, reflecting the informativeness of a data point. While the sample's distance to the decision boundary intuitively measures predictive uncertainty, its computation becomes intractable for complex decision boundaries formed in multiclass classification tasks. This paper introduces the *least disagree metric* (LDM), the smallest probability of predicted label disagreement. We propose an asymptotically consistent estimator for LDM under mild assumptions. The estimator boasts computational efficiency and straightforward implementation for deep learning models using parameter perturbation. The LDM-based active learning algorithm queries unlabeled data with the smallest LDM, achieving state-of-the-art *overall* performance across various datasets and deep architectures, as demonstrated by the experimental results."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7a5f9135aa347ebc2c3dcde54c8e4c4af570183c.pdf"}, "_bibtex": {"value": "@inproceedings{\ncho2024querying,\ntitle={Querying Easily Flip-flopped Samples for Deep Active Learning},\nauthor={Seong Jin Cho and Gwangsu Kim and Junghyun Lee and Jinwoo Shin and Chang D. Yoo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=THUBTfSAS2}\n}"}, "paperhash": {"value": "cho|querying_easily_flipflopped_samples_for_deep_active_learning"}}, "number": 7173, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7173/-/Revision", "ICLR.cc/2024/Conference/Submission7173/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7173/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695459298144, "cdate": 1695459298144, "tmdate": 1713147561968, "mdate": 1713147561968, "pdate": 1705411001051, "version": 2}, {"id": "FDb2JQZsFH", "forum": "FDb2JQZsFH", "signatures": ["ICLR.cc/2024/Conference/Submission7169/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7169/Authors"], "content": {"title": {"value": "Attention-based Iterative Decomposition for Tensor Product Representation"}, "authors": {"value": ["Taewon Park", "Inchul Choi", "Minho Lee"]}, "authorids": {"value": ["~Taewon_Park1", "~Inchul_Choi1", "~Minho_Lee2"]}, "keywords": {"value": ["tensor product representation", "systematic generalization", "compositional generalization", "binding problem", "structured representation learning", "competitive attention"]}, "abstract": {"value": "In recent research, Tensor Product Representation (TPR) is applied for the systematic generalization task of deep neural networks by learning the compositional structure of data. However, such prior works show limited performance in discovering and representing the symbolic structure from unseen test data because their decomposition to the structural representations was incomplete. In this work, we propose an Attention-based Iterative Decomposition (AID) module designed to enhance the decomposition operations for the structured representations encoded from the sequential input data with TPR. Our AID can be easily adapted to any TPR-based model and provides enhanced systematic decomposition through a competitive attention mechanism between input features and structured representations. In our experiments, AID shows effectiveness by significantly improving the performance of TPR-based prior works on the series of systematic generalization tasks. Moreover, in the quantitative and qualitative evaluations, AID produces more compositional and well-bound structural representations than other works."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ef6edba1a437c906a4d0af4a676c5dfc0cfbf6cb.pdf"}, "supplementary_material": {"value": "/attachment/6d1f11974a82ecd4b29be4477fcad12f55e17a87.zip"}, "TLDR": {"value": "Slot-based competitive mechanism that effectively binds sequential features to the structured representations (roles and fillers) of TPR"}, "_bibtex": {"value": "@inproceedings{\npark2024attentionbased,\ntitle={Attention-based Iterative Decomposition for Tensor Product Representation},\nauthor={Taewon Park and Inchul Choi and Minho Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FDb2JQZsFH}\n}"}, "paperhash": {"value": "park|attentionbased_iterative_decomposition_for_tensor_product_representation"}}, "number": 7169, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7169/-/Revision", "ICLR.cc/2024/Conference/Submission7169/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7169/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695459055806, "cdate": 1695459055806, "tmdate": 1712115401563, "mdate": 1712115401563, "pdate": 1705411000949, "version": 2}, {"id": "RR70yWYenC", "forum": "RR70yWYenC", "signatures": ["ICLR.cc/2024/Conference/Submission7163/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7163/Authors"], "content": {"title": {"value": "Efficient Continual Finite-Sum Minimization"}, "authors": {"value": ["Ioannis Mavrothalassitis", "Stratis Skoulakis", "Leello Tadesse Dadi", "Volkan Cevher"]}, "authorids": {"value": ["~Ioannis_Mavrothalassitis1", "~Stratis_Skoulakis2", "~Leello_Tadesse_Dadi1", "~Volkan_Cevher1"]}, "keywords": {"value": ["Finite Sum Minimization", "Variance Reduction", "Optimization"]}, "abstract": {"value": "Given a sequence of functions $f_1,\\ldots,f_n$ with $f_i:\\mathcal{D}\\mapsto \\mathbb{R}$, finite-sum minimization seeks a point ${x}^\\star \\in \\mathcal{D}$ minimizing $\\sum_{j=1}^nf_j(x)/n$. In this work, we propose a key twist into the finite-sum minimization, dubbed as *continual finite-sum minimization*, that asks for a sequence of points $x_1^\\star, \\ldots, x_n^\\star \\in D$ such that each ${x}^\\star_i \\in D$ minimizes the prefix-sum $\\sum_{j=1}^if_j(x)/i$. Assuming that each prefix-sum is strongly convex, we develop a first-order continual stochastic variance reduction gradient method ($\\mathrm{CSVRG}$) producing an $\\epsilon$-optimal sequence with $\\tilde{\\mathcal{O}}(n/\\epsilon^{1/3} + 1/\\sqrt{\\epsilon})$ overall *first-order oracles* (FO). An FO corresponds to the computation of a single gradient $\\nabla f_j(x)$ at a given $x \\in \\mathcal{D}$ for some $j \\in [n]$. Our approach significantly improves upon the $\\mathcal{O}(n/\\epsilon)$ FOs that $\\mathrm{StochasticGradientDescent}$ requires and the $\\mathcal{O}(n^2 \\log (1/\\epsilon))$ FOs that state-of-the-art variance reduction methods such as $\\mathrm{Katyusha}$ require. We also prove that there is no natural first-order method with $\\mathcal{O}\\left(n/\\epsilon^\\alpha\\right)$ gradient complexity for $\\alpha < 1/4$, establishing that the first-order complexity of our method is nearly tight."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/75cda28a7c459f0c79da3a8ce13bd4fca3ff5efd.pdf"}, "supplementary_material": {"value": "/attachment/5f88bad9683884a02818df25fc5221c5356d5a98.zip"}, "_bibtex": {"value": "@inproceedings{\nmavrothalassitis2024efficient,\ntitle={Efficient Instance-Optimal Finite-Sum Minimization},\nauthor={Ioannis Mavrothalassitis and Stratis Skoulakis and Leello Tadesse Dadi and Volkan Cevher},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RR70yWYenC}\n}"}, "paperhash": {"value": "mavrothalassitis|efficient_continual_finitesum_minimization"}}, "number": 7163, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7163/-/Revision", "ICLR.cc/2024/Conference/Submission7163/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7163/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695458758189, "cdate": 1695458758189, "tmdate": 1710514776138, "mdate": 1710514776138, "pdate": 1705411000711, "version": 2}, {"id": "2iGiSHmeAN", "forum": "2iGiSHmeAN", "signatures": ["ICLR.cc/2024/Conference/Submission7162/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7162/Authors"], "content": {"title": {"value": "BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics"}, "authors": {"value": ["Suresh Bishnoi", "Jayadeva Jayadeva", "Sayan Ranu", "N M Anoop Krishnan"]}, "authorids": {"value": ["~Suresh_Bishnoi1", "~Jayadeva_Jayadeva1", "~Sayan_Ranu2", "~N_M_Anoop_Krishnan1"]}, "keywords": {"value": ["Brownian dynamics", "stochastic differential equation", "graph neural network", "scientific machine learning"]}, "TLDR": {"value": "Here, we present a momentum-conserving graph neural network for learning brownian dynamics represented by a stochastic differential equation"}, "abstract": {"value": "Neural networks (NNs) that exploit strong inductive biases based on physical laws and symmetries have shown remarkable success in learning the dynamics of physical systems directly from their trajectory. However, these works focus only on the systems that follow deterministic dynamics, such as Newtonian or Hamiltonian. Here, we propose a framework, namely Brownian graph neural networks (BroGNet), combining stochastic differential equations (SDEs) and GNNs to learn Brownian dynamics directly from the trajectory. We modify the architecture of BroGNet to enforce linear momentum conservation of the system, which, in turn, provides superior performance on learning dynamics as revealed empirically. We demonstrate this approach on several systems, namely, linear spring, linear spring with binary particle types, and non-linear spring systems, all following Brownian dynamics at finite temperatures. We show that BroGNet significantly outperforms proposed baselines across all the benchmarked Brownian systems. In addition, we demonstrate zero-shot generalizability of BroGNet to simulate unseen system sizes that are two orders of magnitude larger and to different temperatures than those used during training. Finally, we show that BroGNet conserves the momentum of the system resulting in superior performance and data efficiency. Altogether, our study contributes to advancing the understanding of the intricate dynamics of Brownian motion and demonstrates the effectiveness of graph neural networks in modeling such complex systems."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7068bcb7f8feb34ebb6a585e0060e3135e592aac.pdf"}, "supplementary_material": {"value": "/attachment/3c5a269cc97726c258f8c59f70a719d96f7f1327.pdf"}, "_bibtex": {"value": "@inproceedings{\nbishnoi2024brognet,\ntitle={Bro{GN}et: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics},\nauthor={Suresh Bishnoi and Jayadeva Jayadeva and Sayan Ranu and N M Anoop Krishnan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2iGiSHmeAN}\n}"}, "paperhash": {"value": "bishnoi|brognet_momentumconserving_graph_neural_stochastic_differential_equation_for_learning_brownian_dynamics"}}, "number": 7162, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7162/-/Revision", "ICLR.cc/2024/Conference/Submission7162/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7162/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695458666120, "cdate": 1695458666120, "tmdate": 1710493272597, "mdate": 1710493272597, "pdate": 1705411000698, "version": 2}, {"id": "5jWsW08zUh", "forum": "5jWsW08zUh", "signatures": ["ICLR.cc/2024/Conference/Submission7155/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7155/Authors"], "content": {"title": {"value": "Some Fundamental Aspects about Lipschitz Continuity of Neural Networks"}, "authors": {"value": ["Grigory Khromov", "Sidak Pal Singh"]}, "authorids": {"value": ["~Grigory_Khromov1", "~Sidak_Pal_Singh1"]}, "keywords": {"value": ["Lipschitz continuity", "Double Descent", "Label Noise", "Generalization"]}, "TLDR": {"value": "An empirical investigation into the behaviour of the Lipschitz constant for Deep Learning models in various learning settings."}, "abstract": {"value": "Lipschitz continuity is a crucial functional property of any predictive model, that naturally governs its robustness, generalisation, as well as adversarial vulnerability. Contrary to other works that focus on obtaining tighter bounds and developing different practical strategies to enforce certain Lipschitz properties, we aim to thoroughly examine and characterise the Lipschitz behaviour of Neural Networks. Thus, we carry out an empirical investigation in a range of different settings (namely, architectures, datasets, label noise, and more) by exhausting the limits of the simplest and the most general lower and upper bounds. As a highlight of this investigation, we showcase a remarkable fidelity of the lower Lipschitz bound, identify a striking Double Descent trend in both upper and lower bounds to the Lipschitz and explain the intriguing effects of label noise on function smoothness and generalisation."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/77f27538640516d4f8766eaa0d2b22a9b895e8c8.pdf"}, "supplementary_material": {"value": "/attachment/6f2067e3b67cea7bfa8af7bc5a39136f8a81af0d.zip"}, "_bibtex": {"value": "@inproceedings{\nkhromov2024some,\ntitle={Some Intriguing Aspects about Lipschitz Continuity of Neural Networks},\nauthor={Grigory Khromov and Sidak Pal Singh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5jWsW08zUh}\n}"}, "paperhash": {"value": "khromov|some_fundamental_aspects_about_lipschitz_continuity_of_neural_networks"}}, "number": 7155, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7155/-/Revision", "ICLR.cc/2024/Conference/Submission7155/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7155/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695458252877, "cdate": 1695458252877, "tmdate": 1713096044318, "mdate": 1713096044318, "pdate": 1705411000381, "version": 2}, {"id": "3ZqKxMHcAg", "forum": "3ZqKxMHcAg", "signatures": ["ICLR.cc/2024/Conference/Submission7151/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7151/Authors"], "content": {"title": {"value": "Evaluating Language Model Agency Through Negotiations"}, "authors": {"value": ["Tim Ruben Davidson", "Veniamin Veselovsky", "Michal Kosinski", "Robert West"]}, "authorids": {"value": ["~Tim_Ruben_Davidson1", "~Veniamin_Veselovsky1", "~Michal_Kosinski1", "~Robert_West1"]}, "keywords": {"value": ["language model evaluation", "dynamic evaluation", "alignment", "cooperative AI", "agency", "evolving benchmarks", "multi-agent interactions"]}, "TLDR": {"value": "A benchmark approach to jointly evaluate performance and alignment of language models through dynamic, multi-step, and cross-model negotiation games."}, "abstract": {"value": "We introduce an approach to evaluate language model (LM) agency using negotiation games. This approach better reflects real-world use cases and addresses some of the shortcomings of alternative LM benchmarks. Negotiation games enable us to study multi-turn, and cross-model interactions, modulate complexity, and side-step accidental evaluation data leakage. We use our approach to test six widely used and publicly accessible LMs, evaluating performance and alignment in both self-play and cross-play settings. Noteworthy findings include: (i) only closed-source models tested here were able to complete these tasks; (ii) cooperative bargaining games proved to be most challenging to the models; and (iii) even the most powerful models sometimes \"lose\" to weaker opponents."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/eb6edda39c7beddd7ba81db3bc6aa787aa542d90.pdf"}, "_bibtex": {"value": "@inproceedings{\ndavidson2024evaluating,\ntitle={Evaluating Language Models Through Negotiations},\nauthor={Tim Ruben Davidson and Veniamin Veselovsky and Michal Kosinski and Robert West},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3ZqKxMHcAg}\n}"}, "paperhash": {"value": "davidson|evaluating_language_model_agency_through_negotiations"}}, "number": 7151, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7151/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7151/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695458015947, "cdate": 1695458015947, "tmdate": 1710694702681, "mdate": 1710694702681, "pdate": 1705411000250, "version": 2}, {"id": "ZS4m74kZpH", "forum": "ZS4m74kZpH", "signatures": ["ICLR.cc/2024/Conference/Submission7143/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7143/Authors"], "content": {"title": {"value": "Making Retrieval-Augmented Language Models Robust to Irrelevant Context"}, "authors": {"value": ["Ori Yoran", "Tomer Wolfson", "Ori Ram", "Jonathan Berant"]}, "authorids": {"value": ["~Ori_Yoran1", "~Tomer_Wolfson1", "~Ori_Ram2", "~Jonathan_Berant1"]}, "keywords": {"value": ["Retrieval Augmented Language Models", "Large Language Models", "Robustness", "Question Answering"]}, "TLDR": {"value": "We present a thorough analysis of cases where retrieval augmentation hurts performance of large language models, and propose methods that improve their robustness to irrelevant context, thereby increasing their overall performance."}, "abstract": {"value": "Retrieval-augmented language models (RALMs) hold promise to produce language understanding systems that are are factual, efficient, and up-to-date. An important desideratum of RALMs, is that retrieved information helps model performance when it is relevant, and does not harm performance when it is not. This is particularly important in multi-hop reasoning scenarios, where misuse of irrelevant evidence can lead to cascading errors. However, recent work has shown that retrieval augmentation can sometimes have a negative effect on performance. In this work, we present a thorough analysis on five open-domain question answering benchmarks, characterizing cases when retrieval reduces accuracy. We then propose two methods to mitigate this issue. First, a simple baseline that filters out retrieved passages that do not entail question-answer pairs according to a natural language inference (NLI) model. This is effective in preventing performance reduction, but at a cost of also discarding relevant passages. Thus, we propose a method for automatically generating data to fine-tune the language model to properly leverage retrieved passages, using a mix of relevant and irrelevant contexts at training time. We empirically show that even 1,000 examples suffice to train the model to be robust to irrelevant contexts while maintaining high performance on examples with relevant ones."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/44aa56e421d689ace11271253f0c0e7e640373db.pdf"}, "_bibtex": {"value": "@inproceedings{\nyoran2024making,\ntitle={Making Retrieval-Augmented Language Models Robust to Irrelevant Context},\nauthor={Ori Yoran and Tomer Wolfson and Ori Ram and Jonathan Berant},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZS4m74kZpH}\n}"}, "paperhash": {"value": "yoran|making_retrievalaugmented_language_models_robust_to_irrelevant_context"}}, "number": 7143, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7143/-/Revision", "ICLR.cc/2024/Conference/Submission7143/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7143/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695457575254, "cdate": 1695457575254, "tmdate": 1709817438941, "mdate": 1709817438941, "pdate": 1705411000033, "version": 2}, {"id": "K9sVJ17zvB", "forum": "K9sVJ17zvB", "signatures": ["ICLR.cc/2024/Conference/Submission7134/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7134/Authors"], "content": {"title": {"value": "VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation"}, "authors": {"value": ["Jinxi Xiang", "Ricong Huang", "Jun Zhang", "Guanbin Li", "Xiao Han", "Yang Wei"]}, "authorids": {"value": ["~Jinxi_Xiang1", "~Ricong_Huang1", "~Jun_Zhang17", "~Guanbin_Li2", "~Xiao_Han2", "~Yang_Wei2"]}, "keywords": {"value": ["video generation", "diffusion model", "temproal modeling"]}, "TLDR": {"value": "We introduce a video generation model for stable and controllable videos across various conditions."}, "abstract": {"value": "Creating stable, controllable videos is a complex task due to the need for significant variation in temporal dynamics and cross-frame temporal consistency. To address this, we enhance the spatial-temporal capability and introduce a versatile video generation model, VersVideo, which leverages textual, visual, and stylistic conditions. Current video diffusion models typically extend image diffusion architectures by supplementing 2D operations (such as convolutions and attentions) with temporal operations. While this approach is efficient, it often restricts spatial-temporal performance due to the oversimplification of standard 3D operations. To counter this, we incorporate two key elements: (1) multi-excitation paths for spatial-temporal convolutions with dimension pooling across different axes, and (2) multi-expert spatial-temporal attention blocks. These enhancements boost the model's spatial-temporal performance without significantly escalating training and inference costs. We also tackle the issue of information loss that arises when a variational autoencoder is used to transform pixel space into latent features and then back into pixel frames. To mitigate this, we incorporate temporal modules into the decoder to maintain inter-frame consistency. Lastly, by utilizing the innovative denoising UNet and decoder, we develop a unified ControlNet model suitable for various conditions, including image, Canny, HED, depth, and style. Examples of the videos generated by our model can be found at https://jinxixiang.github.io/versvideo/."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c902ffd1003c9b396d53b8dd10187884b72ccd17.pdf"}, "_bibtex": {"value": "@inproceedings{\nxiang2024versvideo,\ntitle={VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation},\nauthor={Jinxi Xiang and Ricong Huang and Jun Zhang and Guanbin Li and Xiao Han and Yang Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=K9sVJ17zvB}\n}"}, "paperhash": {"value": "xiang|versvideo_leveraging_enhanced_temporal_diffusion_models_for_versatile_video_generation"}}, "number": 7134, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7134/-/Revision", "ICLR.cc/2024/Conference/Submission7134/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7134/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456865659, "cdate": 1695456865659, "tmdate": 1712698544534, "mdate": 1712698544534, "pdate": 1705410999698, "version": 2}, {"id": "SIZWiya7FE", "forum": "SIZWiya7FE", "signatures": ["ICLR.cc/2024/Conference/Submission7132/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7132/Authors"], "content": {"title": {"value": "Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models"}, "authors": {"value": ["Shaofei Shen", "Chenhao Zhang", "Yawen Zhao", "Alina Bialkowski", "Weitong Tony Chen", "Miao Xu"]}, "authorids": {"value": ["~Shaofei_Shen1", "~Chenhao_Zhang1", "~Yawen_Zhao1", "~Alina_Bialkowski4", "~Weitong_Tony_Chen1", "~Miao_Xu3"]}, "keywords": {"value": ["Machine Unlearning", "Unsupervised Learning", "Deep Learning"]}, "TLDR": {"value": "A supervision-free framework for deep model unlearning via variational inference and contrastive loss"}, "abstract": {"value": "Machine unlearning aims to remove information derived from forgotten data while preserving that of the remaining dataset in a well-trained model. With the increasing emphasis on data privacy, several approaches to machine unlearning have emerged. However, these methods typically rely on complete supervision throughout the unlearning process. Unfortunately, obtaining such supervision, whether for the forgetting or remaining data, can be impractical due to the substantial cost associated with annotating real-world datasets. This challenge prompts us to propose a supervision-free unlearning approach that operates without the need for labels during the unlearning process. Specifically, we introduce a variational approach to approximate the distribution of representations for the remaining data. Leveraging this approximation, we adapt the original model to eliminate information from the forgotten data at the representation level. To further address the issue of lacking supervision information, which hinders alignment with ground truth, we introduce a contrastive loss to facilitate the matching of representations between the remaining data and those of the original model, thus preserving predictive performance. Experimental results across various unlearning tasks demonstrate the effectiveness of our proposed method, Label-Agnostic Forgetting (LAF) without using any labels, which achieves comparable performance to state-of-the-art methods that rely on full supervision information. Furthermore, our approach excels in semi-supervised scenarios, leveraging limited supervision information to outperform fully supervised baselines. This work not only showcases the viability of supervision-free unlearning in deep models but also opens up a new possibility for future research in unlearning at the representation level."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/698122cbfa4ac413cdd6ecfdc0c2697c9cf4a05d.pdf"}, "supplementary_material": {"value": "/attachment/71ba9f76e45f5aefec4990400971b91c1721a4ac.pdf"}, "_bibtex": {"value": "@inproceedings{\nshen2024labelagnostic,\ntitle={Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models},\nauthor={Shaofei Shen and Chenhao Zhang and Yawen Zhao and Alina Bialkowski and Weitong Tony Chen and Miao Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SIZWiya7FE}\n}"}, "paperhash": {"value": "shen|labelagnostic_forgetting_a_supervisionfree_unlearning_in_deep_models"}}, "number": 7132, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7132/-/Revision", "ICLR.cc/2024/Conference/Submission7132/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7132/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456760924, "cdate": 1695456760924, "tmdate": 1711843752514, "mdate": 1711843752514, "pdate": 1705410999612, "version": 2}, {"id": "t3vnnLeajU", "forum": "t3vnnLeajU", "signatures": ["ICLR.cc/2024/Conference/Submission7130/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7130/Authors"], "content": {"title": {"value": "Controlling Vision-Language Models for Multi-Task Image Restoration"}, "authors": {"value": ["Ziwei Luo", "Fredrik K. Gustafsson", "Zheng Zhao", "Jens Sj\u00f6lund", "Thomas B. Sch\u00f6n"]}, "authorids": {"value": ["~Ziwei_Luo1", "~Fredrik_K._Gustafsson1", "~Zheng_Zhao1", "~Jens_Sj\u00f6lund1", "~Thomas_B._Sch\u00f6n1"]}, "keywords": {"value": ["Image restoration", "vision-language model", "low-level vision"]}, "TLDR": {"value": "Controlling vision-language models to understand image degradation and improve image restoration."}, "abstract": {"value": "Vision-language models such as CLIP have shown great impact on diverse downstream tasks for zero-shot or label-free predictions. However, when it comes to low-level vision such as image restoration their performance deteriorates dramatically due to corrupted inputs. In this paper, we present a degradation-aware vision-language model (DA-CLIP) to better transfer pretrained vision-language models to low-level vision tasks as a multi-task framework for image restoration. More specifically, DA-CLIP trains an additional controller that adapts the fixed CLIP image encoder to predict high-quality feature embeddings. By integrating the embedding into an image restoration network via cross-attention, we are able to pilot the model to learn a high-fidelity image reconstruction. The controller itself will also output a degradation feature that matches the real corruptions of the input, yielding a natural classifier for different degradation types. In addition, we construct a mixed degradation dataset with synthetic captions for DA-CLIP training. Our approach advances state-of-the-art performance on both degradation-specific and unified image restoration tasks, showing a promising direction of prompting image restoration with large-scale pretrained vision-language models. Our code is available at https://github.com/Algolzw/daclip-uir."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/da340221403bab803b16154d81342e02c4eeaa69.pdf"}, "supplementary_material": {"value": "/attachment/4bcd721a298cabf07db93649988ce20d53dffadf.zip"}, "_bibtex": {"value": "@inproceedings{\nluo2024controlling,\ntitle={Controlling Vision-Language Models for Universal Image Restoration},\nauthor={Ziwei Luo and Fredrik K. Gustafsson and Zheng Zhao and Jens Sj{\\\"o}lund and Thomas B. Sch{\\\"o}n},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=t3vnnLeajU}\n}"}, "paperhash": {"value": "luo|controlling_visionlanguage_models_for_multitask_image_restoration"}}, "number": 7130, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7130/-/Revision", "ICLR.cc/2024/Conference/Submission7130/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7130/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456651714, "cdate": 1695456651714, "tmdate": 1709661537929, "mdate": 1709661537929, "pdate": 1705410999571, "version": 2}, {"id": "ox2ATRM90I", "forum": "ox2ATRM90I", "signatures": ["ICLR.cc/2024/Conference/Submission7128/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7128/Authors"], "content": {"title": {"value": "Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML"}, "authors": {"value": ["Robin van de Water", "Hendrik Nils Aurel Schmidt", "Paul Elbers", "Patrick Thoral", "Bert Arnrich", "Patrick Rockenschaub"]}, "authorids": {"value": ["~Robin_van_de_Water1", "~Hendrik_Nils_Aurel_Schmidt1", "~Paul_Elbers1", "~Patrick_Thoral1", "~Bert_Arnrich1", "~Patrick_Rockenschaub1"]}, "keywords": {"value": ["ICU", "Intensive Care Unit", "EHR", "ML", "Time Series", "Patient Monitoring", "Clinical ML", "Benchmark", "Multi-Center", "MIMIC", "eICU", "HiRID", "AmsterdamUMCdb"]}, "TLDR": {"value": "We introduce Yet Another ICU Benchmark: a flexible, holistic framework for the standardization of clinical prediction model experiments."}, "abstract": {"value": "Medical applications of machine learning (ML) have experienced a surge in popularity in recent years. Given the abundance of available data from electronic health records, the intensive care unit (ICU) is a natural habitat for ML. Models have been proposed to address numerous ICU prediction tasks like the early detection of complications. While authors frequently report state-of-the-art performance, it is challenging to verify claims of superiority. Datasets and code are not always published, and cohort definitions, preprocessing pipelines, and training setups are difficult to reproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular framework that allows researchers to define reproducible and comparable clinical ML experiments; we offer an end-to-end solution from cohort definition to model evaluation. The framework natively supports most open-access ICU datasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future ICU datasets. Combined with a transparent preprocessing pipeline and extensible training code for multiple ML and deep learning models, YAIB enables unified model development, transfer, and evaluation. Our benchmark comes with five predefined established prediction tasks (mortality, acute kidney injury, sepsis, kidney function, and length of stay) developed in collaboration with clinicians. Adding further tasks is straightforward by design. Using YAIB, we demonstrate that the choice of dataset, cohort definition, and preprocessing have a major impact on the prediction performance \u2014 often more so than model class \u2014 indicating an urgent need for YAIB as a holistic benchmarking tool. We provide our work to the clinical ML community to accelerate method development and enable real-world clinical implementations."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e9360ba07222c245452ad806aa26dd6388d12e5d.pdf"}, "supplementary_material": {"value": "/attachment/c8e0b816896de1f14c6a21f63137ad1718d3540a.zip"}, "_bibtex": {"value": "@inproceedings{\nwater2024yet,\ntitle={Yet Another {ICU} Benchmark: A Flexible Multi-Center Framework for Clinical {ML}},\nauthor={Robin van de Water and Hendrik Nils Aurel Schmidt and Paul Elbers and Patrick Thoral and Bert Arnrich and Patrick Rockenschaub},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ox2ATRM90I}\n}"}, "paperhash": {"value": "water|yet_another_icu_benchmark_a_flexible_multicenter_framework_for_clinical_ml"}}, "number": 7128, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7128/-/Revision", "ICLR.cc/2024/Conference/Submission7128/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7128/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456571924, "cdate": 1695456571924, "tmdate": 1710499356442, "mdate": 1710499356442, "pdate": 1705410999461, "version": 2}, {"id": "iPWxqnt2ke", "forum": "iPWxqnt2ke", "signatures": ["ICLR.cc/2024/Conference/Submission7121/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7121/Authors"], "content": {"title": {"value": "Identifying Policy Gradient Subspaces"}, "authors": {"value": ["Jan Schneider", "Pierre Schumacher", "Simon Guist", "Le Chen", "Daniel Haeufle", "Bernhard Sch\u00f6lkopf", "Dieter B\u00fcchler"]}, "authorids": {"value": ["~Jan_Schneider1", "~Pierre_Schumacher1", "~Simon_Guist1", "~Le_Chen3", "~Daniel_Haeufle1", "~Bernhard_Sch\u00f6lkopf1", "~Dieter_B\u00fcchler1"]}, "keywords": {"value": ["reinforcement learning", "policy gradients", "gradient subspaces"]}, "abstract": {"value": "Policy gradient methods hold great potential for solving complex continuous control tasks. Still, their training efficiency can be improved by exploiting structure within the optimization problem. Recent work indicates that supervised learning can be accelerated by leveraging the fact that gradients lie in a low-dimensional and slowly-changing subspace. In this paper, we conduct a thorough evaluation of this phenomenon for two popular deep policy gradient methods on various simulated benchmark tasks. Our results demonstrate the existence of such gradient subspaces despite the continuously changing data distribution inherent to reinforcement learning. These findings reveal promising directions for future work on more efficient reinforcement learning, e.g., through improving parameter-space exploration or enabling second-order optimization."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/65262297ee59531d431a33331edbd9d708cf9033.pdf"}, "TLDR": {"value": "We investigate the potential of gradient subspaces in deep reinforcement learning."}, "_bibtex": {"value": "@inproceedings{\nschneider2024identifying,\ntitle={Identifying Policy Gradient Subspaces},\nauthor={Jan Schneider and Pierre Schumacher and Simon Guist and Le Chen and Daniel Haeufle and Bernhard Sch{\\\"o}lkopf and Dieter B{\\\"u}chler},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iPWxqnt2ke}\n}"}, "paperhash": {"value": "schneider|identifying_policy_gradient_subspaces"}}, "number": 7121, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7121/-/Revision", "ICLR.cc/2024/Conference/Submission7121/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7121/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695456061732, "cdate": 1695456061732, "tmdate": 1710585183725, "mdate": 1710585183725, "pdate": 1705410999069, "version": 2}, {"id": "j4VMrwgn1M", "forum": "j4VMrwgn1M", "signatures": ["ICLR.cc/2024/Conference/Submission7112/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7112/Authors"], "content": {"title": {"value": "Training Graph Transformers via Curriculum-Enhanced Attention Distillation"}, "authors": {"value": ["Yisong Huang", "Jin Li", "Xinlong Chen", "Yang-Geng Fu"]}, "authorids": {"value": ["~Yisong_Huang1", "~Jin_Li8", "~Xinlong_Chen1", "~Yang-Geng_Fu1"]}, "keywords": {"value": ["graph transformers", "graph neural networks", "knowledge distillation", "curriculum learning", "node classification"]}, "abstract": {"value": "Recent studies have shown that Graph Transformers (GTs) can be effective for specific graph-level tasks. However, when it comes to node classification, training GTs remains challenging, especially in semi-supervised settings with a severe scarcity of labeled data. Our paper aims to address this research gap by focusing on semi-supervised node classification. To accomplish this, we develop a curriculum-enhanced attention distillation method that involves utilizing a Local GT teacher and a Global GT student. Additionally, we introduce the concepts of in-class and out-of-class and then propose two improvements, out-of-class entropy and top-k pruning, to facilitate the student's out-of-class exploration under the teacher's in-class guidance. Taking inspiration from human learning, our method involves a curriculum mechanism for distillation that initially provides strict guidance to the student and gradually allows for more out-of-class exploration by a dynamic balance. Extensive experiments show that our method outperforms many state-of-the-art approaches on seven public graph benchmarks, proving its effectiveness."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/05ecdafa1d0a9af650b4d69a74bf746a6bc9ea37.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024training,\ntitle={Training Graph Transformers via Curriculum-Enhanced Attention Distillation},\nauthor={Yisong Huang and Jin Li and Xinlong Chen and Yang-Geng Fu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=j4VMrwgn1M}\n}"}, "paperhash": {"value": "huang|training_graph_transformers_via_curriculumenhanced_attention_distillation"}}, "number": 7112, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7112/-/Revision", "ICLR.cc/2024/Conference/Submission7112/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7112/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695455854090, "cdate": 1695455854090, "tmdate": 1710327888371, "mdate": 1710327888371, "pdate": 1705410998648, "version": 2}, {"id": "bm1JVsVZVu", "forum": "bm1JVsVZVu", "signatures": ["ICLR.cc/2024/Conference/Submission7111/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7111/Authors"], "content": {"title": {"value": "Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning"}, "authors": {"value": ["Feiyang YE", "Yueming Lyu", "Xuehao Wang", "Yu Zhang", "Ivor Tsang"]}, "authorids": {"value": ["~Feiyang_YE1", "~Yueming_Lyu1", "~Xuehao_Wang3", "~Yu_Zhang3", "~Ivor_Tsang1"]}, "keywords": {"value": ["Multi-Objective Optimization", "Black-Box Optimization", "Black-Box Multi-Objective Optimization"]}, "abstract": {"value": "Multi-objective optimization (MOO) has become an influential framework for various machine learning problems, including reinforcement learning and multi-task learning. In this paper, we study the black-box multi-objective optimization problem, where we aim to optimize multiple potentially conflicting objectives with function queries only. To address this challenging problem and find a Pareto optimal solution or the Pareto stationary solution, \nwe propose a novel adaptive stochastic gradient algorithm for black-box MOO, called ASMG. \nSpecifically, we use the stochastic gradient approximation method to obtain the gradient for the distribution parameters of the Gaussian smoothed MOO with function queries only. Subsequently, an adaptive weight is employed to aggregate all stochastic gradients to optimize all objective functions effectively. \nTheoretically, we explicitly provide the connection between the original MOO problem and the corresponding Gaussian smoothed MOO problem and prove the convergence rate for the proposed ASMG algorithm in both convex and non-convex scenarios.\nEmpirically, the proposed ASMG method achieves competitive performance on multiple numerical benchmark problems. Additionally, the state-of-the-art performance on the black-box multi-task learning problem demonstrates the effectiveness of the proposed ASMG method."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/38053ef299dd27490c69c5bbf90f1583cefcb7a5.pdf"}, "_bibtex": {"value": "@inproceedings{\nye2024adaptive,\ntitle={Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning},\nauthor={Feiyang YE and Yueming Lyu and Xuehao Wang and Yu Zhang and Ivor Tsang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bm1JVsVZVu}\n}"}, "paperhash": {"value": "ye|adaptive_stochastic_gradient_algorithm_for_blackbox_multiobjective_learning"}}, "number": 7111, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7111/-/Revision", "ICLR.cc/2024/Conference/Submission7111/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7111/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695455725780, "cdate": 1695455725780, "tmdate": 1713168822169, "mdate": 1713168822169, "pdate": 1705410998589, "version": 2}, {"id": "zAdUB0aCTQ", "forum": "zAdUB0aCTQ", "signatures": ["ICLR.cc/2024/Conference/Submission7101/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7101/Authors"], "content": {"title": {"value": "AgentBench: Evaluating LLMs as Agents"}, "authors": {"value": ["Xiao Liu", "Hao Yu", "Hanchen Zhang", "Yifan Xu", "Xuanyu Lei", "Hanyu Lai", "Yu Gu", "Hangliang Ding", "Kaiwen Men", "Kejuan Yang", "Shudan Zhang", "Xiang Deng", "Aohan Zeng", "Zhengxiao Du", "Chenhui Zhang", "Sheng Shen", "Tianjun Zhang", "Yu Su", "Huan Sun", "Minlie Huang", "Yuxiao Dong", "Jie Tang"]}, "authorids": {"value": ["~Xiao_Liu15", "~Hao_Yu12", "~Hanchen_Zhang1", "~Yifan_Xu7", "~Xuanyu_Lei1", "~Hanyu_Lai2", "~Yu_Gu5", "~Hangliang_Ding1", "~Kaiwen_Men1", "~Kejuan_Yang1", "~Shudan_Zhang1", "~Xiang_Deng2", "~Aohan_Zeng1", "~Zhengxiao_Du1", "~Chenhui_Zhang1", "~Sheng_Shen2", "~Tianjun_Zhang1", "~Yu_Su2", "~Huan_Sun1", "~Minlie_Huang1", "~Yuxiao_Dong1", "~Jie_Tang1"]}, "keywords": {"value": ["Large language models", "Autonomous agents", "Reasoning", "Evaluation", "Benchmark"]}, "abstract": {"value": "Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. \nAs a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments.\nWe present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting.\nOur extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors.\nWe identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents.\nTraining on code and high quality multi-turn alignment data could improve agent performance.\nDatasets, environments, and an integrated evaluation package for AgentBench are released."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e3e4d360626c6c09907a0df4ed6f86b8dc38b900.pdf"}, "TLDR": {"value": "The first systematic benchmark for evaluating LLMs as Agents"}, "_bibtex": {"value": "@inproceedings{\nliu2024agentbench,\ntitle={AgentBench: Evaluating {LLM}s as Agents},\nauthor={Xiao Liu and Hao Yu and Hanchen Zhang and Yifan Xu and Xuanyu Lei and Hanyu Lai and Yu Gu and Hangliang Ding and Kaiwen Men and Kejuan Yang and Shudan Zhang and Xiang Deng and Aohan Zeng and Zhengxiao Du and Chenhui Zhang and Sheng Shen and Tianjun Zhang and Yu Su and Huan Sun and Minlie Huang and Yuxiao Dong and Jie Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zAdUB0aCTQ}\n}"}, "paperhash": {"value": "liu|agentbench_evaluating_llms_as_agents"}}, "number": 7101, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7101/-/Revision", "ICLR.cc/2024/Conference/Submission7101/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695455338027, "cdate": 1695455338027, "tmdate": 1707625637639, "mdate": 1707625637639, "pdate": 1705410998204, "version": 2}, {"id": "ym0ubZrsmm", "forum": "ym0ubZrsmm", "signatures": ["ICLR.cc/2024/Conference/Submission7098/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7098/Authors"], "content": {"title": {"value": "Image Background Serves as Good Proxy for Out-of-distribution Data"}, "authors": {"value": ["Sen Pei"]}, "authorids": {"value": ["~Sen_Pei1"]}, "keywords": {"value": ["Out-of-distribution detection", "OOD supervision", "robust image classification"]}, "abstract": {"value": "Out-of-distribution (OOD) detection empowers the model trained on the closed image set to identify unknown data in the open world. Though many prior techniques have yielded considerable improvements in this research direction, two crucial obstacles still remain. Firstly, a unified perspective has yet to be presented to view the developed arts with individual designs, which is vital for providing insights into future work. Secondly, we expect sufficient natural OOD supervision to promote the generation of compact boundaries between the in-distribution (ID) and OOD data without collecting explicit OOD samples. To tackle these issues, we propose a general probabilistic framework to interpret many existing methods and an OOD-data-free model, namely $\\textbf{S}$elf-supervised $\\textbf{S}$ampling for $\\textbf{O}$OD $\\textbf{D}$etection (SSOD). SSOD efficiently exploits natural OOD signals from the ID data based on the local property of convolution. With these supervisions, it jointly optimizes the OOD detection and conventional ID classification in an end-to-end manner. Extensive experiments reveal that SSOD establishes competitive state-of-the-art performance on many large-scale benchmarks, outperforming the best previous method by a large margin, e.g., reporting $\\textbf{-6.28}$% FPR95 and $\\textbf{+0.77}$% AUROC on ImageNet, $\\textbf{-19.01}$% FPR95 and $\\textbf{+3.04}$% AUROC on CIFAR-10, and top-ranked performance on hard OOD datasets, i.e., ImageNet-O and OpenImage-O."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "An unified perspective to view the out-of-distribution detection, and an effective method to generate natural OOD supervision."}, "pdf": {"value": "/pdf/ce35926d8e1dc4e9380e646387f1583e4b652e00.pdf"}, "supplementary_material": {"value": "/attachment/d5be46357a8c3e37d39e09016908747c384da508.zip"}, "_bibtex": {"value": "@inproceedings{\npei2024image,\ntitle={Image Background Serves as Good Proxy for Out-of-distribution Data},\nauthor={Sen Pei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ym0ubZrsmm}\n}"}, "paperhash": {"value": "pei|image_background_serves_as_good_proxy_for_outofdistribution_data"}}, "number": 7098, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7098/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7098/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695455317621, "cdate": 1695455317621, "tmdate": 1709661537616, "mdate": 1709661537616, "pdate": 1705410997979, "version": 2}, {"id": "YEhQs8POIo", "forum": "YEhQs8POIo", "signatures": ["ICLR.cc/2024/Conference/Submission7090/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7090/Authors"], "content": {"title": {"value": "Differentially Private Synthetic Data via Foundation Model APIs 1: Images"}, "authors": {"value": ["Zinan Lin", "Sivakanth Gopi", "Janardhan Kulkarni", "Harsha Nori", "Sergey Yekhanin"]}, "authorids": {"value": ["~Zinan_Lin1", "~Sivakanth_Gopi1", "~Janardhan_Kulkarni2", "~Harsha_Nori1", "~Sergey_Yekhanin1"]}, "keywords": {"value": ["synthetic data", "differential privacy", "model API", "foundation models"]}, "TLDR": {"value": "Generating differentially private synthetic from foundation model APIs without any model training."}, "abstract": {"value": "Generating differentially private (DP) synthetic data that closely resembles the original private data is a scalable way to mitigate privacy concerns in the current data-driven world. In contrast to current practices that train customized models for this task, we aim to generate DP Synthetic Data via APIs (DPSDA), where we treat foundation models as blackboxes and only utilize their inference APIs. Such API-based, training-free approaches are easier to deploy as exemplified by the recent surge in the number of API-based apps. These approaches can also leverage the power of large foundation models which are only accessible via their inference APIs. However, this comes with greater challenges due to strictly more restrictive model access and the need to protect privacy from the API provider. \n\nIn this paper, we present a new framework called Private Evolution (PE) to solve this problem and show its initial promise on synthetic images. Surprisingly, PE can match or even outperform state-of-the-art (SOTA) methods without any model training. For example, on CIFAR10 (with ImageNet as the public data), we achieve FID \u2264 7.9 with privacy cost \u03b5 = 0.67, significantly improving the previous SOTA from \u03b5 = 32. We further demonstrate the promise of applying PE on large foundation models such as Stable Diffusion to tackle challenging private datasets with a small number of high-resolution images. The code and data are released at https://github.com/microsoft/DPSDA."}, "pdf": {"value": "/pdf/234b2f2be9197c43fbf0e155d4e1d8eaa11cfb64.pdf"}, "supplementary_material": {"value": "/attachment/319ee1fd03a1fbd39ed2f106267ed0e7063d8923.zip"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nlin2024differentially,\ntitle={Differentially Private Synthetic Data via Foundation Model {API}s 1: Images},\nauthor={Zinan Lin and Sivakanth Gopi and Janardhan Kulkarni and Harsha Nori and Sergey Yekhanin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YEhQs8POIo}\n}"}, "paperhash": {"value": "lin|differentially_private_synthetic_data_via_foundation_model_apis_1_images"}}, "number": 7090, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7090/-/Revision", "ICLR.cc/2024/Conference/Submission7090/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7090/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695454652451, "cdate": 1695454652451, "tmdate": 1711489659145, "mdate": 1711489659145, "pdate": 1705410997832, "version": 2}, {"id": "pdJXYfJjz9", "forum": "pdJXYfJjz9", "signatures": ["ICLR.cc/2024/Conference/Submission7082/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7082/Authors"], "content": {"title": {"value": "Harnessing Joint Rain-/Detail-aware Representations to Eliminate Intricate Rains"}, "authors": {"value": ["Wu Ran", "Peirong Ma", "Zhiquan He", "Hao Ren", "Hong Lu"]}, "authorids": {"value": ["~Wu_Ran1", "~Peirong_Ma1", "~Zhiquan_He1", "~Hao_Ren2", "~Hong_Lu2"]}, "keywords": {"value": ["Joint rain-/detail-aware representation learning", "contrastive learning", "context-based modulation mechanism", "image deraining"]}, "TLDR": {"value": "This study introduces a joint rain- and detail-aware representation learning approach for training powerful image deraining models from multiple dataset sources."}, "abstract": {"value": "Recent advances in image deraining have focused on training powerful models on mixed multiple datasets comprising diverse rain types and backgrounds. However, this approach tends to overlook the inherent differences among rainy images, leading to suboptimal results. To overcome this limitation, we focus on addressing various rainy images by delving into meaningful representations that encapsulate both the rain and background components. Leveraging these representations as instructive guidance, we put forth a Context-based Instance-level Modulation (CoI-M) mechanism adept at efficiently modulating CNN- or Transformer-based models. Furthermore, we devise a rain-/detail-aware contrastive learning strategy to help extract joint rain-/detail-aware representations. By integrating CoI-M with the rain-/detail-aware Contrastive learning, we develop [CoIC](https://github.com/Schizophreni/CoIC), an innovative and potent algorithm tailored for training models on mixed datasets. Moreover, CoIC offers insight into modeling relationships of datasets, quantitatively assessing the impact of rain and details on restoration, and unveiling distinct behaviors of models given diverse inputs. Extensive experiments validate the efficacy of CoIC in boosting the deraining ability of CNN and Transformer models. CoIC also enhances the deraining prowess remarkably when real-world dataset is included."}, "pdf": {"value": "/pdf/ea42d35acafbb449e6553bbd9a5bdf8353482426.pdf"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nran2024exploring,\ntitle={{EXPLORING} {RAIN}-/{DETAIL}-{AWARE} {REPRESENTATION} {FOR} {INSTANCE}-{SPECIFIC} {IMAGE} {DE}-{RAINING}},\nauthor={Wu Ran and Peirong Ma and Zhiquan He and Hao Ren and Hong Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pdJXYfJjz9}\n}"}, "paperhash": {"value": "ran|harnessing_joint_raindetailaware_representations_to_eliminate_intricate_rains"}}, "number": 7082, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7082/-/Revision", "ICLR.cc/2024/Conference/Submission7082/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7082/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695454342976, "cdate": 1695454342976, "tmdate": 1710256270165, "mdate": 1710256270165, "pdate": 1705410997571, "version": 2}, {"id": "1Wi0Ys33Nm", "forum": "1Wi0Ys33Nm", "signatures": ["ICLR.cc/2024/Conference/Submission7072/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7072/Authors"], "content": {"title": {"value": "Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes"}, "authors": {"value": ["Thiziri Nait Saada", "Alireza Naderi", "Jared Tanner"]}, "authorids": {"value": ["~Thiziri_Nait_Saada1", "~Alireza_Naderi1", "~Jared_Tanner1"]}, "keywords": {"value": ["Deep Neural Networks", "Gaussian processes", "Neural Networks initialisation", "Edge of chaos", "Large width limit", "Mean-Field"]}, "abstract": {"value": "The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that enables a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al., 2018 to a larger class of initial weight distributions (which we call pseudo-iid), including the established cases of iid and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialised with pseudo-iid distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge of Chaos for a broader class of neural networks and tune them at criticality in order to enhance their training. Moreover, they enable the posterior distribution of Bayesian Neural Networks to be tractable across these various initialization schemes."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d0a957bcdabe94b4a65f76bf19fc021ca00c79cc.pdf"}, "_bibtex": {"value": "@inproceedings{\nsaada2024beyond,\ntitle={Beyond {IID} weights: sparse and low-rank deep Neural Networks are also Gaussian Processes},\nauthor={Thiziri Nait Saada and Alireza Naderi and Jared Tanner},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1Wi0Ys33Nm}\n}"}, "paperhash": {"value": "saada|beyond_iid_weights_sparse_and_lowrank_deep_neural_networks_are_also_gaussian_processes"}}, "number": 7072, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7072/-/Revision", "ICLR.cc/2024/Conference/Submission7072/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7072/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695453986706, "cdate": 1695453986706, "tmdate": 1710779566748, "mdate": 1710779566748, "pdate": 1705410997310, "version": 2}, {"id": "rIx1YXVWZb", "forum": "rIx1YXVWZb", "signatures": ["ICLR.cc/2024/Conference/Submission7065/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7065/Authors"], "content": {"title": {"value": "Understanding Addition in Transformers"}, "authors": {"value": ["Philip Quirke", "Fazl Barez"]}, "authorids": {"value": ["~Philip_Quirke1", "~Fazl_Barez1"]}, "keywords": {"value": ["Interpretability", "Transformers"]}, "abstract": {"value": "Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper provides a comprehensive analysis of a one-layer Transformer model trained to perform n-digit integer addition. Our findings suggests that the model dissects the task into parallel streams dedicated to individual digits, employing varied algorithms tailored to different positions within the digits. Furthermore, we identify a rare scenario characterized by high loss, which we explain. By thoroughly elucidating the model\u2019s algorithm, we provide new insights into its functioning. These findings are validated through rigorous testing and mathematical modeling, thereby contributing to the broader fields of model understanding and interpretability. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d60d609e1b043eaaea0409dee0abe2d2934209d1.pdf"}, "_bibtex": {"value": "@inproceedings{\nquirke2024understanding,\ntitle={Understanding Addition in Transformers},\nauthor={Philip Quirke and Fazl Barez},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rIx1YXVWZb}\n}"}, "paperhash": {"value": "quirke|understanding_addition_in_transformers"}}, "number": 7065, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7065/-/Revision", "ICLR.cc/2024/Conference/Submission7065/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7065/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695453637820, "cdate": 1695453637820, "tmdate": 1710621021332, "mdate": 1710621021332, "pdate": 1705410996913, "version": 2}, {"id": "36L7W3ri4U", "forum": "36L7W3ri4U", "signatures": ["ICLR.cc/2024/Conference/Submission7062/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7062/Authors"], "content": {"title": {"value": "Beating Price of Anarchy and Gradient Descent without Regret in Potential Games"}, "authors": {"value": ["Iosif Sakos", "Stefanos Leonardos", "Stelios Andrew Stavroulakis", "William Overman", "Ioannis Panageas", "Georgios Piliouras"]}, "authorids": {"value": ["~Iosif_Sakos1", "~Stefanos_Leonardos1", "~Stelios_Andrew_Stavroulakis1", "~William_Overman1", "~Ioannis_Panageas1", "~Georgios_Piliouras1"]}, "keywords": {"value": ["q-replicator dynamics", "potential games", "average price of anarchy", "learning"]}, "TLDR": {"value": "Despite being almost optimal on average in a class of $2\\times2$ potential games with unbounded Price of Anarchy, gradient descent is not always the optimal choice even in this restricted setting. These findings extend experimentally in larger games."}, "abstract": {"value": "Arguably one of the thorniest problems in game theory is that of equilibrium selection. Specifically, in the presence of multiple equilibria do self-interested learning dynamics typically select the socially optimal ones? We study a rich class of continuous-time no-regret dynamics in potential games (PGs). Our class of dynamics, *Q-Replicator Dynamics* (QRD), include gradient descent (GD), log-barrier and replicator dynamics (RD) as special cases. We start by establishing *pointwise convergence* of all QRD to Nash equilibria in almost all PGs. In the case of GD, we show a tight average case performance within a factor of two of optimal, for a class of symmetric $2\\times2$ potential games with unbounded Price of Anarchy (PoA). Despite this positive result, we show that GD is not always the optimal choice even in this restricted setting. Specifically, GD outperforms RD, if and only if *risk-* and *payoff-dominance* equilibria coincide. Finally, we experimentally show how these insights extend to all QRD dynamics and that unbounded gaps between average case performance and PoA analysis are common even in larger settings."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/49a0dc51cc4b32a2833746bc5f12100770d65a2a.pdf"}, "_bibtex": {"value": "@inproceedings{\nsakos2024beating,\ntitle={Beating Price of Anarchy and Gradient Descent without Regret in Potential Games},\nauthor={Iosif Sakos and Stefanos Leonardos and Stelios Andrew Stavroulakis and William Overman and Ioannis Panageas and Georgios Piliouras},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=36L7W3ri4U}\n}"}, "paperhash": {"value": "sakos|beating_price_of_anarchy_and_gradient_descent_without_regret_in_potential_games"}}, "number": 7062, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7062/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7062/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695453381251, "cdate": 1695453381251, "tmdate": 1710555779360, "mdate": 1710555779360, "pdate": 1705410996866, "version": 2}, {"id": "ypAT2ixD4X", "forum": "ypAT2ixD4X", "signatures": ["ICLR.cc/2024/Conference/Submission7052/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7052/Authors"], "content": {"title": {"value": "In defense of parameter sharing for model-compression"}, "authors": {"value": ["Aditya Desai", "Anshumali Shrivastava"]}, "authorids": {"value": ["~Aditya_Desai1", "~Anshumali_Shrivastava1"]}, "keywords": {"value": ["parameter sharing", "model compression", "pruning"]}, "abstract": {"value": "When considering a model architecture, there are several ways to reduce its memory footprint. Historically, popular approaches included selecting smaller architectures and creating sparse networks through pruning. More recently, randomized parameter-sharing (RPS) methods have gained traction for model compression at\nstart of training. In this paper, we comprehensively assess the trade-off between\nmemory and accuracy across RPS, pruning techniques, and building smaller models. Our findings demonstrate that RPS, which is both data and model-agnostic, consistently outperforms smaller models and all moderately informed pruning strategies, such as MAG, SNIP, SYNFLOW, and GRASP, across the entire compression range. This advantage becomes particularly pronounced in higher compression scenarios. Notably, even when compared to highly informed pruning techniques like Lottery Ticket Rewinding (LTR), RPS exhibits superior performance in high compression settings. This points out inherent capacity advantage that RPS enjoys over sparse models. Theoretically, we establish RPS as a superior\ntechnique in terms of memory-efficient representation when compared to pruning\nfor linear models. This paper argues in favor of paradigm shift towards RPS based\nmodels. During our rigorous evaluation of RPS, we identified issues in the state-\nof-the-art RPS technique ROAST, specifically regarding stability (ROAST\u2019s sensitivity to initialization hyperparameters, often leading to divergence) and Pareto-continuity (ROAST\u2019s inability to recover the accuracy of the original model at zero\ncompression). We provably address both of these issues. We refer to the modified\nRPS, which incorporates our improvements, as STABLE-RPS"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a23b706b1870dc64c177040abebdc7c98f8c2013.pdf"}, "TLDR": {"value": "in terms of memory-accuracy tradeoff parameter sharing is a better compression technique than pruning for model compression at start"}, "_bibtex": {"value": "@inproceedings{\ndesai2024in,\ntitle={In defense of parameter sharing for model-compression},\nauthor={Aditya Desai and Anshumali Shrivastava},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ypAT2ixD4X}\n}"}, "paperhash": {"value": "desai|in_defense_of_parameter_sharing_for_modelcompression"}}, "number": 7052, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7052/-/Revision", "ICLR.cc/2024/Conference/Submission7052/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7052/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452758383, "cdate": 1695452758383, "tmdate": 1711992613686, "mdate": 1711992613686, "pdate": 1705410996635, "version": 2}, {"id": "RzY9qQHUXy", "forum": "RzY9qQHUXy", "signatures": ["ICLR.cc/2024/Conference/Submission7051/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7051/Authors"], "content": {"title": {"value": "Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning"}, "authors": {"value": ["Binwu Wang", "Pengkun Wang", "Wei Xu", "Xu Wang", "Yudong Zhang", "Kun Wang", "Yang Wang"]}, "authorids": {"value": ["~Binwu_Wang1", "~Pengkun_Wang1", "~Wei_Xu21", "~Xu_Wang16", "~Yudong_Zhang3", "~Kun_Wang15", "~Yang_Wang32"]}, "keywords": {"value": ["Long-tailed learning", "data augmentation", "imbalance", "fairness"]}, "abstract": {"value": "Real-world tasks are universally associated with training samples that exhibit a long-tailed class distribution, and traditional deep learning models are not suitable for fitting this distribution, thus resulting in a biased trained model. To surmount this dilemma, massive deep long-tailed learning studies have been proposed to achieve inter-class fairness models by designing sophisticated sampling strategies or improving existing model structures and loss functions. Habitually, these studies tend to apply data augmentation strategies to improve the generalization performance of their models. However, this augmentation strategy applied to balanced distributions may not be the best option for long-tailed distributions. For a profound understanding of data augmentation, we first theoretically analyze the gains of traditional augmentation strategies in long-tailed learning, and observe that augmentation methods cause the long-tailed distribution to be imbalanced again, resulting in an intertwined imbalance: inherent data-wise imbalance and extrinsic augmentation-wise imbalance, i.e., two 'birds' co-exist in long-tailed learning. Motivated by this observation, we propose an adaptive Dynamic Optional Data Augmentation (DODA) to address this intertwined imbalance, i.e., one 'stone' simultaneously 'kills' two 'birds', which allows each class to choose appropriate augmentation methods by maintaining a corresponding augmentation probability distribution for each class during training. Extensive experiments across mainstream long-tailed recognition benchmarks (e.g., CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018) prove the effectiveness and flexibility of the DODA in overcoming the intertwined imbalance."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d43b0b4d48cd13ce9ebcad15bd1f5014d705cd63.pdf"}, "supplementary_material": {"value": "/attachment/075ec5602cc9213e20606e680ffdebb51234c229.zip"}, "TLDR": {"value": "We find traditional augmentation strategies in long-tailed learning lead to an extrinsic augmentation-wise imbalance, so we propose a Dynamic Optional Data Augmentation to overcoming this intertwined imbalance."}, "_bibtex": {"value": "@inproceedings{\nwang2024kill,\ntitle={Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning},\nauthor={Binwu Wang and Pengkun Wang and Wei Xu and Xu Wang and Yudong Zhang and Kun Wang and Yang Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RzY9qQHUXy}\n}"}, "paperhash": {"value": "wang|kill_two_birds_with_one_stone_rethinking_data_augmentation_for_deep_longtailed_learning"}}, "number": 7051, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7051/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7051/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452645918, "cdate": 1695452645918, "tmdate": 1709661537218, "mdate": 1709661537218, "pdate": 1705410996572, "version": 2}, {"id": "MCNqgUFTHI", "forum": "MCNqgUFTHI", "signatures": ["ICLR.cc/2024/Conference/Submission7048/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7048/Authors"], "content": {"title": {"value": "Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents"}, "authors": {"value": ["Yang Deng", "Wenxuan Zhang", "Wai Lam", "See-Kiong Ng", "Tat-Seng Chua"]}, "authorids": {"value": ["~Yang_Deng4", "~Wenxuan_Zhang1", "~Wai_Lam1", "~See-Kiong_Ng1", "~Tat-Seng_Chua2"]}, "keywords": {"value": ["Dialogue Policy Planning", "Proactive Dialogue", "Large Language Model"]}, "abstract": {"value": "Proactive dialogues serve as a practical yet challenging dialogue problem in the era of large language models (LLMs), where the dialogue policy planning is the key to improving the proactivity of LLMs. Most existing studies enable the dialogue policy planning of LLMs using various prompting schemes or iteratively enhance this capability in handling the given case with verbal AI feedback. However, these approaches are either bounded by the policy planning capability of the frozen LLMs or hard to be transferred to new cases. In this work, we introduce a new dialogue policy planning paradigm to strategize LLMs for proactive dialogue problems with a tunable language model plug-in as a plug-and-play dialogue policy planner, named PPDPP. Specifically, we develop a novel training framework to facilitate supervised fine-tuning over available human-annotated data as well as reinforcement learning from goal-oriented AI feedback with dynamic interaction data collected by the LLM-based self-play simulation. In this manner, the LLM-powered dialogue agent can not only be generalized to different cases after the training, but also be applicable to different applications by just substituting the learned plug-in. In addition, we propose to evaluate the policy planning capability of dialogue systems under the interactive setting. Experimental results demonstrate that PPDPP consistently and substantially outperforms existing approaches on three different proactive dialogue applications, including negotiation, emotional support, and tutoring dialogues."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/30c7e22635f23140a4f37883885b6e80b5f7c750.pdf"}, "_bibtex": {"value": "@inproceedings{\ndeng2024plugandplay,\ntitle={Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents},\nauthor={Yang Deng and Wenxuan Zhang and Wai Lam and See-Kiong Ng and Tat-Seng Chua},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MCNqgUFTHI}\n}"}, "paperhash": {"value": "deng|plugandplay_policy_planner_for_large_language_model_powered_dialogue_agents"}}, "number": 7048, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7048/-/Revision", "ICLR.cc/2024/Conference/Submission7048/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7048/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452594816, "cdate": 1695452594816, "tmdate": 1710145889242, "mdate": 1710145889242, "pdate": 1705410996467, "version": 2}, {"id": "9bmTbVaA2A", "forum": "9bmTbVaA2A", "signatures": ["ICLR.cc/2024/Conference/Submission7046/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7046/Authors"], "content": {"title": {"value": "Bootstrapping Variational Information Pursuit with Large Language and Vision Models for Interpretable Image Classification"}, "authors": {"value": ["Aditya Chattopadhyay", "Kwan Ho Ryan Chan", "Rene Vidal"]}, "authorids": {"value": ["~Aditya_Chattopadhyay1", "~Kwan_Ho_Ryan_Chan1", "~Rene_Vidal1"]}, "keywords": {"value": ["Interpretable ML", "Explainable AI", "Information Pursuit", "Large Language Models", "Large Multimodal Models", "Vision Language Models"]}, "TLDR": {"value": "Extending the Variational Information Pursuit framework by annotating data with Large Language and Multimodal Models"}, "abstract": {"value": "Variational Information Pursuit (V-IP) is an interpretable-by-design framework that makes predictions by sequentially selecting a short chain of user-defined, interpretable queries about the data that are most informative for the task. The prediction is based solely on the obtained query answers, which also serve as a faithful explanation for the prediction. Applying the framework to any task requires (i) specification of a query set, and (ii) densely annotated data with query answers to train classifiers to answer queries at test time. This limits V-IP's application to small-scale tasks where manual data annotation is feasible. In this work, we focus on image classification tasks and propose to relieve this bottleneck by leveraging pretrained language and vision models. Specifically, following recent work, we propose to use GPT, a Large Language Model, to propose semantic concepts as queries for a given classification task. To answer these queries, we propose a light-weight Concept Question-Answering network (Concept-QA) which learns to answer binary queries about semantic concepts in images. We design pseudo-labels to train our Concept-QA model using GPT and CLIP (a Vision-Language Model). Empirically, we find our Concept-QA model to be competitive with state-of-the-art VQA models in terms of answering accuracy but with an order of magnitude fewer parameters. This allows for seamless integration of Concept-QA into the V-IP framework as a fast-answering mechanism. We name this method Concept-QA+V-IP. Finally, we show on several datasets that Concept-QA+V-IP produces shorter, interpretable query chains which are more accurate than V-IP trained with CLIP-based answering systems. Code available at https://github.com/adityac94/conceptqa_vip."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/99b395411f56b8fb09da061b311aee5baa35298f.pdf"}, "_bibtex": {"value": "@inproceedings{\nchattopadhyay2024bootstrapping,\ntitle={Bootstrapping Variational Information Pursuit with Foundation Models for Interpretable Image Classification},\nauthor={Aditya Chattopadhyay and Kwan Ho Ryan Chan and Rene Vidal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9bmTbVaA2A}\n}"}, "paperhash": {"value": "chattopadhyay|bootstrapping_variational_information_pursuit_with_large_language_and_vision_models_for_interpretable_image_classification"}}, "number": 7046, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7046/-/Revision", "ICLR.cc/2024/Conference/Submission7046/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7046/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452528460, "cdate": 1695452528460, "tmdate": 1713057978013, "mdate": 1713057978013, "pdate": 1705410996362, "version": 2}, {"id": "5ep85sakT3", "forum": "5ep85sakT3", "signatures": ["ICLR.cc/2024/Conference/Submission7040/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7040/Authors"], "content": {"title": {"value": "Contextual Bandits with Online Neural Regression"}, "authors": {"value": ["Rohan Deb", "Yikun Ban", "Shiliang Zuo", "Jingrui He", "Arindam Banerjee"]}, "authorids": {"value": ["~Rohan_Deb1", "~Yikun_Ban1", "~Shiliang_Zuo1", "~Jingrui_He1", "~Arindam_Banerjee4"]}, "keywords": {"value": ["Neural Bandits", "Contextual Bandits", "Regret Bounds", "Deep Learning", "Online Regression"]}, "abstract": {"value": "Recent works have shown a reduction from contextual bandits to online regression under a realizability assumption (Foster and Rakhlin, 2020; Foster and Krishnamurthy, 2021). In this work, we investigate the use of neural networks for such online regression and associated Neural Contextual Bandits (NeuCBs). Using existing results for wide networks, one can readily show a  ${\\mathcal{O}}(\\sqrt{T})$ regret for online regression with square loss, which via the reduction implies a ${\\mathcal{O}}(\\sqrt{K} T^{3/4})$ regret for NeuCBs. Departing from this standard approach, we first show a $\\mathcal{O}(\\log T)$ regret for online regression with almost convex losses that satisfy QG (Quadratic Growth) condition, a generalization of the PL (Polyak-\\L ojasiewicz) condition, and that have a unique minima. Although not directly applicable to wide networks since they do not have unique minima, we show that adding a suitable small random perturbation to the network predictions surprisingly makes the loss satisfy QG with unique minima. Based on such a perturbed prediction, we show a ${\\mathcal{O}}(\\log T)$ regret for online regression with both squared loss and KL loss, and subsequently convert these respectively to $\\tilde{\\mathcal{O}}(\\sqrt{KT})$ and $\\tilde{\\mathcal{O}}(\\sqrt{KL^*} + K)$ regret for NeuCB, where $L^*$ is the loss of the best policy. Separately, we also show that existing regret bounds for NeuCBs are $\\Omega(T)$ or assume i.i.d. contexts, unlike this work. Finally, our experimental results on various datasets demonstrate that our algorithms, especially the one based on KL loss, persistently outperform existing algorithms."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1c5cb630500cf6bb4d108d78c1092e9a6220ec43.pdf"}, "supplementary_material": {"value": "/attachment/367a6ec5730f985923a8518d673013750decf8f0.zip"}, "TLDR": {"value": "Neural bandit algorithms with provable regret gurantees and significantly better empirical performance"}, "_bibtex": {"value": "@inproceedings{\ndeb2024contextual,\ntitle={Contextual Bandits with Online Neural Regression},\nauthor={Rohan Deb and Yikun Ban and Shiliang Zuo and Jingrui He and Arindam Banerjee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5ep85sakT3}\n}"}, "paperhash": {"value": "deb|contextual_bandits_with_online_neural_regression"}}, "number": 7040, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7040/-/Revision", "ICLR.cc/2024/Conference/Submission7040/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7040/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452320737, "cdate": 1695452320737, "tmdate": 1713082710827, "mdate": 1713082710827, "pdate": 1705410995876, "version": 2}, {"id": "tr0KidwPLc", "forum": "tr0KidwPLc", "signatures": ["ICLR.cc/2024/Conference/Submission7039/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7039/Authors"], "content": {"title": {"value": "Evaluating Large Language Models at Evaluating Instruction Following"}, "authors": {"value": ["Zhiyuan Zeng", "Jiatong Yu", "Tianyu Gao", "Yu Meng", "Tanya Goyal", "Danqi Chen"]}, "authorids": {"value": ["~Zhiyuan_Zeng3", "~Jiatong_Yu1", "~Tianyu_Gao1", "~Yu_Meng1", "~Tanya_Goyal1", "~Danqi_Chen1"]}, "keywords": {"value": ["large language models", "instruction tuning", "evaluation", "benchmark", "instruction following"]}, "TLDR": {"value": "We introduce a challenging meta-evaluation dataset LLMBar, designed to test the ability of an LLM evaluator to discern instruction-following outputs."}, "abstract": {"value": "As research in large language models (LLMs) continues to accelerate, LLM-based evaluation has emerged as a scalable and cost-effective alternative to human evaluations for comparing the ever increasing list of models. This paper investigates the efficacy of these \u201cLLM evaluators\u201d, particularly in using them to assess instruction following, a metric that gauges how closely generated text adheres to the given instruction. We introduce a challenging meta-evaluation benchmark, LLMBar, designed to test the ability of an LLM evaluator in discerning instruction-following outputs. The authors manually curated 419 pairs of outputs, one adhering to instructions while the other diverging, yet may possess deceptive qualities that mislead an LLM evaluator, e.g., a more engaging tone. Contrary to existing meta-evaluation, we discover that different evaluators (i.e., combinations of LLMs and prompts) exhibit distinct performance on LLMBar and even the highest-scoring ones have substantial room for improvement. We also present a novel suite of prompting strategies that further close the gap between LLM and human evaluators. With LLMBar, we hope to offer more insight into LLM evaluators and foster future research in developing better instruction-following models."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6d8f83b85deebd43468e85ff17a6f0b0da6f0698.pdf"}, "supplementary_material": {"value": "/attachment/2b6b9404f4be0614497a30e550cbe5fc5dcc5352.zip"}, "_bibtex": {"value": "@inproceedings{\nzeng2024evaluating,\ntitle={Evaluating Large Language Models at Evaluating Instruction Following},\nauthor={Zhiyuan Zeng and Jiatong Yu and Tianyu Gao and Yu Meng and Tanya Goyal and Danqi Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tr0KidwPLc}\n}"}, "paperhash": {"value": "zeng|evaluating_large_language_models_at_evaluating_instruction_following"}}, "number": 7039, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7039/-/Revision", "ICLR.cc/2024/Conference/Submission7039/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7039/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452302329, "cdate": 1695452302329, "tmdate": 1713159693767, "mdate": 1713159693767, "pdate": 1705410995873, "version": 2}, {"id": "ZTssMmhC2X", "forum": "ZTssMmhC2X", "signatures": ["ICLR.cc/2024/Conference/Submission7034/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7034/Authors"], "content": {"title": {"value": "How to Fine-Tune Vision Models with SGD"}, "authors": {"value": ["Ananya Kumar", "Ruoqi Shen", "Sebastien Bubeck", "Suriya Gunasekar"]}, "authorids": {"value": ["~Ananya_Kumar1", "~Ruoqi_Shen1", "~Sebastien_Bubeck1", "~Suriya_Gunasekar1"]}, "keywords": {"value": ["fine-tuning", "SGD", "freezing layers", "distribution shift"]}, "TLDR": {"value": "SGD can do worse than AdamW under distribution shifts, but simple changes make SGD competitive (and more memory efficient)"}, "abstract": {"value": "SGD and AdamW are the two most used optimizers for fine-tuning large neural networks in computer vision. When the two methods perform the same, SGD is preferable because it uses less memory (12 bytes/parameter with momentum and 8 bytes/parameter without) than AdamW (16 bytes/parameter). However, on a suite of downstream tasks, especially those with distribution shifts, we find that fine-tuning with AdamW performs substantially better than SGD on modern Vision Transformer and ConvNeXt models. We find that large gaps in performance between SGD and AdamW occur when the fine-tuning gradients in the first \"embedding\" layer are much larger than in the rest of the model. Our analysis suggests an easy fix that works consistently across datasets and models: freezing the embedding layer (less than 1% of the parameters) leads to SGD with or without momentum performing slightly better than AdamW while using less memory (e.g., on ViT-L, SGD uses 33% less GPU memory). Our insights result in state-of-the-art accuracies on five popular distribution shift benchmarks: WILDS-FMoW, WILDS-Camelyon, BREEDS-Living-17, Waterbirds, and DomainNet."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fa42625f628a19d02d5cff6ae7766e08e5209faf.pdf"}, "_bibtex": {"value": "@inproceedings{\nkumar2024how,\ntitle={How to Fine-Tune Vision Models with {SGD}},\nauthor={Ananya Kumar and Ruoqi Shen and Sebastien Bubeck and Suriya Gunasekar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZTssMmhC2X}\n}"}, "paperhash": {"value": "kumar|how_to_finetune_vision_models_with_sgd"}}, "number": 7034, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7034/-/Revision", "ICLR.cc/2024/Conference/Submission7034/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7034/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452177952, "cdate": 1695452177952, "tmdate": 1710487469213, "mdate": 1710487469213, "pdate": 1705410995732, "version": 2}, {"id": "oxjeePpgSP", "forum": "oxjeePpgSP", "signatures": ["ICLR.cc/2024/Conference/Submission7033/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7033/Authors"], "content": {"title": {"value": "Backdoor Contrastive Learning via Bi-level Trigger Optimization"}, "authors": {"value": ["Weiyu Sun", "Xinyu Zhang", "Hao LU", "Ying-Cong Chen", "Ting Wang", "Jinghui Chen", "Lu Lin"]}, "authorids": {"value": ["~Weiyu_Sun1", "~Xinyu_Zhang20", "~Hao_LU8", "~Ying-Cong_Chen1", "~Ting_Wang1", "~Jinghui_Chen1", "~Lu_Lin2"]}, "keywords": {"value": ["backdoor attack", "unsupervised contrastive learning"]}, "TLDR": {"value": "We provide a bi-level optimization to produce an efficient backdoor attack against unsupervised contrastive learning."}, "abstract": {"value": "Contrastive Learning (CL) has attracted enormous attention due to its remarkable capability in unsupervised representation learning. However, recent works have revealed the vulnerability of CL to backdoor attacks: the feature extractor could be misled to embed backdoored data close to an attack target class, thus fooling the downstream predictor to misclassify it as the target. Existing attacks usually adopt a fixed trigger pattern and poison the training set with trigger-injected data, hoping for the feature extractor to learn the association between trigger and target class. However, we find that such fixed trigger design fails to effectively associate trigger-injected data with target class in the embedding space due to special CL mechanisms, leading to a limited attack success rate (ASR). This phenomenon motivates us to find a better backdoor trigger design tailored for CL framework. In this paper, we propose a bi-level optimization approach to achieve this goal, where the inner optimization simulates the CL dynamics of a surrogate victim, and the outer optimization enforces the backdoor trigger to stay close to the target throughout the surrogate CL procedure. Extensive experiments show that our attack can achieve a higher attack success rate (e.g., 99\\% ASR on ImageNet-100) with a very low poisoning rate (1\\%). Besides, our attack can effectively evade existing state-of-the-art defenses."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d94dd9ec562aacfbdd702e84e73d72a38e64ce77.pdf"}, "_bibtex": {"value": "@inproceedings{\nsun2024backdoor,\ntitle={Backdoor Contrastive Learning via Bi-level Trigger Optimization},\nauthor={Weiyu Sun and Xinyu Zhang and Hao LU and Ying-Cong Chen and Ting Wang and Jinghui Chen and Lu Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oxjeePpgSP}\n}"}, "paperhash": {"value": "sun|backdoor_contrastive_learning_via_bilevel_trigger_optimization"}}, "number": 7033, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7033/-/Revision", "ICLR.cc/2024/Conference/Submission7033/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7033/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695452142788, "cdate": 1695452142788, "tmdate": 1713080613083, "mdate": 1713080613083, "pdate": 1705410995709, "version": 2}, {"id": "ByR3NdDSZB", "forum": "ByR3NdDSZB", "signatures": ["ICLR.cc/2024/Conference/Submission7021/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7021/Authors"], "content": {"title": {"value": "PARL: A Unified Framework for Policy Alignment in Reinforcement Learning from Human Feedback"}, "authors": {"value": ["Souradip Chakraborty", "Amrit Bedi", "Alec Koppel", "Huazheng Wang", "Dinesh Manocha", "Mengdi Wang", "Furong Huang"]}, "authorids": {"value": ["~Souradip_Chakraborty1", "~Amrit_Bedi1", "~Alec_Koppel1", "~Huazheng_Wang1", "~Dinesh_Manocha3", "~Mengdi_Wang1", "~Furong_Huang1"]}, "keywords": {"value": ["Reinforcement Learning", "Policy optimization", "Policy alignment", "Preference based RL", "RLHF"]}, "TLDR": {"value": "Aligning agent policy with utility and human preferences"}, "abstract": {"value": "We present a novel unified bilevel optimization-based framework, \\textsf{PARL}, formulated to address the recently highlighted critical issue of policy alignment in reinforcement learning using utility or preference-based feedback. We identify a major gap within current algorithmic designs for solving policy alignment due to a lack of precise characterization of the dependence of the alignment objective on the data generated by policy trajectories. This shortfall contributes to the sub-optimal performance observed in contemporary algorithms. Our framework addressed these concerns by explicitly parameterizing the distribution of the upper alignment objective (reward design)  by the lower optimal variable (optimal policy for the designed reward). Interestingly, from an optimization perspective, our formulation leads to a new class of stochastic bilevel problems where the stochasticity at the upper objective depends upon the lower-level variable. {True to our best knowledge, this work presents the first formulation of the RLHF as a bilevel optimization problem which generalizes the existing RLHF formulations and addresses the existing distribution shift issues in RLHF formulations.} To demonstrate the efficacy of our formulation in resolving alignment issues in RL, we devised an algorithm named \\textsf{A-PARL} to solve PARL problem, establishing sample complexity bounds of order $\\mathcal{O}(1/T)$. Our empirical results substantiate that the proposed \\textsf{PARL} can address the alignment concerns in RL by showing significant improvements (up to 63\\% in terms of required samples) for policy alignment in large-scale environments of the Deepmind control suite and Meta world tasks."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1c20db91b1806b5b9d804ef67251667b7ce808b6.pdf"}, "_bibtex": {"value": "@inproceedings{\nchakraborty2024parl,\ntitle={{PARL}: A Unified Framework for Policy Alignment in Reinforcement Learning},\nauthor={Souradip Chakraborty and Amrit Bedi and Alec Koppel and Huazheng Wang and Dinesh Manocha and Mengdi Wang and Furong Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ByR3NdDSZB}\n}"}, "paperhash": {"value": "chakraborty|parl_a_unified_framework_for_policy_alignment_in_reinforcement_learning_from_human_feedback"}}, "number": 7021, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7021/-/Revision", "ICLR.cc/2024/Conference/Submission7021/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7021/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695451669195, "cdate": 1695451669195, "tmdate": 1713148790492, "mdate": 1713148790492, "pdate": 1705410995174, "version": 2}, {"id": "tsE5HLYtYg", "forum": "tsE5HLYtYg", "signatures": ["ICLR.cc/2024/Conference/Submission7020/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7020/Authors"], "content": {"title": {"value": "SafeDreamer: Safe Reinforcement Learning with World Models"}, "authors": {"value": ["Weidong Huang", "Jiaming Ji", "Borong Zhang", "Chunhe Xia", "Yaodong Yang"]}, "authorids": {"value": ["~Weidong_Huang3", "~Jiaming_Ji2", "~Borong_Zhang1", "~Chunhe_Xia1", "~Yaodong_Yang1"]}, "keywords": {"value": ["Safe Reinforcement Learning", "SafeRL", "World Model"]}, "TLDR": {"value": "A novel algorithm for Model-based Safe Reinforcement Learning."}, "abstract": {"value": "The deployment of Reinforcement Learning (RL) in real-world applications is constrained by its failure to satisfy safety criteria.\nExisting Safe Reinforcement Learning (SafeRL) methods, which rely on cost functions to enforce safety, often fail to achieve zero-cost performance in complex scenarios, especially vision-only tasks. These limitations are primarily due to model inaccuracies and inadequate sample efficiency. The integration of the world model has proven effective in mitigating these shortcomings. In this work, we introduce SafeDreamer, a novel algorithm incorporating Lagrangian-based methods into world model planning processes within the superior Dreamer framework. Our method achieves nearly zero-cost performance on various tasks, spanning low-dimensional and vision-only input, within the Safety-Gymnasium benchmark, showcasing its efficacy in balancing performance and safety in RL tasks. Further details can be seen on our project website: https://sites.google.com/view/safedreamer."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e2c298aa28c3bf7f29f083aa771cea8d1ae3a54a.pdf"}, "supplementary_material": {"value": "/attachment/302e3830f71be0d1604433fef29569a5d6668471.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024safedreamer,\ntitle={SafeDreamer: Safe Reinforcement Learning with World Models},\nauthor={Weidong Huang and Jiaming Ji and Borong Zhang and Chunhe Xia and Yaodong Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tsE5HLYtYg}\n}"}, "paperhash": {"value": "huang|safedreamer_safe_reinforcement_learning_with_world_models"}}, "number": 7020, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7020/-/Revision", "ICLR.cc/2024/Conference/Submission7020/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7020/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695451668179, "cdate": 1695451668179, "tmdate": 1710440212791, "mdate": 1710440212791, "pdate": 1705410995126, "version": 2}, {"id": "DiWRG9JTWZ", "forum": "DiWRG9JTWZ", "signatures": ["ICLR.cc/2024/Conference/Submission7015/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7015/Authors"], "content": {"title": {"value": "MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation"}, "authors": {"value": ["Min Zhang", "Haoxuan Li", "Fei Wu", "Kun Kuang"]}, "authorids": {"value": ["~Min_Zhang17", "~Haoxuan_Li6", "~Fei_Wu1", "~Kun_Kuang1"]}, "keywords": {"value": ["Benchmark; Few-shot classification; Spurious-correlation shifts"]}, "abstract": {"value": "Out-of-distribution (OOD) problems in few-shot classification (FSC) occur when novel classes sampled from testing distributions differ from base classes drawn from training distributions, which considerably degrades the performance of deep learning models deployed in real-world applications. Recent studies suggest that the OOD problems in FSC mainly including: (a) cross-domain few-shot classification (CD-FSC) and (b) spurious-correlation few-shot classification (SC-FSC). Specifically, CD-FSC occurs when a classifier learns transferring knowledge from base classes drawn from \\underline{seen} training distributions but recognizes novel classes sampled from unseen testing distributions. In contrast, SC-FSC arises when a classifier relies on non-causal features (or contexts) that happen to be correlated with the labels (or concepts) in base classes but such relationships no longer hold during the model deployment. Despite CD-FSC has been extensively studied, SC-FSC remains understudied due to lack of the corresponding evaluation benchmarks. To this end, we present Meta Concept Context (MetaCoCo), a benchmark with spurious-correlation shifts collected from real-world scenarios. Moreover, to quantify the extent of spurious-correlation shifts of the presented MetaCoCo, we further propose a metric by using CLIP as a pre-trained vision-language model. Extensive experiments on the proposed benchmark are performed to evaluate the state-of-the-art methods in FSC, cross-domain shifts, and self-supervised learning. The experimental results show that the performance of the existing methods degrades significantly in the presence of spurious-correlation shifts. We open-source all codes of our benchmark and hope that the proposed MetaCoCo can facilitate future research on spurious-correlation shifts problems in FSC."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/52f0ee4d82c8f6c79eb193ff65109566b3a6a152.pdf"}, "TLDR": {"value": "We present MetaCoCo, a benchmark with spurious-correlation shifts collected from real-world scenarios for few-shot classification."}, "_bibtex": {"value": "@inproceedings{\nzhang2024metacoco,\ntitle={MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation},\nauthor={Min Zhang and Haoxuan Li and Fei Wu and Kun Kuang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DiWRG9JTWZ}\n}"}, "paperhash": {"value": "zhang|metacoco_a_new_fewshot_classification_benchmark_with_spurious_correlation"}}, "number": 7015, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7015/-/Revision", "ICLR.cc/2024/Conference/Submission7015/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7015/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695451450691, "cdate": 1695451450691, "tmdate": 1712684351326, "mdate": 1712684351326, "pdate": 1705410994999, "version": 2}, {"id": "5sixirvG0I", "forum": "5sixirvG0I", "signatures": ["ICLR.cc/2024/Conference/Submission7012/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7012/Authors"], "content": {"title": {"value": "Whittle Index with Multiple Actions and State Constraint for Inventory Management"}, "authors": {"value": ["Chuheng Zhang", "Xiangsen Wang", "Wei Jiang", "Xianliang Yang", "Siwei Wang", "Lei Song", "Jiang Bian"]}, "authorids": {"value": ["~Chuheng_Zhang1", "~Xiangsen_Wang1", "~Wei_Jiang12", "~Xianliang_Yang1", "~Siwei_Wang2", "~Lei_Song3", "~Jiang_Bian1"]}, "keywords": {"value": ["MARL", "Inventory Management", "Whittle Index"]}, "TLDR": {"value": "We propose a novel form of Whittle index that extend to a MARL setting suitable for practical inventory management."}, "abstract": {"value": "Whittle index is a heuristic tool that leads to good performance for the restless bandits problem. In this paper, we extend Whittle index to a new multi-agent reinforcement learning (MARL) setting with multiple discrete actions and a possibly changing constraint on the state space, resulting in WIMS (Whittle Index with Multiple actions and State constraint). This setting is common for inventory management where each agent chooses a replenishing quantity level for the corresponding stock-keeping-unit (SKU) such that the total profit is maximized while the total inventory does not exceed a certain limit. Accordingly, we propose a deep MARL algorithm based on WIMS for inventory management. Empirically, our algorithm is evaluated on real large-scale inventory management problems with up to 2307 SKUs and outperforms operation-research-based methods and baseline MARL algorithms."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a731cb3f2f2ba65bd749c1f7858d1296de0dbde8.pdf"}, "supplementary_material": {"value": "/attachment/12a415ec19b65954850e84b6c838bc6cb9025594.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024whittle,\ntitle={Whittle Index with Multiple Actions and State Constraint for Inventory Management},\nauthor={Chuheng Zhang and Xiangsen Wang and Wei Jiang and Xianliang Yang and Siwei Wang and Lei Song and Jiang Bian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5sixirvG0I}\n}"}, "paperhash": {"value": "zhang|whittle_index_with_multiple_actions_and_state_constraint_for_inventory_management"}}, "number": 7012, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7012/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7012/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695451259681, "cdate": 1695451259681, "tmdate": 1709661536802, "mdate": 1709661536802, "pdate": 1705410994894, "version": 2}, {"id": "HHbRxoDTxE", "forum": "HHbRxoDTxE", "signatures": ["ICLR.cc/2024/Conference/Submission7006/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7006/Authors"], "content": {"title": {"value": "Looped Transformers are Better at Learning Learning Algorithms"}, "authors": {"value": ["Liu Yang", "Kangwook Lee", "Robert D Nowak", "Dimitris Papailiopoulos"]}, "authorids": {"value": ["~Liu_Yang6", "~Kangwook_Lee1", "~Robert_D_Nowak1", "~Dimitris_Papailiopoulos1"]}, "keywords": {"value": ["in-context learning", "transformers", "looped transformers"]}, "TLDR": {"value": "We train a looped transformer from scratch to perform in-context learning of simple function classes. Empirical results indicate the looped transformer can match or outperform the standard transformer."}, "abstract": {"value": "Transformers have demonstrated effectiveness in in-context solving data-fitting problems from various (latent) models, as reported by Garg et al. (2022). However, the absence of an inherent iterative structure in the transformer architecture presents a challenge in emulating the iterative algorithms, which are commonly employed in traditional machine learning methods. To address this, we propose the utilization of looped transformer architecture and its associated training methodology, with the aim of incorporating iterative characteristics into the transformer architectures. Experimental results suggest that the looped transformer achieves performance comparable to the standard transformer in solving various data-fitting problems, while utilizing less than 10% of the parameter count."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a219e6634e4f6e9791efebd86e86ed03c0e5fd3e.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024looped,\ntitle={Looped Transformers are Better at Learning Learning Algorithms},\nauthor={Liu Yang and Kangwook Lee and Robert D Nowak and Dimitris Papailiopoulos},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HHbRxoDTxE}\n}"}, "paperhash": {"value": "yang|looped_transformers_are_better_at_learning_learning_algorithms"}}, "number": 7006, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7006/-/Revision", "ICLR.cc/2024/Conference/Submission7006/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7006/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695450873525, "cdate": 1695450873525, "tmdate": 1710271255421, "mdate": 1710271255421, "pdate": 1705410994768, "version": 2}, {"id": "mF3cTns4pe", "forum": "mF3cTns4pe", "signatures": ["ICLR.cc/2024/Conference/Submission7005/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7005/Authors"], "content": {"title": {"value": "Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs"}, "authors": {"value": ["Milan Papez", "Martin Rektoris", "Vaclav Smidl", "Tom\u00e1\u0161 Pevn\u00fd"]}, "authorids": {"value": ["~Milan_Papez1", "~Martin_Rektoris1", "~Vaclav_Smidl1", "~Tom\u00e1\u0161_Pevn\u00fd1"]}, "keywords": {"value": ["Sum-product networks", "graph neural networks", "probabilistic circuits", "tree-structured graphs", "supervised learning"]}, "TLDR": {"value": "We propose sum-product-set networks, an extension of probabilistic circuits for tree-structured graphs."}, "abstract": {"value": "Daily internet communication relies heavily on tree-structured graphs, embodied by popular data formats such as XML and JSON. However, many recent generative (probabilistic) models utilize neural networks to learn a probability distribution over undirected cyclic graphs. This assumption of a generic graph structure brings various computational challenges, and, more importantly, the presence of non-linearities in neural networks does not permit tractable probabilistic inference. We address these problems by proposing sum-product-set networks, an extension of probabilistic circuits from unstructured tensor data to tree-structured graph data. To this end, we use random finite sets to reflect a variable number of nodes and edges in the graph and to allow for exact and efficient inference. We demonstrate that our tractable model performs comparably to various intractable models based on neural networks."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3832e966df2e6f75cb753da1041d7eb365da4e8e.pdf"}, "_bibtex": {"value": "@inproceedings{\npapez2024sumproductset,\ntitle={Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs},\nauthor={Milan Papez and Martin Rektoris and Tom{\\'a}{\\v{s}} Pevn{\\'y} and Vaclav Smidl},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mF3cTns4pe}\n}"}, "paperhash": {"value": "papez|sumproductset_networks_deep_tractable_models_for_treestructured_graphs"}}, "number": 7005, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7005/-/Revision", "ICLR.cc/2024/Conference/Submission7005/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7005/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695450856461, "cdate": 1695450856461, "tmdate": 1710589888371, "mdate": 1710589888371, "pdate": 1705410994737, "version": 2}, {"id": "qaKRfobbTg", "forum": "qaKRfobbTg", "signatures": ["ICLR.cc/2024/Conference/Submission7000/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7000/Authors"], "content": {"title": {"value": "Learning Thresholds with Latent Values and Censored Feedback"}, "authors": {"value": ["Jiahao Zhang", "Tao Lin", "Weiqiang Zheng", "Zhe Feng", "Yifeng Teng", "Xiaotie Deng"]}, "authorids": {"value": ["~Jiahao_Zhang5", "~Tao_Lin2", "~Weiqiang_Zheng1", "~Zhe_Feng3", "~Yifeng_Teng1", "~Xiaotie_Deng1"]}, "keywords": {"value": ["Threshold", "Latent Value", "Censored Feedback", "Query Complexity"]}, "abstract": {"value": "In this paper, we investigate a problem of *actively* learning threshold in latent space, where the *unknown* reward $g(\\gamma, v)$ depends on the proposed threshold $\\gamma$ and latent value $v$ and it can be $only$ achieved if the threshold is lower than or equal to the *unknown* latent value. This problem has broad applications in practical scenarios, e.g., reserve price optimization in online auctions, online task assignments in crowdsourcing, setting recruiting bars in hiring, etc. We first characterize the query complexity of learning a threshold with the expected reward at most $\\epsilon$ smaller than the optimum and prove that the number of queries needed can be infinitely large even when $g(\\gamma, v)$ is monotone with respect to both $\\gamma$ and $v$. On the positive side, we provide a tight query complexity $\\tilde{\\Theta}(1/\\epsilon^3)$ when $g$ is monotone and the CDF of value distribution is Lipschitz. Moreover, we show a tight $\\tilde{\\Theta}(1/\\epsilon^3)$ query complexity can be achieved as long as $g$ satisfies one-sided Lipschitzness, which provides a complete characterization for this problem. Finally, we extend this model to an online learning setting and demonstrate a tight $\\Theta(T^{2/3})$ regret bound using continuous-arm bandit techniques and the aforementioned query complexity results."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ba68807a548d72279a1d2c88f159aeee9707e14c.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024learning,\ntitle={Learning Thresholds with Latent Values and Censored Feedback},\nauthor={Jiahao Zhang and Tao Lin and Weiqiang Zheng and Zhe Feng and Yifeng Teng and Xiaotie Deng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qaKRfobbTg}\n}"}, "paperhash": {"value": "zhang|learning_thresholds_with_latent_values_and_censored_feedback"}}, "number": 7000, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7000/-/Revision", "ICLR.cc/2024/Conference/Submission7000/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7000/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695450586145, "cdate": 1695450586145, "tmdate": 1710678329666, "mdate": 1710678329666, "pdate": 1705410994693, "version": 2}, {"id": "Qwq4cpLtoX", "forum": "Qwq4cpLtoX", "signatures": ["ICLR.cc/2024/Conference/Submission6993/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6993/Authors"], "content": {"title": {"value": "Is attention required for ICL? Exploring the Relationship Between Model Architecture and In-Context Learning Ability"}, "authors": {"value": ["Ivan Lee", "Nan Jiang", "Taylor Berg-Kirkpatrick"]}, "authorids": {"value": ["~Ivan_Lee2", "~Nan_Jiang11", "~Taylor_Berg-Kirkpatrick1"]}, "keywords": {"value": ["in-context learning", "neural architectures"]}, "abstract": {"value": "What is the relationship between model architecture and the ability to perform in-context learning? In this empirical study, we take the first steps toward answering this question. We evaluate thirteen model architectures capable of causal language modeling across a suite of synthetic in-context learning tasks. These selected architectures represent a broad range of paradigms, including recurrent and convolution-based neural networks, transformers, state space model inspired, and other emerging attention alternatives. We discover that all the considered architectures can perform in-context learning under a wider range of conditions than previously documented. Additionally, we observe stark differences in statistical efficiency and consistency by varying the number of in-context examples and task difficulty. We also measure each architecture's predisposition towards in-context learning when presented with the option to memorize rather than leverage in-context examples. Finally, and somewhat surprisingly, we find that several attention alternatives are sometimes competitive with or better in-context learners than transformers. However, no single architecture demonstrates consistency across all tasks, with performance either plateauing or declining when confronted with a significantly larger number of in-context examples than those encountered during gradient-based training."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b3a829acfd26790f582233e7748752863f7a744.pdf"}, "_bibtex": {"value": "@inproceedings{\nlee2024exploring,\ntitle={Exploring the Relationship Between Model Architecture and In-Context Learning Ability},\nauthor={Ivan Lee and Nan Jiang and Taylor Berg-Kirkpatrick},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Qwq4cpLtoX}\n}"}, "paperhash": {"value": "lee|is_attention_required_for_icl_exploring_the_relationship_between_model_architecture_and_incontext_learning_ability"}}, "number": 6993, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6993/-/Revision", "ICLR.cc/2024/Conference/Submission6993/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6993/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695450252317, "cdate": 1695450252317, "tmdate": 1712022468533, "mdate": 1712022468533, "pdate": 1705410994437, "version": 2}, {"id": "nJnky5K944", "forum": "nJnky5K944", "signatures": ["ICLR.cc/2024/Conference/Submission6982/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6982/Authors"], "content": {"title": {"value": "Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?"}, "authors": {"value": ["Tokio Kajitsuka", "Issei Sato"]}, "authorids": {"value": ["~Tokio_Kajitsuka1", "sato@g.ecc.u-tokyo.ac.jp"]}, "keywords": {"value": ["Transformer", "Self-Attention", "Memorization", "Universal Approximation Theorem", "Contextual Mapping"]}, "abstract": {"value": "Existing analyses of the expressive capacity of Transformer models have required excessively deep layers for data memorization, leading to a discrepancy with the Transformers actually used in practice. \nThis is primarily due to the interpretation of the softmax function as an approximation of the hardmax function.\nBy clarifying the connection between the softmax function and the Boltzmann operator, we prove that a single layer of self-attention with low-rank weight matrices possesses the capability to perfectly capture the context of an entire input sequence.\nAs a consequence, we show that one-layer and single-head Transformers have a memorization capacity for finite samples, and that Transformers consisting of one self-attention layer with two feed-forward neural networks are universal approximators for continuous functions on a compact domain."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1551254dde77118686005288781324e270dcc0aa.pdf"}, "TLDR": {"value": "One-layer and single-head self-attention with low-rank weight matrices is expressive enough to be a contextual mapping."}, "_bibtex": {"value": "@inproceedings{\nkajitsuka2024are,\ntitle={Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?},\nauthor={Tokio Kajitsuka and Issei Sato},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nJnky5K944}\n}"}, "paperhash": {"value": "kajitsuka|are_transformers_with_one_layer_selfattention_using_lowrank_weight_matrices_universal_approximators"}}, "number": 6982, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6982/-/Revision", "ICLR.cc/2024/Conference/Submission6982/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6982/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695449558707, "cdate": 1695449558707, "tmdate": 1710171685505, "mdate": 1710171685505, "pdate": 1705410994050, "version": 2}, {"id": "8F6bws5JBy", "forum": "8F6bws5JBy", "signatures": ["ICLR.cc/2024/Conference/Submission6977/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6977/Authors"], "content": {"title": {"value": "Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication"}, "authors": {"value": ["June Yong Yang", "Geondo Park", "Joowon Kim", "Hyeongwon Jang", "Eunho Yang"]}, "authorids": {"value": ["~June_Yong_Yang1", "~Geondo_Park1", "~Joowon_Kim1", "~Hyeongwon_Jang1", "~Eunho_Yang1"]}, "keywords": {"value": ["Tabular data", "imbalanced learning", "language models"]}, "abstract": {"value": "Tabular data in the wild are frequently afflicted with class-imbalance, biasing machine learning model predictions towards major classes. A data-centric solution to this problem is oversampling - where the classes are balanced by adding synthetic minority samples via generative methods. However, although tabular generative models are capable of generating synthetic samples under a balanced distribution, their integrity suffers when the number of minority samples is low. To this end, pre-trained generative language models with rich prior knowledge are a fitting candidate for the task at hand. Nevertheless, an oversampling strategy tailored for tabular data that utilizes the extensive capabilities of such language models is yet to emerge. In this paper, we propose a novel oversampling framework for tabular data to channel the abilities of generative language models. By leveraging its conditional sampling capabilities, we synthesize minority samples by progressively masking the important features of the majority class samples and imputing them towards the minority distribution. To reduce the inclusion of imperfectly converted samples, we utilize the power of the language model itself to self-authenticate the labels of the samples generated by itself, sifting out ill-converted samples. Extensive experiments on a variety of datasets and imbalance ratios reveal that the proposed method successfully generates reliable minority samples to boost the performance of machine learning classifiers, even under heavy imbalance ratios."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a26f38f14c8805d676e8192ad38267dc304ffabe.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024languageinterfaced,\ntitle={Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication},\nauthor={June Yong Yang and Geondo Park and Joowon Kim and Hyeongwon Jang and Eunho Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=8F6bws5JBy}\n}"}, "paperhash": {"value": "yang|languageinterfaced_tabular_oversampling_via_progressive_imputation_and_selfauthentication"}}, "number": 6977, "odate": 1697213872796, "pdate": 1705410993785, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6977/-/Revision", "ICLR.cc/2024/Conference/Submission6977/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6977/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695449493874, "cdate": 1695449493874, "tmdate": 1710600908481, "mdate": 1710600908481, "version": 2}, {"id": "5bNYf0CqxY", "forum": "5bNYf0CqxY", "signatures": ["ICLR.cc/2024/Conference/Submission6976/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6976/Authors"], "content": {"title": {"value": "Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks"}, "authors": {"value": ["Bhaskar Mukhoty", "Hilal AlQuabeh", "Giulia De Masi", "Huan Xiong", "Bin Gu"]}, "authorids": {"value": ["~Bhaskar_Mukhoty1", "~Hilal_AlQuabeh1", "~Giulia_De_Masi1", "~Huan_Xiong1", "~Bin_Gu1"]}, "keywords": {"value": ["Spiking Neural Networks", "Randomized Smoothing", "Adversarial Learning", "Certified Robustness"]}, "abstract": {"value": "The spiking neural networks are inspired by the biological neurons that employ binary spikes to propagate information in the neural network. It has garnered considerable attention as the next-generation neural network, as the spiking activity simplifies the computation burden of the network to a large extent and is known for its low energy deployment enabled by specialized neuromorphic hardware. One popular technique to feed a static image to such a network is rate encoding, where each pixel is encoded into random binary spikes, following a Bernoulli distribution that uses the pixel intensity as bias. By establishing a novel connection between rate-encoding and randomized smoothing, we give the first provable robustness guarantee for spiking neural networks against adversarial perturbation of inputs bounded under $l_1$-norm. We introduce novel adversarial training algorithms for rate-encoded models that significantly improve the state-of-the-art empirical robust accuracy result. Experimental validation of the method is performed across various static image datasets, including CIFAR-10, CIFAR-100 and ImageNet-100. The code is available at \\url{https://github.com/BhaskarMukhoty/CertifiedSNN}."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4f74eaff2e05305ae3827ba06178636592b02568.pdf"}, "_bibtex": {"value": "@inproceedings{\nmukhoty2024certified,\ntitle={Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks},\nauthor={Bhaskar Mukhoty and Hilal AlQuabeh and Giulia De Masi and Huan Xiong and Bin Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5bNYf0CqxY}\n}"}, "paperhash": {"value": "mukhoty|certified_adversarial_robustness_for_rate_encoded_spiking_neural_networks"}}, "number": 6976, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6976/-/Revision", "ICLR.cc/2024/Conference/Submission6976/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6976/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695449463582, "cdate": 1695449463582, "tmdate": 1710932016863, "mdate": 1710932016863, "pdate": 1705410993768, "version": 2}, {"id": "NY3wMJuaLf", "forum": "NY3wMJuaLf", "signatures": ["ICLR.cc/2024/Conference/Submission6970/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6970/Authors"], "content": {"title": {"value": "Fake It Till Make It: Federated Learning with Consensus-Oriented Generation"}, "authors": {"value": ["Rui Ye", "Yaxin Du", "Zhenyang Ni", "Yanfeng Wang", "Siheng Chen"]}, "authorids": {"value": ["~Rui_Ye1", "~Yaxin_Du1", "~Zhenyang_Ni1", "~Yanfeng_Wang1", "~Siheng_Chen1"]}, "keywords": {"value": ["Federated learning", "data heterogeneity"]}, "abstract": {"value": "In federated learning (FL), data heterogeneity is one key bottleneck that causes model divergence and limits performance. Addressing this, existing methods often regard data heterogeneity as an inherent property and propose to mitigate its adverse effects by correcting models. In this paper, we seek to break this inherent property by generating data to complement the original dataset to fundamentally mitigate heterogeneity level. \nAs a novel attempt from the perspective of data, we propose federated learning with consensus-oriented generation (FedCOG). FedCOG consists of two key components at the client side: complementary data generation, which generates data extracted from the shared global model to complement the original dataset, and knowledge-distillation-based model training, which distills knowledge from global model to local model based on the generated data to mitigate over-fitting the original heterogeneous dataset.\nFedCOG has two critical advantages: 1) it can be a plug-and-play module to further improve the performance of most existing FL methods, and 2) it is naturally compatible with standard FL protocols such as Secure Aggregation since it makes no modification in communication process.\nExtensive experiments on classical and real-world FL datasets show that FedCOG consistently outperforms state-of-the-art methods. Code is available at https://github.com/rui-ye/FedCOG."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/71acc2b60c35a91a970164afaa39838aeaf4b0f6.pdf"}, "_bibtex": {"value": "@inproceedings{\nye2024fake,\ntitle={Fake It Till Make It: Federated Learning with Consensus-Oriented Generation},\nauthor={Rui Ye and Yaxin Du and Zhenyang Ni and Siheng Chen and Yanfeng Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NY3wMJuaLf}\n}"}, "paperhash": {"value": "ye|fake_it_till_make_it_federated_learning_with_consensusoriented_generation"}}, "number": 6970, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6970/-/Revision", "ICLR.cc/2024/Conference/Submission6970/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6970/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695449117476, "cdate": 1695449117476, "tmdate": 1713112866968, "mdate": 1713112866968, "pdate": 1705410993546, "version": 2}, {"id": "FNq3nIvP4F", "forum": "FNq3nIvP4F", "signatures": ["ICLR.cc/2024/Conference/Submission6964/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6964/Authors"], "content": {"title": {"value": "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction"}, "authors": {"value": ["Xinyuan Chen", "Yaohui Wang", "Lingjun Zhang", "Shaobin Zhuang", "Xin Ma", "Jiashuo Yu", "Yali Wang", "Dahua Lin", "Yu Qiao", "Ziwei Liu"]}, "authorids": {"value": ["~Xinyuan_Chen1", "~Yaohui_Wang1", "~Lingjun_Zhang1", "~Shaobin_Zhuang1", "~Xin_Ma3", "~Jiashuo_Yu1", "~Yali_Wang1", "~Dahua_Lin1", "~Yu_Qiao1", "~Ziwei_Liu1"]}, "keywords": {"value": ["generative model; video generation; diffusion model"]}, "abstract": {"value": "Recently video generation has achieved substantial progress with realistic results. Nevertheless, existing AI-generated videos are usually very short clips (\"shot-level'') depicting a single scene. To deliver a coherent long video (\"story-level''), it is desirable to have creative transition and prediction effects across different clips. This paper presents a short-to-long video diffusion model, SEINE, that focuses on generative transition and prediction. The goal is to generate high-quality long videos with smooth and creative transitions between scenes and varying lengths of shot-level videos. Specifically, we propose a random-mask video diffusion model to automatically generate transitions based on textual descriptions. By providing the images of different scenes as inputs, combined with text-based control, our model generates transition videos that ensure coherence and visual quality. Furthermore, the model can be readily extended to various tasks such as image-to-video animation and autoregressive video prediction. To conduct a comprehensive evaluation of this new generative task, we propose three assessing criteria for smooth and creative transition: temporal consistency, semantic similarity, and video-text semantic alignment. Extensive experiments validate the effectiveness of our approach over existing methods for generative transition and prediction, enabling the creation of story-level long videos."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3f1069641eb7f0b47e27967faa59a2b59b6097bb.pdf"}, "supplementary_material": {"value": "/attachment/0aca679cba688b36d8b9e374ec4f09022aa9a1fa.zip"}, "_bibtex": {"value": "@inproceedings{\nchen2024seine,\ntitle={{SEINE}: Short-to-Long Video Diffusion Model for Generative Transition and Prediction},\nauthor={Xinyuan Chen and Yaohui Wang and Lingjun Zhang and Shaobin Zhuang and Xin Ma and Jiashuo Yu and Yali Wang and Dahua Lin and Yu Qiao and Ziwei Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FNq3nIvP4F}\n}"}, "paperhash": {"value": "chen|seine_shorttolong_video_diffusion_model_for_generative_transition_and_prediction"}}, "number": 6964, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6964/-/Revision", "ICLR.cc/2024/Conference/Submission6964/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6964/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695448923415, "cdate": 1695448923415, "tmdate": 1711109642004, "mdate": 1711109642004, "pdate": 1705410993428, "version": 2}, {"id": "qDdSRaOiyb", "forum": "qDdSRaOiyb", "signatures": ["ICLR.cc/2024/Conference/Submission6953/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6953/Authors"], "content": {"title": {"value": "Explaining Time Series via Contrastive and Locally Sparse Perturbations"}, "authors": {"value": ["Zichuan Liu", "Yingying ZHANG", "Tianchun Wang", "Zefan Wang", "Dongsheng Luo", "Mengnan Du", "Min Wu", "Yi Wang", "Chunlin Chen", "Lunting Fan", "Qingsong Wen"]}, "authorids": {"value": ["~Zichuan_Liu3", "~Yingying_ZHANG4", "~Tianchun_Wang1", "~Zefan_Wang2", "~Dongsheng_Luo1", "~Mengnan_Du1", "~Min_Wu2", "~Yi_Wang43", "~Chunlin_Chen1", "~Lunting_Fan1", "~Qingsong_Wen2"]}, "keywords": {"value": ["time series", "explainability", "perturbation"]}, "abstract": {"value": "Explaining multivariate time series is a compound challenge, as it requires identifying important locations in the time series and matching complex temporal patterns.\nAlthough previous saliency-based methods addressed the challenges,\ntheir perturbation may not alleviate the distribution shift issue, which is inevitable especially in heterogeneous samples.\nWe present ContraLSP, a locally sparse model that introduces counterfactual samples to build uninformative perturbations but keeps distribution using contrastive learning.\nFurthermore, we incorporate sample-specific sparse gates to generate more binary-skewed and smooth masks, which easily integrate temporal trends and select the salient features parsimoniously.\nEmpirical studies on both synthetic and real-world datasets show that ContraLSP outperforms state-of-the-art models, demonstrating a substantial improvement in explanation quality for time series data.\nThe source code is available at \\url{https://github.com/zichuan-liu/ContraLSP}."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/139dd222fff7b006a509d6db2182fd7b8e17c46b.pdf"}, "TLDR": {"value": "A novel perturbation-based method for time series explanation"}, "_bibtex": {"value": "@inproceedings{\nliu2024explaining,\ntitle={Explaining Time Series via Contrastive and Locally Sparse Perturbations},\nauthor={Zichuan Liu and Yingying ZHANG and Tianchun Wang and Zefan Wang and Dongsheng Luo and Mengnan Du and Min Wu and Yi Wang and Chunlin Chen and Lunting Fan and Qingsong Wen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qDdSRaOiyb}\n}"}, "paperhash": {"value": "liu|explaining_time_series_via_contrastive_and_locally_sparse_perturbations"}}, "number": 6953, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6953/-/Revision", "ICLR.cc/2024/Conference/Submission6953/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6953/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695448454707, "cdate": 1695448454707, "tmdate": 1709661536398, "mdate": 1709661536398, "pdate": 1705410993237, "version": 2}, {"id": "VJvbOSXRUq", "forum": "VJvbOSXRUq", "signatures": ["ICLR.cc/2024/Conference/Submission6942/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6942/Authors"], "content": {"title": {"value": "GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking"}, "authors": {"value": ["Mert Kosan", "Samidha Verma", "Burouj Armgaan", "Khushbu Pahwa", "Ambuj Singh", "Sourav Medya", "Sayan Ranu"]}, "authorids": {"value": ["~Mert_Kosan1", "~Samidha_Verma1", "~Burouj_Armgaan1", "~Khushbu_Pahwa1", "~Ambuj_Singh1", "~Sourav_Medya1", "~Sayan_Ranu2"]}, "keywords": {"value": ["graph neural network explanations", "factual explanations", "counterfactual explanations"]}, "abstract": {"value": "Numerous explainability methods have been proposed to shed light on the inner workings of GNNs. Despite the inclusion of empirical evaluations in all the proposed algorithms, the interrogative aspects of these evaluations lack diversity. As a result, various facets of explainability pertaining to GNNs, such as a comparative analysis of counterfactual reasoners, their stability to variational factors such as different GNN architectures, noise, stochasticity in non-convex loss surfaces, feasibility amidst domain constraints, and so forth, have yet to be formally investigated. Motivated by this need, we present a benchmarking study on perturbation-based explainability methods for GNNs, aiming to systematically evaluate and compare a wide range of explainability techniques. Among the key findings of our study, we identify the Pareto-optimal methods that exhibit superior efficacy and stability in the presence of noise. Nonetheless, our study reveals that\nall algorithms are affected by stability issues when faced with noisy data. Furthermore, we have established that the current generation of counterfactual explainers often fails to provide feasible recourses due to violations of topological constraints encoded by domain-specific considerations. Overall, this benchmarking study empowers stakeholders in the field of GNNs with a comprehensive understanding of the state-of-the-art explainability methods, potential research problems for further enhancement, and the implications of their application in real-world scenarios."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f55ca936fddaaf6375c775104a74bf4854a69781.pdf"}, "supplementary_material": {"value": "/attachment/bc91a4ea642a6b3ef9b4066158610c604bf1e224.pdf"}, "_bibtex": {"value": "@inproceedings{\nkosan2024gnnxbench,\ntitle={GnnX-Bench: Unravelling the Utility of Perturbation-based {GNN} Explainers through In-depth Benchmarking},\nauthor={Mert Kosan and Samidha Verma and Burouj Armgaan and Khushbu Pahwa and Ambuj Singh and Sourav Medya and Sayan Ranu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VJvbOSXRUq}\n}"}, "paperhash": {"value": "kosan|gnnxbench_unravelling_the_utility_of_perturbationbased_gnn_explainers_through_indepth_benchmarking"}}, "number": 6942, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6942/-/Revision", "ICLR.cc/2024/Conference/Submission6942/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6942/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695447829947, "cdate": 1695447829947, "tmdate": 1710211477337, "mdate": 1710211477337, "pdate": 1705410992896, "version": 2}, {"id": "pBxeZ6pVUD", "forum": "pBxeZ6pVUD", "signatures": ["ICLR.cc/2024/Conference/Submission6936/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6936/Authors"], "content": {"title": {"value": "Grounded Object-Centric Learning"}, "authors": {"value": ["Avinash Kori", "Francesco Locatello", "Fabio De Sousa Ribeiro", "Francesca Toni", "Ben Glocker"]}, "authorids": {"value": ["~Avinash_Kori1", "~Francesco_Locatello1", "~Fabio_De_Sousa_Ribeiro1", "~Francesca_Toni1", "~Ben_Glocker1"]}, "keywords": {"value": ["object-centric representation learning", "the binding problem", "the grounding problem", "slot attention"]}, "TLDR": {"value": "We propose conditional slot attention model to learn specialized slots which bind to specific object types and remain invariant to identity-preserving changes in object appearance."}, "abstract": {"value": "The extraction of object-centric representations for downstream tasks is an emerging area of research. Learning grounded representations of objects that are guaranteed to be stable and invariant promises robust performance across different tasks and environments. Slot Attention (SA) learns object-centric representations by assigning objects to *slots*, but presupposes a *single* distribution from which all slots are randomly initialised. This results in an inability to learn *specialized* slots which bind to specific object types and remain invariant to identity-preserving changes in object appearance. To address this, we present *Conditional Slot Attention* (CoSA) using a novel concept of *Grounded Slot Dictionary* (GSD) inspired by vector quantization. Our proposed GSD comprises (i) canonical object-level property vectors and (ii) parametric Gaussian distributions, which define a prior over the slots. We demonstrate the benefits of our method in multiple downstream tasks such as scene generation, composition, and task adaptation, whilst remaining competitive with SA in object discovery."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/66165ac8488ed6d946efbafac570d3d4388587c6.pdf"}, "supplementary_material": {"value": "/attachment/778c69bf9cadf8dd5b1dbabde73ea062f4941b8e.zip"}, "_bibtex": {"value": "@inproceedings{\nkori2024grounded,\ntitle={Grounded Object-Centric Learning},\nauthor={Avinash Kori and Francesco Locatello and Fabio De Sousa Ribeiro and Francesca Toni and Ben Glocker},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pBxeZ6pVUD}\n}"}, "paperhash": {"value": "kori|grounded_objectcentric_learning"}}, "number": 6936, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6936/-/Revision", "ICLR.cc/2024/Conference/Submission6936/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6936/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695447186437, "cdate": 1695447186437, "tmdate": 1710843661301, "mdate": 1710843661301, "pdate": 1705410992576, "version": 2}, {"id": "xAqcJ9XoTf", "forum": "xAqcJ9XoTf", "signatures": ["ICLR.cc/2024/Conference/Submission6928/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6928/Authors"], "content": {"title": {"value": "On the Stability of Expressive Positional Encodings for Graphs"}, "authors": {"value": ["Yinan Huang", "William Lu", "Joshua Robinson", "Yu Yang", "Muhan Zhang", "Stefanie Jegelka", "Pan Li"]}, "authorids": {"value": ["~Yinan_Huang1", "~William_Lu1", "~Joshua_Robinson4", "~Yu_Yang15", "~Muhan_Zhang1", "~Stefanie_Jegelka3", "~Pan_Li2"]}, "keywords": {"value": ["graph neural networks", "positional encoding", "stability"]}, "abstract": {"value": "Designing effective positional encodings for graphs is key to building powerful graph transformers and enhancing message-passing graph neural networks. Although widespread, using Laplacian eigenvectors as positional encodings faces two fundamental challenges: (1) *Non-uniqueness*: there are many different eigendecompositions of the same Laplacian, and (2) *Instability*: small perturbations to the Laplacian could result in completely different eigenspaces, leading to unpredictable changes in positional encoding.  Despite many attempts to address non-uniqueness, most methods overlook stability, leading to poor generalization on unseen graph structures. We identify the cause of instability to be the use of \"hard partition'' of eigenspaces. Hence, we introduce Stable and Expressive Positional Encodings (SPE), an architecture for processing eigenvectors that uses eigenvalues to ``softly partition'' eigenspaces. SPE is the first architecture that is (1) provably stable, and (2) universally expressive for basis invariant functions whilst respecting all symmetries of eigenvectors. Besides guaranteed stability, we prove that SPE is at least as expressive as existing methods, and highly capable of counting graph structures. Finally, we evaluate the effectiveness of our method on molecular property prediction, and out-of-distribution generalization tasks, finding improved generalization compared to existing positional encoding methods. Our code is available\nat https://github.com/Graph-COM/SPE."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/da037814874ad9b5d5e4d54c3a585436f85c792f.pdf"}, "supplementary_material": {"value": "/attachment/c5dbf31c748d4fa53a93b7ad55b10ba05c893d31.zip"}, "_bibtex": {"value": "@inproceedings{\nhuang2024on,\ntitle={On the Stability of Expressive Positional Encodings for Graph Neural Networks},\nauthor={Yinan Huang and William Lu and Joshua Robinson and Yu Yang and Muhan Zhang and Stefanie Jegelka and Pan Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xAqcJ9XoTf}\n}"}, "paperhash": {"value": "huang|on_the_stability_of_expressive_positional_encodings_for_graphs"}}, "number": 6928, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6928/-/Revision", "ICLR.cc/2024/Conference/Submission6928/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6928/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446894256, "cdate": 1695446894256, "tmdate": 1713164439052, "mdate": 1713164439052, "pdate": 1705410992283, "version": 2}, {"id": "HiTg16qhxp", "forum": "HiTg16qhxp", "signatures": ["ICLR.cc/2024/Conference/Submission6922/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6922/Authors"], "content": {"title": {"value": "Dynamic Neural Response Tuning"}, "authors": {"value": ["Tian Qiu", "Wenxiang Xu", "lin chen", "Zhou Linyun", "Zunlei Feng", "Mingli Song"]}, "authorids": {"value": ["~Tian_Qiu2", "~Wenxiang_Xu1", "~lin_chen21", "~Zhou_Linyun1", "~Zunlei_Feng1", "~Mingli_Song1"]}, "keywords": {"value": ["biological neuron", "artificial neural network", "information transmission", "information aggregation", "neural response", "dynamic tuning", "activation function", "neural representation", "neuronal"]}, "abstract": {"value": "Artificial Neural Networks (ANNs) have gained widespread applications across various areas in recent years. The ANN design was initially inspired by principles of biology. The biological neural network's fundamental response process comprises information transmission and aggregation. The information transmission in biological neurons is often achieved by triggering action potentials that propagate through axons. ANNs utilize activation mechanisms to simulate such biological behavior. However, previous studies have only considered static response conditions, while the biological neuron's response conditions are typically dynamic, depending on multiple factors such as neuronal properties and the real-time environment. Therefore, the dynamic response conditions of biological neurons could help improve the static ones of existing activations in ANNs. Additionally, the biological neuron's aggregated response exhibits high specificity for different categories, allowing the nervous system to differentiate and identify objects. Inspired by these biological patterns, we propose a novel Dynamic Neural Response Tuning (DNRT) mechanism, which aligns the response patterns of ANNs with those of biological neurons. DNRT comprises Response-Adaptive Activation (RAA) and Aggregated Response Regularization (ARR), mimicking the biological neuron's information transmission and aggregation behaviors. RAA dynamically adjusts the response condition based on the characteristics and strength of the input signal. ARR is devised to enhance the network's ability to learn category specificity by imposing constraints on the network's response distribution. Extensive experimental studies indicate that the proposed DNRT is highly interpretable, applicable to various mainstream network architectures, and can achieve remarkable performance compared with existing neural response mechanisms in multiple tasks and domains. Code is available at https://github.com/horrible-dong/DNRT."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7cbbd2896e4dd9b581f2e3e528a591df3fa6280a.pdf"}, "_bibtex": {"value": "@inproceedings{\nqiu2024dynamic,\ntitle={Dynamic Neural Response Tuning},\nauthor={Tian Qiu and Wenxiang Xu and lin chen and Zhou Linyun and Zunlei Feng and Mingli Song},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HiTg16qhxp}\n}"}, "paperhash": {"value": "qiu|dynamic_neural_response_tuning"}}, "number": 6922, "odate": 1697213872796, "pdate": 1705410992072, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6922/-/Revision", "ICLR.cc/2024/Conference/Submission6922/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6922/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446427585, "cdate": 1695446427585, "tmdate": 1712770652928, "mdate": 1712770652928, "version": 2}, {"id": "Let8OMe20n", "forum": "Let8OMe20n", "signatures": ["ICLR.cc/2024/Conference/Submission6921/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6921/Authors"], "content": {"title": {"value": "Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models"}, "authors": {"value": ["Kyuyoung Kim", "Jongheon Jeong", "Minyong An", "Mohammad Ghavamzadeh", "Krishnamurthy Dj Dvijotham", "Jinwoo Shin", "Kimin Lee"]}, "authorids": {"value": ["~Kyuyoung_Kim1", "~Jongheon_Jeong1", "~Minyong_An2", "~Mohammad_Ghavamzadeh2", "~Krishnamurthy_Dj_Dvijotham1", "~Jinwoo_Shin1", "~Kimin_Lee1"]}, "keywords": {"value": ["text-to-image generation", "overoptimization", "confidence calibration"]}, "abstract": {"value": "Fine-tuning text-to-image models with reward functions trained on human feedback data has proven effective for aligning model behavior with human intent. However, excessive optimization with such reward models, which serve as mere proxy objectives, can compromise the performance of fine-tuned models, a phenomenon known as reward overoptimization. To investigate this issue in depth, we introduce the Text-Image Alignment Assessment (TIA2) benchmark, which comprises a diverse collection of text prompts, images, and human annotations. Our evaluation of several state-of-the-art reward models on this benchmark reveals their frequent misalignment with human assessment. We empirically demonstrate that overoptimization occurs notably when a poorly aligned reward model is used as the fine-tuning objective. To address this, we propose TextNorm, a simple method that enhances alignment based on a measure of reward model confidence estimated across a set of semantically contrastive text prompts. We demonstrate that incorporating the confidence-calibrated rewards in fine-tuning effectively reduces overoptimization, resulting in twice as many wins in human evaluation for text-image alignment compared against the baseline reward models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/828a0528a628cbdef49c41493ee521fc32d6f646.pdf"}, "supplementary_material": {"value": "/attachment/f9ab1ff78b1acb0aa28d3c3956733f32ca4a22bd.zip"}, "TLDR": {"value": "We explore the issue of reward overoptimization in text-to-image generation and propose a simple uncertainty estimation-based method for mitigating the risk."}, "_bibtex": {"value": "@inproceedings{\nkim2024confidenceaware,\ntitle={Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models},\nauthor={Kyuyoung Kim and Jongheon Jeong and Minyong An and Mohammad Ghavamzadeh and Krishnamurthy Dj Dvijotham and Jinwoo Shin and Kimin Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Let8OMe20n}\n}"}, "paperhash": {"value": "kim|confidenceaware_reward_optimization_for_finetuning_texttoimage_models"}}, "number": 6921, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6921/-/Revision", "ICLR.cc/2024/Conference/Submission6921/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6921/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446306458, "cdate": 1695446306458, "tmdate": 1710986461327, "mdate": 1710986461327, "pdate": 1705410991866, "version": 2}, {"id": "jvtmdK69KQ", "forum": "jvtmdK69KQ", "signatures": ["ICLR.cc/2024/Conference/Submission6919/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6919/Authors"], "content": {"title": {"value": "Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts"}, "authors": {"value": ["Huy Nguyen", "Pedram Akbarian", "Fanqi Yan", "Nhat Ho"]}, "authorids": {"value": ["~Huy_Nguyen5", "~Pedram_Akbarian1", "~Fanqi_Yan1", "~Nhat_Ho1"]}, "keywords": {"value": ["Mixture of Experts", "Maximum Likelihood Estimation", "Voronoi Loss Function"]}, "abstract": {"value": "Top-K sparse softmax gating mixture of experts has been widely used for scaling up massive deep-learning architectures without increasing the computational cost. Despite its popularity in real-world applications, the theoretical understanding of that gating function has remained an open problem. The main challenge comes from the structure of the top-K sparse softmax gating function, which partitions the input space into multiple regions with distinct behaviors. By focusing on a Gaussian mixture of experts, we establish theoretical results on the effects of the top-K sparse softmax gating function on both density and parameter estimations. Our results hinge upon defining novel loss functions among parameters to capture different behaviors of the input regions. When the true number of experts $k_{\\ast}$ is known, we demonstrate that the convergence rates of density and parameter estimations are both parametric on the sample size. However, when $k_{\\ast}$ becomes unknown and the true model is over-specified by a Gaussian mixture of $k$ experts where $k > k_{\\ast}$, our findings suggest that the number of experts selected from the top-K sparse softmax gating function must exceed the total cardinality of a certain number of Voronoi cells associated with the true parameters to guarantee the convergence of the density estimation. Moreover, while the density estimation rate remains parametric under this setting, the parameter estimation rates become substantially slow due to an intrinsic interaction between the softmax gating and expert functions."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4a7464fb42e89d2b35f17d3ea36a7c378e0c6f78.pdf"}, "supplementary_material": {"value": "/attachment/0ab4499caadd154d69b94cf867880c715ae28a35.pdf"}, "_bibtex": {"value": "@inproceedings{\nnguyen2024statistical,\ntitle={Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts},\nauthor={Huy Nguyen and Pedram Akbarian and Fanqi Yan and Nhat Ho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jvtmdK69KQ}\n}"}, "paperhash": {"value": "nguyen|statistical_perspective_of_topk_sparse_softmax_gating_mixture_of_experts"}}, "number": 6919, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6919/-/Revision", "ICLR.cc/2024/Conference/Submission6919/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6919/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446233736, "cdate": 1695446233736, "tmdate": 1709661535879, "mdate": 1709661535879, "pdate": 1705410991718, "version": 2}, {"id": "SQGUDc9tC8", "forum": "SQGUDc9tC8", "signatures": ["ICLR.cc/2024/Conference/Submission6917/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6917/Authors"], "content": {"title": {"value": "The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models"}, "authors": {"value": ["Yan Liu", "Yu Liu", "Xiaokang Chen", "Pin-Yu Chen", "Daoguang Zan", "Min-Yen Kan", "Tsung-Yi Ho"]}, "authorids": {"value": ["~Yan_Liu13", "~Yu_Liu34", "~Xiaokang_Chen1", "~Pin-Yu_Chen1", "~Daoguang_Zan1", "~Min-Yen_Kan1", "~Tsung-Yi_Ho2"]}, "keywords": {"value": ["Interpretable social bias"]}, "abstract": {"value": "Pre-trained Language models (PLMs) have been acknowledged to contain harmful information, such as social biases, which may cause negative social impacts or even bring catastrophic results in application. Previous works on this problem mainly focused on using black-box methods such as probing to detect and quantify social biases in PLMs by observing model outputs. As a result, previous debiasing methods mainly finetune or even pre-train PLMs on newly constructed anti-stereotypical datasets, which are high-cost. In this work, we try to unveil the mystery of social bias inside language models by introducing the concept of {\\sc Social Bias Neurons}. Specifically, we propose {\\sc Integrated Gap Gradients (IG$^2$)} to accurately pinpoint units (i.e., neurons) in a language model that can be attributed to undesirable behavior, such as social bias.  By formalizing undesirable behavior as a distributional property of language, we employ sentiment-bearing prompts to elicit classes of sensitive words (demographics) correlated with such sentiments. Our IG$^2$ thus attributes the uneven distribution for different demographics to specific Social Bias Neurons, which track the trail of unwanted behavior inside PLM units to achieve interoperability. Moreover, derived from our interpretable technique, {\\sc Bias Neuron Suppression (BNS)} is further proposed to mitigate social biases. By studying BERT, RoBERTa, and their attributable differences from debiased FairBERTa, IG$^2$ allows us to locate and suppress identified neurons, and further mitigate undesired behaviors. As measured by prior metrics from StereoSet, our model achieves a higher degree of fairness while maintaining language modeling ability with low cost\\footnote{This work contains examples that potentially implicate stereotypes, associations, and other harms that could be offensive to individuals in certain social groups.}."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/00e3b9b382dd650b339739dc00fadf43859a081f.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024the,\ntitle={The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models},\nauthor={Yan Liu and Yu Liu and Xiaokang Chen and Pin-Yu Chen and Daoguang Zan and Min-Yen Kan and Tsung-Yi Ho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=SQGUDc9tC8}\n}"}, "paperhash": {"value": "liu|the_devil_is_in_the_neurons_interpreting_and_mitigating_social_biases_in_language_models"}}, "number": 6917, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6917/-/Revision", "ICLR.cc/2024/Conference/Submission6917/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6917/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446161771, "cdate": 1695446161771, "tmdate": 1710949393450, "mdate": 1710949393450, "pdate": 1705410991664, "version": 2}, {"id": "vW1SkPl4kp", "forum": "vW1SkPl4kp", "signatures": ["ICLR.cc/2024/Conference/Submission6915/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6915/Authors"], "content": {"title": {"value": "Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback"}, "authors": {"value": ["Yu Chen", "Yihan Du", "Pihe Hu", "Siwei Wang", "Desheng Wu", "Longbo Huang"]}, "authorids": {"value": ["~Yu_Chen19", "~Yihan_Du2", "~Pihe_Hu1", "~Siwei_Wang2", "~Desheng_Wu1", "~Longbo_Huang2"]}, "keywords": {"value": ["Reinforcement Learning", "Iterated CVaR", "Learning Theory", "Function Approximation", "Human Feedback"]}, "abstract": {"value": "Risk-sensitive reinforcement learning (RL) aims to optimize policies that balance the expected reward and risk. In this paper, we present a novel risk-sensitive RL framework that employs an Iterated Conditional Value-at-Risk (CVaR) objective under both linear and general function approximations, enriched by human feedback. These new formulations provide a principled way to guarantee safety in each decision making step throughout the control process. Moreover, integrating human feedback into risk-sensitive RL framework bridges the gap between algorithmic decision-making and human participation, allowing us to also guarantee safety for human-in-the-loop systems. We propose provably sample-efficient algorithms for this Iterated CVaR RL and provide rigorous theoretical analysis. Furthermore, we establish a matching lower bound to corroborate the optimality of our algorithms in a linear context."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2fdeb6baf39a009b91cb61477698c072bc06ee4c.pdf"}, "supplementary_material": {"value": "/attachment/f11b7c698d4722205d8df32225e7359ed786b514.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024provably,\ntitle={Provably Efficient Iterated {CV}aR Reinforcement Learning with Function Approximation and Human Feedback},\nauthor={Yu Chen and Yihan Du and Pihe Hu and Siwei Wang and Desheng Wu and Longbo Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vW1SkPl4kp}\n}"}, "paperhash": {"value": "chen|provably_efficient_iterated_cvar_reinforcement_learning_with_function_approximation_and_human_feedback"}}, "number": 6915, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6915/-/Revision", "ICLR.cc/2024/Conference/Submission6915/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6915/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446109044, "cdate": 1695446109044, "tmdate": 1710595872959, "mdate": 1710595872959, "pdate": 1705410991483, "version": 2}, {"id": "vSwu81S33z", "forum": "vSwu81S33z", "signatures": ["ICLR.cc/2024/Conference/Submission6913/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6913/Authors"], "content": {"title": {"value": "Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling"}, "authors": {"value": ["Hyungi Lee", "Giung Nam", "Edwin Fong", "Juho Lee"]}, "authorids": {"value": ["~Hyungi_Lee1", "~Giung_Nam1", "~Edwin_Fong1", "~Juho_Lee2"]}, "keywords": {"value": ["Transfer Learning", "Nonparametric Learning", "Bayesian Neural Network"]}, "abstract": {"value": "Transfer learning has recently shown significant performance across various tasks involving deep neural networks. In these transfer learning scenarios, the prior distribution for downstream data becomes crucial in Bayesian model averaging (BMA). While previous works proposed the prior over the neural network parameters centered around the pre-trained solution, such strategies have limitations when dealing with distribution shifts between upstream and downstream data. This paper introduces nonparametric transfer learning (NPTL), a flexible posterior sampling method to address the distribution shift issue within the context of nonparametric learning. The nonparametric learning (NPL) method is a recent approach that employs a nonparametric prior for posterior sampling, efficiently accounting for model misspecification scenarios, which is suitable for transfer learning scenarios that may involve the distribution shift between upstream and downstream tasks. Through extensive empirical validations, we demonstrate that our approach surpasses other baselines in BMA performance."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d6bc9a17c08b05f6ad8a9b72350d1330bd28b82f.pdf"}, "supplementary_material": {"value": "/attachment/4e152dfd7d4a881cbd0a7e653fe55e479393ecb8.zip"}, "TLDR": {"value": "Posterior sampling method for transfer learning scenarios using nonparametric prior"}, "_bibtex": {"value": "@inproceedings{\nlee2024enhancing,\ntitle={Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling},\nauthor={Hyungi Lee and Giung Nam and Edwin Fong and Juho Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vSwu81S33z}\n}"}, "paperhash": {"value": "lee|enhancing_transfer_learning_with_flexible_nonparametric_posterior_sampling"}}, "number": 6913, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6913/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6913/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695446057029, "cdate": 1695446057029, "tmdate": 1709661535785, "mdate": 1709661535785, "pdate": 1705410991451, "version": 2}, {"id": "B6pQxqUcT8", "forum": "B6pQxqUcT8", "signatures": ["ICLR.cc/2024/Conference/Submission6910/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6910/Authors"], "content": {"title": {"value": "ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search"}, "authors": {"value": ["Yuchen Zhuang", "Xiang Chen", "Tong Yu", "Saayan Mitra", "Victor Bursztyn", "Ryan A. Rossi", "Somdeb Sarkhel", "Chao Zhang"]}, "authorids": {"value": ["~Yuchen_Zhuang1", "~Xiang_Chen9", "~Tong_Yu3", "~Saayan_Mitra1", "~Victor_Bursztyn1", "~Ryan_A._Rossi2", "~Somdeb_Sarkhel2", "~Chao_Zhang15"]}, "keywords": {"value": ["Large Language Model", "Tool Use", "Tree Search", "A* Search"]}, "abstract": {"value": "Large language models (LLMs) have demonstrated powerful decision-making and planning capabilities in solving complicated real-world problems. LLM-based autonomous agents can interact with diverse tools (e.g., functional APIs) and generate solution plans that execute a series of API function calls in a step-by-step manner. The multitude of candidate API function calls significantly expands the action space, amplifying the critical need for efficient action space navigation. However, existing methods either struggle with unidirectional exploration in expansive action spaces, trapped into a locally optimal solution, or suffer from exhaustively traversing all potential actions, causing inefficient navigation. To address these issues, we propose ToolChain*, an efficient tree search-based planning algorithm for LLM-based agents. It formulates the entire action space as a decision tree, where each node represents a possible API function call involved in a solution plan. By incorporating the A$^*$ search algorithm with task-specific cost function design, it efficiently prunes high-cost branches that may involve incorrect actions, identifying the most low-cost valid path as the solution. Extensive experiments on multiple tool-use and reasoning tasks demonstrate that ToolChain* efficiently balances exploration and exploitation within an expansive action space. It outperforms state-of-the-art baselines on planning and reasoning tasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time, respectively."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/489eb6cf5855d6657af7e78fc4c04f4eb79c6cdd.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhuang2024toolchain,\ntitle={ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search},\nauthor={Yuchen Zhuang and Xiang Chen and Tong Yu and Saayan Mitra and Victor Bursztyn and Ryan A. Rossi and Somdeb Sarkhel and Chao Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=B6pQxqUcT8}\n}"}, "paperhash": {"value": "zhuang|toolchain_efficient_action_space_navigation_in_large_language_models_with_a_search"}}, "number": 6910, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6910/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6910/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695445921562, "cdate": 1695445921562, "tmdate": 1710269590528, "mdate": 1710269590528, "pdate": 1705410991353, "version": 2}, {"id": "RR8y0WKrFv", "forum": "RR8y0WKrFv", "signatures": ["ICLR.cc/2024/Conference/Submission6909/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6909/Authors"], "content": {"title": {"value": "Ensemble Distillation for Unsupervised Constituency Parsing"}, "authors": {"value": ["Behzad Shayegh", "Yanshuai Cao", "Xiaodan Zhu", "Jackie CK Cheung", "Lili Mou"]}, "authorids": {"value": ["~Behzad_Shayegh1", "~Yanshuai_Cao1", "~Xiaodan_Zhu1", "~Jackie_CK_Cheung1", "~Lili_Mou1"]}, "keywords": {"value": ["Constituency Parsing", "Unsupervised Grammar Induction", "Knowledge Distillation"]}, "TLDR": {"value": "The paper proposes an ensemble method and multi-teacher distillation approach for unsupervised constituency parsing, demonstrating robustness and effectiveness."}, "abstract": {"value": "We investigate the unsupervised constituency parsing task, which organizes words and phrases of a sentence into a hierarchical structure without using linguistically annotated data. We observe that existing unsupervised parsers capture different aspects of parsing structures, which can be leveraged to enhance unsupervised parsing performance.\nTo this end, we propose a notion of \"tree averaging,\" based on which we further propose a novel ensemble method for unsupervised parsing.\nTo improve inference efficiency, we further distill the ensemble knowledge into a student model; such an ensemble-then-distill process is an effective approach to mitigate the over-smoothing problem existing in common multi-teacher distilling methods.\nExperiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs, with different ensemble components, and under domain-shift conditions."}, "pdf": {"value": "/pdf/7a5feee9949b906657595e1365733b61602391d9.pdf"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "supplementary_material": {"value": "/attachment/13f69a89832f171a99810492537b96fb1bb580e0.pdf"}, "_bibtex": {"value": "@inproceedings{\nshayegh2024ensemble,\ntitle={Ensemble Distillation for Unsupervised Constituency Parsing},\nauthor={Behzad Shayegh and Yanshuai Cao and Xiaodan Zhu and Jackie CK Cheung and Lili Mou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RR8y0WKrFv}\n}"}, "paperhash": {"value": "shayegh|ensemble_distillation_for_unsupervised_constituency_parsing"}}, "number": 6909, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6909/-/Revision", "ICLR.cc/2024/Conference/Submission6909/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6909/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695445917583, "cdate": 1695445917583, "tmdate": 1709914444113, "mdate": 1709914444113, "pdate": 1705410991312, "version": 2}, {"id": "AssIuHnmHX", "forum": "AssIuHnmHX", "signatures": ["ICLR.cc/2024/Conference/Submission6895/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6895/Authors"], "content": {"title": {"value": "What Algorithms can Transformers Learn? A Study in Length Generalization"}, "authors": {"value": ["Hattie Zhou", "Arwen Bradley", "Etai Littwin", "Noam Razin", "Omid Saremi", "Joshua M. Susskind", "Samy Bengio", "Preetum Nakkiran"]}, "authorids": {"value": ["~Hattie_Zhou1", "~Arwen_Bradley1", "~Etai_Littwin1", "~Noam_Razin1", "~Omid_Saremi1", "~Joshua_M._Susskind1", "~Samy_Bengio1", "~Preetum_Nakkiran1"]}, "keywords": {"value": ["length generalization", "systematic generalization", "understanding", "transformer", "scratchpad", "LLM", "algorithmic reasoning"]}, "TLDR": {"value": "We show that length generalization of Transformer models trained from scratch strongly correlates with the simplicity of the true RASP-L program for the task."}, "abstract": {"value": "Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. In this work, we focus on length generalization, and we propose a unifying framework to understand when and how Transformers can be expected to length generalize on a given task. First, we show that there exist algorithmic tasks for which standard\ndecoder-only Transformers trained from scratch naturally exhibit strong length generalization. For these tasks, we leverage the RASP programming language (Weiss et al., 2021) to show that the correct algorithmic solution which solves the task can be represented by a simple Transformer. We thus propose the RASP-Generalization Conjecture: Transformers tend to learn a length-generalizing solution if there exists a short RASP-L program that works for all input lengths. We present empirical evidence to support the correlation between RASP-simplicity and generalization. We leverage our insights to give new scratchpad formats which yield strong length generalization on traditionally hard tasks (such as parity and addition), and we illustrate how scratchpad can hinder generalization when it increases the complexity of the corresponding RASP-L program. Overall, our work provides a novel perspective on the mechanisms of length generalization and the algorithmic capabilities of Transformers."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5d2d4bf238aa8f548ba72df177f3c7dbcf06d72a.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhou2024understanding,\ntitle={Understanding Length Generalization by Thinking Like Transformers},\nauthor={Hattie Zhou and Arwen Bradley and Etai Littwin and Noam Razin and Omid Saremi and Joshua M. Susskind and Samy Bengio and Preetum Nakkiran},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AssIuHnmHX}\n}"}, "paperhash": {"value": "zhou|what_algorithms_can_transformers_learn_a_study_in_length_generalization"}}, "number": 6895, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6895/-/Revision", "ICLR.cc/2024/Conference/Submission6895/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6895/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695445040398, "cdate": 1695445040398, "tmdate": 1710823366840, "mdate": 1710823366840, "pdate": 1705410991036, "version": 2}, {"id": "4zZFGliCl9", "forum": "4zZFGliCl9", "signatures": ["ICLR.cc/2024/Conference/Submission6893/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6893/Authors"], "content": {"title": {"value": "Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders"}, "authors": {"value": ["Hien Dang", "Tho Tran Huu", "Tan Minh Nguyen", "Nhat Ho"]}, "authorids": {"value": ["~Hien_Dang1", "~Tho_Tran_Huu1", "~Tan_Minh_Nguyen1", "~Nhat_Ho1"]}, "keywords": {"value": ["variational autoencoders", "posterior collapse"]}, "TLDR": {"value": "We prove and study posterior collapse occurence for conditional and hierarchical variational autoencoders"}, "abstract": {"value": "The posterior collapse phenomenon in variational autoencoder (VAE), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables. As a consequence of posterior collapse, the latent variables extracted by the encoder in VAE preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder. While this phenomenon has been an actively addressed topic related to VAE performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAE. In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAE: conditional VAE and hierarchical VAE. Specifically, via a non-trivial theoretical analysis of linear conditional VAE and hierarchical VAE with two levels of latent, we prove that the cause of posterior collapses in these models includes the correlation between the input and output of the conditional VAE and the effect of learnable encoder variance in the hierarchical VAE. We empirically validate our theoretical findings for linear conditional and hierarchical VAE and demonstrate that these results are also predictive for non-linear cases with extensive experiments."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/026b2fe5b8e01f96bc45f8c3c2df5b26e6c9bede.pdf"}, "supplementary_material": {"value": "/attachment/edc531461a86d46ea17a15ff21f0575acc5e5447.zip"}, "_bibtex": {"value": "@inproceedings{\ndang2024beyond,\ntitle={Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders},\nauthor={Hien Dang and Tho Tran Huu and Tan Minh Nguyen and Nhat Ho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4zZFGliCl9}\n}"}, "paperhash": {"value": "dang|beyond_vanilla_variational_autoencoders_detecting_posterior_collapse_in_conditional_and_hierarchical_variational_autoencoders"}}, "number": 6893, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6893/-/Revision", "ICLR.cc/2024/Conference/Submission6893/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6893/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695444872917, "cdate": 1695444872917, "tmdate": 1712676916310, "mdate": 1712676916310, "pdate": 1705410991007, "version": 2}, {"id": "X41c4uB4k0", "forum": "X41c4uB4k0", "signatures": ["ICLR.cc/2024/Conference/Submission6892/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6892/Authors"], "content": {"title": {"value": "Training-free Multi-objective Diffusion Model for 3D Molecule Generation"}, "authors": {"value": ["Xu Han", "Caihua Shan", "Yifei Shen", "Can Xu", "Han Yang", "Xiang Li", "Dongsheng Li"]}, "authorids": {"value": ["~Xu_Han9", "~Caihua_Shan1", "~Yifei_Shen1", "~Can_Xu7", "~Han_Yang6", "~Xiang_Li24", "~Dongsheng_Li2"]}, "keywords": {"value": ["Multi-objective Diffusion Model", "3D Molecule"]}, "abstract": {"value": "Searching for novel and diverse molecular candidates is a critical undertaking in drug and material discovery. Existing approaches have successfully adapted the diffusion model, the most effective generative model in image generation, to create 1D SMILES strings, 2D chemical graphs, or 3D molecular conformers. However, these methods are not efficient and flexible enough to generate 3D molecules with multiple desired properties, as they require additional training for the models for each new property or even a new combination of existing properties. Moreover, some properties may potentially conflict, making it impossible to find a molecule that satisfies all of them simultaneously. To address these challenges, we present a training-free conditional 3D molecular generation algorithm based on off-the-shelf unconditional diffusion models and property prediction models. The key techniques include modeling the loss of property prediction models as energy functions, considering the property relation between multiple conditions as a probabilistic graph, and developing a stable posterior estimation for computing the conditional score function. We conducted experiments on both single-objective and multi-objective 3D molecule generation, focusing on quantum properties, and compared our approach with the trained or fine-tuned diffusion models. Our proposed model achieves superior performance in generating molecules that meet the conditions, without any additional training cost."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/717e170104a536d5a082442609bfcaa6255a13d2.pdf"}, "_bibtex": {"value": "@inproceedings{\nhan2024trainingfree,\ntitle={Training-free Multi-objective Diffusion Model for 3D Molecule Generation},\nauthor={Xu Han and Caihua Shan and Yifei Shen and Can Xu and Han Yang and Xiang Li and Dongsheng Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=X41c4uB4k0}\n}"}, "paperhash": {"value": "han|trainingfree_multiobjective_diffusion_model_for_3d_molecule_generation"}}, "number": 6892, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6892/-/Revision", "ICLR.cc/2024/Conference/Submission6892/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6892/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695444862887, "cdate": 1695444862887, "tmdate": 1711000568861, "mdate": 1711000568861, "pdate": 1705410990940, "version": 2}, {"id": "Z9AZsU1Tju", "forum": "Z9AZsU1Tju", "signatures": ["ICLR.cc/2024/Conference/Submission6883/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6883/Authors"], "content": {"title": {"value": "Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning"}, "authors": {"value": ["Xiongye Xiao", "Gengshuo Liu", "Gaurav Gupta", "Defu Cao", "Shixuan Li", "Yaxing Li", "Tianqing Fang", "Mingxi Cheng", "Paul Bogdan"]}, "authorids": {"value": ["~Xiongye_Xiao1", "~Gengshuo_Liu1", "~Gaurav_Gupta2", "~Defu_Cao1", "sli97750@usc.edu", "~Yaxing_Li1", "~Tianqing_Fang1", "~Mingxi_Cheng1", "~Paul_Bogdan1"]}, "keywords": {"value": ["multimodal learning", "information bottleneck", "sentiment analysis"]}, "abstract": {"value": "Integrating and processing information from various sources or modalities are critical for obtaining a comprehensive and accurate perception of the real world in autonomous systems and cyber-physical systems. Drawing inspiration from neuroscience, we develop the Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the concept of information bottleneck. Different from most traditional fusion models that incorporate all modalities identically in neural networks, our model designates a prime modality and regards the remaining modalities as detectors in the information pathway, serving to distill the flow of information. Our proposed perception model focuses on constructing an effective and compact information flow by achieving a balance between the minimization of mutual information between the latent state and the input modal state, and the maximization of mutual information between the latent states and the remaining modal states. This approach leads to compact latent state representations that retain relevant information while minimizing redundancy, thereby substantially enhancing the performance of multimodal representation learning. Experimental evaluations on the MUStARD, CMU-MOSI, and CMU-MOSEI datasets demonstrate that our model consistently distills crucial information in multimodal learning scenarios, outperforming state-of-the-art benchmarks. Remarkably, on the CMU-MOSI dataset, ITHP surpasses human-level performance in the multimodal sentiment binary classification task across all evaluation metrics (i.e., Binary Accuracy, F1 Score, Mean Absolute Error, and Pearson Correlation)."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ebbb7ad5da0f88bc346d6ca2ac034c15d80949ba.pdf"}, "supplementary_material": {"value": "/attachment/752137e801bb2326ba7e29ad2628b3f90dc0bc40.pdf"}, "_bibtex": {"value": "@inproceedings{\nxiao2024neuroinspired,\ntitle={Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning},\nauthor={Xiongye Xiao and Gengshuo Liu and Gaurav Gupta and Defu Cao and Shixuan Li and Yaxing Li and Tianqing Fang and Mingxi Cheng and Paul Bogdan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Z9AZsU1Tju}\n}"}, "paperhash": {"value": "xiao|neuroinspired_informationtheoretic_hierarchical_perception_for_multimodal_learning"}}, "number": 6883, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6883/-/Revision", "ICLR.cc/2024/Conference/Submission6883/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6883/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695444224885, "cdate": 1695444224885, "tmdate": 1713139055257, "mdate": 1713139055257, "pdate": 1705410990657, "version": 2}, {"id": "7avlrpzWqo", "forum": "7avlrpzWqo", "signatures": ["ICLR.cc/2024/Conference/Submission6879/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6879/Authors"], "content": {"title": {"value": "Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization"}, "authors": {"value": ["Hamidreza Almasi", "Harsh Mishra", "Balajee Vamanan", "Sathya N. Ravi"]}, "authorids": {"value": ["~Hamidreza_Almasi1", "~Harsh_Mishra1", "~Balajee_Vamanan1", "~Sathya_N._Ravi1"]}, "keywords": {"value": ["Robust", "Aggregation", "Distributed", "Training", "Failure", "Augmented", "Byzantine", "Resilience"]}, "abstract": {"value": "Modern ML applications increasingly rely on complex deep learning models and large datasets. There has been an exponential growth in the amount of computation needed to train the largest models. Therefore, to scale computation and data, these models are inevitably trained in a distributed manner in clusters of nodes, and their updates are aggregated before being applied to the model. However, a distributed setup is prone to Byzantine failures of individual nodes, components, and software. With data augmentation added to these settings, there is a critical need for robust and efficient aggregation systems. We define the quality of workers as reconstruction ratios $\\in (0,1]$, and formulate aggregation as a Maximum Likelihood Estimation procedure using Beta densities. We show that the Regularized form of log-likelihood wrt subspace can be approximately solved using iterative least squares solver, and provide convergence guarantees using recent Convex Optimization landscape results. Our empirical findings demonstrate that our approach significantly enhances the robustness of state-of-the-art Byzantine resilient aggregators. We evaluate our method in a distributed setup with a parameter server, and show simultaneous improvements in communication efficiency and accuracy across various tasks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/442708b2d6a95857db7069f0f7be2e9f0a9c4560.pdf"}, "supplementary_material": {"value": "/attachment/aae05857d3367152772f83487cd072c367bd1e99.zip"}, "_bibtex": {"value": "@inproceedings{\nalmasi2024flag,\ntitle={Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization},\nauthor={Hamidreza Almasi and Harsh Mishra and Balajee Vamanan and Sathya N. Ravi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7avlrpzWqo}\n}"}, "paperhash": {"value": "almasi|flag_aggregator_scalable_distributed_training_under_failures_and_augmented_losses_using_convex_optimization"}}, "number": 6879, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6879/-/Revision", "ICLR.cc/2024/Conference/Submission6879/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6879/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695443930721, "cdate": 1695443930721, "tmdate": 1710698201526, "mdate": 1710698201526, "pdate": 1705410990612, "version": 2}, {"id": "9m02ib92Wz", "forum": "9m02ib92Wz", "signatures": ["ICLR.cc/2024/Conference/Submission6868/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6868/Authors"], "content": {"title": {"value": "DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models"}, "authors": {"value": ["Yongchan Kwon", "Eric Wu", "Kevin Wu", "James Zou"]}, "authorids": {"value": ["~Yongchan_Kwon1", "~Eric_Wu3", "~Kevin_Wu1", "~James_Zou1"]}, "keywords": {"value": ["Influence function", "Data valuation"]}, "abstract": {"value": "Quantifying the impact of training data points is crucial for understanding the outputs of machine learning models and for improving the transparency of the AI pipeline. The influence function is a principled and popular data attribution method, but its computational cost often makes it challenging to use. This issue becomes more pronounced in the setting of large language models and text-to-image models. In this work, we propose DataInf, an efficient influence approximation method that is practical for large-scale generative AI models. Leveraging an easy-to-compute closed-form expression, DataInf outperforms existing influence computation algorithms in terms of computational and memory efficiency. Our theoretical analysis shows that DataInf is particularly well-suited for parameter-efficient fine-tuning techniques such as LoRA. Through systematic empirical evaluations, we show that DataInf accurately approximates influence scores and is orders of magnitude faster than existing methods. In applications to RoBERTa-large, Llama-2-13B-chat, and stable-diffusion-v1.5 models, DataInf effectively identifies the most influential fine-tuning examples better than other approximate influence scores. Moreover, it can help to identify which data points are mislabeled."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We propose DataInf, an efficient influence calculation method that can be easily applied to LLMs and diffusion models."}, "pdf": {"value": "/pdf/f648e527ea8555fa59078bf60005056e9de1b956.pdf"}, "supplementary_material": {"value": "/attachment/e078e037cea2844184989983823731a351cdeacf.zip"}, "_bibtex": {"value": "@inproceedings{\nkwon2024datainf,\ntitle={DataInf: Efficiently Estimating Data Influence in Lo{RA}-tuned {LLM}s and Diffusion Models},\nauthor={Yongchan Kwon and Eric Wu and Kevin Wu and James Zou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9m02ib92Wz}\n}"}, "paperhash": {"value": "kwon|datainf_efficiently_estimating_data_influence_in_loratuned_llms_and_diffusion_models"}}, "number": 6868, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6868/-/Revision", "ICLR.cc/2024/Conference/Submission6868/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6868/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695443296717, "cdate": 1695443296717, "tmdate": 1710339506059, "mdate": 1710339506059, "pdate": 1705410990207, "version": 2}, {"id": "I2mIxuXA72", "forum": "I2mIxuXA72", "signatures": ["ICLR.cc/2024/Conference/Submission6861/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6861/Authors"], "content": {"title": {"value": "Understanding Domain Generalization: A Noise Robustness Perspective"}, "authors": {"value": ["Rui Qiao", "Bryan Kian Hsiang Low"]}, "authorids": {"value": ["~Rui_Qiao3", "~Bryan_Kian_Hsiang_Low1"]}, "keywords": {"value": ["out-of-distribution generalization", "distribution shifts", "spurious correlation", "noise robustness"]}, "abstract": {"value": "Despite the rapid development of machine learning algorithms for domain generalization (DG), there is no clear empirical evidence that the existing DG algorithms outperform the classic empirical risk minimization (ERM) across standard benchmarks. To better understand this phenomenon, we investigate whether there are benefits of DG algorithms over ERM through the lens of label noise.\nSpecifically, our finite-sample analysis reveals that label noise exacerbates the effect of spurious correlations for ERM, undermining generalization. \nConversely, we illustrate that DG algorithms exhibit implicit label-noise robustness during finite-sample training even when spurious correlation is present.\nSuch desirable property helps mitigate spurious correlations and improve generalization in synthetic experiments. \nHowever, additional comprehensive experiments on real-world benchmark datasets indicate that label-noise robustness does not necessarily translate to better performance compared to ERM. \nWe conjecture that the failure mode of ERM arising from spurious correlations may be less pronounced in practice. Our code is available at https://github.com/qiaoruiyt/NoiseRobustDG"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a53902576d4d742fd5f4175a0e1c0ee4657327ad.pdf"}, "supplementary_material": {"value": "/attachment/3c3190ccab92b7056e0b2794120ff1ea5d80e8b8.zip"}, "TLDR": {"value": "Label noise exacerbates the effect of spurious correlations for ERM. Invariance learning algorithms with label-noise robustness may improve the situation under certain circumstances."}, "_bibtex": {"value": "@inproceedings{\nqiao2024understanding,\ntitle={Understanding Domain Generalization: A Noise Robustness Perspective},\nauthor={Rui Qiao and Bryan Kian Hsiang Low},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=I2mIxuXA72}\n}"}, "paperhash": {"value": "qiao|understanding_domain_generalization_a_noise_robustness_perspective"}}, "number": 6861, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6861/-/Revision", "ICLR.cc/2024/Conference/Submission6861/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6861/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442823217, "cdate": 1695442823217, "tmdate": 1710426803552, "mdate": 1710426803552, "pdate": 1705410990097, "version": 2}, {"id": "lNCnZwcH5Z", "forum": "lNCnZwcH5Z", "signatures": ["ICLR.cc/2024/Conference/Submission6860/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6860/Authors"], "content": {"title": {"value": "Non-negative Contrastive Learning"}, "authors": {"value": ["Yifei Wang", "Qi Zhang", "Yaoyu Guo", "Yisen Wang"]}, "authorids": {"value": ["~Yifei_Wang1", "~Qi_Zhang28", "~Yaoyu_Guo1", "~Yisen_Wang1"]}, "keywords": {"value": ["Contrastive Learning", "Representation Learning", "Self-supervised Learning", "Deep Learning", "Disentanglement", "Interpretability"]}, "abstract": {"value": "Deep representations have shown promising performance when transferred to downstream tasks in a black-box manner. Yet, their inherent lack of interpretability remains a significant challenge, as these features are often opaque to human understanding. In this paper, we propose Non-negative Contrastive Learning (NCL), a renaissance of Non-negative Matrix Factorization (NMF) aimed at deriving interpretable features. The power of NCL lies in its enforcement of non-negativity constraints on features, reminiscent of NMF's capability to extract features that align closely with sample clusters. NCL not only aligns mathematically well with an NMF objective but also preserves NMF's interpretability attributes, resulting in a more sparse and disentangled representation compared to standard contrastive learning (CL). Theoretically, we establish guarantees on the identifiability and downstream generalization of NCL. Empirically, we show that these advantages enable NCL to outperform CL significantly on feature disentanglement, feature selection, as well as downstream classification tasks. At last, we show that NCL can be easily extended to other learning scenarios and benefit supervised learning as well. Code is available at https://github.com/PKU-ML/non_neg."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1b45f1b0bffc56e9836a42d2720e3924d2c2079c.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024nonnegative,\ntitle={Non-negative Contrastive Learning},\nauthor={Yifei Wang and Qi Zhang and Yaoyu Guo and Yisen Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lNCnZwcH5Z}\n}"}, "paperhash": {"value": "wang|nonnegative_contrastive_learning"}}, "number": 6860, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6860/-/Revision", "ICLR.cc/2024/Conference/Submission6860/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6860/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442781569, "cdate": 1695442781569, "tmdate": 1711544727161, "mdate": 1711544727161, "pdate": 1705410990056, "version": 2}, {"id": "G2cG3mQqop", "forum": "G2cG3mQqop", "signatures": ["ICLR.cc/2024/Conference/Submission6858/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6858/Authors"], "content": {"title": {"value": "Image Clustering Conditioned on Text Criteria"}, "authors": {"value": ["Sehyun Kwon", "Jaeseung Park", "Minkyu Kim", "Jaewoong Cho", "Ernest K. Ryu", "Kangwook Lee"]}, "authorids": {"value": ["~Sehyun_Kwon1", "~Jaeseung_Park1", "~Minkyu_Kim2", "~Jaewoong_Cho1", "~Ernest_K._Ryu1", "~Kangwook_Lee1"]}, "keywords": {"value": ["image clustering", "vision-language models", "large language models", "foundation models"]}, "TLDR": {"value": "We propose a novel image clustering method that perform clustering based on a user-specified criterion."}, "abstract": {"value": "Classical clustering methods do not provide users with direct control of the clustering results, and the clustering results may not be consistent with the relevant criterion that a user has in mind. In this work, we present a new methodology for performing image clustering based on user-specified criteria in the form of text by leveraging modern Vision-Language Models and Large Language Models. We call our method Image Clustering Conditioned on Text Criteria (IC$|$TC), and it represents a different paradigm of image clustering. IC$|$TC requires a minimal and practical degree of human intervention and grants the user significant control over the clustering results in return. Our experiments show that IC$|$TC can effectively cluster images with various criteria, such as human action, physical location, or the person's mood, significantly outperforming baselines."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/83489d736d85ac2c125c212368f64b8749617029.pdf"}, "supplementary_material": {"value": "/attachment/4c0a7552023c95cd25fc3902e8b054ed9fcf81f4.zip"}, "_bibtex": {"value": "@inproceedings{\nkwon2024image,\ntitle={Image Clustering Conditioned on Text Criteria},\nauthor={Sehyun Kwon and Jaeseung Park and Minkyu Kim and Jaewoong Cho and Ernest K. Ryu and Kangwook Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=G2cG3mQqop}\n}"}, "paperhash": {"value": "kwon|image_clustering_conditioned_on_text_criteria"}}, "number": 6858, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6858/-/Revision", "ICLR.cc/2024/Conference/Submission6858/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6858/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442749267, "cdate": 1695442749267, "tmdate": 1709661535259, "mdate": 1709661535259, "pdate": 1705410989989, "version": 2}, {"id": "xHmCdSArUC", "forum": "xHmCdSArUC", "signatures": ["ICLR.cc/2024/Conference/Submission6856/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6856/Authors"], "content": {"title": {"value": "Correlated Noise Provably Beats Independent Noise for Differentially Private Learning"}, "authors": {"value": ["Christopher A. Choquette-Choo", "Krishnamurthy Dj Dvijotham", "Krishna Pillutla", "Arun Ganesh", "Thomas Steinke", "Abhradeep Guha Thakurta"]}, "authorids": {"value": ["~Christopher_A._Choquette-Choo1", "~Krishnamurthy_Dj_Dvijotham1", "~Krishna_Pillutla1", "~Arun_Ganesh1", "~Thomas_Steinke2", "~Abhradeep_Guha_Thakurta1"]}, "keywords": {"value": ["differentially private optimization", "stochastic gradient descent", "linear regression theory", "private deep learning"]}, "TLDR": {"value": "We prove the benefits of correlated noise for DP optimization in linear regression. Using the theory, we derive an orders-of-magnitude more efficient correlated noise generation algorithm that nearly matches SOTA for private deep learning."}, "abstract": {"value": "Differentially private learning algorithms inject noise into the learning process. While the most common private learning algorithm, DP-SGD, adds independent Gaussian noise in each iteration, recent work on matrix factorization mechanisms has shown empirically that introducing correlations in the noise can greatly improve their utility. We characterize the asymptotic learning utility for any choice of the correlation function, giving precise analytical bounds for linear regression and as the solution to a convex program for general convex functions. We show, using these bounds, how correlated noise provably improves upon vanilla DP-SGD as a function of problem parameters such as the effective dimension and condition number. Moreover, our analytical expression for the near-optimal correlation function circumvents the cubic complexity of the semi-definite program used to optimize the noise correlation matrix in previous work. We validate these theoretical results with experiments on private deep learning. Our work matches or outperforms prior work while being efficient both in terms of computation and memory."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/07874a562caa579a83a03bac6b2e1b60b3da81e6.pdf"}, "supplementary_material": {"value": "/attachment/334409445c03fce78f4825d0b1e2ba7b1e679ff9.pdf"}, "_bibtex": {"value": "@inproceedings{\nchoquette-choo2024correlated,\ntitle={Correlated Noise Provably Beats Independent Noise for Differentially Private Learning},\nauthor={Christopher A. Choquette-Choo and Krishnamurthy Dj Dvijotham and Krishna Pillutla and Arun Ganesh and Thomas Steinke and Abhradeep Guha Thakurta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xHmCdSArUC}\n}"}, "paperhash": {"value": "choquettechoo|correlated_noise_provably_beats_independent_noise_for_differentially_private_learning"}}, "number": 6856, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6856/-/Revision", "ICLR.cc/2024/Conference/Submission6856/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6856/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442614918, "cdate": 1695442614918, "tmdate": 1709661535246, "mdate": 1709661535246, "pdate": 1705410989880, "version": 2}, {"id": "6bcAD6g688", "forum": "6bcAD6g688", "signatures": ["ICLR.cc/2024/Conference/Submission6855/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6855/Authors"], "content": {"title": {"value": "Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models"}, "authors": {"value": ["Zhaowei Zhu", "Jialu Wang", "Hao Cheng", "Yang Liu"]}, "authorids": {"value": ["~Zhaowei_Zhu1", "~Jialu_Wang1", "~Hao_Cheng5", "~Yang_Liu3"]}, "keywords": {"value": ["Label errors", "dataset cleaning", "AI safety", "toxicity", "harmless", "language models"]}, "abstract": {"value": "Language models have shown promise in various tasks but can be affected by undesired data during training, fine-tuning, or alignment. For example, if some unsafe conversations are wrongly annotated as safe ones, the model fine-tuned on these samples may be harmful. Therefore, the correctness of annotations, i.e., the credibility of the dataset, is important. This study focuses on the credibility of real-world datasets, including the popular benchmarks Jigsaw Civil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that can be used for training a harmless language model. Given the cost and difficulty of cleaning these datasets by humans, we introduce a systematic framework for evaluating the credibility of datasets, identifying label errors, and evaluating the influence of noisy labels in the curated language data, specifically focusing on unsafe comments and conversation classification. With the framework, we find and fix an average of **6.16\\%** label errors in **11** datasets constructed from the above benchmarks. The data credibility and downstream learning performance can be remarkably improved by directly fixing label errors, indicating the significance of cleaning existing real-world datasets. Code is available at [https://github.com/Docta-ai/docta](https://github.com/Docta-ai/docta)."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c63cbbf9bcdf0edbb4b24aceb8baceb5a774466e.pdf"}, "supplementary_material": {"value": "/attachment/e944516261150a416fc2926d2276766a0a3dc06c.zip"}, "TLDR": {"value": "We provide an opensource tool to find and fix an average of 6.16% label errors in 11 text datasets for training harmless language models."}, "_bibtex": {"value": "@inproceedings{\nzhu2024unmasking,\ntitle={Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models},\nauthor={Zhaowei Zhu and Jialu Wang and Hao Cheng and Yang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6bcAD6g688}\n}"}, "paperhash": {"value": "zhu|unmasking_and_improving_data_credibility_a_study_with_datasets_for_training_harmless_language_models"}}, "number": 6855, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6855/-/Revision", "ICLR.cc/2024/Conference/Submission6855/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6855/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442551627, "cdate": 1695442551627, "tmdate": 1710519025202, "mdate": 1710519025202, "pdate": 1705410989861, "version": 2}, {"id": "43cYe4oogi", "forum": "43cYe4oogi", "signatures": ["ICLR.cc/2024/Conference/Submission6850/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6850/Authors"], "content": {"title": {"value": "Understanding Expressivity of GNN in Rule Learning"}, "authors": {"value": ["Haiquan Qiu", "Yongqi Zhang", "Yong Li", "quanming yao"]}, "authorids": {"value": ["~Haiquan_Qiu1", "~Yongqi_Zhang2", "~Yong_Li7", "~quanming_yao1"]}, "keywords": {"value": ["Graph Neural Networks", "KG reasoning", "Link prediction", "Rule learning", "Expressivity"]}, "abstract": {"value": "Rule learning is critical to improving knowledge graph (KG) reasoning due to their ability to provide logical and interpretable explanations. Recently, Graph Neural Networks (GNNs) with tail entity scoring achieve the state-of-the-art performance on KG reasoning. However, the theoretical understandings for these GNNs are either lacking or focusing on single-relational graphs, leaving what the kind of rules these GNNs can learn an open problem. We propose to fill the above gap in this paper. Specifically, GNNs with tail entity scoring are unified into a common framework. Then, we analyze their expressivity by formally describing the rule structures they can learn and theoretically demonstrating their superiority. These results further inspire us to propose a novel labeling strategy to learn more rules in KG reasoning. Experimental results are consistent with our theoretical findings and verify the effectiveness of our proposed method. The code is publicly available at https://github.com/LARS-research/Rule-learning-expressivity."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/93bd4984c19e009f47d8628c5f0b810a9a863e31.pdf"}, "TLDR": {"value": "We analyze the expressivity of SOTA GNNs for KG reasoning by deducing the rule strcutures they can learn."}, "_bibtex": {"value": "@inproceedings{\nqiu2024understanding,\ntitle={Understanding Expressivity of Neural {KG} Reasoning from Rule Structure Learning},\nauthor={Haiquan Qiu and Yongqi Zhang and Yong Li and quanming yao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=43cYe4oogi}\n}"}, "paperhash": {"value": "qiu|understanding_expressivity_of_gnn_in_rule_learning"}}, "number": 6850, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6850/-/Revision", "ICLR.cc/2024/Conference/Submission6850/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6850/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442190470, "cdate": 1695442190470, "tmdate": 1710316826254, "mdate": 1710316826254, "pdate": 1705410989676, "version": 2}, {"id": "kxgSlyirUZ", "forum": "kxgSlyirUZ", "signatures": ["ICLR.cc/2024/Conference/Submission6849/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6849/Authors"], "content": {"title": {"value": "COLLIE: Systematic Construction of Constrained Text Generation Tasks"}, "authors": {"value": ["Shunyu Yao", "Howard Chen", "Austin W. Hanjie", "Runzhe Yang", "Karthik R Narasimhan"]}, "authorids": {"value": ["~Shunyu_Yao1", "~Howard_Chen1", "~Austin_W._Hanjie1", "~Runzhe_Yang1", "~Karthik_R_Narasimhan1"]}, "keywords": {"value": ["constrained text generation", "large language models", "compositional benchmark"]}, "TLDR": {"value": "We propose a new framework for the systematic construction of challenging instances for constrained text generation."}, "abstract": {"value": "Text generation under constraints have seen increasing interests in natural language processing, especially with the rapidly improving capabilities of large language models. However, existing benchmarks for constrained generation usually focus on fixed constraint types (e.g. generate a sentence containing certain words) that have proved to be easy for state-of-the-art models like GPT-4. We present COLLIE, a grammar-based framework that allows the specification of rich, compositional constraints with diverse generation levels (word, sentence, paragraph, passage) and modeling challenges (e.g. language understanding, logical reasoning, counting, semantic planning). We also develop tools for automatic extraction of task instances given a constraint structure and a raw text corpus. Using COLLIE, we compile the COLLIE-v1 dataset with 1,132 instances comprising 13 constraint structures. We perform systematic experiments across five state-of-the-art instruction-tuned language models and analyze their performances to reveal shortcomings. COLLIE is designed to be extensible and lightweight, and we hope the community finds it useful to develop more complex constraints and evaluations in the future."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2b91743058a323d7558fd428a55ec0c50428ae1f.pdf"}, "supplementary_material": {"value": "/attachment/46d554feb444395549dd744cec0c18722b675fbe.pdf"}, "_bibtex": {"value": "@inproceedings{\nyao2024collie,\ntitle={{COLLIE}: Systematic Construction of Constrained Text Generation Tasks},\nauthor={Shunyu Yao and Howard Chen and Austin W. Hanjie and Runzhe Yang and Karthik R Narasimhan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kxgSlyirUZ}\n}"}, "paperhash": {"value": "yao|collie_systematic_construction_of_constrained_text_generation_tasks"}}, "number": 6849, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6849/-/Revision", "ICLR.cc/2024/Conference/Submission6849/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6849/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695442156063, "cdate": 1695442156063, "tmdate": 1712250011482, "mdate": 1712250011482, "pdate": 1705410989627, "version": 2}, {"id": "MNShbDSxKH", "forum": "MNShbDSxKH", "signatures": ["ICLR.cc/2024/Conference/Submission6843/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6843/Authors"], "content": {"title": {"value": "GENOME: Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules"}, "authors": {"value": ["Zhenfang Chen", "Rui Sun", "Wenjun Liu", "Yining Hong", "Chuang Gan"]}, "authorids": {"value": ["~Zhenfang_Chen1", "~Rui_Sun10", "~Wenjun_Liu2", "~Yining_Hong1", "~Chuang_Gan1"]}, "keywords": {"value": ["Large language models", "Neuro-symbolic Visual Reasoning"]}, "abstract": {"value": "Recent works have shown that Large Language Models (LLMs) could empower traditional neuro-symbolic models via programming capabilities to translate languages into module descriptions, thus achieving strong visual reasoning results while maintaining the model\u2019s transparency and efficiency. However, these models usually exhaustively generate the entire code snippet given each new instance of a task, which is extremely ineffective. On the contrary, human beings gradually acquire knowledge that can be reused and grow into more profound skills for fast generalization to new tasks since we are an infant. Inspired by this, we propose generative neuro-symbolic visual reasoning by growing and reusing modules. Specifically, our model consists of three unique stages, module initialization, module generation, and module execution. First, given a vision-language task, we adopt LLMs to examine whether we could reuse and grow over established modules to handle this new task. If not, we initialize a new module needed by the task and specify the inputs and outputs of this new module. After that, the new module is created by querying LLMs to generate corresponding code snippets that match the requirements. In order to get a better sense of the new module\u2019s ability, we treat few-shot training examples as test cases to see if our new module could pass these cases. If yes, the new module is added to the module library for future reuse. Finally, we evaluate the performance of our model on the testing set by executing the parsed programs with the newly made visual modules to get the results. We find the proposed GENOME model possesses several advantages. First, it performs competitively on standard tasks like visual question answering and referring expression comprehension; Second, the visual modules learned from one task can be seamlessly transferred to new tasks; Last but not least, it is able to adapt to new visual reasoning tasks by observing a few training examples and reusing modules."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8031fe0e67ddfaabc507eed53fd4d5f548655c87.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024generative,\ntitle={Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules},\nauthor={Zhenfang Chen and Rui Sun and Wenjun Liu and Yining Hong and Chuang Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MNShbDSxKH}\n}"}, "paperhash": {"value": "chen|genome_generative_neurosymbolic_visual_reasoning_by_growing_and_reusing_modules"}}, "number": 6843, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6843/-/Revision", "ICLR.cc/2024/Conference/Submission6843/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6843/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441884442, "cdate": 1695441884442, "tmdate": 1713063919877, "mdate": 1713063919877, "pdate": 1705410989352, "version": 2}, {"id": "IcVNBR7qZi", "forum": "IcVNBR7qZi", "signatures": ["ICLR.cc/2024/Conference/Submission6841/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6841/Authors"], "content": {"title": {"value": "Vanishing Gradients in Reinforcement Finetuning of Language Models"}, "authors": {"value": ["Noam Razin", "Hattie Zhou", "Omid Saremi", "Vimal Thilak", "Arwen Bradley", "Preetum Nakkiran", "Joshua M. Susskind", "Etai Littwin"]}, "authorids": {"value": ["~Noam_Razin1", "~Hattie_Zhou1", "~Omid_Saremi1", "~Vimal_Thilak2", "~Arwen_Bradley1", "~Preetum_Nakkiran1", "~Joshua_M._Susskind1", "~Etai_Littwin1"]}, "keywords": {"value": ["Vanishing Gradients", "Reinforcement Finetuning", "Supervised Finetuning", "Language Models"]}, "TLDR": {"value": "We uncover a fundamental vanishing gradients problem in reinforcement finetuning of language models, demonstrate its prevalence and detrimental effects, and explore possible solutions."}, "abstract": {"value": "Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which refers to maximizing a (possibly learned) reward function using policy gradient algorithms. This work identifies a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small number of SFT optimization steps on as few as 1% of the input samples can suffice, indicating that the initial SFT phase need not be expensive in terms of compute and data labeling efforts. Overall, our results emphasize that being mindful for inputs whose expected gradient vanishes, as measured by the reward standard deviation, is crucial for successful execution of RFT."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d3b687ffd92b6da5e5c3af179d6dbc54d3f3286a.pdf"}, "_bibtex": {"value": "@inproceedings{\nrazin2024vanishing,\ntitle={Vanishing Gradients in Reinforcement Finetuning of Language Models},\nauthor={Noam Razin and Hattie Zhou and Omid Saremi and Vimal Thilak and Arwen Bradley and Preetum Nakkiran and Joshua M. Susskind and Etai Littwin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IcVNBR7qZi}\n}"}, "paperhash": {"value": "razin|vanishing_gradients_in_reinforcement_finetuning_of_language_models"}}, "number": 6841, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6841/-/Revision", "ICLR.cc/2024/Conference/Submission6841/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6841/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441840506, "cdate": 1695441840506, "tmdate": 1710401447591, "mdate": 1710401447591, "pdate": 1705410989277, "version": 2}, {"id": "A7t7z6g6tM", "forum": "A7t7z6g6tM", "signatures": ["ICLR.cc/2024/Conference/Submission6833/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6833/Authors"], "content": {"title": {"value": "Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty"}, "authors": {"value": ["Changbin Li", "Kangshuo Li", "Yuzhe Ou", "Lance M. Kaplan", "Audun J\u00f8sang", "Jin-Hee Cho", "DONG HYUN JEONG", "Feng Chen"]}, "authorids": {"value": ["~Changbin_Li1", "~Kangshuo_Li1", "~Yuzhe_Ou1", "~Lance_M._Kaplan1", "~Audun_J\u00f8sang1", "~Jin-Hee_Cho1", "~DONG_HYUN_JEONG1", "~Feng_Chen7"]}, "keywords": {"value": ["Evidential Neural Network", "hyperdomain", "vagueness"]}, "TLDR": {"value": "We propose a novel framework called Hyper-Evidential Neural Network (HENN) that explicitly models predictive uncertainty caused by composite set labels in training data using a belief theory called Subjective Logic (SL)."}, "abstract": {"value": "Deep neural networks (DNNs) have been shown to perform well on exclusive, multi-class classification tasks. However, when different classes have similar visual features, it becomes challenging for human annotators to differentiate them. When an image is ambiguous, such as a blurry one where an annotator can't distinguish between a husky and a wolf, it may be labeled with both classes: {husky, wolf}. This scenario necessitates the use of composite set labels. \nIn this paper, we propose a novel framework called Hyper-Evidential Neural Network (HENN) that explicitly models predictive uncertainty caused by composite set labels in training data in the context of the belief theory called Subjective Logic (SL).\nBy placing a Grouped Dirichlet distribution on the class probabilities, we treat predictions of a neural network as parameters of hyper-subjective opinions and learn the network that collects both single and composite evidence leading to these hyper-opinions by a deterministic DNN from data.\nWe introduce a new uncertainty type called vagueness originally designed for hyper-opinions in SL to quantify composite classification uncertainty for DNNs.\nOur experiments prove that HENN outperforms its state-of-the-art counterparts based on four image datasets.\nThe code and datasets are available at: https://shorturl.at/dhoqx."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d9fa37fd81bb8872a6d08f243c35eaa3601d077e.pdf"}, "supplementary_material": {"value": "/attachment/1fd560a2f772a6859278424b89556b9bd878913d.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024hyper,\ntitle={Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty},\nauthor={Changbin Li and Kangshuo Li and Yuzhe Ou and Lance M. Kaplan and Audun J{\\o}sang and Jin-Hee Cho and DONG HYUN JEONG and Feng Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=A7t7z6g6tM}\n}"}, "paperhash": {"value": "li|hyper_evidential_deep_learning_to_quantify_composite_classification_uncertainty"}}, "number": 6833, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6833/-/Revision", "ICLR.cc/2024/Conference/Submission6833/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441508613, "cdate": 1695441508613, "tmdate": 1707625635536, "mdate": 1707625635536, "pdate": 1705410988916, "version": 2}, {"id": "5o9G4XF1LI", "forum": "5o9G4XF1LI", "signatures": ["ICLR.cc/2024/Conference/Submission6832/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6832/Authors"], "content": {"title": {"value": "Goodhart's Law in Reinforcement Learning"}, "authors": {"value": ["Jacek Karwowski", "Oliver Hayman", "Xingjian Bai", "Klaus Kiendlhofer", "Charlie Griffin", "Joar Max Viktor Skalse"]}, "authorids": {"value": ["~Jacek_Karwowski1", "~Oliver_Hayman1", "~Xingjian_Bai1", "~Klaus_Kiendlhofer1", "~Charlie_Griffin1", "~Joar_Max_Viktor_Skalse1"]}, "keywords": {"value": ["reinforcement learning", "goodhart's law", "misspecification", "reward learning"]}, "TLDR": {"value": "We study Goodhart's law in RL empirically, provide a theoretical explanation for why it occurs, and use these theoretical insights to derive two methods for avoiding Goodharting."}, "abstract": {"value": "Implementing a reward function that perfectly captures a complex task in the real world is impractical. As a result, it is often appropriate to think of the reward function as a *proxy* for the true objective rather than as its definition. We study this phenomenon through the lens of *Goodhart\u2019s law*, which predicts that increasing optimisation of an imperfect proxy beyond some critical point decreases performance on the true objective. First, we propose a way to *quantify* the magnitude of this effect and *show empirically* that optimising an imperfect proxy reward often leads to the behaviour predicted by Goodhart\u2019s law for a wide range of environments and reward functions. We then provide a *geometric explanation* for why Goodhart's law occurs in Markov decision processes. We use these theoretical insights to propose an *optimal early stopping method* that provably avoids the aforementioned pitfall and derive theoretical *regret bounds* for this method. Moreover, we derive a training method that maximises worst-case reward, for the setting where there is uncertainty about the true reward function. Finally, we evaluate our early stopping method experimentally. Our results support a foundation for a theoretically-principled study of reinforcement learning under reward misspecification."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6153eba150ad68aef8616d6e9956362c49c52bf0.pdf"}, "_bibtex": {"value": "@inproceedings{\nkarwowski2024goodharts,\ntitle={Goodhart's Law in Reinforcement Learning},\nauthor={Jacek Karwowski and Oliver Hayman and Xingjian Bai and Klaus Kiendlhofer and Charlie Griffin and Joar Max Viktor Skalse},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5o9G4XF1LI}\n}"}, "paperhash": {"value": "karwowski|goodharts_law_in_reinforcement_learning"}}, "number": 6832, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6832/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6832/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441452361, "cdate": 1695441452361, "tmdate": 1710516940492, "mdate": 1710516940492, "pdate": 1705410988855, "version": 2}, {"id": "xCRr9DrolJ", "forum": "xCRr9DrolJ", "signatures": ["ICLR.cc/2024/Conference/Submission6831/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6831/Authors"], "content": {"title": {"value": "Score Regularized Policy Optimization through Diffusion Behavior"}, "authors": {"value": ["Huayu Chen", "Cheng Lu", "Zhengyi Wang", "Hang Su", "Jun Zhu"]}, "authorids": {"value": ["~Huayu_Chen1", "~Cheng_Lu5", "~Zhengyi_Wang1", "~Hang_Su3", "~Jun_Zhu2"]}, "keywords": {"value": ["offline reinforcement learning", "generative models", "diffusion models", "behavior modeling", "computational efficiency"]}, "TLDR": {"value": "We propose a new diffusion-based offline RL algorithm which circumvents the time-consuming diffusion sampling scheme."}, "abstract": {"value": "Recent developments in offline reinforcement learning have uncovered the immense potential of diffusion modeling, which excels at representing heterogeneous behavior policies. However, sampling from diffusion policies is considerably slow because it necessitates tens to hundreds of iterative inference steps for one action. To address this issue, we propose to extract an efficient deterministic inference policy from critic models and pretrained diffusion behavior models, leveraging the latter to directly regularize the policy gradient with the behavior\ndistribution\u2019s score function during optimization. Our method enjoys powerful generative capabilities of diffusion modeling while completely circumventing the computationally intensive and time-consuming diffusion sampling scheme, both during training and evaluation. Extensive results on D4RL tasks show that our method boosts action sampling speed by more than 25 times compared with various leading diffusion-based methods in locomotion tasks, while still maintaining state-of-the-art performance."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0b7046c1b69414c1351e50e82242d4d0f7f1e704.pdf"}, "supplementary_material": {"value": "/attachment/c92cd005689471bdbd0c0ec01fd63fb4b8bde9cc.zip"}, "_bibtex": {"value": "@inproceedings{\nchen2024score,\ntitle={Score Regularized Policy Optimization through Diffusion Behavior},\nauthor={Huayu Chen and Cheng Lu and Zhengyi Wang and Hang Su and Jun Zhu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xCRr9DrolJ}\n}"}, "paperhash": {"value": "chen|score_regularized_policy_optimization_through_diffusion_behavior"}}, "number": 6831, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6831/-/Revision", "ICLR.cc/2024/Conference/Submission6831/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6831/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441440308, "cdate": 1695441440308, "tmdate": 1710471370607, "mdate": 1710471370607, "pdate": 1705410988795, "version": 2}, {"id": "qPloNoDJZn", "forum": "qPloNoDJZn", "signatures": ["ICLR.cc/2024/Conference/Submission6827/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6827/Authors"], "content": {"title": {"value": "Robustifying and Boosting Training-Free Neural Architecture Search"}, "authors": {"value": ["Zhenfeng He", "Yao Shu", "Zhongxiang Dai", "Bryan Kian Hsiang Low"]}, "authorids": {"value": ["~Zhenfeng_He3", "~Yao_Shu1", "~Zhongxiang_Dai1", "~Bryan_Kian_Hsiang_Low1"]}, "keywords": {"value": ["Neural Architecture Search", "Training-free NAS", "Bayesian Optimization", "Precision@K", "Partial Monitoring"]}, "abstract": {"value": "Neural architecture search (NAS) has become a key component of AutoML and a standard tool to automate the design of deep neural networks. Recently, training-free NAS as an emerging paradigm has successfully reduced the search costs of standard training-based NAS by estimating the true architecture performance with only training-free metrics. Nevertheless, the estimation ability of these metrics typically varies across different tasks, making it challenging to achieve robust and consistently good search performance on diverse tasks with only a single training-free metric. Meanwhile, the estimation gap between training-free metrics and the true architecture performances limits training-free NAS to achieve superior performance. To address these challenges, we propose the robustifying and boosting training-free NAS (RoBoT) algorithm which (a) employs the optimized combination of existing training-free metrics explored from Bayesian optimization to develop a robust and consistently better-performing metric on diverse tasks, and (b) applies greedy search, i.e., the exploitation, on the newly developed metric to bridge the aforementioned gap and consequently to boost the search performance of standard training-free NAS further. Remarkably, the expected performance of our RoBoT can be theoretically guaranteed, which improves over the existing training-free NAS under mild conditions with additional interesting insights. Our extensive experiments on various NAS benchmark tasks yield substantial empirical evidence to support our theoretical results."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f97ed936f6ee4c7934b224a81e86983a64344534.pdf"}, "supplementary_material": {"value": "/attachment/a1f2471e62d08b40b4ac63dcc78572dc7b83de88.zip"}, "TLDR": {"value": "The paper proposes a new NAS algorithm RoBoT to robustify existing training-free NAS and further boost them."}, "_bibtex": {"value": "@inproceedings{\nhe2024robustifying,\ntitle={Robustifying and Boosting Training-Free Neural Architecture Search},\nauthor={Zhenfeng He and Yao Shu and Zhongxiang Dai and Bryan Kian Hsiang Low},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qPloNoDJZn}\n}"}, "paperhash": {"value": "he|robustifying_and_boosting_trainingfree_neural_architecture_search"}}, "number": 6827, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6827/-/Revision", "ICLR.cc/2024/Conference/Submission6827/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6827/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441218493, "cdate": 1695441218493, "tmdate": 1710246611214, "mdate": 1710246611214, "pdate": 1705410988595, "version": 2}, {"id": "L9U5MJJleF", "forum": "L9U5MJJleF", "signatures": ["ICLR.cc/2024/Conference/Submission6823/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6823/Authors"], "content": {"title": {"value": "Concept Bottleneck Generative Models"}, "authors": {"value": ["Aya Abdelsalam Ismail", "Julius Adebayo", "Hector Corrada Bravo", "Stephen Ra", "Kyunghyun Cho"]}, "authorids": {"value": ["~Aya_Abdelsalam_Ismail1", "~Julius_Adebayo1", "~Hector_Corrada_Bravo1", "~Stephen_Ra1", "~Kyunghyun_Cho1"]}, "keywords": {"value": ["Interpretability", "generative models"]}, "TLDR": {"value": "We extend Concept bottleneck models to generative models."}, "abstract": {"value": "We introduce a generative model with an intrinsically interpretable layer---a concept bottleneck layer---that constrains the model to encode human-understandable concepts. The concept bottleneck layer partitions the generative model into three parts: the pre-concept bottleneck portion, the CB layer, and the post-concept bottleneck portion. To train CB generative models, we complement the traditional task-based loss function for training generative models with a concept loss and an orthogonality loss. The CB layer and these loss terms are model agnostic, which we demonstrate by applying the CB layer to three different families of generative models: generative adversarial networks, variational autoencoders, and diffusion models. On multiple datasets across different types of generative models, steering a generative model, with the CB layer, outperforms all baselines---in some cases, it is \\textit{10 times} more effective. In addition, we show how the CB layer can be used to interpret the output of the generative model and debug the model during or post training."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dad495929f0813c69425f15d346956d175a0567f.pdf"}, "supplementary_material": {"value": "/attachment/18d6c8c979e6fca094062c3d55655ab4dce53aff.zip"}, "_bibtex": {"value": "@inproceedings{\nismail2024concept,\ntitle={Concept Bottleneck Generative Models},\nauthor={Aya Abdelsalam Ismail and Julius Adebayo and Hector Corrada Bravo and Stephen Ra and Kyunghyun Cho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L9U5MJJleF}\n}"}, "paperhash": {"value": "ismail|concept_bottleneck_generative_models"}}, "number": 6823, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6823/-/Revision", "ICLR.cc/2024/Conference/Submission6823/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6823/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695441026143, "cdate": 1695441026143, "tmdate": 1712975027750, "mdate": 1712975027750, "pdate": 1705410988483, "version": 2}, {"id": "1vrS1zwekw", "forum": "1vrS1zwekw", "signatures": ["ICLR.cc/2024/Conference/Submission6820/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6820/Authors"], "content": {"title": {"value": "MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following"}, "authors": {"value": ["Renze Lou", "Kai Zhang", "Jian Xie", "Yuxuan Sun", "Janice Ahn", "Hanzi Xu", "Yu Su", "Wenpeng Yin"]}, "authorids": {"value": ["~Renze_Lou1", "~Kai_Zhang10", "~Jian_Xie3", "~Yuxuan_Sun3", "~Janice_Ahn1", "~Hanzi_Xu1", "~Yu_Su2", "~Wenpeng_Yin1"]}, "keywords": {"value": ["Instruction Tuning", "Large Language Models", "Automatic Data Generation"]}, "abstract": {"value": "In the realm of large language models (LLMs), enhancing instruction-following capability often involves curating expansive training data. This is achieved through two primary schemes: i) Scaling-Inputs: Amplifying (input, output) pairs per task instruction, aiming for better instruction adherence. ii) Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction, output) pair (without requiring a separate input anymore). However, LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs. This work introduces MUFFIN, a new scheme of instruction-following dataset curation. Specifically, we automatically Scale Tasks per Input by diversifying these tasks with various input facets. Experimental results across four zero-shot benchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes, reveal that LLMs, at various scales, trained on MUFFIN generally demonstrate superior instruction-following capabilities compared to those trained on the two aforementioned schemes."}, "pdf": {"value": "/pdf/cb21fdbe286222611b32d87c39a5f91de9bbc580.pdf"}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nlou2024muffin,\ntitle={{MUFFIN}: Curating Multi-Faceted Instructions for Improving Instruction Following},\nauthor={Renze Lou and Kai Zhang and Jian Xie and Yuxuan Sun and Janice Ahn and Hanzi Xu and Yu Su and Wenpeng Yin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1vrS1zwekw}\n}"}, "paperhash": {"value": "lou|muffin_curating_multifaceted_instructions_for_improving_instruction_following"}}, "number": 6820, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6820/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6820/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695440883918, "cdate": 1695440883918, "tmdate": 1710471826631, "mdate": 1710471826631, "pdate": 1705410988379, "version": 2}, {"id": "2JF8mJRJ7M", "forum": "2JF8mJRJ7M", "signatures": ["ICLR.cc/2024/Conference/Submission6807/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6807/Authors"], "content": {"title": {"value": "Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance"}, "authors": {"value": ["Giung Nam", "Byeongho Heo", "Juho Lee"]}, "authorids": {"value": ["~Giung_Nam1", "~Byeongho_Heo1", "~Juho_Lee2"]}, "keywords": {"value": ["computer vision", "vision-langauge model", "transfer learning", "fine-tuning", "distribution shifts"]}, "TLDR": {"value": "We propose a novel robust fine-tuning method tailored for vision-language models."}, "abstract": {"value": "Large-scale contrastive vision-language pre-trained models provide the zero-shot model achieving competitive performance across a range of image classification tasks without requiring training on downstream data. Recent works have confirmed that while additional fine-tuning of the zero-shot model on the reference data results in enhanced downstream performance, it compromises the model's robustness against distribution shifts. Our investigation begins by examining the conditions required to achieve the goals of robust fine-tuning, employing descriptions based on feature distortion theory and joint energy-based models. Subsequently, we propose a novel robust fine-tuning algorithm, Lipsum-FT, that effectively utilizes the language modeling aspect of the vision-language pre-trained models. Extensive experiments conducted on distribution shift scenarios in DomainNet and ImageNet confirm the superiority of our proposed Lipsum-FT approach over existing robust fine-tuning methods."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/14b8b0a78b23ac1bde62ba9ebae344a82107a3e7.pdf"}, "supplementary_material": {"value": "/attachment/f06d7c8550270c7566e73feb061af263396284a3.zip"}, "_bibtex": {"value": "@inproceedings{\nnam2024lipsumft,\ntitle={Lipsum-{FT}: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance},\nauthor={Giung Nam and Byeongho Heo and Juho Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2JF8mJRJ7M}\n}"}, "paperhash": {"value": "nam|lipsumft_robust_finetuning_of_zeroshot_models_using_random_text_guidance"}}, "number": 6807, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6807/-/Revision", "ICLR.cc/2024/Conference/Submission6807/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6807/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695440479149, "cdate": 1695440479149, "tmdate": 1710899779020, "mdate": 1710899779020, "pdate": 1705410987840, "version": 2}, {"id": "eY7sLb0dVF", "forum": "eY7sLb0dVF", "signatures": ["ICLR.cc/2024/Conference/Submission6799/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6799/Authors"], "content": {"title": {"value": "Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs"}, "authors": {"value": ["Ilan Naiman", "N. Benjamin Erichson", "Pu Ren", "Michael W. Mahoney", "Omri Azencot"]}, "authorids": {"value": ["~Ilan_Naiman1", "~N._Benjamin_Erichson1", "~Pu_Ren1", "~Michael_W._Mahoney1", "~Omri_Azencot1"]}, "keywords": {"value": ["Time Series Generation", "Koopman Theory; Variational Autoencoder; Generative Modeling"]}, "abstract": {"value": "Generating realistic time series data is important for many engineering and scientific applications. \nExisting work tackles this problem using generative adversarial networks (GANs).\nHowever, GANs are unstable during training, and they can suffer from mode collapse. \nWhile variational autoencoders (VAEs) are known to be more robust to the these issues, they are (surprisingly) less considered for time series generation. \nIn this work, we introduce Koopman VAE (KoVAE), a new generative framework that is based on a novel design for the model prior, and that can be optimized for either regular and irregular training data. \nInspired by Koopman theory, we represent the latent conditional prior dynamics using a linear map. \nOur approach enhances generative modeling with two desired features: (i) incorporating domain knowledge can be achieved by leveraging spectral tools that prescribe constraints on the eigenvalues of the linear map; and (ii) studying the qualitative behavior and stability of the system can be performed using tools from dynamical systems theory. \nOur results show that KoVAE outperforms state-of-the-art GAN and VAE methods across several challenging synthetic and real-world time series generation benchmarks. \nWhether trained on regular or irregular data, KoVAE generates time series that improve both discriminative and predictive metrics. \nWe also present visual evidence suggesting that KoVAE learns probability density functions that better approximate the empirical ground truth distribution."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We introduce Koopman VAE (KoVAE) for time series generation, which is based on a novel design for the model prior, and which can be optimized for either regular and irregular training data."}, "pdf": {"value": "/pdf/fb39133e3e34567def62064e0567dfe5b9e688b3.pdf"}, "_bibtex": {"value": "@inproceedings{\nnaiman2024generative,\ntitle={Generative Modeling of Regular and Irregular Time Series Data via Koopman {VAE}s},\nauthor={Ilan Naiman and N. Benjamin Erichson and Pu Ren and Michael W. Mahoney and Omri Azencot},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eY7sLb0dVF}\n}"}, "paperhash": {"value": "naiman|generative_modeling_of_regular_and_irregular_time_series_data_via_koopman_vaes"}}, "number": 6799, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6799/-/Revision", "ICLR.cc/2024/Conference/Submission6799/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6799/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695440112873, "cdate": 1695440112873, "tmdate": 1710096047244, "mdate": 1710096047244, "pdate": 1705410987600, "version": 2}, {"id": "yxKZGQLzOP", "forum": "yxKZGQLzOP", "signatures": ["ICLR.cc/2024/Conference/Submission6796/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6796/Authors"], "content": {"title": {"value": "Generating Pragmatic Examples to Train Neural Program Synthesizers"}, "authors": {"value": ["Saujas Vaduguru", "Daniel Fried", "Yewen Pu"]}, "authorids": {"value": ["~Saujas_Vaduguru1", "~Daniel_Fried1", "~Yewen_Pu1"]}, "keywords": {"value": ["program synthesis", "pragmatics", "self-play"]}, "TLDR": {"value": "Pragmatic program synthesis in a realistic program space without human supervision in training"}, "abstract": {"value": "Programming-by-example is the task of synthesizing a program that is consistent with a set of user-provided input-output examples. \nAs examples are often an under-specification of one's intent, a good synthesizer must choose the intended program from the many that are consistent with the given set of examples. Prior work frames program synthesis as a cooperative game between a listener (that synthesizes programs) and a speaker (a user choosing examples), and shows that models of computational pragmatic inference are effective in choosing the user intended programs. However, these models require counterfactual reasoning over a large set of programs and examples, which is infeasible in realistic program spaces. In this paper, we propose PraX, a novel way to amortize this search with neural networks. We sample pairs of programs and examples via self-play between listener and speaker models, and use pragmatic inference to choose informative training examples from this sample. We then use the informative dataset to train models to improve the synthesizer's ability to disambiguate user-provided examples _without human supervision_. We validate PraX on the challenging task of synthesizing regular expressions from example strings, and find that our method (1) outperforms models trained without choosing pragmatic examples by 23% (a 51% relative increase) (2) matches the performance of supervised learning on a dataset of pragmatic examples provided by humans, despite using no human data in training."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4f3d3262b64cbcf71bd096e5b1b8cb05434eab92.pdf"}, "supplementary_material": {"value": "/attachment/b2b14cc63a89dc796fd98253199156544d204a01.zip"}, "_bibtex": {"value": "@inproceedings{\nvaduguru2024generating,\ntitle={Generating Pragmatic Examples to Train Neural Program Synthesizers},\nauthor={Saujas Vaduguru and Daniel Fried and Yewen Pu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yxKZGQLzOP}\n}"}, "paperhash": {"value": "vaduguru|generating_pragmatic_examples_to_train_neural_program_synthesizers"}}, "number": 6796, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6796/-/Revision", "ICLR.cc/2024/Conference/Submission6796/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6796/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695440057836, "cdate": 1695440057836, "tmdate": 1712850820140, "mdate": 1712850820140, "pdate": 1705410987536, "version": 2}, {"id": "Pe2lo3QOvo", "forum": "Pe2lo3QOvo", "signatures": ["ICLR.cc/2024/Conference/Submission6791/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6791/Authors"], "content": {"title": {"value": "Making RL with Preference-based Feedback Efficient via Randomization"}, "authors": {"value": ["Runzhe Wu", "Wen Sun"]}, "authorids": {"value": ["~Runzhe_Wu1", "~Wen_Sun1"]}, "keywords": {"value": ["reinforcement learning", "preference-based feedback", "theory", "active learning", "posterior sampling"]}, "abstract": {"value": "Reinforcement Learning algorithms that learn from human feedback (RLHF) need to be efficient in terms of *statistical complexity, computational complexity, and query complexity*. In this work, we consider the RLHF setting where the feedback is given in the format of preferences over pairs of trajectories. In the linear MDP model, using randomization in algorithm design, we present an algorithm that is sample efficient (i.e., has near-optimal worst-case regret bounds) and has polynomial running time (i.e., computational complexity is polynomial with respect to relevant parameters). Our algorithm further minimizes the query complexity through a novel randomized active learning procedure. In particular, our algorithm demonstrates a near-optimal tradeoff between the regret bound and the query complexity. To extend the results to more general nonlinear function approximation, we design a model-based randomized algorithm inspired by the idea of Thompson sampling. Our algorithm minimizes Bayesian regret bound and query complexity, again achieving a near-optimal tradeoff between these two quantities. Computation-wise, similar to the prior Thompson sampling algorithms under the regular RL setting, the main computation primitives of our algorithm are Bayesian supervised learning oracles which have been heavily investigated on the empirical side when applying Thompson sampling algorithms to RL benchmark problems."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b301dd87a8571ef6107196d69fbc3b48500d9855.pdf"}, "supplementary_material": {"value": "/attachment/46b146bdee8975568a261fcbfc355687aada35bd.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024making,\ntitle={Making {RL} with Preference-based Feedback Efficient via Randomization},\nauthor={Runzhe Wu and Wen Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Pe2lo3QOvo}\n}"}, "paperhash": {"value": "wu|making_rl_with_preferencebased_feedback_efficient_via_randomization"}}, "number": 6791, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6791/-/Revision", "ICLR.cc/2024/Conference/Submission6791/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6791/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695439848196, "cdate": 1695439848196, "tmdate": 1710279740803, "mdate": 1710279740803, "pdate": 1705410987281, "version": 2}, {"id": "AY9KyTGcnk", "forum": "AY9KyTGcnk", "signatures": ["ICLR.cc/2024/Conference/Submission6783/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6783/Authors"], "content": {"title": {"value": "Adaptive Regret for Bandits Made Possible: Two Queries Suffice"}, "authors": {"value": ["Zhou Lu", "Qiuyi Zhang", "Xinyi Chen", "Fred Zhang", "David Woodruff", "Elad Hazan"]}, "authorids": {"value": ["~Zhou_Lu1", "~Qiuyi_Zhang1", "~Xinyi_Chen1", "~Fred_Zhang1", "~David_Woodruff1", "~Elad_Hazan1"]}, "keywords": {"value": ["adaptive regret", "multi arm bandit"]}, "abstract": {"value": "Fast changing states or volatile environments pose a significant challenge to online optimization, which needs to perform rapid adaptation under limited observation. In this paper, we give query and regret optimal bandit algorithms under the strict notion of strongly adaptive regret, which measures the maximum regret over any contiguous interval  $I$. Due to its worst-case nature, there is an almost-linear $\\Omega(|I|^{1-\\epsilon})$ regret lower bound, when only one query per round is allowed [Daniely el al, ICML 2015]. Surprisingly, with just two queries per round, we give Strongly Adaptive Bandit Learner (StABL) that achieves $\\widetilde{O}(\\sqrt{n|I|})$ adaptive regret for multi-armed bandits with $n$ arms. The bound is tight and  cannot be improved in general. Our algorithm leverages a  multiplicative update scheme of varying stepsizes and a carefully chosen observation distribution to control the variance. Furthermore, we extend our results and provide optimal algorithms in the bandit convex optimization setting. Finally, we empirically demonstrate the superior performance of our algorithms under volatile environments and for downstream tasks, such as algorithm selection for hyperparameter optimization."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e11fe2085a7c3fadc1c5f729f6c77062a6d49331.pdf"}, "supplementary_material": {"value": "/attachment/7a031b522a5172e1fbc1beb205c51f0e9e9d3f39.pdf"}, "_bibtex": {"value": "@inproceedings{\nlu2024adaptive,\ntitle={Adaptive Regret for Bandits Made Possible: Two Queries Suffice},\nauthor={Zhou Lu and Qiuyi Zhang and Xinyi Chen and Fred Zhang and David Woodruff and Elad Hazan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AY9KyTGcnk}\n}"}, "paperhash": {"value": "lu|adaptive_regret_for_bandits_made_possible_two_queries_suffice"}}, "number": 6783, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6783/-/Revision", "ICLR.cc/2024/Conference/Submission6783/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695439504698, "cdate": 1695439504698, "tmdate": 1707625635096, "mdate": 1707625635096, "pdate": 1705410987012, "version": 2}, {"id": "iAW2EQXfwb", "forum": "iAW2EQXfwb", "signatures": ["ICLR.cc/2024/Conference/Submission6772/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6772/Authors"], "content": {"title": {"value": "Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation"}, "authors": {"value": ["Ziqi Wang", "Chengpeng Hu", "Jialin Liu", "Xin Yao"]}, "authorids": {"value": ["~Ziqi_Wang7", "~Chengpeng_Hu1", "~Jialin_Liu4", "~Xin_Yao1"]}, "keywords": {"value": ["Level Generation", "Video Games", "Deep Reinforcement Learning", "Ensemble Learning", "Regularisation"]}, "TLDR": {"value": "This paper proposes a regularised ensemble reinforcement learning approach with policy regularisation theorems to train generators that generates diverse and promising game levels in real-time."}, "abstract": {"value": "Deep reinforcement learning has recently been successfully applied to online procedural content generation in which a policy determines promising game-level segments.  However, existing methods can hardly discover diverse level patterns, while the lack of diversity makes the gameplay boring. This paper proposes an ensemble reinforcement learning approach that uses multiple negatively correlated sub-policies to generate different alternative level segments, and stochastically selects one of them following a selector model. A novel policy regularisation technique is integrated into the approach to diversify the generated alternatives. In addition, we develop theorems to provide general methodologies for optimising policy regularisation in a Markov decision process. The proposed approach is compared with several state-of-the-art policy ensemble methods and classic methods on a well-known level generation benchmark, with two different reward functions expressing game-design goals from different perspectives. Results show that our approach boosts level diversity notably with competitive performance in terms of the reward.  Furthermore, by varying the regularisation coefficient, the trained generators form a well-spread Pareto front, allowing explicit trade-offs between diversity and rewards of generated levels."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/528d772d8756cd47e712f18946afd4c36d3dfb76.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024negatively,\ntitle={Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation},\nauthor={Ziqi Wang and Chengpeng Hu and Jialin Liu and Xin Yao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iAW2EQXfwb}\n}"}, "paperhash": {"value": "wang|negatively_correlated_ensemble_reinforcement_learning_for_online_diverse_game_level_generation"}}, "number": 6772, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6772/-/Revision", "ICLR.cc/2024/Conference/Submission6772/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6772/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695438972053, "cdate": 1695438972053, "tmdate": 1710903445161, "mdate": 1710903445161, "pdate": 1705410986533, "version": 2}, {"id": "MOmqfJovQ6", "forum": "MOmqfJovQ6", "signatures": ["ICLR.cc/2024/Conference/Submission6769/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6769/Authors"], "content": {"title": {"value": "Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping"}, "authors": {"value": ["Yining Li", "Peizhong Ju", "Ness Shroff"]}, "authorids": {"value": ["~Yining_Li3", "~Peizhong_Ju1", "~Ness_Shroff1"]}, "keywords": {"value": ["reinforcement learning", "abstraction"]}, "abstract": {"value": "Reinforcement learning often needs to deal with the exponential growth of states and actions when exploring optimal control in high-dimensional spaces (often known as the curse of dimensionality). In this work, we address this issue by learning the inherent structure of action-wise similar MDP to appropriately balance the performance degradation versus sample/computational complexity.  In particular, we partition the action spaces into multiple groups based on the similarity in transition distribution and reward function, and build a linear decomposition model to capture the difference between the intra-group transition kernel and the intra-group rewards. Both our theoretical analysis and experiments reveal a *surprising and counter-intuitive result*: while a more refined grouping strategy can reduce the approximation error caused by treating actions in the same group as identical, it also leads to increased estimation error when the size of samples or the computation resources is limited. This finding highlights the grouping strategy as a new degree of freedom that can be optimized to minimize the overall performance loss. To address this issue, we formulate a general optimization problem for determining the optimal grouping strategy, which strikes a balance between performance loss and sample/computational complexity. We further propose a computationally efficient method for selecting a nearly-optimal grouping strategy, which maintains its computational complexity independent of the size of the action space."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/eeafc70620abb8c937abf1608fb8f981f5559532.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024achieving,\ntitle={Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping},\nauthor={Yining Li and Peizhong Ju and Ness Shroff},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MOmqfJovQ6}\n}"}, "paperhash": {"value": "li|achieving_sample_and_computational_efficient_reinforcement_learning_by_action_space_reduction_via_grouping"}}, "number": 6769, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6769/-/Revision", "ICLR.cc/2024/Conference/Submission6769/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6769/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695438756185, "cdate": 1695438756185, "tmdate": 1709847650458, "mdate": 1709847650458, "pdate": 1705410986486, "version": 2}, {"id": "QgwAYFrh9t", "forum": "QgwAYFrh9t", "signatures": ["ICLR.cc/2024/Conference/Submission6768/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6768/Authors"], "content": {"title": {"value": "Learning Hierarchical Polynomials with Three-Layer Neural Networks"}, "authors": {"value": ["Zihao Wang", "Eshaan Nichani", "Jason D. Lee"]}, "authorids": {"value": ["~Zihao_Wang25", "~Eshaan_Nichani1", "~Jason_D._Lee1"]}, "keywords": {"value": ["Hierarchical polynomials", "feature learning", "three-layer networks", "sample complexity", "gradient descent"]}, "abstract": {"value": "We study the problem of learning hierarchical polynomials over the standard Gaussian distribution with three-layer neural networks. We specifically consider target functions of the form $h = g \\circ p$ where $p : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is a degree $k$ polynomial and $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ is a degree $q$ polynomial. This function class generalizes the single-index model, which corresponds to $k=1$, and is a natural class of functions possessing an underlying hierarchical structure. Our main result shows that for a large subclass of degree $k$ polynomials $p$, a three-layer neural network trained via layerwise gradient descent on the square loss learns the target $h$ up to vanishing test error in $\\widetilde O(d^k)$ samples and polynomial time. This is a strict improvement over kernel methods, which require $\\widetilde \\Theta(d^{kq})$ samples, as well as existing guarantees for two-layer networks, which require the target function to be low-rank. Our result also generalizes prior works on three-layer neural networks, which were restricted to the case of $p$ being a quadratic. When $p$ is indeed a quadratic, we achieve the information-theoretically optimal sample complexity $\\widetilde O(d^2)$, which is an improvement over prior work (Nichani et al., 2023) requiring a sample size of $\\widetilde\\Theta(d^4)$. Our proof proceeds by showing that during the initial stage of training the network performs feature learning to recover the feature $p$ with $\\widetilde O(d^k)$ samples. This work demonstrates the ability of three-layer neural networks to learn complex features and as a result, learn a broad class of hierarchical functions."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/345e76db40c6a456fddcfd882c336b91fdaa4019.pdf"}, "TLDR": {"value": "We show that three-layer neural networks learn hierarchical polynomials of the form $h = g \\circ p$, where $p : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is a degree $k$ polynomial, in $\\widetilde O(d^k)$ samples."}, "_bibtex": {"value": "@inproceedings{\nwang2024learning,\ntitle={Learning Hierarchical Polynomials with Three-Layer Neural Networks},\nauthor={Zihao Wang and Eshaan Nichani and Jason D. Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QgwAYFrh9t}\n}"}, "paperhash": {"value": "wang|learning_hierarchical_polynomials_with_threelayer_neural_networks"}}, "number": 6768, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6768/-/Revision", "ICLR.cc/2024/Conference/Submission6768/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6768/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695438659180, "cdate": 1695438659180, "tmdate": 1710255297829, "mdate": 1710255297829, "pdate": 1705410986411, "version": 2}, {"id": "qJ0Cfj4Ex9", "forum": "qJ0Cfj4Ex9", "signatures": ["ICLR.cc/2024/Conference/Submission6756/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6756/Authors"], "content": {"title": {"value": "Learning Grounded Action Abstractions from Language"}, "authors": {"value": ["Lionel Wong", "Jiayuan Mao", "Pratyusha Sharma", "Zachary S Siegel", "Jiahai Feng", "Noa Korneev", "Joshua B. Tenenbaum", "Jacob Andreas"]}, "authorids": {"value": ["~Lionel_Wong1", "~Jiayuan_Mao1", "~Pratyusha_Sharma1", "~Zachary_S_Siegel1", "~Jiahai_Feng1", "~Noa_Korneev1", "~Joshua_B._Tenenbaum1", "~Jacob_Andreas1"]}, "keywords": {"value": ["planning abstractions", "hierarchical planning", "library learning", "learning from language"]}, "TLDR": {"value": "We learn libraries of \\textit{grounded action abstractions} from language that support efficient hierarchical planning in interactive environments."}, "abstract": {"value": "Effective planning in the real world requires not only world knowledge, but the ability to leverage that knowledge to build the right representation of the task at hand. Decades of hierarchical planning techniques have used domain-specific temporal action abstractions to support efficient and accurate planning, almost always relying on human priors and domain knowledge to decompose hard tasks into smaller subproblems appropriate for a goal or set of goals. This paper describes Ada (Action Domain Acquisition), a framework for automatically constructing task-specific planning representations using task-general background knowledge from language models (LMs). Starting with a general-purpose hierarchical planner and a low-level goal-conditioned policy, Ada interactively learns a library of planner-compatible high-level action abstractions and low-level controllers adapted to a particular domain of planning tasks. On two language-guided interactive planning benchmarks (Mini Minecraft and ALFRED Household Tasks), Ada strongly outperforms other approaches that use LMs for sequential decision-making, offering more accurate plans and better generalization to complex tasks."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a3faff925f168054618a2b0ebb461d4ecb3867f9.pdf"}, "_bibtex": {"value": "@inproceedings{\nwong2024learning,\ntitle={Learning Grounded Action Abstractions from Language},\nauthor={Lionel Wong and Jiayuan Mao and Pratyusha Sharma and Zachary S Siegel and Jiahai Feng and Noa Korneev and Joshua B. Tenenbaum and Jacob Andreas},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qJ0Cfj4Ex9}\n}"}, "paperhash": {"value": "wong|learning_grounded_action_abstractions_from_language"}}, "number": 6756, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6756/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6756/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695438110330, "cdate": 1695438110330, "tmdate": 1710456752588, "mdate": 1710456752588, "pdate": 1705410986050, "version": 2}, {"id": "BEH4mGo7zP", "forum": "BEH4mGo7zP", "signatures": ["ICLR.cc/2024/Conference/Submission6755/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6755/Authors"], "content": {"title": {"value": "Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning"}, "authors": {"value": ["Youhan Lee", "Hasun Yu", "Jaemyung Lee", "Jaehoon Kim"]}, "authorids": {"value": ["~Youhan_Lee1", "~Hasun_Yu2", "~Jaemyung_Lee1", "~Jaehoon_Kim1"]}, "keywords": {"value": ["Protein representation learning", "self-supervised learning", "implicit neural representation"]}, "abstract": {"value": "Proteins can be represented in various ways, including their sequences, 3D structures, and surfaces. While recent studies have successfully employed sequence- or structure-based representations to address multiple tasks in protein science, there has been significant oversight in incorporating protein surface information, a critical factor for protein function. In this paper, we present a pre-training strategy that incorporates information from protein sequences, 3D structures, and surfaces to improve protein representation learning. Specifically, we utilize Implicit Neural Representations (INRs) for learning surface characteristics, and name it ProteinINR. We confirm that ProteinINR successfully reconstructs protein surfaces, and integrate this surface learning into the existing pre-training strategy of sequences and structures. Our results demonstrate that our approach can enhance performance in various downstream tasks, thereby underscoring the importance of including surface attributes in protein representation learning. These findings underline the importance of understanding protein surfaces for generating effective protein representations."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d85441e5f968c9ae883e09ec5a06e9f9eda773c2.pdf"}, "TLDR": {"value": "We describe a new pre-training approach for protein representation learning using generalizable implicit neural networks on protein molecular surfaces, showing SOTA results for various tasks."}, "_bibtex": {"value": "@inproceedings{\nlee2024pretraining,\ntitle={Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning},\nauthor={Youhan Lee and Hasun Yu and Jaemyung Lee and Jaehoon Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BEH4mGo7zP}\n}"}, "paperhash": {"value": "lee|pretraining_sequence_structure_and_surface_features_for_comprehensive_protein_representation_learning"}}, "number": 6755, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6755/-/Revision", "ICLR.cc/2024/Conference/Submission6755/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6755/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695438107751, "cdate": 1695438107751, "tmdate": 1709661534242, "mdate": 1709661534242, "pdate": 1705410986007, "version": 2}, {"id": "H396R79GiQ", "forum": "H396R79GiQ", "signatures": ["ICLR.cc/2024/Conference/Submission6743/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6743/Authors"], "content": {"title": {"value": "A unique M-pattern for micro-expression spotting in long videos"}, "authors": {"value": ["Jinxuan Wang", "Shiting Xu", "Tong Zhang"]}, "authorids": {"value": ["~Jinxuan_Wang1", "~Shiting_Xu2", "~Tong_Zhang14"]}, "keywords": {"value": ["Micro-expression spotting", "Optical flow", "Facial alignment"]}, "abstract": {"value": "Micro-expression spotting (MES) is challenging since the small magnitude of micro-expression (ME) makes them susceptible to global movements like head rotation. However, the unique movement pattern and inherent characteristics of ME allow them to be distinguished from other movements. Existing MES methods based on fixed reference frame degrade optical flow accuracy and are overly dependent on facial alignment. In this paper, we propose a skip-$k$-frame block-wise main directional mean optical flow (MDMO) feature for MES based on unfixed reference frame. By employing skip-$k$-frame strategy, we substantiate the existence of a distinct and exclusive movement pattern in ME, called M-pattern due to its feature curve resembling the letter `M'. Based on M-pattern and characteristics of ME, we then provide a novel spotting rules to precisely locate ME intervals. Block-wise MDMO feature is capable of removing global movements without compromising complete ME movements in the early feature extraction stage. Besides, A novel pixelmatch-based facial alignment algorithm with dynamic update of reference frame is proposed to better align facial images and reduce jitter between frames. Experimental results on CAS(ME)$^2$, SAMM-LV and CASME II validate the proposed methods are superior to the state-of-the-art methods."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/07a298c6706ad96d8ea465374268994c1caf8701.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024a,\ntitle={A unique M-pattern for micro-expreesion spotting in long videos},\nauthor={Jinxuan Wang and Shiting Xu and Tong Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=H396R79GiQ}\n}"}, "paperhash": {"value": "wang|a_unique_mpattern_for_microexpression_spotting_in_long_videos"}}, "number": 6743, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6743/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6743/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695437639773, "cdate": 1695437639773, "tmdate": 1710298612441, "mdate": 1710298612441, "pdate": 1705410985737, "version": 2}, {"id": "YcM6ofShwY", "forum": "YcM6ofShwY", "signatures": ["ICLR.cc/2024/Conference/Submission6736/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6736/Authors"], "content": {"title": {"value": "BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference"}, "authors": {"value": ["Siqi Kou", "Lei Gan", "Dequan Wang", "Chongxuan Li", "Zhijie Deng"]}, "authorids": {"value": ["~Siqi_Kou1", "~Lei_Gan1", "~Dequan_Wang1", "~Chongxuan_Li1", "~Zhijie_Deng1"]}, "keywords": {"value": ["diffusion model", "Bayesian uncertainty"]}, "abstract": {"value": "Diffusion models have impressive image generation capability, but low-quality generations still exist, and their identification remains challenging due to the lack of a proper sample-wise metric. To address this, we propose BayesDiff, a pixel-wise uncertainty estimator for generations from diffusion models based on Bayesian inference. In particular, we derive a novel uncertainty iteration principle to characterize the uncertainty dynamics in diffusion, and leverage the last-layer Laplace approximation for efficient Bayesian inference. The estimated pixel-wise uncertainty can not only be aggregated into a sample-wise metric to filter out low-fidelity images but also aids in augmenting successful generations and rectifying artifacts in failed generations in text-to-image tasks. Extensive experiments demonstrate the efficacy of BayesDiff and its promise for practical applications."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a89f50009d9d43c9ab257ef46f36abf04f1c05a4.pdf"}, "supplementary_material": {"value": "/attachment/abd4368a46d6fb1226d7e99d84cb272059855984.zip"}, "_bibtex": {"value": "@inproceedings{\nkou2024bayesdiff,\ntitle={BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference},\nauthor={Siqi Kou and Lei Gan and Dequan Wang and Chongxuan Li and Zhijie Deng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YcM6ofShwY}\n}"}, "paperhash": {"value": "kou|bayesdiff_estimating_pixelwise_uncertainty_in_diffusion_via_bayesian_inference"}}, "number": 6736, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6736/-/Revision", "ICLR.cc/2024/Conference/Submission6736/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6736/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695437277082, "cdate": 1695437277082, "tmdate": 1709661534056, "mdate": 1709661534056, "pdate": 1705410985159, "version": 2}, {"id": "thbtoAkCe9", "forum": "thbtoAkCe9", "signatures": ["ICLR.cc/2024/Conference/Submission6731/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6731/Authors"], "content": {"title": {"value": "$\\mathbb{D}^2$ Pruning: Message Passing for Balancing Diversity & Difficulty in Data Pruning"}, "authors": {"value": ["Adyasha Maharana", "Prateek Yadav", "Mohit Bansal"]}, "authorids": {"value": ["~Adyasha_Maharana1", "~Prateek_Yadav1", "~Mohit_Bansal2"]}, "keywords": {"value": ["coreset selection", "data pruning", "data", "graph", "message passing", "data distillation"]}, "abstract": {"value": "In recent years, data quality has emerged as an important factor for training massive models. Analytical theories suggest that higher-quality data can lead to lower test errors in models trained on a fixed data budget. Moreover, a model can be trained on a lower compute budget without compromising performance if a dataset can be stripped of its redundancies. Coreset selection (or data pruning) seeks to select a subset of the training data so as to maximize the performance of models trained on this subset, also referred to as coreset. There are two dominant approaches: (1) geometry-based data selection for maximizing *data diversity* in the coreset, and (2) functions that assign *difficulty scores* to samples based on training dynamics. Optimizing for data diversity leads to a coreset that is biased towards easier samples, whereas, selection by difficulty ranking omits easy samples that are necessary for the training of deep learning models. This demonstrates that data diversity and importance scores are two complementary factors that need to be jointly considered during coreset selection. In this work, we represent a dataset as an undirected graph and propose a novel pruning algorithm, $\\mathbb{D}^2$ Pruning, that uses message passing over this dataset graph for coreset selection. $\\mathbb{D}^2$ Pruning updates the difficulty scores of each example by incorporating the difficulty of its neighboring examples in the dataset graph. Then, these updated difficulty scores direct a graph-based sampling method to select a coreset that encapsulates both diverse and difficult regions of the dataset space. We evaluate supervised and self-supervised versions of our method on various vision and NLP datasets. Results show that $\\mathbb{D}^2$ Pruning improves coreset selection over previous state-of-the-art methods at low-to-medium pruning rates. Additionally, we find that using $\\mathbb{D}^2$ Pruning for filtering large multimodal datasets leads to increased diversity in the dataset and improved generalization of pretrained models. Our work shows that $\\mathbb{D}^2$ Pruning is a versatile framework for understanding and processing datasets."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/411967173bd4d8a9da1c3aa80b7fb6843c9f1a1d.pdf"}, "_bibtex": {"value": "@inproceedings{\nmaharana2024mathbbd,\ntitle={\\${\\textbackslash}mathbb\\{D\\}{\\textasciicircum}2\\$ Pruning: Message Passing for Balancing Diversity \\& Difficulty in Data Pruning},\nauthor={Adyasha Maharana and Prateek Yadav and Mohit Bansal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=thbtoAkCe9}\n}"}, "paperhash": {"value": "maharana|\\mathbbd^2_pruning_message_passing_for_balancing_diversity_difficulty_in_data_pruning"}}, "number": 6731, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6731/-/Revision", "ICLR.cc/2024/Conference/Submission6731/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6731/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695437097644, "cdate": 1695437097644, "tmdate": 1710571305913, "mdate": 1710571305913, "pdate": 1705410984896, "version": 2}, {"id": "tVTN7Zs0ml", "forum": "tVTN7Zs0ml", "signatures": ["ICLR.cc/2024/Conference/Submission6728/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6728/Authors"], "content": {"title": {"value": "GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs"}, "authors": {"value": ["Pengcheng Jiang", "Cao Xiao", "Adam Richard Cross", "Jimeng Sun"]}, "authorids": {"value": ["~Pengcheng_Jiang2", "~Cao_Xiao2", "~Adam_Richard_Cross1", "~Jimeng_Sun3"]}, "keywords": {"value": ["EHR Prediction", "Personalized Knowledge Graph", "Graph Neural Network"]}, "abstract": {"value": "Clinical predictive models often rely on patients\u2019 electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledge\ngraphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GraphCare, an open-world framework that uses external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to build patient-specific KGs, which are then used to train our proposed Bi-attention AugmenTed\n(BAT) graph neural network (GNN) for healthcare predictions. On two public datasets, MIMIC-III and MIMIC-IV, GraphCare surpasses baselines in four vital healthcare prediction tasks: mortality, readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it boosts AUROC by 17.6% and 6.6% for mortality and readmission, and F1-score by 7.9% and 10.8% for LOS and drug recommendation, respectively. Notably, GraphCare demonstrates a substantial edge in scenarios with limited data availability. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GraphCare in generating personalized KGs for promoting personalized medicine."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9d4b1861dcc34e0a1a44adb87b0002e33c8d03e6.pdf"}, "supplementary_material": {"value": "/attachment/98c33106aa6c6bf822c59700ab7bd6860f1e0dd2.zip"}, "_bibtex": {"value": "@inproceedings{\njiang2024graphcare,\ntitle={GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs},\nauthor={Pengcheng Jiang and Cao Xiao and Adam Richard Cross and Jimeng Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tVTN7Zs0ml}\n}"}, "paperhash": {"value": "jiang|graphcare_enhancing_healthcare_predictions_with_personalized_knowledge_graphs"}}, "number": 6728, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6728/-/Revision", "ICLR.cc/2024/Conference/Submission6728/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6728/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436918536, "cdate": 1695436918536, "tmdate": 1710477760198, "mdate": 1710477760198, "pdate": 1705410984844, "version": 2}, {"id": "s5hSp7EdL3", "forum": "s5hSp7EdL3", "signatures": ["ICLR.cc/2024/Conference/Submission6724/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6724/Authors"], "content": {"title": {"value": "The Human-AI Substitution game: active learning from a strategic labeler"}, "authors": {"value": ["Tom Yan", "Chicheng Zhang"]}, "authorids": {"value": ["~Tom_Yan1", "~Chicheng_Zhang1"]}, "keywords": {"value": ["active learning", "strategic learning"]}, "abstract": {"value": "The standard active learning setting assumes a willing labeler, who provides labels on informative examples to speed up learning. However, if the labeler wishes to be compensated for as many labels as possible before learning finishes, the labeler may benefit from actually slowing down learning. This incentive arises for instance if the labeler is to be replaced by the ML model once it is trained. In this paper, we initiate the study of learning from a strategic labeler, who may abstain from labeling to slow down learning. We first prove that strategic abstention can prolong learning, and propose a novel complexity measure and representation to analyze the query complexity of the learning game. Next, we develop a near-optimal deterministic algorithm, prove its robustness to strategic labeling, and contrast it with other active learning algorithms. We also analyze extensions that encompass more general learning goals and labeler assumptions. Finally, we characterize the query cost of multi-task active learning, with and without abstention. Our first exploration of strategic labeling aims to consolidate our theoretical understanding of the \\emph{imitative} nature of ML in human-AI interaction."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5d843ae529fbc65e713b48e10257d9d17ba3535f.pdf"}, "supplementary_material": {"value": "/attachment/1bba04ff11cd8d28185684595e8b934210b3f510.pdf"}, "_bibtex": {"value": "@inproceedings{\nyan2024the,\ntitle={The Human-{AI} Substitution game: active learning from a strategic labeler},\nauthor={Tom Yan and Chicheng Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=s5hSp7EdL3}\n}"}, "paperhash": {"value": "yan|the_humanai_substitution_game_active_learning_from_a_strategic_labeler"}}, "number": 6724, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6724/-/Revision", "ICLR.cc/2024/Conference/Submission6724/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6724/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436786099, "cdate": 1695436786099, "tmdate": 1713147037967, "mdate": 1713147037967, "pdate": 1705410984761, "version": 2}, {"id": "UfBIxpTK10", "forum": "UfBIxpTK10", "signatures": ["ICLR.cc/2024/Conference/Submission6722/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6722/Authors"], "content": {"title": {"value": "Deep Confident Steps to New Pockets: Strategies for Docking Generalization"}, "authors": {"value": ["Gabriele Corso", "Arthur Deng", "Nicholas Polizzi", "Regina Barzilay", "Tommi S. Jaakkola"]}, "authorids": {"value": ["~Gabriele_Corso1", "~Arthur_Deng1", "~Nicholas_Polizzi1", "~Regina_Barzilay1", "~Tommi_S._Jaakkola1"]}, "keywords": {"value": ["generalization", "molecular docking", "protein-ligand binding", "diffusion models", "benchmark", "bootstrapping", "self-training"]}, "TLDR": {"value": "A new benchmark to test docking generalization and a novel self-training technique to learn without access to data"}, "abstract": {"value": "Accurate blind docking has the potential to lead to new biological breakthroughs, but for this promise to be realized, docking methods must generalize well across the proteome. Existing benchmarks, however, fail to rigorously assess generalizability. Therefore, we develop DockGen, a new benchmark based on the ligand-binding domains of proteins, and we show that existing machine learning-based docking models have very weak generalization abilities. We carefully analyze the scaling laws of ML-based docking and show that, by scaling data and model size, as well as integrating synthetic data strategies, we are able to significantly increase the generalization capacity and set new state-of-the-art performance across benchmarks.  Further, we propose Confidence Bootstrapping, a new training paradigm that solely relies on the interaction between diffusion and confidence models and exploits the multi-resolution generation process of diffusion models. We demonstrate that Confidence Bootstrapping significantly improves the ability of ML-based docking methods to dock to unseen protein classes, edging closer to accurate and generalizable blind docking methods."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6482d88857d6eb089f7b4a5808e73ee7180fa42e.pdf"}, "_bibtex": {"value": "@inproceedings{\ncorso2024the,\ntitle={The Discovery of Binding Modes Requires Rethinking Docking Generalization},\nauthor={Gabriele Corso and Arthur Deng and Nicholas Polizzi and Regina Barzilay and Tommi S. Jaakkola},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UfBIxpTK10}\n}"}, "paperhash": {"value": "corso|deep_confident_steps_to_new_pockets_strategies_for_docking_generalization"}}, "number": 6722, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6722/-/Revision", "ICLR.cc/2024/Conference/Submission6722/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6722/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436724353, "cdate": 1695436724353, "tmdate": 1710382523656, "mdate": 1710382523656, "pdate": 1705410984718, "version": 2}, {"id": "mqVgBbNCm9", "forum": "mqVgBbNCm9", "signatures": ["ICLR.cc/2024/Conference/Submission6721/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6721/Authors"], "content": {"title": {"value": "Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation"}, "authors": {"value": ["Xuefei Ning", "Zinan Lin", "Zixuan Zhou", "Zifu Wang", "Huazhong Yang", "Yu Wang"]}, "authorids": {"value": ["~Xuefei_Ning1", "~Zinan_Lin1", "~Zixuan_Zhou2", "~Zifu_Wang1", "~Huazhong_Yang2", "~Yu_Wang3"]}, "keywords": {"value": ["large language model", "efficient inference", "data-centric optimization", "parallel generation", "prompt engineering", "planning"]}, "TLDR": {"value": "As a data-centric efficiency technique, SoT decreases the generation latency by guiding the LLM itself to organize the output data and generate multiple segments in parallel."}, "abstract": {"value": "This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose Skeleton-of-Thought (SoT), which first guides LLMs to generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-ups across 12 LLMs, but it can also potentially improve the answer quality on several question categories. SoT is an initial attempt at data-centric optimization for inference efficiency, and showcases the potential of eliciting high-quality answers by explicitly planning the answer structure in language."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/adbc638bac7059e2103c1b7a8d9774891dd76fa8.pdf"}, "supplementary_material": {"value": "/attachment/c0b74bdcf243b7a56b7186cd99073d2d5e4a2ff6.zip"}, "_bibtex": {"value": "@inproceedings{\nning2024skeletonofthought,\ntitle={Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding},\nauthor={Xuefei Ning and Zinan Lin and Zixuan Zhou and Zifu Wang and Huazhong Yang and Yu Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mqVgBbNCm9}\n}"}, "paperhash": {"value": "ning|skeletonofthought_prompting_llms_for_efficient_parallel_generation"}}, "number": 6721, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6721/-/Revision", "ICLR.cc/2024/Conference/Submission6721/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6721/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436657620, "cdate": 1695436657620, "tmdate": 1710514223718, "mdate": 1710514223718, "pdate": 1705410984685, "version": 2}, {"id": "gzqrANCF4g", "forum": "gzqrANCF4g", "signatures": ["ICLR.cc/2024/Conference/Submission6714/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6714/Authors"], "content": {"title": {"value": "Language Model Beats Diffusion - Tokenizer is key to visual generation"}, "authors": {"value": ["Lijun Yu", "Jose Lezama", "Nitesh Bharadwaj Gundavarapu", "Luca Versari", "Kihyuk Sohn", "David Minnen", "Yong Cheng", "Agrim Gupta", "Xiuye Gu", "Alexander G Hauptmann", "Boqing Gong", "Ming-Hsuan Yang", "Irfan Essa", "David A Ross", "Lu Jiang"]}, "authorids": {"value": ["~Lijun_Yu1", "~Jose_Lezama1", "~Nitesh_Bharadwaj_Gundavarapu1", "~Luca_Versari1", "~Kihyuk_Sohn1", "~David_Minnen1", "~Yong_Cheng3", "~Agrim_Gupta1", "~Xiuye_Gu1", "~Alexander_G_Hauptmann1", "~Boqing_Gong1", "~Ming-Hsuan_Yang1", "~Irfan_Essa1", "~David_A_Ross1", "~Lu_Jiang1"]}, "keywords": {"value": ["language model", "diffusion model", "video generation", "visual tokenization"]}, "TLDR": {"value": "With a good visual tokenizer, language model style transformer outperforms diffusion models on image and video generation."}, "abstract": {"value": "While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce \\modelname{}, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9cc7b12b9ea33c67f8286cd28b98e72cf43d8a0f.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024language,\ntitle={Language Model Beats Diffusion - Tokenizer is key to visual generation},\nauthor={Lijun Yu and Jose Lezama and Nitesh Bharadwaj Gundavarapu and Luca Versari and Kihyuk Sohn and David Minnen and Yong Cheng and Agrim Gupta and Xiuye Gu and Alexander G Hauptmann and Boqing Gong and Ming-Hsuan Yang and Irfan Essa and David A Ross and Lu Jiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gzqrANCF4g}\n}"}, "paperhash": {"value": "yu|language_model_beats_diffusion_tokenizer_is_key_to_visual_generation"}}, "number": 6714, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6714/-/Revision", "ICLR.cc/2024/Conference/Submission6714/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6714/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436419522, "cdate": 1695436419522, "tmdate": 1711734513637, "mdate": 1711734513637, "pdate": 1705410984557, "version": 2}, {"id": "N2WchST43h", "forum": "N2WchST43h", "signatures": ["ICLR.cc/2024/Conference/Submission6712/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6712/Authors"], "content": {"title": {"value": "A Sublinear Adversarial Training Algorithm"}, "authors": {"value": ["Yeqi Gao", "Lianke Qin", "Zhao Song", "Yitan Wang"]}, "authorids": {"value": ["~Yeqi_Gao1", "~Lianke_Qin2", "~Zhao_Song3", "~Yitan_Wang1"]}, "keywords": {"value": ["Adversarial training"]}, "abstract": {"value": "Adversarial training is a widely used strategy for making neural networks resistant to adversarial perturbations. For a neural network of width $m$, $n$ input training data in $d$ dimension, it takes $\\Omega(mnd)$ time cost per training iteration for the forward and backward computation. In this paper we analyze the convergence guarantee of adversarial training procedure on a two-layer neural network with shifted ReLU activation, and shows that only $o(m)$ neurons will be activated for each input data per iteration. Furthermore, we develop an algorithm for adversarial training with time cost $o(m n d)$ per iteration by applying half-space reporting data structure."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f125800dd0aac2746b3211f388e6cc9f687866e2.pdf"}, "_bibtex": {"value": "@inproceedings{\ngao2024a,\ntitle={A Sublinear Adversarial Training Algorithm},\nauthor={Yeqi Gao and Lianke Qin and Zhao Song and Yitan Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=N2WchST43h}\n}"}, "paperhash": {"value": "gao|a_sublinear_adversarial_training_algorithm"}}, "number": 6712, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6712/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6712/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436380207, "cdate": 1695436380207, "tmdate": 1710306623308, "mdate": 1710306623308, "pdate": 1705410984447, "version": 2}, {"id": "7gLfQT52Nn", "forum": "7gLfQT52Nn", "signatures": ["ICLR.cc/2024/Conference/Submission6711/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6711/Authors"], "content": {"title": {"value": "Proper Laplacian Representation Learning"}, "authors": {"value": ["Diego Gomez", "Michael Bowling", "Marlos C. Machado"]}, "authorids": {"value": ["~Diego_Gomez1", "~Michael_Bowling1", "~Marlos_C._Machado1"]}, "keywords": {"value": ["Reinforcement learning", "Graph Laplacian", "Representation learning", "Augmented Lagrangian optimization", "Hyperparameter robustness"]}, "TLDR": {"value": "We propose a theoretically-sound method to learn the Laplacian representation with deep neural networks, addressing limitations of all the previous methods in the literature."}, "abstract": {"value": "The ability to learn good representations of states is essential for solving large reinforcement learning problems, where exploration, generalization, and transfer are particularly challenging. The _Laplacian representation_ is a promising approach to address these problems by inducing informative state encoding and intrinsic rewards for temporally-extended action discovery and reward shaping. To obtain the Laplacian representation one needs to compute the eigensystem of the graph Laplacian, which is often approximated through optimization objectives compatible with deep learning approaches. These approximations, however, depend on hyperparameters that are impossible to tune efficiently, converge to arbitrary rotations of the desired eigenvectors, and are unable to accurately recover the corresponding eigenvalues. In this paper we introduce a theoretically sound objective and corresponding optimization algorithm for approximating the Laplacian representation. Our approach naturally recovers both the true eigenvectors and eigenvalues while eliminating the hyperparameter dependence of previous approximations. We provide theoretical guarantees for our method and we show that those results translate empirically into robust learning across multiple environments."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a24a9e1be294a6a4ef1fcc909df07eb085944cfd.pdf"}, "_bibtex": {"value": "@inproceedings{\ngomez2024proper,\ntitle={Proper Laplacian Representation Learning},\nauthor={Diego Gomez and Michael Bowling and Marlos C. Machado},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7gLfQT52Nn}\n}"}, "paperhash": {"value": "gomez|proper_laplacian_representation_learning"}}, "number": 6711, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6711/-/Revision", "ICLR.cc/2024/Conference/Submission6711/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6711/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695436220552, "cdate": 1695436220552, "tmdate": 1710181766089, "mdate": 1710181766089, "pdate": 1705410984427, "version": 2}, {"id": "xw29VvOMmU", "forum": "xw29VvOMmU", "signatures": ["ICLR.cc/2024/Conference/Submission6703/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6703/Authors"], "content": {"title": {"value": "LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning"}, "authors": {"value": ["Han Guo", "Philip Greengard", "Eric Xing", "Yoon Kim"]}, "authorids": {"value": ["~Han_Guo1", "~Philip_Greengard1", "~Eric_Xing1", "~Yoon_Kim1"]}, "keywords": {"value": ["Low-rank plus Quantized Matrix Decomposition", "Efficient Language Model Finetuning"]}, "abstract": {"value": "We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative  algorithm  to decompose each  pretrained  matrix into a high-precision low-rank component  and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the  low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic  configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget.  We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the  reconstruction objective during matrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enables aggressive quantization to sub-3 bits with only minor performance degradations. When finetuned on a language modeling calibration dataset, LQ-LoRA can also be used for model compression; in this setting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when including the low-rank components and requires 27GB of GPU memory) performs respectably compared to the 16-bit baseline."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a03fbee75acb58362e8187794d4f47e7e88aaea1.pdf"}, "TLDR": {"value": "Using matrix decomposition to enable more aggressive quantization before LoRA fine-tuning."}, "_bibtex": {"value": "@inproceedings{\nguo2024lqlora,\ntitle={{LQ}-Lo{RA}: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning},\nauthor={Han Guo and Philip Greengard and Eric Xing and Yoon Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xw29VvOMmU}\n}"}, "paperhash": {"value": "guo|lqlora_lowrank_plus_quantized_matrix_decomposition_for_efficient_language_model_finetuning"}}, "number": 6703, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6703/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6703/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695435948100, "cdate": 1695435948100, "tmdate": 1710539342424, "mdate": 1710539342424, "pdate": 1705410984144, "version": 2}, {"id": "ViNe1fjGME", "forum": "ViNe1fjGME", "signatures": ["ICLR.cc/2024/Conference/Submission6696/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6696/Authors"], "content": {"title": {"value": "Deep Temporal Graph Clustering"}, "authors": {"value": ["Meng Liu", "Yue Liu", "KE LIANG", "Wenxuan Tu", "Siwei Wang", "sihang zhou", "Xinwang Liu"]}, "authorids": {"value": ["~Meng_Liu6", "~Yue_Liu10", "~KE_LIANG1", "~Wenxuan_Tu1", "~Siwei_Wang4", "~sihang_zhou1", "~Xinwang_Liu1"]}, "keywords": {"value": ["Clustering", "Graph Learning", "Temporal Graph"]}, "TLDR": {"value": "We present the first general framework TGC for deep temporal graph clustering and discuss the differences between temporal graph clustering and existing graph clustering from multi-levels."}, "abstract": {"value": "Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which introduces deep clustering techniques to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and static graph clustering from several levels. To verify the superiority of the proposed framework TGC, we conduct extensive experiments. The experimental results show that temporal graph clustering enables more flexibility in finding a balance between time and space requirements, and our framework can effectively improve the performance of existing temporal graph learning methods. The code is released: https://github.com/MGitHubL/Deep-Temporal-Graph-Clustering."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4d06c0819e60a25475b015004ef7a52d00c05c57.pdf"}, "supplementary_material": {"value": "/attachment/4832058bb7f462433f418a4b86b3ac28c93d7ac8.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024deep,\ntitle={Deep Temporal Graph Clustering},\nauthor={Meng Liu and Yue Liu and KE LIANG and Wenxuan Tu and Siwei Wang and sihang zhou and Xinwang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ViNe1fjGME}\n}"}, "paperhash": {"value": "liu|deep_temporal_graph_clustering"}}, "number": 6696, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6696/-/Revision", "ICLR.cc/2024/Conference/Submission6696/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6696/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695435621211, "cdate": 1695435621211, "tmdate": 1712801808409, "mdate": 1712801808409, "pdate": 1705410984010, "version": 2}, {"id": "PHGxChm1l5", "forum": "PHGxChm1l5", "signatures": ["ICLR.cc/2024/Conference/Submission6693/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6693/Authors"], "content": {"title": {"value": "CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"}, "authors": {"value": ["Junyan Li", "Delin Chen", "Yining Hong", "Zhenfang Chen", "Peihao Chen", "Yikang Shen", "Chuang Gan"]}, "authorids": {"value": ["~Junyan_Li1", "~Delin_Chen1", "~Yining_Hong1", "~Zhenfang_Chen1", "~Peihao_Chen1", "~Yikang_Shen1", "~Chuang_Gan1"]}, "keywords": {"value": ["vision-language model", "compositionality"]}, "abstract": {"value": "A remarkable ability of human beings resides in compositional reasoning, i.e., the capacity to make \"infinite use of finite means\". However, current large vision-language foundation models (VLMs)  fall short of such compositional abilities due to their ``bag-of-words\" behaviors and inability to construct words that correctly represent visual entities and the relations among the entities. To this end, we propose CoVLM, which can guide the LLM to explicitly compose visual entities and relationships among the text and dynamically communicate with the vision encoder and detection network to achieve vision-language communicative decoding. Specifically, we first devise a set of novel communication tokens for the LLM, for dynamic communication between the visual detection system and the language system. A communication token is generated by the LLM following a visual entity or a relation, to inform the detection network to propose regions that are relevant to the sentence generated so far. The proposed regions-of-interests (ROIs) are then fed back into the LLM for better language generation contingent on the relevant regions. The LLM is thus able to compose the visual entities and relationships through the communication tokens. The vision-to-language and language-to-vision communication are iteratively performed until the entire sentence is generated. Our framework seamlessly bridges the gap between visual perception and LLMs and outperforms previous VLMs by a large margin on compositional reasoning benchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on ARO top-1 accuracy). We also achieve state-of-the-art performances on traditional vision-language tasks such as referring expression comprehension and visual question answering."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/56276fba67ee6d922ff1c04c50816a9b58c18fb2.pdf"}, "TLDR": {"value": "Our proposed CoVLM improves compositional reasoning ability of VLM through dynamically communicating between vision and language, achieving the SOTA on both compositional reasoning task and traditional VL tasks."}, "_bibtex": {"value": "@inproceedings{\nli2024compositional,\ntitle={Compositional {VLM}: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding},\nauthor={Junyan Li and Delin Chen and Yining Hong and Zhenfang Chen and Peihao Chen and Yikang Shen and Chuang Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PHGxChm1l5}\n}"}, "paperhash": {"value": "li|covlm_composing_visual_entities_and_relationships_in_large_language_models_via_communicative_decoding"}}, "number": 6693, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6693/-/Revision", "ICLR.cc/2024/Conference/Submission6693/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6693/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695435550419, "cdate": 1695435550419, "tmdate": 1713149207590, "mdate": 1713149207590, "pdate": 1705410983896, "version": 2}, {"id": "oOGqJ6Z1sA", "forum": "oOGqJ6Z1sA", "signatures": ["ICLR.cc/2024/Conference/Submission6688/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6688/Authors"], "content": {"title": {"value": "Treatment Effects Estimation By Uniform Transformer"}, "authors": {"value": ["Ruoqi Yu", "Shulei Wang"]}, "authorids": {"value": ["~Ruoqi_Yu1", "~Shulei_Wang1"]}, "keywords": {"value": ["Causal inference", "covariate balance", "nonparametric estimation", "observational studies", "weighting method"]}, "abstract": {"value": "In observational studies, balancing covariates in different treatment groups is essential to estimate treatment effects. One of the most commonly used methods for such purposes is weighting. The performance of this class of methods usually depends on strong regularity conditions for the underlying model, which might not hold in practice. In this paper, we investigate weighting methods from a functional estimation perspective and argue that the weights needed for covariate balancing could differ from those needed for treatment effects estimation under low regularity conditions. Motivated by this observation, we introduce a new framework of weighting that directly targets the treatment effects estimation. Unlike existing methods, the resulting estimator for a treatment effect under this new framework is a simple kernel-based $U$-statistic after applying a data-driven transformation to the observed covariates. We characterize the theoretical properties of the new estimators of treatment effects under a nonparametric setting and show that they are able to work robustly under low regularity conditions. The new framework is also applied to several numerical examples to demonstrate its practical merits."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/83bd4b7e66cdb87665b320af56e9b5ea4a2b731b.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024treatment,\ntitle={Treatment Effects Estimation By Uniform Transformer},\nauthor={Ruoqi Yu and Shulei Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oOGqJ6Z1sA}\n}"}, "paperhash": {"value": "yu|treatment_effects_estimation_by_uniform_transformer"}}, "number": 6688, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6688/-/Revision", "ICLR.cc/2024/Conference/Submission6688/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6688/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695435396185, "cdate": 1695435396185, "tmdate": 1710115229630, "mdate": 1710115229630, "pdate": 1705410983840, "version": 2}, {"id": "RDSj6S8WJe", "forum": "RDSj6S8WJe", "signatures": ["ICLR.cc/2024/Conference/Submission6687/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6687/Authors"], "content": {"title": {"value": "Demystifying Linear MDPs and Novel Dynamics Aggregation Framework"}, "authors": {"value": ["Joongkyu Lee", "Min-hwan Oh"]}, "authorids": {"value": ["~Joongkyu_Lee1", "~Min-hwan_Oh1"]}, "keywords": {"value": ["linear MDPs", "hierarchical reinforcement learning", "linear function approximation", "aggregation"]}, "TLDR": {"value": "We first provide a rigorous analysis of the limitations of existing algorithms under linear MDPs and then propose a provably efficient HRL algorithm in linear function approximation."}, "abstract": {"value": "In this work, we prove that, in linear MDPs, the feature dimension $d$ is lower bounded by $S/U$ in order to aptly represent transition probabilities, where $S$ is the size of the state space and $U$ is the maximum size of directly reachable states.\nHence, $d$ can still scale with $S$ depending on the direct reachability of the environment.  To address this limitation of linear MDPs, we propose a novel structural aggregation framework based on dynamics, named as the *dynamics aggregation*.\n    For this newly proposed framework,\n    we design a provably efficient hierarchical reinforcement learning algorithm in linear function approximation that leverages aggregated sub-structures. Our proposed algorithm exhibits statistical efficiency, achieving a regret of $\\tilde{O} \\big( d_{\\psi}^{3/2} H^{3/2}\\sqrt{ NT} \\big)$, where $d_{\\psi}$ represents the feature dimension of *aggregated subMDPs* and $N$ signifies the number of aggregated subMDPs. \n    We establish that the condition $d_{\\psi}^3 N \\ll d^{3}$ is readily met in most real-world environments with hierarchical structures, enabling a substantial improvement in the regret bound compared to LSVI-UCB, which enjoys a regret of $\\tilde{O}(d^{3/2} H^{3/2} \\sqrt{ T})$.\n    To the best of our knowledge, this work presents the first HRL algorithm with linear function approximation that offers provable guarantees."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/049e9d877a8c9fa0ea92ea25be9e4cf2cc72ad91.pdf"}, "supplementary_material": {"value": "/attachment/c47c210909ea1555f774c5b14a14306c9f3a3544.zip"}, "_bibtex": {"value": "@inproceedings{\nlee2024demystifying,\ntitle={Demystifying Linear {MDP}s and Novel Dynamics Aggregation Framework},\nauthor={Joongkyu Lee and Min-hwan Oh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RDSj6S8WJe}\n}"}, "paperhash": {"value": "lee|demystifying_linear_mdps_and_novel_dynamics_aggregation_framework"}}, "number": 6687, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6687/-/Revision", "ICLR.cc/2024/Conference/Submission6687/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6687/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695435359533, "cdate": 1695435359533, "tmdate": 1712462258898, "mdate": 1712462258898, "pdate": 1705410983749, "version": 2}, {"id": "kJ0qp9Xdsh", "forum": "kJ0qp9Xdsh", "signatures": ["ICLR.cc/2024/Conference/Submission6682/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6682/Authors"], "content": {"title": {"value": "Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints"}, "authors": {"value": ["Jian Chen", "Ruiyi Zhang", "Yufan Zhou", "Changyou Chen"]}, "authorids": {"value": ["~Jian_Chen9", "~Ruiyi_Zhang3", "~Yufan_Zhou1", "~Changyou_Chen1"]}, "keywords": {"value": ["Diffusion model", "Layout generation", "Constrained Optimization"]}, "TLDR": {"value": "Unified model for layout generation using constrained diffusion."}, "abstract": {"value": "Controllable layout generation refers to the process of creating a plausible visual arrangement of elements within a graphic design (*e.g.*, document and web designs) with constraints representing design intentions. Although recent diffusion-based models have achieved state-of-the-art FID scores, they tend to exhibit more pronounced misalignment compared to earlier transformer-based models. In this work, we propose the **LA**yout **C**onstraint diffusion mod**E**l (LACE), a unified model to handle a broad range of layout generation tasks, such as arranging elements with specified attributes and refining or completing a coarse layout design. The model is based on continuous diffusion models. Compared with existing methods that use discrete diffusion models, continuous state-space design can enable the incorporation of continuous aesthetic constraint functions in training more naturally. For conditional generation, we propose injecting layout conditions in the form of masks or gradient guidance during inference. Empirical results show that LACE produces high-quality layouts and outperforms existing state-of-the-art baselines. We will release our source code and model checkpoints."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/04e7806219285a0540cd51b589eb2928e15aac57.pdf"}, "supplementary_material": {"value": "/attachment/a101a473865e0d4a3f7d7df6f6a4d69a3429705d.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024towards,\ntitle={Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints},\nauthor={Jian Chen and Ruiyi Zhang and Yufan Zhou and Changyou Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kJ0qp9Xdsh}\n}"}, "paperhash": {"value": "chen|towards_aligned_layout_generation_via_diffusion_model_with_aesthetic_constraints"}}, "number": 6682, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6682/-/Revision", "ICLR.cc/2024/Conference/Submission6682/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6682/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695435123523, "cdate": 1695435123523, "tmdate": 1710323838937, "mdate": 1710323838937, "pdate": 1705410983505, "version": 2}, {"id": "4olqbTBt1Y", "forum": "4olqbTBt1Y", "signatures": ["ICLR.cc/2024/Conference/Submission6668/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6668/Authors"], "content": {"title": {"value": "DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption"}, "authors": {"value": ["Nan Yin", "Mengzhu Wang", "Zhenghan Chen", "Li Shen", "Huan Xiong", "Bin Gu", "Xiao Luo"]}, "authorids": {"value": ["~Nan_Yin4", "~Mengzhu_Wang3", "~Zhenghan_Chen3", "~Li_Shen1", "~Huan_Xiong1", "~Bin_Gu1", "~Xiao_Luo3"]}, "keywords": {"value": ["Open-set Recognization", "Graph Classification", "Domain Adaptation"]}, "abstract": {"value": "Recently, numerous graph neural network methods have been developed to tackle domain shifts in graph data. However, these methods presuppose that unlabeled target graphs belong to categories previously seen in the source domain. This assumption could not hold true for in-the-wild target graphs. In this paper, we delve deeper to explore a more realistic problem open-set graph domain adaptation. Our objective is to not only identify target graphs from new categories but also accurately classify remaining target graphs into their respective categories under domain shift and label scarcity. To solve this challenging problem, we introduce a new method named Dual Structured Exploration with Mixup (DREAM). DREAM incorporates a graph-level representation learning branch as well as a subgraph-enhanced branch, which jointly explores graph topological structures from both global and local viewpoints. To maximize the use of unlabeled target graphs, we train these two branches simultaneously using posterior regularization to enhance their inter-module consistency. To accommodate the open-set setting, we amalgamate dissimilar samples to generate virtual unknown samples belonging to novel classes. Moreover, to alleviate domain shift, we establish a k nearest neighbor-based graph-of-graphs and blend multiple neighbors of each sample to produce cross-domain virtual samples for inter-domain consistency learning. Extensive experiments validate the effectiveness of the proposed DREAM in comparison to various state-of-the-art approaches in different settings."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5ce73ff559d349b26fbe8e1bd677248f097e918b.pdf"}, "_bibtex": {"value": "@inproceedings{\nyin2024dream,\ntitle={{DREAM}: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption},\nauthor={Nan Yin and Mengzhu Wang and Zhenghan Chen and Li Shen and Huan Xiong and Bin Gu and Xiao Luo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4olqbTBt1Y}\n}"}, "paperhash": {"value": "yin|dream_dual_structured_exploration_with_mixup_for_openset_graph_domain_adaption"}}, "number": 6668, "odate": 1697213872796, "pdate": 1705410982988, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6668/-/Revision", "ICLR.cc/2024/Conference/Submission6668/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6668/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695434292046, "cdate": 1695434292046, "tmdate": 1712743600878, "mdate": 1712743600878, "version": 2}, {"id": "nFI3wFM9yN", "forum": "nFI3wFM9yN", "signatures": ["ICLR.cc/2024/Conference/Submission6665/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6665/Authors"], "content": {"title": {"value": "Communication-Efficient Federated Non-Linear Bandit Optimization"}, "authors": {"value": ["Chuanhao Li", "Chong Liu", "Yu-Xiang Wang"]}, "authorids": {"value": ["~Chuanhao_Li1", "~Chong_Liu1", "~Yu-Xiang_Wang1"]}, "keywords": {"value": ["federated optimization", "communication cost", "non-linear bandit", "bandit optimization", "cumulative regret"]}, "TLDR": {"value": "federated bandit optimization of generic non-linear objective function"}, "abstract": {"value": "Federated optimization studies the problem of collaborative function optimization among multiple clients (e.g. mobile devices or organizations) under the coordination of a central server. Since the data is collected separately by each client and always remains decentralized, federated optimization preserves data privacy and allows for large-scale computing, which makes it a promising decentralized machine learning paradigm. Though it is often deployed for tasks that are online in nature, e.g., next-word prediction on keyboard apps, most works formulate it as an offline problem. The few exceptions that consider federated bandit optimization are limited to very simplistic function classes, e.g., linear, generalized linear, or non-parametric function class with bounded RKHS norm, which severely hinders its practical usage. In this paper, we propose a new algorithm, named Fed-GO-UCB, for federated bandit optimization with generic non-linear objective function. Under some mild conditions, we rigorously prove that Fed-GO-UCB is able to achieve sub-linear rate for both cumulative regret and communication cost. At the heart of our theoretical analysis are distributed regression oracle and individual confidence set construction, which can be of independent interests. Empirical evaluations also demonstrate the effectiveness of the proposed algorithm."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8a12d6f42e1cfca5a370ef8a8717c2674952b3ec.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024communicationefficient,\ntitle={Communication-Efficient Federated Non-Linear Bandit Optimization},\nauthor={Chuanhao Li and Chong Liu and Yu-Xiang Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nFI3wFM9yN}\n}"}, "paperhash": {"value": "li|communicationefficient_federated_nonlinear_bandit_optimization"}}, "number": 6665, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6665/-/Revision", "ICLR.cc/2024/Conference/Submission6665/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6665/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695434090224, "cdate": 1695434090224, "tmdate": 1710558980853, "mdate": 1710558980853, "pdate": 1705410982909, "version": 2}, {"id": "5Nn2BLV7SB", "forum": "5Nn2BLV7SB", "signatures": ["ICLR.cc/2024/Conference/Submission6662/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6662/Authors"], "content": {"title": {"value": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"}, "authors": {"value": ["Yidong Wang", "Zhuohao Yu", "Wenjin Yao", "Zhengran Zeng", "Linyi Yang", "Cunxiang Wang", "Hao Chen", "Chaoya Jiang", "Rui Xie", "Jindong Wang", "Xing Xie", "Wei Ye", "Shikun Zhang", "Yue Zhang"]}, "authorids": {"value": ["~Yidong_Wang1", "~Zhuohao_Yu1", "~Wenjin_Yao1", "~Zhengran_Zeng2", "~Linyi_Yang1", "~Cunxiang_Wang1", "~Hao_Chen15", "~Chaoya_Jiang1", "~Rui_Xie2", "~Jindong_Wang1", "~Xing_Xie3", "~Wei_Ye2", "~Shikun_Zhang2", "~Yue_Zhang7"]}, "keywords": {"value": ["LLM evaluation"]}, "abstract": {"value": "Instruction tuning large language models (LLMs) remains a challenging task, owing to the complexity of hyperparameter selection and the difficulty involved in evaluating the tuned models. To determine the optimal hyperparameters, an automatic, robust, and reliable evaluation benchmark is essential. However, establishing such a benchmark is not a trivial task due to the challenges associated with evaluation accuracy and privacy protection. In response to these challenges, we introduce a judge large language model, named PandaLM, which is trained to distinguish the superior model given several LLMs. PandaLM's focus extends beyond just the objective correctness of responses, which is the main focus of traditional evaluation datasets. It addresses vital subjective factors such as relative conciseness, clarity, adherence to instructions, comprehensiveness, and formality. To ensure the reliability of PandaLM, we collect a diverse human-annotated test dataset, where all contexts are generated by humans and labels are aligned with human preferences. Our findings reveal that PandaLM-7B offers a performance comparable to both GPT-3.5 and GPT-4. Impressively, PandaLM-70B surpasses their performance. PandaLM enables the evaluation of LLM to be fairer but with less cost, evidenced by significant improvements achieved by models tuned through PandaLM compared to their counterparts trained with default Alpaca's hyperparameters. In addition, PandaLM does not depend on API-based evaluations, thus avoiding potential data leakage."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/abded65724c71911185dbb4ab72a213967689bc0.pdf"}, "supplementary_material": {"value": "/attachment/4400e4f0f67603849e18132665f6c3cb9cd1ce73.pdf"}, "TLDR": {"value": "We introduce a judge large language model, named PandaLM, which is trained to distinguish the superior model given several LLMs."}, "_bibtex": {"value": "@inproceedings{\nwang2024pandalm,\ntitle={Panda{LM}: An Automatic Evaluation Benchmark for {LLM} Instruction Tuning Optimization},\nauthor={Yidong Wang and Zhuohao Yu and Zhengran Zeng and Linyi Yang and Wenjin Yao and Cunxiang Wang and Hao Chen and Chaoya Jiang and Rui Xie and Jindong Wang and Xing Xie and Wei Ye and Shikun Zhang and Yue Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5Nn2BLV7SB}\n}"}, "paperhash": {"value": "wang|pandalm_an_automatic_evaluation_benchmark_for_llm_instruction_tuning_optimization"}}, "number": 6662, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6662/-/Revision", "ICLR.cc/2024/Conference/Submission6662/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6662/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695433908586, "cdate": 1695433908586, "tmdate": 1711692677952, "mdate": 1711692677952, "pdate": 1705410982838, "version": 2}, {"id": "NltzxpG0nz", "forum": "NltzxpG0nz", "signatures": ["ICLR.cc/2024/Conference/Submission6659/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6659/Authors"], "content": {"title": {"value": "Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds"}, "authors": {"value": ["Sipeng Zheng", "jiazheng liu", "Yicheng Feng", "Zongqing Lu"]}, "authorids": {"value": ["~Sipeng_Zheng1", "~jiazheng_liu2", "~Yicheng_Feng1", "~Zongqing_Lu2"]}, "keywords": {"value": ["large multimodal pre-training", "open-world embodied agent", "large language model"]}, "abstract": {"value": "Recent studies have presented compelling evidence that large language models (LLMs) can equip embodied agents with the self-driven capability to interact with the world, which marks an initial step toward versatile robotics. However, these efforts tend to overlook the visual richness of open worlds, rendering the entire interactive process akin to ``a blindfolded text-based game.'' Consequently, LLM-based agents frequently encounter challenges in intuitively comprehending their surroundings and producing responses that are easy to understand. In this paper, we propose Steve-Eye, an end-to-end trained large multimodal model to address this limitation. Steve-Eye integrates the LLM with a visual encoder to process visual-text inputs and generate multimodal feedback. We adopt a semi-automatic strategy to collect an extensive dataset comprising 850K open-world instruction pairs, enabling our model to encompass three essential functions for an agent: multimodal perception, foundational knowledge base, and skill prediction and planning. Lastly, we develop three open-world evaluation benchmarks and carry out experiments from a wide range of perspectives to validate our model's capability to strategically act and plan. The project\u2019s website and code can be found at https://sites.google.com/view/steve-eye."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a46ce05ff44a87fada32b918f094df26df3d2f07.pdf"}, "_bibtex": {"value": "@inproceedings{\nzheng2024steveeye,\ntitle={Steve-Eye: Equipping {LLM}-based Embodied Agents with Visual Perception in Open Worlds},\nauthor={Sipeng Zheng and jiazheng liu and Yicheng Feng and Zongqing Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NltzxpG0nz}\n}"}, "paperhash": {"value": "zheng|steveeye_equipping_llmbased_embodied_agents_with_visual_perception_in_open_worlds"}}, "number": 6659, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6659/-/Revision", "ICLR.cc/2024/Conference/Submission6659/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6659/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695433646907, "cdate": 1695433646907, "tmdate": 1710585221733, "mdate": 1710585221733, "pdate": 1705410982718, "version": 2}, {"id": "4aywmeb97I", "forum": "4aywmeb97I", "signatures": ["ICLR.cc/2024/Conference/Submission6656/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6656/Authors"], "content": {"title": {"value": "Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration"}, "authors": {"value": ["Yujia Wang", "Yuanpu Cao", "Jingcheng Wu", "Ruoyu Chen", "Jinghui Chen"]}, "authorids": {"value": ["~Yujia_Wang3", "~Yuanpu_Cao1", "~Jingcheng_Wu1", "~Ruoyu_Chen4", "~Jinghui_Chen1"]}, "keywords": {"value": ["Federated learning", "Nonconvex optimization"]}, "abstract": {"value": "Asynchronous federated learning, which enables local clients to send their model update asynchronously to the server without waiting for others, has recently emerged for its improved efficiency and scalability over traditional synchronized federated learning. In this paper, we study how the asynchronous delay affects the convergence of asynchronous federated learning under non-i.i.d. distributed data across clients. Through the theoretical convergence analysis of one representative asynchronous federated learning algorithm under standard nonconvex stochastic settings, we show that the asynchronous delay can largely slow down the convergence, especially with high data heterogeneity. To further improve the convergence of asynchronous federated learning under heterogeneous data distributions, we propose a novel asynchronous federated learning method with a cached update calibration. Specifically, we let the server cache the latest update for each client and reuse these variables for calibrating the global update at each round. We theoretically prove the convergence acceleration for our proposed method under nonconvex stochastic settings. Extensive experiments on several vision and language tasks demonstrate our superior performances compared to other asynchronous federated learning baselines."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/27435ec4a665a94e797c956f5ed0829196e5d371.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024tackling,\ntitle={Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration},\nauthor={Yujia Wang and Yuanpu Cao and Jingcheng Wu and Ruoyu Chen and Jinghui Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4aywmeb97I}\n}"}, "paperhash": {"value": "wang|tackling_the_data_heterogeneity_in_asynchronous_federated_learning_with_cached_update_calibration"}}, "number": 6656, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6656/-/Revision", "ICLR.cc/2024/Conference/Submission6656/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6656/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695433467110, "cdate": 1695433467110, "tmdate": 1713170640630, "mdate": 1713170640630, "pdate": 1705410982651, "version": 2}, {"id": "TilcG5C8bN", "forum": "TilcG5C8bN", "signatures": ["ICLR.cc/2024/Conference/Submission6644/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6644/Authors"], "content": {"title": {"value": "Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning"}, "authors": {"value": ["Sheng Li", "Chao Wu", "Ao Li", "Yanzhi Wang", "Xulong Tang", "Geng Yuan"]}, "authorids": {"value": ["~Sheng_Li16", "~Chao_Wu4", "~Ao_Li7", "~Yanzhi_Wang3", "~Xulong_Tang1", "~Geng_Yuan1"]}, "keywords": {"value": ["Self-supervised learning", "efficient training", "image similarity"]}, "abstract": {"value": "Deep Neural Networks (DNNs), essential for diverse applications such as visual recognition and eldercare, often require a large amount of labeled data for training, making widespread deployment of DNNs a challenging task. Self-supervised learning (SSL) emerges as a promising approach, which leverages inherent patterns within data through diverse augmentations to train models without explicit labels. However, while SSL has shown notable advancements in accuracy, its high computation costs remain a daunting impediment, particularly for resource-constrained platforms. To address this problem, we introduce SimWnW, a similarity-based efficient self-supervised learning framework. By strategically removing less important regions in augmented images and feature maps, SimWnW not only reduces computation costs but also eliminates irrelevant features that might slow down the learning process, thereby accelerating model convergence. The experimental results show that SimWnW effectively reduces the amount of computation costs in self-supervised model training without compromising accuracy. Specifically, SimWnW yields up to 54\\% and 51\\% computation savings in training from scratch and transfer learning tasks, respectively."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ebe0687d227e149f6b820f179df4be651f001b27.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024waxingandwaning,\ntitle={Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning},\nauthor={Sheng Li and Chao Wu and Ao Li and Yanzhi Wang and Xulong Tang and Geng Yuan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TilcG5C8bN}\n}"}, "paperhash": {"value": "li|waxingandwaning_a_generic_similaritybased_framework_for_efficient_selfsupervised_learning"}}, "number": 6644, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6644/-/Revision", "ICLR.cc/2024/Conference/Submission6644/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6644/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695432504315, "cdate": 1695432504315, "tmdate": 1713097543865, "mdate": 1713097543865, "pdate": 1705410982174, "version": 2}, {"id": "CfXh93NDgH", "forum": "CfXh93NDgH", "signatures": ["ICLR.cc/2024/Conference/Submission6631/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6631/Authors"], "content": {"title": {"value": "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions"}, "authors": {"value": ["Can Xu", "Qingfeng Sun", "Kai Zheng", "Xiubo Geng", "Pu Zhao", "Jiazhan Feng", "Chongyang Tao", "Qingwei Lin", "Daxin Jiang"]}, "authorids": {"value": ["~Can_Xu2", "~Qingfeng_Sun1", "~Kai_Zheng8", "~Xiubo_Geng2", "~Pu_Zhao3", "~Jiazhan_Feng1", "~Chongyang_Tao1", "~Qingwei_Lin1", "~Daxin_Jiang2"]}, "keywords": {"value": ["Large Language Model", "Instruction Fine-tuning"]}, "abstract": {"value": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Both automatic and human evaluations consistently indicate that WizardLM outperforms baselines such as Alpaca (trained from Self-Instruct) and Vicuna (trained from human-created instructions). The experimental results demonstrate that the quality of instruction-following dataset crafted by Evol-Instruct can significantly improve the performance of LLMs."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4760b6872282dc467e4ea0d825a5a186c2b18b66.pdf"}, "supplementary_material": {"value": "/attachment/8b061fd1e3b9512d743627cf2a25daab1314afc5.zip"}, "_bibtex": {"value": "@inproceedings{\nxu2024wizardlm,\ntitle={Wizard{LM}: Empowering Large Pre-Trained Language Models to Follow Complex Instructions},\nauthor={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Qingwei Lin and Daxin Jiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CfXh93NDgH}\n}"}, "paperhash": {"value": "xu|wizardlm_empowering_large_pretrained_language_models_to_follow_complex_instructions"}}, "number": 6631, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6631/-/Revision", "ICLR.cc/2024/Conference/Submission6631/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6631/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695431608807, "cdate": 1695431608807, "tmdate": 1710346114748, "mdate": 1710346114748, "pdate": 1705410981767, "version": 2}, {"id": "usrChqw6yK", "forum": "usrChqw6yK", "signatures": ["ICLR.cc/2024/Conference/Submission6622/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6622/Authors"], "content": {"title": {"value": "LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors"}, "authors": {"value": ["Sheng Jin", "Xueying Jiang", "Jiaxing Huang", "Lewei Lu", "Shijian Lu"]}, "authorids": {"value": ["~Sheng_Jin3", "~Xueying_Jiang1", "~Jiaxing_Huang2", "~Lewei_Lu1", "~Shijian_Lu1"]}, "keywords": {"value": ["Open Vocabulary Object Detection", "Visual descriptors"]}, "abstract": {"value": "Inspired by the outstanding zero-shot capability of vision language models (VLMs) in image classification tasks, open-vocabulary object detection has attracted increasing interest by distilling the broad VLM knowledge into detector training. However, most existing open-vocabulary detectors learn by aligning region embeddings with categorical labels (e.g., bicycle) only, disregarding the capability of VLMs on aligning visual embeddings with fine-grained text descriptions of object parts (e.g., pedals and bells). This paper presents DVDet, a Descriptor-Enhanced Open Vocabulary Detector that introduces conditional context prompts and hierarchical textual descriptors that enable precise region-text alignment as well as open-vocabulary detection training in general. Specifically, the conditional context prompt transforms regional embeddings into image-like representations that can be directly integrated into general open vocabulary detection training. In addition, we introduce large language models as an interactive and implicit knowledge repository which enables iterative mining and refining visually oriented textual descriptors for precise region-text alignment. Extensive experiments over multiple large-scale benchmarks show that DVDet outperforms the state-of-the-art consistently by large margins."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b259ea0d1805736d528b713e9eb3971190dfa924.pdf"}, "_bibtex": {"value": "@inproceedings{\njin2024llms,\ntitle={{LLM}s Meet {VLM}s: Boost Open Vocabulary Object Detection with Fine-grained Descriptors},\nauthor={Sheng Jin and Xueying Jiang and Jiaxing Huang and Lewei Lu and Shijian Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=usrChqw6yK}\n}"}, "supplementary_material": {"value": "/attachment/69c9a3bae14b5b65846b050fca49c999d0c6813e.pdf"}, "paperhash": {"value": "jin|llms_meet_vlms_boost_open_vocabulary_object_detection_with_finegrained_descriptors"}}, "number": 6622, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6622/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6622/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695431168343, "cdate": 1695431168343, "tmdate": 1710232544331, "mdate": 1710232544331, "pdate": 1705410981584, "version": 2}, {"id": "lKxL5zkssv", "forum": "lKxL5zkssv", "signatures": ["ICLR.cc/2024/Conference/Submission6614/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6614/Authors"], "content": {"title": {"value": "CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding"}, "authors": {"value": ["Qiongyi Zhou", "Changde Du", "Shengpei Wang", "Huiguang He"]}, "authorids": {"value": ["~Qiongyi_Zhou2", "~Changde_Du2", "~Shengpei_Wang1", "~Huiguang_He1"]}, "keywords": {"value": ["Multi-subject visual neural decoding", "representational similarity analysis", "CLIP", "transformer"]}, "TLDR": {"value": "We propose a multi-subject visual neural decoding method based on Transformer with subject-specific tokens, of which the shared neural representations are learned under the guidance of CLIP."}, "abstract": {"value": "The study of decoding visual neural information faces challenges in generalizing single-subject decoding models to multiple subjects, due to individual differences. Moreover, the limited availability of data from a single subject has a constraining impact on model performance. Although prior multi-subject decoding methods have made significant progress, they still suffer from several limitations, including difficulty in extracting global neural response features, linear scaling of model parameters with the number of subjects, and inadequate characterization of the relationship between neural responses of different subjects to various stimuli.\nTo overcome these limitations, we propose a CLIP-guided Multi-sUbject visual neural information SEmantic Decoding (CLIP-MUSED) method. Our method consists of a Transformer-based feature extractor to effectively model global neural representations. It also incorporates learnable subject-specific tokens that facilitates the aggregation of multi-subject data without a linear increase of parameters. Additionally, we employ representational similarity analysis (RSA) to guide token representation learning based on the topological relationship of visual stimuli in the representation space of CLIP, enabling full characterization of the relationship between neural responses of different subjects under different stimuli. Finally, token representations are used for multi-subject semantic decoding. Our proposed method outperforms single-subject decoding methods and achieves state-of-the-art performance among the existing multi-subject methods on two fMRI datasets. Visualization results provide insights into the effectiveness of our proposed method. Code is available at https://github.com/CLIP-MUSED/CLIP-MUSED."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c028064068fcf4f9af8e2dbdeddd65e4aecc1b9f.pdf"}, "supplementary_material": {"value": "/attachment/f14ce0bd0cf430d283aa61d322c6c8592a1b15bc.zip"}, "_bibtex": {"value": "@inproceedings{\nzhou2024clipmused,\ntitle={{CLIP}-{MUSED}: {CLIP}-Guided Multi-Subject Visual Neural Information Semantic},\nauthor={Qiongyi Zhou and Changde Du and Shengpei Wang and Huiguang He},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lKxL5zkssv}\n}"}, "paperhash": {"value": "zhou|clipmused_clipguided_multisubject_visual_neural_information_semantic_decoding"}}, "number": 6614, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6614/-/Revision", "ICLR.cc/2024/Conference/Submission6614/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6614/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430652093, "cdate": 1695430652093, "tmdate": 1712404451121, "mdate": 1712404451121, "pdate": 1705410981189, "version": 2}, {"id": "v8jdwkUNXb", "forum": "v8jdwkUNXb", "signatures": ["ICLR.cc/2024/Conference/Submission6598/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6598/Authors"], "content": {"title": {"value": "Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning"}, "authors": {"value": ["Zihan Ding", "Chi Jin"]}, "authorids": {"value": ["~Zihan_Ding1", "~Chi_Jin1"]}, "keywords": {"value": ["Generative Model", "Expressiveness", "Deep Reinforcement Learning"]}, "abstract": {"value": "Score-based generative models like the diffusion model have been testified to be effective in modeling multi-modal data from image generation to reinforcement learning (RL). However, the inference process of diffusion model can be slow, which hinders its usage in RL with iterative sampling. We propose to apply the consistency model as an efficient yet expressive policy representation, namely consistency policy, with an actor-critic style algorithm for three typical RL settings: offline, offline-to-online and online. For offline RL, we demonstrate the expressiveness of generative models as policies from multi-modal data. For offline-to-online RL, the consistency policy is shown to be more computational efficient than diffusion policy, with a comparable performance. For online RL, the consistency policy demonstrates significant speedup and even higher average performances than the diffusion policy."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3fc563685e5ff161dce37ccd2ac0d49b71899da3.pdf"}, "_bibtex": {"value": "@inproceedings{\nding2024consistency,\ntitle={Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning},\nauthor={Zihan Ding and Chi Jin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=v8jdwkUNXb}\n}"}, "paperhash": {"value": "ding|consistency_models_as_a_rich_and_efficient_policy_class_for_reinforcement_learning"}}, "number": 6598, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6598/-/Revision", "ICLR.cc/2024/Conference/Submission6598/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6598/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695429987019, "cdate": 1695429987019, "tmdate": 1710442236278, "mdate": 1710442236278, "pdate": 1705410980595, "version": 2}, {"id": "iX1RjVQODj", "forum": "iX1RjVQODj", "signatures": ["ICLR.cc/2024/Conference/Submission6593/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6593/Authors"], "content": {"title": {"value": "Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning"}, "authors": {"value": ["Joey Hejna", "Rafael Rafailov", "Harshit Sikchi", "Chelsea Finn", "Scott Niekum", "W. Bradley Knox", "Dorsa Sadigh"]}, "authorids": {"value": ["~Joey_Hejna1", "~Rafael_Rafailov1", "~Harshit_Sikchi1", "~Chelsea_Finn1", "~Scott_Niekum1", "~W._Bradley_Knox2", "~Dorsa_Sadigh1"]}, "keywords": {"value": ["reinforcement learning from human feedback", "preference-based RL", "human-in-the-loop RL", "preference learning"]}, "TLDR": {"value": "We propose Constrastive Preference Learning, a new supervised algorithm for learning optimal policies from regret-based preferences in general MDPs."}, "abstract": {"value": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the \\emph{regret} under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new family of algorithms for optimizing behavior from human feedback using the \\textit{regret}-based model of human preferences. Using the principle of maximum entropy, we derive \\fullname (\\abv), an algorithm for learning optimal policies from preferences without learning reward functions, circumventing the need for RL. \\abv is fully off-policy, uses only a simple contrastive objective, and can be applied to arbitrary MDPs. This enables \\abv to elegantly scale to high-dimensional and sequential RLHF problems while being simpler than prior methods."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/45058c90136046596530d7ce4145d2948f976ad0.pdf"}, "supplementary_material": {"value": "/attachment/efa06c4501dbc2e21a0c40ca772daba508b73299.zip"}, "_bibtex": {"value": "@inproceedings{\nhejna2024contrastive,\ntitle={Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning},\nauthor={Joey Hejna and Rafael Rafailov and Harshit Sikchi and Chelsea Finn and Scott Niekum and W. Bradley Knox and Dorsa Sadigh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iX1RjVQODj}\n}"}, "paperhash": {"value": "hejna|contrastive_preference_learning_learning_from_human_feedback_without_reinforcement_learning"}}, "number": 6593, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6593/-/Revision", "ICLR.cc/2024/Conference/Submission6593/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6593/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695429580997, "cdate": 1695429580997, "tmdate": 1711600057693, "mdate": 1711600057693, "pdate": 1705410980392, "version": 2}, {"id": "h8GeqOxtd4", "forum": "h8GeqOxtd4", "signatures": ["ICLR.cc/2024/Conference/Submission6589/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6589/Authors"], "content": {"title": {"value": "Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization"}, "authors": {"value": ["Yinbin Han", "Meisam Razaviyayn", "Renyuan Xu"]}, "authorids": {"value": ["~Yinbin_Han1", "~Meisam_Razaviyayn1", "~Renyuan_Xu1"]}, "keywords": {"value": ["diffusion models; score estimation; neural networks; neural tangent kernels"]}, "abstract": {"value": "Diffusion models have emerged as a powerful tool rivaling GANs in generating high-quality samples with improved fidelity, flexibility, and robustness. A key component of these models is to learn the score function through score matching. Despite empirical success on various tasks,  it remains unclear whether gradient-based algorithms can learn the score function with a provable accuracy. As a first step toward answering this question, this paper establishes a mathematical framework for analyzing score estimation using neural networks trained by gradient descent. Our analysis covers both the optimization and the generalization aspects of the learning procedure. In particular, we propose a parametric form to formulate the denoising score-matching problem as a regression with noisy labels. Compared to the standard supervised learning setup, the score-matching problem introduces distinct challenges, including unbounded input, vector-valued output, and an additional time variable, preventing existing techniques from being applied directly. In this paper, we show that with proper designs, the evolution of neural networks during training can be accurately modeled by a series of kernel regression tasks. Furthermore, by applying an early-stopping rule for gradient descent and leveraging recent developments in neural tangent kernels, we establish the first generalization error (sample complexity) bounds for learning the score function with neural networks, despite the presence of noise in the observations. Our analysis is grounded in a novel parametric form of the neural network and an innovative connection between score matching and regression analysis, facilitating the application of advanced statistical and optimization techniques."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4b8bd494b6c8445e4cf89a97c812638b9b150bb3.pdf"}, "_bibtex": {"value": "@inproceedings{\nhan2024neural,\ntitle={Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization},\nauthor={Yinbin Han and Meisam Razaviyayn and Renyuan Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=h8GeqOxtd4}\n}"}, "paperhash": {"value": "han|neural_networkbased_score_estimation_in_diffusion_models_optimization_and_generalization"}}, "number": 6589, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6589/-/Revision", "ICLR.cc/2024/Conference/Submission6589/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6589/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695429520940, "cdate": 1695429520940, "tmdate": 1710292943282, "mdate": 1710292943282, "pdate": 1705410980291, "version": 2}, {"id": "m0x0rv6Iwm", "forum": "m0x0rv6Iwm", "signatures": ["ICLR.cc/2024/Conference/Submission6570/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6570/Authors"], "content": {"title": {"value": "Time-Varying Propensity Score to Bridge the Gap between the Past and Present"}, "authors": {"value": ["Rasool Fakoor", "Jonas Mueller", "Zachary Chase Lipton", "Pratik Chaudhari", "Alex Smola"]}, "authorids": {"value": ["~Rasool_Fakoor1", "~Jonas_Mueller1", "~Zachary_Chase_Lipton1", "~Pratik_Chaudhari1", "~Alex_Smola1"]}, "keywords": {"value": ["model adaptation to changing data", "distribution shift"]}, "TLDR": {"value": "To keep models accurate in the real world, we must regularly update them with relevant data. This paper proposes a new method for doing so."}, "abstract": {"value": "Real-world deployment of machine learning models is challenging because data evolves over time. While no model can work when data evolves in an arbitrary fashion, if there is some pattern to these changes, we might be able to design methods to address it. This paper addresses situations when data evolves gradually. We introduce a time-varying propensity score that can detect gradual shifts in the distribution of data which allows us to selectively sample past data to update the model---not just similar data from the past like that of a standard propensity score but also data that evolved in a similar fashion in the past. The time-varying propensity score is quite general: we demonstrate different ways of implementing it and evaluate it on a variety of problems ranging from supervised learning (e.g., image classification problems) where data undergoes a sequence of gradual shifts, to reinforcement learning tasks (e.g., robotic manipulation and continuous control) where data shifts as the policy or the task changes."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5b11f3eed8b0d7474148defc87b1c6b07a950bdf.pdf"}, "_bibtex": {"value": "@inproceedings{\nfakoor2024timevarying,\ntitle={Time-Varying Propensity Score to Bridge the Gap between the Past and Present},\nauthor={Rasool Fakoor and Jonas Mueller and Zachary Chase Lipton and Pratik Chaudhari and Alex Smola},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=m0x0rv6Iwm}\n}"}, "paperhash": {"value": "fakoor|timevarying_propensity_score_to_bridge_the_gap_between_the_past_and_present"}}, "number": 6570, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6570/-/Revision", "ICLR.cc/2024/Conference/Submission6570/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6570/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695428415201, "cdate": 1695428415201, "tmdate": 1710403184188, "mdate": 1710403184188, "pdate": 1705410979779, "version": 2}, {"id": "jLIUfrAcMQ", "forum": "jLIUfrAcMQ", "signatures": ["ICLR.cc/2024/Conference/Submission6565/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6565/Authors"], "content": {"title": {"value": "Debiasing Attention Mechanism in Transformer without Demographics"}, "authors": {"value": ["Shenyu Lu", "Yipei Wang", "Xiaoqian Wang"]}, "authorids": {"value": ["~Shenyu_Lu1", "~Yipei_Wang1", "~Xiaoqian_Wang1"]}, "keywords": {"value": ["Fairness", "Transformer", "Attention", "Without demographics"]}, "TLDR": {"value": "Improve fairness in transformers without demographics"}, "abstract": {"value": "Although transformers demonstrate impressive capabilities in a variety of tasks, the fairness issue remains a significant concern when deploying these models. Existing works to address fairness issues in transformers require sensitive labels (such as age, gender, etc.), which can raise privacy concerns or violate legal regulations. An alternative way is through fairness without demographics. However, existing works that improve Rawlsian Max-Min fairness may impose overly restrictive constraints. Other methods that use auxiliary networks could be parameter inefficient. In this paper, we present a new approach to debiasing transformers by leveraging their inherent structure.  By reconsidering the roles of important components (queries, keys, and values) in the attention mechanism, we introduce a simple yet effective debiasing strategy from two perspectives: 1) Grounded in theoretical analysis, we normalize and apply absolute value operations to queries and keys to minimize the bias in attention weight allocation; 2) We reduce the bias within values through local alignment via contrastive learning. Throughout the entire process, our approach does not require any sensitive labels. Furthermore, to enhance memory efficiency in the training phase, we propose a strategy that debias only the last encoder to improve fairness in pre-trained models. We conduct experiments in computer vision and natural language processing tasks and show that our method is comparable and even outperforms the state-of-the-art method with substantially lower energy consumption."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b8783df5d0643c7756d5409d1426b24bcf369ad3.pdf"}, "supplementary_material": {"value": "/attachment/56ee979ef4a66f68ede5d811ad748e3ad1327391.zip"}, "_bibtex": {"value": "@inproceedings{\nlu2024debiasing,\ntitle={Debiasing Attention Mechanism in Transformer without Demographics},\nauthor={Shenyu Lu and Yipei Wang and Xiaoqian Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jLIUfrAcMQ}\n}"}, "paperhash": {"value": "lu|debiasing_attention_mechanism_in_transformer_without_demographics"}}, "number": 6565, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6565/-/Revision", "ICLR.cc/2024/Conference/Submission6565/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6565/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427987546, "cdate": 1695427987546, "tmdate": 1713061893314, "mdate": 1713061893314, "pdate": 1705410979547, "version": 2}, {"id": "22OTbutug9", "forum": "22OTbutug9", "signatures": ["ICLR.cc/2024/Conference/Submission6563/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6563/Authors"], "content": {"title": {"value": "RA-DIT: Retrieval-Augmented Dual Instruction Tuning"}, "authors": {"value": ["Xi Victoria Lin", "Xilun Chen", "Mingda Chen", "Weijia Shi", "Maria Lomeli", "Richard James", "Pedro Rodriguez", "Jacob Kahn", "Gergely Szilvasy", "Mike Lewis", "Luke Zettlemoyer", "Wen-tau Yih"]}, "authorids": {"value": ["~Xi_Victoria_Lin1", "~Xilun_Chen1", "~Mingda_Chen1", "~Weijia_Shi1", "~Maria_Lomeli2", "~Richard_James2", "~Pedro_Rodriguez1", "~Jacob_Kahn1", "gsz@meta.com", "~Mike_Lewis1", "~Luke_Zettlemoyer1", "~Wen-tau_Yih1"]}, "keywords": {"value": ["retrieval-augmented language model", "large language model", "knowledge intensive NLP"]}, "TLDR": {"value": "We propose a fine-tuning approach that effectively retrofits any LLM with retrieval capabilities."}, "abstract": {"value": "Retrieval-augmented language models (RALMs) improve performance by accessing long-tail and up-to-date knowledge from external data stores, but are challenging to build. Existing approaches require either expensive retrieval-specific modifications to LM pre-training or use post-hoc integration of the data store that leads to suboptimal performance. We introduce Retrieval-Augmented Dual Instruction Tuning (RA-DIT), a lightweight fine-tuning methodology that provides a third option by retrofitting any LLM with retrieval capabilities. Our approach operates in two distinct fine-tuning steps: (1) one updates a pre-trained LM to better use retrieved information, while (2) the other updates the retriever to return more relevant results, as preferred by the LM. By fine-tuning over tasks that require both knowledge utilization and contextual awareness, we demonstrate that each stage yields significant performance improvements, and using both leads to additional gains. Our best model, RA-DIT 65B, achieves state-of-the-art performance across a range of knowledge-intensive zero- and few-shot learning benchmarks, significantly outperforming existing in-context RALM approaches by up to +8.9% in 0-shot setting and +1.4% in 5-shot setting on average."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/017d267eefef6640ab9899888561b31b4b8ff711.pdf"}, "supplementary_material": {"value": "/attachment/b6da7054aeda7183488cdd1e45f8a3c869210ddc.pdf"}, "_bibtex": {"value": "@inproceedings{\nlin2024radit,\ntitle={{RA}-{DIT}: Retrieval-Augmented Dual Instruction Tuning},\nauthor={Xi Victoria Lin and Xilun Chen and Mingda Chen and Weijia Shi and Maria Lomeli and Richard James and Pedro Rodriguez and Jacob Kahn and Gergely Szilvasy and Mike Lewis and Luke Zettlemoyer and Wen-tau Yih},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=22OTbutug9}\n}"}, "paperhash": {"value": "lin|radit_retrievalaugmented_dual_instruction_tuning"}}, "number": 6563, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6563/-/Revision", "ICLR.cc/2024/Conference/Submission6563/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6563/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427853444, "cdate": 1695427853444, "tmdate": 1710535833110, "mdate": 1710535833110, "pdate": 1705410979485, "version": 2}, {"id": "rM9VJPB20F", "forum": "rM9VJPB20F", "signatures": ["ICLR.cc/2024/Conference/Submission6555/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6555/Authors"], "content": {"title": {"value": "Like Oil and Water: Group Robustness Methods and Poisoning Defenses May Be at Odds"}, "authors": {"value": ["Michael-Andrei Panaitescu-Liess", "Yigitcan Kaya", "Sicheng Zhu", "Furong Huang", "Tudor Dumitras"]}, "authorids": {"value": ["~Michael-Andrei_Panaitescu-Liess1", "~Yigitcan_Kaya2", "~Sicheng_Zhu1", "~Furong_Huang1", "~Tudor_Dumitras1"]}, "keywords": {"value": ["poisoning", "adversarial machine learning", "group robustness"]}, "TLDR": {"value": "We identify that inadvertently (i) approaches to group robustness without annotations amplify poison samples and (ii) poisoning defenses eliminate legitimate minority samples."}, "abstract": {"value": "Group robustness has become a major concern in machine learning (ML) as conventional training paradigms were found to produce high error on minority groups. Without explicit group annotations, proposed solutions rely on heuristics that aim to identify and then amplify the minority samples during training. In our work, we first uncover a critical shortcoming of these methods: an inability to distinguish legitimate minority samples from poison samples in the training set. By amplifying poison samples as well, group robustness methods inadvertently boost the success rate of an adversary---e.g., from 0\\% without amplification to over 97\\% with it. Notably, we supplement our empirical evidence with an impossibility result proving this inability of a standard heuristic under some assumptions. Moreover, scrutinizing recent poisoning defenses both in centralized and federated learning, we observe that they rely on similar heuristics to identify which samples should be eliminated as poisons. In consequence, minority samples are eliminated along with poisons, which damages group robustness---e.g., from 55\\% without the removal of the minority samples to 41\\% with it. Finally, as they pursue opposing goals using similar heuristics, our attempt to alleviate the trade-off by combining group robustness methods and poisoning defenses falls short. By exposing this tension, we also hope to highlight how benchmark-driven ML scholarship can obscure the trade-offs among different metrics with potentially detrimental consequences."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/20fa00ae60a87a5305a6cbef2e84388f4cc63d22.pdf"}, "_bibtex": {"value": "@inproceedings{\npanaitescu-liess2024like,\ntitle={Like Oil and Water: Group Robustness Methods and Poisoning Defenses Don't Mix},\nauthor={Michael-Andrei Panaitescu-Liess and Yigitcan Kaya and Sicheng Zhu and Furong Huang and Tudor Dumitras},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rM9VJPB20F}\n}"}, "paperhash": {"value": "panaitesculiess|like_oil_and_water_group_robustness_methods_and_poisoning_defenses_may_be_at_odds"}}, "number": 6555, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6555/-/Revision", "ICLR.cc/2024/Conference/Submission6555/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6555/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427589871, "cdate": 1695427589871, "tmdate": 1713171160935, "mdate": 1713171160935, "pdate": 1705410979271, "version": 2}, {"id": "WyEdX2R4er", "forum": "WyEdX2R4er", "signatures": ["ICLR.cc/2024/Conference/Submission6549/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6549/Authors"], "content": {"title": {"value": "Visual Data-Type Understanding does not emerge from scaling Vision-Language Models"}, "authors": {"value": ["Vishaal Udandarao", "Max F Burg", "Samuel Albanie", "Matthias Bethge"]}, "authorids": {"value": ["~Vishaal_Udandarao1", "~Max_F_Burg1", "~Samuel_Albanie2", "~Matthias_Bethge1"]}, "keywords": {"value": ["Data-Type Understanding", "Vision-Language Models", "Scaling"]}, "abstract": {"value": "Recent advances in the development of vision-language models (VLMs) are yielding remarkable success in recognizing visual semantic content, including impressive instances of compositional image understanding. Here, we introduce the novel task of Visual Data-Type Identification, a basic perceptual skill with implications for data curation (e.g., noisy data-removal from large datasets, domains pecific retrieval) and autonomous vision (e.g., distinguishing changing weather conditions from camera lens staining). We develop two datasets consisting of animal images altered across a diverse set of 27 visual data-types, spanning four broad categories. An extensive zero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced performance landscape. While VLMs are reasonably good at identifying certain stylistic data-types, such as cartoons and sketches, they struggle with simpler data-types arising from basic manipulations like image rotations or additive noise. Our findings reveal that (i) model scaling alone yields marginal gains for contrastively-trained models like CLIP, and (ii) there is a pronounced drop in performance for the largest auto-regressively trained VLMs like OpenFlamingo. This finding points to a blind spot in current frontier VLMs: they excel in recognizing semantic content but fail to acquire an\nunderstanding of visual data-types through scaling. By analyzing the pre-training distributions of these models and incorporating data-type information into the captions during fine-tuning, we achieve a significant enhancement in performance. By exploring this previously uncharted task, we aim to set the stage for further advancing VLMs to equip them with visual data-type understanding."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3d6f28056a72139d6a3d3b820e88727454b8139b.pdf"}, "_bibtex": {"value": "@inproceedings{\nudandarao2024visual,\ntitle={Visual Data-Type Understanding does not emerge from scaling Vision-Language Models},\nauthor={Vishaal Udandarao and Max F Burg and Samuel Albanie and Matthias Bethge},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WyEdX2R4er}\n}"}, "TLDR": {"value": "We introduce \"Visual Data-Type Identification\", a novel task for identifying visual distortions or perceptual changes to images, we find poor performance of VLMs across the board, and scaling models up does not improve performance significantly."}, "supplementary_material": {"value": "/attachment/0ddd4ec602e887cceb7f2bbd26e682e277001631.pdf"}, "paperhash": {"value": "udandarao|visual_datatype_understanding_does_not_emerge_from_scaling_visionlanguage_models"}}, "number": 6549, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6549/-/Revision", "ICLR.cc/2024/Conference/Submission6549/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6549/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427118096, "cdate": 1695427118096, "tmdate": 1710068585661, "mdate": 1710068585661, "pdate": 1705410979112, "version": 2}, {"id": "ORUiqcLpV6", "forum": "ORUiqcLpV6", "signatures": ["ICLR.cc/2024/Conference/Submission6539/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6539/Authors"], "content": {"title": {"value": "CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding"}, "authors": {"value": ["Eslam Mohamed BAKR", "Mohamed Ayman Mohamed", "Mahmoud Ahmed", "Habib Slim", "Mohamed Elhoseiny"]}, "authorids": {"value": ["~Eslam_Mohamed_BAKR1", "~Mohamed_Ayman_Mohamed1", "~Mahmoud_Ahmed2", "~Habib_Slim1", "~Mohamed_Elhoseiny1"]}, "keywords": {"value": ["3D referring", "3D visual grounding", "localization", "3D"]}, "TLDR": {"value": "We formulate the 3D visual grounding problem as a sequence-to-sequence (Seq2Seq) task, by predicting a chain of anchors first then utilizing them to predict the final target."}, "abstract": {"value": "3D visual grounding is the ability to localize objects in 3D scenes conditioned on\nan input utterance. Most existing methods devote the referring head to localize the\nreferred object directly. However, this approach will fail in complex scenarios and\nnot illustrate how and why the network reaches the final decision. In this paper,\nwe address this question \u201cCan we design an interpretable 3D visual grounding\nframework that has the potential to mimic the human perception system?\u201d. To this\nend, we formulate the 3D visual grounding problem as a sequence-to-sequence\n(Seq2Seq) task by first predicting a chain of anchors and then utilizing them to pre-\ndict the final target. Following the chain of thoughts approach enables us to decom-\npose the referring task into interpretable intermediate steps, which in turn, boosts\nthe performance and makes our framework extremely data-efficient. Interpretabil-\nity not only improves the overall performance but also helps us identify failure\ncases. Moreover, our proposed framework can be easily integrated into any existing\narchitecture. We validate our approach through comprehensive experiments on the\nNr3D and Sr3D benchmarks and show consistent performance gains compared to\nexisting methods without requiring any manually annotated data. Furthermore, our\nproposed framework, dubbed CoT3DRef, is significantly data-efficient, whereas\nwhen trained only on 10% of the data, we match the SOTA performance that trained\non the entire data. The code is available at https://cot3dref.github.io/."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/76338126d1c431a7680d43bbbf685cb6598f03ba.pdf"}, "supplementary_material": {"value": "/attachment/84138ef2b80a9545264ccd23266798e9c97deb18.zip"}, "_bibtex": {"value": "@inproceedings{\nbakr2024cotdref,\ntitle={CoT3{DR}ef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding},\nauthor={Eslam Mohamed BAKR and Mohamed Ayman Mohamed and Mahmoud Ahmed and Habib Slim and Mohamed Elhoseiny},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ORUiqcLpV6}\n}"}, "paperhash": {"value": "bakr|cot3dref_chainofthoughts_dataefficient_3d_visual_grounding"}}, "number": 6539, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6539/-/Revision", "ICLR.cc/2024/Conference/Submission6539/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695426590816, "cdate": 1695426590816, "tmdate": 1707625633160, "mdate": 1707625633160, "pdate": 1705410978924, "version": 2}, {"id": "z6n1fKMMC1", "forum": "z6n1fKMMC1", "signatures": ["ICLR.cc/2024/Conference/Submission6537/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6537/Authors"], "content": {"title": {"value": "An Efficient Tester-Learner for Halfspaces"}, "authors": {"value": ["Aravind Gollakota", "Adam Klivans", "Konstantinos Stavropoulos", "Arsen Vasilyan"]}, "authorids": {"value": ["~Aravind_Gollakota1", "~Adam_Klivans1", "~Konstantinos_Stavropoulos1", "~Arsen_Vasilyan1"]}, "keywords": {"value": ["testable learning", "pac learning", "agnostic learning", "Massart label noise", "adversarial label noise", "distribution testing"]}, "abstract": {"value": "We give the first efficient algorithm for learning halfspaces in the testable learning model recently defined by Rubinfeld and Vasilyan [2022]. In this model, a learner certifies that the accuracy of its output hypothesis is near optimal whenever the training set passes an associated test, and training sets drawn from some target distribution must pass the test. This model is more challenging than distribution-specific agnostic or Massart noise models where the learner is allowed to fail arbitrarily if the distributional assumption does not hold. We consider the setting where the target distribution is the standard Gaussian in $d$ dimensions and the label noise is either Massart or adversarial (agnostic). For Massart noise, our tester-learner runs in polynomial time and outputs a hypothesis with (information-theoretically optimal) error $\\mathrm{opt}+\\epsilon$ (and extends to any fixed strongly log-concave target distribution). For adversarial noise, our tester-learner obtains error $O(\\mathrm{opt})+\\epsilon$ in polynomial time. Prior work on testable learning ignores the labels in the training set and checks that the empirical moments of the covariates are close to the moments of the base distribution. Here we develop new tests of independent interest that make critical use of the labels and combine them with the moment-matching approach of Gollakota et al. [2022]. This enables us to implement a testable variant of the algorithm of Diakonikolas et al. [2020a, 2020b] for learning noisy halfspaces using nonconvex SGD."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/eefce7fc0abe769edbcacf76a21bdd77c35bbbad.pdf"}, "_bibtex": {"value": "@inproceedings{\ngollakota2024an,\ntitle={An Efficient Tester-Learner for Halfspaces},\nauthor={Aravind Gollakota and Adam Klivans and Konstantinos Stavropoulos and Arsen Vasilyan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=z6n1fKMMC1}\n}"}, "paperhash": {"value": "gollakota|an_efficient_testerlearner_for_halfspaces"}}, "number": 6537, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6537/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6537/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695426533900, "cdate": 1695426533900, "tmdate": 1710278868942, "mdate": 1710278868942, "pdate": 1705410978778, "version": 2}, {"id": "NGVljI6HkR", "forum": "NGVljI6HkR", "signatures": ["ICLR.cc/2024/Conference/Submission6536/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6536/Authors"], "content": {"title": {"value": "Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces"}, "authors": {"value": ["Tales Henrique Carvalho", "Kenneth Tjhia", "Levi Lelis"]}, "authorids": {"value": ["~Tales_Henrique_Carvalho1", "~Kenneth_Tjhia1", "~Levi_Lelis1"]}, "keywords": {"value": ["programmatic policy", "reinforcement learning"]}, "abstract": {"value": "Recent works have introduced LEAPS and HPRL, systems that learn latent spaces of domain-specific languages, which are used to define programmatic policies for partially observable Markov decision processes (POMDPs). These systems induce a latent space while optimizing losses such as the behavior loss, which aim to achieve locality in program behavior, meaning that vectors close in the latent space should correspond to similarly behaving programs. In this paper, we show that the programmatic space, induced by the domain-specific language and requiring no training, presents values for the behavior loss similar to those observed in latent spaces presented in previous work. Moreover, algorithms searching in the programmatic space significantly outperform those in LEAPS and HPRL. To explain our results, we measured the \"friendliness\" of the two spaces to local search algorithms. We discovered that algorithms are more likely to stop at local maxima when searching in the latent space than when searching in the programmatic space. This implies that the optimization topology of the programmatic space, induced by the reward function in conjunction with the neighborhood function, is more conducive to search than that of the latent space. This result provides an explanation for the superior performance in the programmatic space."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3df7742658d0b4fb95074a7d340cdf72ad6e5b70.pdf"}, "_bibtex": {"value": "@inproceedings{\ncarvalho2024reclaiming,\ntitle={Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces},\nauthor={Tales Henrique Carvalho and Kenneth Tjhia and Levi Lelis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NGVljI6HkR}\n}"}, "paperhash": {"value": "carvalho|reclaiming_the_source_of_programmatic_policies_programmatic_versus_latent_spaces"}}, "number": 6536, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6536/-/Revision", "ICLR.cc/2024/Conference/Submission6536/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6536/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695426486022, "cdate": 1695426486022, "tmdate": 1713073926170, "mdate": 1713073926170, "pdate": 1705410978770, "version": 2}, {"id": "EpVe8jAjdx", "forum": "EpVe8jAjdx", "signatures": ["ICLR.cc/2024/Conference/Submission6525/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6525/Authors"], "content": {"title": {"value": "Privileged Sensing Scaffolds Reinforcement Learning"}, "authors": {"value": ["Edward S. Hu", "James Springer", "Oleh Rybkin", "Dinesh Jayaraman"]}, "authorids": {"value": ["~Edward_S._Hu1", "~James_Springer1", "~Oleh_Rybkin1", "~Dinesh_Jayaraman2"]}, "keywords": {"value": ["reinforcement learning", "model-based reinforcement learning", "world models", "robotics", "privileged information", "asymmetric learning", "multimodality", "perception", "sensing"]}, "TLDR": {"value": "We study how privileged, training-time only observation streams can aid skill learning, and instantiate a MBRL algorithm that incorporates privileged sensing into all auxiliary, training-time components of RL to better train the policy."}, "abstract": {"value": "We need to look at our shoelaces as we first learn to tie them but having mastered this skill, can do it from touch alone. We call this phenomenon \u201csensory scaffolding\u201d: observation streams that are not needed by a master might yet aid a novice learner. We consider such sensory scaffolding setups for training artificial agents. For example, a robot arm may need to be deployed with just a low-cost, robust, general-purpose camera; yet its performance may improve by having privileged training-time-only access to informative albeit expensive and unwieldy motion capture rigs or fragile tactile sensors. For these settings, we propose \u201cScaffolder\u201d, a reinforcement learning approach which effectively exploits privileged sensing in critics, world models, reward estimators, and other such auxiliary components that are only used at training time, to improve the target policy. For evaluating sensory scaffolding agents, we design a new \u201cS3\u201d suite of ten diverse simulated robotic tasks that explore a wide range of practical sensor setups. Agents must use privileged camera sensing to train blind hurdlers, privileged active visual perception to help robot arms overcome visual occlusions, privileged touch sensors to train robot hands, and more. Scaffolder easily outperforms relevant prior baselines and frequently performs comparably even to policies that have test-time access to the privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8ab7ec56b6e56ac45ce2b68e95b277283dbb8377.pdf"}, "_bibtex": {"value": "@inproceedings{\nhu2024privileged,\ntitle={Privileged Sensing Scaffolds Reinforcement Learning},\nauthor={Edward S. Hu and James Springer and Oleh Rybkin and Dinesh Jayaraman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EpVe8jAjdx}\n}"}, "paperhash": {"value": "hu|privileged_sensing_scaffolds_reinforcement_learning"}}, "number": 6525, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6525/-/Revision", "ICLR.cc/2024/Conference/Submission6525/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6525/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425995877, "cdate": 1695425995877, "tmdate": 1710535293576, "mdate": 1710535293576, "pdate": 1705410978560, "version": 2}, {"id": "w9tc699w3Z", "forum": "w9tc699w3Z", "signatures": ["ICLR.cc/2024/Conference/Submission6524/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6524/Authors"], "content": {"title": {"value": "Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment"}, "authors": {"value": ["Utkarsh Mall", "Cheng Perng Phoo", "Meilin Kelsey Liu", "Carl Vondrick", "Bharath Hariharan", "Kavita Bala"]}, "authorids": {"value": ["~Utkarsh_Mall1", "~Cheng_Perng_Phoo1", "~Meilin_Kelsey_Liu1", "~Carl_Vondrick2", "~Bharath_Hariharan3", "~Kavita_Bala1"]}, "keywords": {"value": ["remote sensing", "vision-language models", "zero-shot", "foundation models", "label-efficiency"]}, "TLDR": {"value": "We train vison-language models for remote sensing by using geo-tagged ground imagery."}, "abstract": {"value": "We introduce a method to train vision-language models for remote-sensing images without using any textual annotations. Our key insight is to use co-located internet imagery taken on the ground as an intermediary for connecting remote-sensing images and language.  Specifically, we train an image encoder for remote sensing images to align with the image encoder of CLIP using a large amount of paired internet and satellite images.  Our unsupervised approach enables the training of a first-of-its-kind large scale VLM for remote sensing images at two different resolutions. We show that these VLMs enable zero-shot, open-vocabulary image classification, retrieval, segmentation and visual question answering for satellite images. On each of these tasks, our VLM trained without textual annotations outperforms existing VLMs trained with supervision, with gains of up to 20\\% for classification and 80\\% for segmentation."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/370ae224e48efdaa00df70ae56301aacb505b967.pdf"}, "_bibtex": {"value": "@inproceedings{\nmall2024remote,\ntitle={Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment},\nauthor={Utkarsh Mall and Cheng Perng Phoo and Meilin Kelsey Liu and Carl Vondrick and Bharath Hariharan and Kavita Bala},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w9tc699w3Z}\n}"}, "paperhash": {"value": "mall|remote_sensing_visionlanguage_foundation_models_without_annotations_via_ground_remote_alignment"}}, "number": 6524, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6524/-/Revision", "ICLR.cc/2024/Conference/Submission6524/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6524/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425951415, "cdate": 1695425951415, "tmdate": 1710272092040, "mdate": 1710272092040, "pdate": 1705410978508, "version": 2}, {"id": "C36v8541Ns", "forum": "C36v8541Ns", "signatures": ["ICLR.cc/2024/Conference/Submission6520/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6520/Authors"], "content": {"title": {"value": "The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing"}, "authors": {"value": ["Blaise Delattre", "Alexandre Araujo", "Quentin Barth\u00e9lemy", "Alexandre Allauzen"]}, "authorids": {"value": ["~Blaise_Delattre1", "~Alexandre_Araujo3", "~Quentin_Barth\u00e9lemy1", "~Alexandre_Allauzen1"]}, "keywords": {"value": ["Lipschitz", "randomized smoothing", "margin", "variance", "deep learning"]}, "TLDR": {"value": "A study on the interplays between Lipschitz constant and randomized smoothing procedure."}, "abstract": {"value": "Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius in this context is a crucial indicator of the robustness of models. However how to design an efficient classifier with an associated certified radius? Randomized smoothing provides a promising framework by relying on noise injection into the inputs to obtain a smoothed and robust classifier. In this paper, we first show that the variance introduced by the Monte-Carlo sampling in the randomized smoothing procedure estimate closely interacts with two other important properties of the classifier, \\textit{i.e.} its Lipschitz constant and margin.  More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. To increase the certified robust radius, we introduce a different way to convert logits to probability vectors for the base classifier to leverage the variance-margin trade-off. We leverage the use of Bernstein's concentration inequality along with enhanced Lipschitz bounds for randomized smoothing. Experimental results show a significant improvement in certified accuracy compared to current state-of-the-art methods. Our novel certification procedure allows us to use pre-trained models with randomized smoothing, effectively improving the current certification radius in a zero-shot manner."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/465af4867b6fc2d48418f4ccca2f8b189ee23c23.pdf"}, "supplementary_material": {"value": "/attachment/e4828517e9cb92e701484d6ccc75713bf7186e27.zip"}, "_bibtex": {"value": "@inproceedings{\ndelattre2024the,\ntitle={The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing},\nauthor={Blaise Delattre and Alexandre Araujo and Quentin Barth{\\'e}lemy and Alexandre Allauzen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=C36v8541Ns}\n}"}, "paperhash": {"value": "delattre|the_lipschitzvariancemargin_tradeoff_for_enhanced_randomized_smoothing"}}, "number": 6520, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6520/-/Revision", "ICLR.cc/2024/Conference/Submission6520/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6520/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425808803, "cdate": 1695425808803, "tmdate": 1710323870344, "mdate": 1710323870344, "pdate": 1705410978452, "version": 2}, {"id": "xnhvVtZtLD", "forum": "xnhvVtZtLD", "signatures": ["ICLR.cc/2024/Conference/Submission6517/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6517/Authors"], "content": {"title": {"value": "On the Fairness ROAD: Robust Optimization for Adversarial Debiasing"}, "authors": {"value": ["Vincent Grari", "Thibault Laugel", "Tatsunori Hashimoto", "sylvain lamprier", "Marcin Detyniecki"]}, "authorids": {"value": ["~Vincent_Grari1", "~Thibault_Laugel1", "~Tatsunori_Hashimoto1", "~sylvain_lamprier1", "~Marcin_Detyniecki1"]}, "keywords": {"value": ["Fairness", "DRO", "Adversarial Learning"]}, "TLDR": {"value": "Enforcing local fairness via robust optimization and adversarial debiasing."}, "abstract": {"value": "In the field of algorithmic fairness, significant attention has been put on group fairness criteria, such as Demographic Parity and Equalized Odds. Nevertheless, these objectives, measured as global averages,  have raised concerns about persistent local disparities between sensitive groups. In this work, we address the problem of local fairness, which ensures that the predictor is unbiased not only in terms of expectations over the whole population, but also within any subregion of the feature space, unknown at training time. To enforce this objective, we introduce ROAD, a novel approach that leverages the Distributionally Robust Optimization (DRO) framework  within a fair adversarial learning objective, where an adversary tries to infer the sensitive attribute from the predictions. Using an instance-level re-weighting strategy, ROAD is designed to prioritize inputs that are likely to be locally unfair, i.e. where the adversary faces the least difficulty in reconstructing the sensitive attribute. Numerical experiments demonstrate the effectiveness of our method: it achieves Pareto dominance with respect to local fairness and accuracy for a given global fairness level across three standard datasets, and also enhances fairness generalization under distribution shift."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b8394144ea84be639b6ebec70f20eb6bba560e7d.pdf"}, "supplementary_material": {"value": "/attachment/56745b711682eb086f29cc62b1eeee99d155f927.zip"}, "_bibtex": {"value": "@inproceedings{\ngrari2024on,\ntitle={On the Fairness {ROAD}: Robust Optimization for Adversarial Debiasing},\nauthor={Vincent Grari and Thibault Laugel and Tatsunori Hashimoto and sylvain lamprier and Marcin Detyniecki},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xnhvVtZtLD}\n}"}, "paperhash": {"value": "grari|on_the_fairness_road_robust_optimization_for_adversarial_debiasing"}}, "number": 6517, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6517/-/Revision", "ICLR.cc/2024/Conference/Submission6517/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6517/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425693060, "cdate": 1695425693060, "tmdate": 1710350245426, "mdate": 1710350245426, "pdate": 1705410978355, "version": 2}, {"id": "3UWuFoksGb", "forum": "3UWuFoksGb", "signatures": ["ICLR.cc/2024/Conference/Submission6513/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6513/Authors"], "content": {"title": {"value": "Learning Planning Abstractions from Language"}, "authors": {"value": ["Weiyu Liu", "Geng Chen", "Joy Hsu", "Jiayuan Mao", "Jiajun Wu"]}, "authorids": {"value": ["~Weiyu_Liu1", "~Geng_Chen3", "~Joy_Hsu2", "~Jiayuan_Mao1", "~Jiajun_Wu1"]}, "keywords": {"value": ["Planning and Learning", "Learning Abstractions", "Compositional Generalization", "Robotic Manipulation"]}, "TLDR": {"value": "A framework that utilizes language-annotated demonstrations to automatically discover a symbolic and abstract action space and induce a latent state abstraction for planning."}, "abstract": {"value": "This paper presents a framework for learning state and action abstractions in sequential decision-making domains. Our framework, planning abstraction from language (PARL), utilizes language-annotated demonstrations to automatically discover a symbolic and abstract action space and induce a latent state abstraction based on it. PARL consists of three stages: 1) recovering object-level and action concepts, 2) learning state abstractions, abstract action feasibility, and transition models, and 3) applying low-level policies for abstract actions. During inference, given the task description, PARL first makes abstract action plans using the latent transition and feasibility functions, then refines the high-level plan using low-level policies. PARL generalizes across scenarios involving novel object instances and environments, unseen concept compositions, and tasks that require longer planning horizons than settings it is trained on."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9d32040b698a4951726efd59207a7258ec83a57c.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024learning,\ntitle={Learning Planning Abstractions from Language},\nauthor={Weiyu Liu and Geng Chen and Jiayuan Mao and Joy Hsu and Jiajun Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3UWuFoksGb}\n}"}, "paperhash": {"value": "liu|learning_planning_abstractions_from_language"}}, "number": 6513, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6513/-/Revision", "ICLR.cc/2024/Conference/Submission6513/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6513/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425535536, "cdate": 1695425535536, "tmdate": 1710568410832, "mdate": 1710568410832, "pdate": 1705410978231, "version": 2}, {"id": "t8eO0CiZJV", "forum": "t8eO0CiZJV", "signatures": ["ICLR.cc/2024/Conference/Submission6506/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6506/Authors"], "content": {"title": {"value": "Tailoring Self-Rationalizers with Multi-Reward Distillation"}, "authors": {"value": ["Sahana Ramnath", "Brihi Joshi", "Skyler Hallinan", "Ximing Lu", "Liunian Harold Li", "Aaron Chan", "Jack Hessel", "Yejin Choi", "Xiang Ren"]}, "authorids": {"value": ["~Sahana_Ramnath2", "~Brihi_Joshi1", "~Skyler_Hallinan1", "~Ximing_Lu1", "~Liunian_Harold_Li1", "~Aaron_Chan1", "~Jack_Hessel1", "~Yejin_Choi1", "~Xiang_Ren1"]}, "keywords": {"value": ["large language models", "rationalization", "explanation generation", "explainability", "rationale generation"]}, "abstract": {"value": "Large language models (LMs) are capable of generating free-text rationales to aid question answering. However, prior work 1) suggests that useful self-rationalization is emergent only at significant scales (e.g., 175B parameter GPT-3); and 2) focuses largely on downstream performance, ignoring the semantics of the rationales themselves, e.g., are they faithful, true, and helpful for humans? In this work, we enable small-scale LMs (\u223c200x smaller than GPT-3) to generate rationales that not only improve downstream task performance, but are also more plausible, consistent, and diverse, assessed both by automatic and human evaluation. Our method, MaRio (Multi-rewArd RatIOnalization), is a multi-reward conditioned self-rationalization algorithm that optimizes multiple distinct properties like plausibility, diversity and consistency. Results on three difficult question-answering datasets StrategyQA, QuaRel and OpenBookQA show that not only does MaRio improve task accuracy, but it also improves the self-rationalization quality of small LMs across the aforementioned axes better than a supervised fine-tuning (SFT) baseline. Extensive human evaluations confirm that MaRio rationales are preferred vs. SFT rationales, as well as qualitative improvements in plausibility and consistency."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/698259d222d1cd982389fd9eae7416b233dc8c06.pdf"}, "supplementary_material": {"value": "/attachment/3e86abcfcc335190c60121bcaf4828402cb3db8c.zip"}, "TLDR": {"value": "Multi-reward conditioned algorithm that makes small LMs stronger rationalizers."}, "_bibtex": {"value": "@inproceedings{\nramnath2024tailoring,\ntitle={Tailoring Self-Rationalizers with Multi-Reward Distillation},\nauthor={Sahana Ramnath and Brihi Joshi and Skyler Hallinan and Ximing Lu and Liunian Harold Li and Aaron Chan and Jack Hessel and Yejin Choi and Xiang Ren},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=t8eO0CiZJV}\n}"}, "paperhash": {"value": "ramnath|tailoring_selfrationalizers_with_multireward_distillation"}}, "number": 6506, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6506/-/Revision", "ICLR.cc/2024/Conference/Submission6506/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6506/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425223497, "cdate": 1695425223497, "tmdate": 1710484297165, "mdate": 1710484297165, "pdate": 1705410977970, "version": 2}, {"id": "EnXJfQqy0K", "forum": "EnXJfQqy0K", "signatures": ["ICLR.cc/2024/Conference/Submission6505/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6505/Authors"], "content": {"title": {"value": "Building Cooperative Embodied Agents Modularly with Large Language Models"}, "authors": {"value": ["Hongxin Zhang", "Weihua Du", "Jiaming Shan", "Qinhong Zhou", "Yilun Du", "Joshua B. Tenenbaum", "Tianmin Shu", "Chuang Gan"]}, "authorids": {"value": ["~Hongxin_Zhang1", "~Weihua_Du1", "~Jiaming_Shan1", "~Qinhong_Zhou1", "~Yilun_Du1", "~Joshua_B._Tenenbaum1", "~Tianmin_Shu1", "~Chuang_Gan1"]}, "keywords": {"value": ["Large Language Models", "Embodied Intelligence", "Multi-Agent Cooperation", "Human-AI Interaction", "Communication"]}, "abstract": {"value": "In this work, we address challenging multi-agent cooperation problems with decentralized control, raw sensory observations, costly communication, and multi-objective tasks instantiated in various embodied environments. While previous research either presupposes a cost-free communication channel or relies on a centralized controller with shared observations, we harness the commonsense knowledge, reasoning ability, language comprehension, and text generation prowess of LLMs and seamlessly incorporate them into a cognitive-inspired modular framework that integrates with perception, memory, and execution. Thus building a Cooperative Embodied Language Agent CoELA, who can plan, communicate, and cooperate with others to accomplish long-horizon tasks efficiently. Our experiments on C-WAH and TDW-MAT demonstrate that CoELA driven by GPT-4 can surpass strong planning-based methods and exhibit emergent effective communication. Though current Open LMs like LLAMA-2 still underperform, we fine-tune a CoELA with data collected with our agents and show how they can achieve promising performance. We also conducted a user study for human-agent interaction and discovered that CoELA communicating in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dc07be159d900727ce3c1de67e030e90e199f0e3.pdf"}, "supplementary_material": {"value": "/attachment/1731274f5896d9b18709ef40c49c8d05cd933277.zip"}, "TLDR": {"value": "We present CoELA, a modular framework integrating LLMs to address the challenging multi-agent embodied cooperation problem with decentralized control, costly communication, and long-horizon multi-objective tasks."}, "_bibtex": {"value": "@inproceedings{\nzhang2024building,\ntitle={Building Cooperative Embodied Agents Modularly with Large Language Models},\nauthor={Hongxin Zhang and Weihua Du and Jiaming Shan and Qinhong Zhou and Yilun Du and Joshua B. Tenenbaum and Tianmin Shu and Chuang Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EnXJfQqy0K}\n}"}, "paperhash": {"value": "zhang|building_cooperative_embodied_agents_modularly_with_large_language_models"}}, "number": 6505, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6505/-/Revision", "ICLR.cc/2024/Conference/Submission6505/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6505/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425214791, "cdate": 1695425214791, "tmdate": 1710442562200, "mdate": 1710442562200, "pdate": 1705410977934, "version": 2}, {"id": "TTonmgTT9X", "forum": "TTonmgTT9X", "signatures": ["ICLR.cc/2024/Conference/Submission6504/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6504/Authors"], "content": {"title": {"value": "Fast Hyperboloid Decision Tree Algorithms"}, "authors": {"value": ["Philippe Chlenski", "Ethan Turok", "Antonio Khalil Moretti", "Itsik Pe'er"]}, "authorids": {"value": ["~Philippe_Chlenski1", "~Ethan_Turok1", "~Antonio_Khalil_Moretti1", "~Itsik_Pe'er1"]}, "keywords": {"value": ["hyperbolic space", "random forest", "decision tree"]}, "TLDR": {"value": "Decision trees and random forests with geodesic splits work well in hyperbolic space"}, "abstract": {"value": "Hyperbolic geometry is gaining traction in machine learning due to its capacity to effectively capture hierarchical structures in real-world data. Hyperbolic spaces, where neighborhoods grow exponentially, offer substantial advantages and have consistently delivered state-of-the-art results across diverse applications. However, hyperbolic classifiers often grapple with computational challenges. Methods reliant on Riemannian optimization frequently exhibit sluggishness, stemming from the increased computational demands of operations on Riemannian manifolds. In response to these challenges, we present HyperDT, a novel extension of decision tree algorithms into hyperbolic space. Crucially, HyperDT eliminates the need for computationally intensive Riemannian optimization, numerically unstable exponential and logarithmic maps, or pairwise comparisons between points by leveraging inner products to adapt Euclidean decision tree algorithms to hyperbolic space. Our approach is conceptually straightforward and maintains constant-time decision complexity while mitigating the scalability issues inherent in high-dimensional Euclidean spaces. Building upon HyperDT, we introduce HyperRF, a hyperbolic random forest model. Extensive benchmarking across diverse datasets underscores the superior performance of these models, providing a swift, precise, accurate, and user-friendly toolkit for hyperbolic data analysis."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/183233d4ddc4a41f3f9bdafc317ae392c3169f9f.pdf"}, "supplementary_material": {"value": "/attachment/3da8fd194bede32dfd451d7cfa91bc0f277b79c4.zip"}, "_bibtex": {"value": "@inproceedings{\nchlenski2024fast,\ntitle={Fast Hyperboloid Decision Tree Algorithms},\nauthor={Philippe Chlenski and Ethan Turok and Antonio Khalil Moretti and Itsik Pe'er},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TTonmgTT9X}\n}"}, "paperhash": {"value": "chlenski|fast_hyperboloid_decision_tree_algorithms"}}, "number": 6504, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6504/-/Revision", "ICLR.cc/2024/Conference/-/PC_Revision", "ICLR.cc/2024/Conference/Submission6504/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6504/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425211825, "cdate": 1695425211825, "tmdate": 1709661531920, "mdate": 1709661531920, "pdate": 1705410977905, "version": 2}, {"id": "IzqZbNMZ0M", "forum": "IzqZbNMZ0M", "signatures": ["ICLR.cc/2024/Conference/Submission6503/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6503/Authors"], "content": {"title": {"value": "Private Zeroth-Order Nonsmooth Nonconvex Optimization"}, "authors": {"value": ["Qinzi Zhang", "Hoang Tran", "Ashok Cutkosky"]}, "authorids": {"value": ["~Qinzi_Zhang1", "~Hoang_Tran4", "~Ashok_Cutkosky1"]}, "keywords": {"value": ["optimization", "differential privacy", "non-convex", "non-smooth"]}, "abstract": {"value": "We introduce a new zeroth-order algorithm for private stochastic optimization on nonconvex and nonsmooth objectives.\nGiven a dataset of size $M$, our algorithm ensures $(\\alpha,\\alpha\\rho^2/2)$-Renyi differential privacy and finds a $(\\delta,\\epsilon)$-stationary point so long as $M=\\tilde\\Omega(\\frac{d}{\\delta\\epsilon^3} + \\frac{d^{3/2}}{\\rho\\delta\\epsilon^2})$.\nThis matches the optimal complexity found in its non-private zeroth-order analog. \nNotably, although the objective is not smooth, we have privacy ``for free'' when $\\rho \\ge \\sqrt{d}\\epsilon$."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/00ea93be69a0a12570a6a8cabcff7d127a3383af.pdf"}, "supplementary_material": {"value": "/attachment/50d724132c30a074d78745a4c31787e41bbcd10c.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024private,\ntitle={Private Zeroth-Order Nonsmooth Nonconvex Optimization},\nauthor={Qinzi Zhang and Hoang Tran and Ashok Cutkosky},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IzqZbNMZ0M}\n}"}, "paperhash": {"value": "zhang|private_zerothorder_nonsmooth_nonconvex_optimization"}}, "number": 6503, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6503/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6503/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425049079, "cdate": 1695425049079, "tmdate": 1710550886305, "mdate": 1710550886305, "pdate": 1705410977868, "version": 2}, {"id": "3xHDeA8Noi", "forum": "3xHDeA8Noi", "signatures": ["ICLR.cc/2024/Conference/Submission6492/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6492/Authors"], "content": {"title": {"value": "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training"}, "authors": {"value": ["Hong Liu", "Zhiyuan Li", "David Leo Wright Hall", "Percy Liang", "Tengyu Ma"]}, "authorids": {"value": ["~Hong_Liu5", "~Zhiyuan_Li2", "~David_Leo_Wright_Hall1", "~Percy_Liang1", "~Tengyu_Ma1"]}, "keywords": {"value": ["large language models", "pretraining", "optimization in deep learning"]}, "abstract": {"value": "Given the massive cost of language model pre-training, a non-trivial improvement of the optimization algorithm would lead to a material reduction on the time and cost of training. Adam and its variants have been state-of-the-art for years, and more sophisticated second-order (Hessian-based) optimizers often incur too much per-step overhead. In this paper, we propose Sophia, a simple scalable second-order optimizer that uses a light-weight estimate of the diagonal Hessian as the pre-conditioner. The update is the moving average of the gradients divided by the moving average of the estimated Hessian, followed by element-wise clipping. The clipping controls the worst-case update size and tames the negative impact of non-convexity and rapid change of Hessian along the trajectory. Sophia only estimates the diagonal Hessian every handful of iterations, which has negligible average per-step time and memory overhead. On language modeling with GPT models of sizes ranging from 125M to 1.5B, Sophia achieves a 2x speed-up compared to Adam in the number of steps, total compute, and wall-clock time, achieving the same perplexity with 50\\% fewer steps, less total compute, and reduced wall-clock time."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/394bc531aa1bd41f10457a74817768d87b04566b.pdf"}, "supplementary_material": {"value": "/attachment/95a79cae116529a8b29395efabc5dd175b828ebd.zip"}, "TLDR": {"value": "We design a stochastic second-order optimizer for language model pre-training which is significantly faster than Adam."}, "_bibtex": {"value": "@inproceedings{\nliu2024sophia,\ntitle={Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training},\nauthor={Hong Liu and Zhiyuan Li and David Leo Wright Hall and Percy Liang and Tengyu Ma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3xHDeA8Noi}\n}"}, "paperhash": {"value": "liu|sophia_a_scalable_stochastic_secondorder_optimizer_for_language_model_pretraining"}}, "number": 6492, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6492/-/Revision", "ICLR.cc/2024/Conference/Submission6492/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6492/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424515896, "cdate": 1695424515896, "tmdate": 1712644618366, "mdate": 1712644618366, "pdate": 1705410977611, "version": 2}, {"id": "yRrPfKyJQ2", "forum": "yRrPfKyJQ2", "signatures": ["ICLR.cc/2024/Conference/Submission6490/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6490/Authors"], "content": {"title": {"value": "Conversational Drug Editing Using Retrieval and Domain Feedback"}, "authors": {"value": ["Shengchao Liu", "Jiongxiao Wang", "Yijin Yang", "Chengpeng Wang", "Ling Liu", "Hongyu Guo", "Chaowei Xiao"]}, "authorids": {"value": ["~Shengchao_Liu1", "~Jiongxiao_Wang1", "~Yijin_Yang2", "~Chengpeng_Wang1", "~Ling_Liu7", "~Hongyu_Guo1", "~Chaowei_Xiao2"]}, "keywords": {"value": ["Large Language Models", "prompt", "retrieval", "domain feedback", "conversation", "drug editing", "drug optimization", "controllable generation", "small molecule", "peptide", "protein"]}, "TLDR": {"value": "We propose ChatDrug, a framework that utilizing Large Language Models for conversation drug editing with a retrieval and domain feedback module."}, "abstract": {"value": "Recent advancements in conversational large language models (LLMs), such as ChatGPT, have demonstrated remarkable promise in various domains, including drug discovery. However, existing works mainly focus on investigating the capabilities of conversational LLMs on chemical reactions and retrosynthesis. While drug editing, a critical task in the drug discovery pipeline, remains largely unexplored. To bridge this gap, we propose ChatDrug, a framework to facilitate the systematic investigation of drug editing using LLMs. ChatDrug jointly leverages a prompt module, a retrieval and domain feedback module, and a conversation module to streamline effective drug editing. We empirically show that ChatDrug reaches the best performance on all 39 drug editing tasks, encompassing small molecules, peptides, and proteins. We further demonstrate, through 10 case studies, that ChatDrug can successfully identify the key substructures for manipulation, generating diverse and valid suggestions for drug editing. Promisingly, we also show that ChatDrug can offer insightful explanations from a domain-specific perspective, enhancing interpretability and enabling informed decision-making."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/857cda25f605f8054f538d39823dd8328fc64da4.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024conversational,\ntitle={Conversational Drug Editing Using Retrieval and Domain Feedback},\nauthor={Shengchao Liu and Jiongxiao Wang and Yijin Yang and Chengpeng Wang and Ling Liu and Hongyu Guo and Chaowei Xiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yRrPfKyJQ2}\n}"}, "paperhash": {"value": "liu|conversational_drug_editing_using_retrieval_and_domain_feedback"}}, "number": 6490, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6490/-/Revision", "ICLR.cc/2024/Conference/Submission6490/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6490/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424451770, "cdate": 1695424451770, "tmdate": 1710647270401, "mdate": 1710647270401, "pdate": 1705410977609, "version": 2}, {"id": "iHcTLIor0m", "forum": "iHcTLIor0m", "signatures": ["ICLR.cc/2024/Conference/Submission6489/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6489/Authors"], "content": {"title": {"value": "Poly-View Contrastive Learning"}, "authors": {"value": ["Amitis Shidani", "R Devon Hjelm", "Jason Ramapuram", "Russell Webb", "Eeshan Gunesh Dhekane", "Dan Busbridge"]}, "authorids": {"value": ["~Amitis_Shidani1", "~R_Devon_Hjelm1", "~Jason_Ramapuram1", "~Russell_Webb1", "~Eeshan_Gunesh_Dhekane1", "~Dan_Busbridge1"]}, "keywords": {"value": ["Contrastive learning", "Self-Supervised Learning", "SimCLR", "Multi-View", "Augmentations", "Multiplicity", "InfoMax", "Sufficient Statistics"]}, "TLDR": {"value": "We look at contrastive learning with more than two related views per sample and find that for some objectives, performance can be improved compared to two views (e.g. SimCLR) at no computational cost."}, "abstract": {"value": "Contrastive learning typically matches pairs of related views among a number of unrelated negative views. Views can be generated (e.g. by augmentations) or be observed. We investigate matching when there are more than two related views which we call poly-view tasks,\nand derive new representation learning objectives using information maximization and sufficient statistics. We show that with unlimited computation, one should maximize the number of related views, and with a fixed compute budget, it is beneficial to decrease the number of unique samples whilst increasing the number of views of those samples. In particular, poly-view contrastive models trained for 128 epochs with batch size 256 outperform SimCLR trained for 1024 epochs at batch size 4096 on ImageNet1k, challenging the belief that contrastive models require large batch sizes and many training epochs."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c9436edbf2873e4b620287d0d65e7203b16ea79b.pdf"}, "_bibtex": {"value": "@inproceedings{\nshidani2024polyview,\ntitle={Poly-View Contrastive Learning},\nauthor={Amitis Shidani and Dan Busbridge and R Devon Hjelm and Jason Ramapuram and Eeshan Gunesh Dhekane and Russell Webb},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iHcTLIor0m}\n}"}, "paperhash": {"value": "shidani|polyview_contrastive_learning"}}, "number": 6489, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6489/-/Revision", "ICLR.cc/2024/Conference/Submission6489/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6489/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424449701, "cdate": 1695424449701, "tmdate": 1709917917425, "mdate": 1709917917425, "pdate": 1705410977561, "version": 2}, {"id": "MVe2dnWPCu", "forum": "MVe2dnWPCu", "signatures": ["ICLR.cc/2024/Conference/Submission6487/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6487/Authors"], "content": {"title": {"value": "A Probabilistic Framework for Modular Continual Learning"}, "authors": {"value": ["Lazar Valkov", "Akash Srivastava", "Swarat Chaudhuri", "Charles Sutton"]}, "authorids": {"value": ["~Lazar_Valkov1", "~Akash_Srivastava1", "~Swarat_Chaudhuri1", "~Charles_Sutton1"]}, "keywords": {"value": ["continual learning", "modular machine learning", "modular continual learning", "transfer learning", "catastrophic forgetting", "Bayesian optimization", "probabilistic modelling"]}, "TLDR": {"value": "We use probabilistic modelling over pre-trained modules and the data to speed up modular continual learning."}, "abstract": {"value": "Modular approaches that use a different composition of modules for each problem are a promising direction in continual learning (CL). However, searching through the large, discrete space of module compositions is challenging, especially because evaluating a composition\u2019s performance requires a round of neural network training. We address this challenge through a modular CL framework, PICLE, that uses a probabilistic model to cheaply compute the fitness of each composition, allowing PICLE to achieve both perceptual, few-shot and latent transfer. The model combines prior knowledge about good module compositions with dataset-specific information. We evaluate PICLE using two benchmark suites designed to assess different desiderata of CL techniques. Comparing to a wide range of approaches, we show that PICLE is the first modular CL algorithm to achieve perceptual, few-shot and latent transfer while scaling well to large search spaces, outperforming previous state-of-the-art modular CL approaches on long problem sequences."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/83a679272bf4e40d150904047ff99ff9aa3a0cbc.pdf"}, "_bibtex": {"value": "@inproceedings{\nvalkov2024a,\ntitle={A Probabilistic Framework for Modular Continual Learning},\nauthor={Lazar Valkov and Akash Srivastava and Swarat Chaudhuri and Charles Sutton},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MVe2dnWPCu}\n}"}, "paperhash": {"value": "valkov|a_probabilistic_framework_for_modular_continual_learning"}}, "number": 6487, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6487/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6487/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424439010, "cdate": 1695424439010, "tmdate": 1710476388878, "mdate": 1710476388878, "pdate": 1705410977496, "version": 2}, {"id": "bLpUtGyf9g", "forum": "bLpUtGyf9g", "signatures": ["ICLR.cc/2024/Conference/Submission6486/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6486/Authors"], "content": {"title": {"value": "Boundary Denoising for Video Activity Localization"}, "authors": {"value": ["Mengmeng Xu", "Mattia Soldan", "Jialin Gao", "Shuming Liu", "Juan-Manuel Perez-Rua", "Bernard Ghanem"]}, "authorids": {"value": ["~Mengmeng_Xu1", "~Mattia_Soldan1", "~Jialin_Gao1", "~Shuming_Liu2", "~Juan-Manuel_Perez-Rua1", "~Bernard_Ghanem1"]}, "keywords": {"value": ["video activity localization", "boundary denoising"]}, "abstract": {"value": "Video activity localization aims at understanding the semantic content in long, untrimmed videos and retrieving actions of interest. The retrieved action with its start and end locations can be used for highlight generation, temporal action detection, etc. Unfortunately, learning the exact boundary location of activities is highly challenging because temporal activities are continuous in time, and there are often no clear-cut transitions between actions. Moreover, the definition of the start and end of events is subjective, which may confuse the model. To alleviate the boundary ambiguity, we propose to study the video activity localization problem from a denoising perspective. Specifically, we propose an encoder-decoder model named DenosieLoc. During training, a set of temporal spans is randomly generated from the ground truth with a controlled noise scale. Then, we attempt to reverse this process by boundary denoising, allowing the localizer to predict activities with precise boundaries and resulting in faster convergence speed. Experiments show that DenosieLoc advances \nseveral video activity understanding tasks. For example, we observe a gain of +12.36% average mAP on the QV-Highlights dataset.\nMoreover, DenosieLoc achieves state-of-the-art performance on the MAD dataset but with much fewer predictions than others."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1063c6f297ce00850de90397c8fd956657d6ee24.pdf"}, "supplementary_material": {"value": "/attachment/d57763043c98e7e1bd743d2a2a7a23e9950774cb.zip"}, "_bibtex": {"value": "@inproceedings{\nxu2024boundary,\ntitle={Boundary Denoising for Video Activity Localization},\nauthor={Mengmeng Xu and Mattia Soldan and Jialin Gao and Shuming Liu and Juan-Manuel Perez-Rua and Bernard Ghanem},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bLpUtGyf9g}\n}"}, "paperhash": {"value": "xu|boundary_denoising_for_video_activity_localization"}}, "number": 6486, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6486/-/Revision", "ICLR.cc/2024/Conference/Submission6486/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6486/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424427735, "cdate": 1695424427735, "tmdate": 1711020875247, "mdate": 1711020875247, "pdate": 1705410977465, "version": 2}, {"id": "cWiEN1plhJ", "forum": "cWiEN1plhJ", "signatures": ["ICLR.cc/2024/Conference/Submission6484/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6484/Authors"], "content": {"title": {"value": "Few-Shot Detection of Machine-Generated Text using Style Representations"}, "authors": {"value": ["Rafael Alberto Rivera Soto", "Kailin Koch", "Aleem Khan", "Barry Y. Chen", "Marcus Bishop", "Nicholas Andrews"]}, "authorids": {"value": ["~Rafael_Alberto_Rivera_Soto2", "koch14@llnl.gov", "~Aleem_Khan1", "~Barry_Y._Chen1", "marcus.bishop@gmail.com", "~Nicholas_Andrews2"]}, "keywords": {"value": ["machine text detection", "large language models", "AI safety", "natural language processing", "stylistic representations", "deep learning", "machine learning"]}, "abstract": {"value": "The advent of instruction-tuned language models that convincingly mimic human writing poses a significant risk of abuse. For example, such models could be used for plagiarism, disinformation, spam, or phishing. However, such abuse may be counteracted with the ability to detect whether a piece of text was composed by a language model rather than a human. Some previous approaches to this problem have relied on supervised methods trained on corpora of confirmed human and machine-written documents. Unfortunately, model under-specification poses an unavoidable challenge for such detectors, making them brittle in the face of data shifts, such as the release of further language models producing still more fluent text than the models used to train the detectors. Other previous approaches require access to the models that generated the text to be detected at inference or detection time, which is often impractical. In light of these challenge, we pursue a fundamentally different approach not relying on samples from language models of concern at training time. Instead, we propose to leverage representations of writing style estimated from human-authored text. Indeed, we find that features effective at distinguishing among human authors are also effective at distinguishing human from machine authors, including state of the art large language models like Llama 2, ChatGPT, and GPT-4. Furthermore, given handfuls of examples composed by each of several specific language models of interest, our approach affords the ability to predict which model specifically generated a given document."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/184e7f39e19aac108b138c8b6676a369abcb2fd0.pdf"}, "_bibtex": {"value": "@inproceedings{\nsoto2024fewshot,\ntitle={Few-Shot Detection of Machine-Generated Text using Style Representations},\nauthor={Rafael Alberto Rivera Soto and Kailin Koch and Aleem Khan and Barry Y. Chen and Marcus Bishop and Nicholas Andrews},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cWiEN1plhJ}\n}"}, "paperhash": {"value": "soto|fewshot_detection_of_machinegenerated_text_using_style_representations"}}, "number": 6484, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6484/-/Revision", "ICLR.cc/2024/Conference/Submission6484/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6484/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424351066, "cdate": 1695424351066, "tmdate": 1710560914017, "mdate": 1710560914017, "pdate": 1705410977381, "version": 2}, {"id": "PCm1oT8pZI", "forum": "PCm1oT8pZI", "signatures": ["ICLR.cc/2024/Conference/Submission6483/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6483/Authors"], "content": {"title": {"value": "Safe and Robust Watermark Injection with a Single OoD Image"}, "authors": {"value": ["Shuyang Yu", "Junyuan Hong", "Haobo Zhang", "Haotao Wang", "Zhangyang Wang", "Jiayu Zhou"]}, "authorids": {"value": ["~Shuyang_Yu1", "~Junyuan_Hong1", "~Haobo_Zhang1", "~Haotao_Wang1", "~Zhangyang_Wang1", "~Jiayu_Zhou1"]}, "keywords": {"value": ["Backdoor", "Watermarking", "robustness"]}, "abstract": {"value": "Training a high-performance deep neural network requires large amounts of data and computational resources. \nProtecting the intellectual property (IP) and commercial ownership of a deep model is challenging yet increasingly crucial. \nA major stream of watermarking strategies implants verifiable backdoor triggers by poisoning training samples, but these are often unrealistic due to data privacy and safety concerns and are vulnerable to minor model changes such as fine-tuning. \nTo overcome these challenges, we propose a safe and robust backdoor-based watermark injection technique that leverages the diverse knowledge from a single out-of-distribution (OoD) image, which serves as a secret key for IP verification. \nThe independence of training data makes it agnostic to third-party promises of IP security. \nWe induce robustness via random perturbation of model parameters during watermark injection to defend against common watermark removal attacks, including fine-tuning, pruning, and model extraction. \nOur experimental results demonstrate that the proposed watermarking approach is not only time- and sample-efficient without training data, but also robust against the watermark removal attacks above."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2f25edcb7a348a94dc4f219ebc634278953c1afe.pdf"}, "supplementary_material": {"value": "/attachment/5c2468b0365992155176b6a7f40854aecc6b8df8.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024safe,\ntitle={Safe and Robust Watermark Injection with a Single OoD Image},\nauthor={Shuyang Yu and Junyuan Hong and Haobo Zhang and Haotao Wang and Zhangyang Wang and Jiayu Zhou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PCm1oT8pZI}\n}"}, "paperhash": {"value": "yu|safe_and_robust_watermark_injection_with_a_single_ood_image"}}, "number": 6483, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6483/-/Revision", "ICLR.cc/2024/Conference/Submission6483/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6483/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424302756, "cdate": 1695424302756, "tmdate": 1709841671967, "mdate": 1709841671967, "pdate": 1705410977362, "version": 2}, {"id": "L6L1CJQ2PE", "forum": "L6L1CJQ2PE", "signatures": ["ICLR.cc/2024/Conference/Submission6482/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6482/Authors"], "content": {"title": {"value": "Massive Editing for Large Language Models via Meta Learning"}, "authors": {"value": ["Chenmien Tan", "Ge Zhang", "Jie Fu"]}, "authorids": {"value": ["~Chenmien_Tan1", "~Ge_Zhang5", "~Jie_Fu2"]}, "keywords": {"value": ["Language Model", "Model Editing", "Meta Learning"]}, "abstract": {"value": "While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training. A promising approach involves employing a hyper-network to generate parameter shift, whereas existing hyper-networks suffer from inferior scalability in synchronous editing operation amount (Hase et al., 2023b; Huang et al., 2023). For instance, Mitchell et al. (2022) mimics gradient accumulation to sum the parameter shifts together, which lacks statistical significance and is prone to cancellation effect. To mitigate the problem, we propose the MAssive Language Model Editing Network (MALMEN), which formulates the parameter shift aggregation as the least square problem, subsequently updating the LM parameter using the normal equation. To accommodate editing multiple facts simultaneously with limited memory budgets, we separate the computation on the hyper-network and LM, enabling arbitrary batch size on both neural networks. Our method is evaluated by editing up to thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2, and GPT-J (6B), across various knowledge-intensive NLP tasks, i.e., closed book fact-checking and question answering. Remarkably, MALMEN is capable of editing hundreds of times more facts than MEND (Mitchell et al., 2022) with the identical hyper-network architecture and outperforms editor specifically designed for GPT, i.e., MEMIT (Meng et al., 2023)."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3ebd770d398a3555f52f8496fa83c188663e9720.pdf"}, "supplementary_material": {"value": "/attachment/91683f06e966f2eca3d368d3245e11b8d361d4e7.zip"}, "_bibtex": {"value": "@inproceedings{\ntan2024massive,\ntitle={Massive Editing for Large Language Model via Meta Learning},\nauthor={Chenmien Tan and Ge Zhang and Jie Fu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L6L1CJQ2PE}\n}"}, "paperhash": {"value": "tan|massive_editing_for_large_language_models_via_meta_learning"}}, "number": 6482, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6482/-/Revision", "ICLR.cc/2024/Conference/Submission6482/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6482/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424224844, "cdate": 1695424224844, "tmdate": 1710347725724, "mdate": 1710347725724, "pdate": 1705410977330, "version": 2}, {"id": "RwI7ZEfR27", "forum": "RwI7ZEfR27", "signatures": ["ICLR.cc/2024/Conference/Submission6480/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6480/Authors"], "content": {"title": {"value": "BrainLM: A foundation model for brain activity recordings"}, "authors": {"value": ["Josue Ortega Caro", "Antonio Henrique de Oliveira Fonseca", "Syed A Rizvi", "Matteo Rosati", "Christopher Averill", "James L Cross", "Prateek Mittal", "Emanuele Zappala", "Rahul Madhav Dhodapkar", "Chadi Abdallah", "David van Dijk"]}, "authorids": {"value": ["~Josue_Ortega_Caro1", "~Antonio_Henrique_de_Oliveira_Fonseca1", "~Syed_A_Rizvi1", "~Matteo_Rosati1", "christopher.averill@bcm.edu", "j.cross@yale.edu", "prateekmittal154@gmail.com", "~Emanuele_Zappala1", "~Rahul_Madhav_Dhodapkar1", "~Chadi_Abdallah1", "~David_van_Dijk1"]}, "keywords": {"value": ["foundation model", "fMRI"]}, "TLDR": {"value": "Trained an masked autoencoder on the largest fMRI dataset"}, "abstract": {"value": "We introduce the Brain Language Model (BrainLM), a foundation model for brain activity dynamics trained on 6,700 hours of fMRI recordings. Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful \"lens\" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9b47441fd8280d26dca4ee62f9ee211888cd42d6.pdf"}, "supplementary_material": {"value": "/attachment/39368d42f1acf1d915509057a285819a7fb0149a.pdf"}, "_bibtex": {"value": "@inproceedings{\ncaro2024brainlm,\ntitle={Brain{LM}: A foundation model for brain activity recordings},\nauthor={Josue Ortega Caro and Antonio Henrique de Oliveira Fonseca and Christopher Averill and Syed A Rizvi and Matteo Rosati and James L Cross and Prateek Mittal and Emanuele Zappala and Rahul Madhav Dhodapkar and Chadi Abdallah and David van Dijk},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RwI7ZEfR27}\n}"}, "paperhash": {"value": "caro|brainlm_a_foundation_model_for_brain_activity_recordings"}}, "number": 6480, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6480/-/Revision", "ICLR.cc/2024/Conference/Submission6480/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6480/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695424022501, "cdate": 1695424022501, "tmdate": 1710465918622, "mdate": 1710465918622, "pdate": 1705410977225, "version": 2}, {"id": "1NHgmKqOzZ", "forum": "1NHgmKqOzZ", "signatures": ["ICLR.cc/2024/Conference/Submission6473/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6473/Authors"], "content": {"title": {"value": "Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality"}, "authors": {"value": ["Xuxi Chen", "Yu Yang", "Zhangyang Wang", "Baharan Mirzasoleiman"]}, "authorids": {"value": ["~Xuxi_Chen1", "~Yu_Yang4", "~Zhangyang_Wang1", "~Baharan_Mirzasoleiman1"]}, "keywords": {"value": ["dataset distillation", "dataset condensation"]}, "abstract": {"value": "Dataset distillation aims to minimize the time and memory needed for training deep networks on large datasets, by creating a small set of synthetic images that has a similar generalization performance to that of the full dataset. However, current dataset distillation techniques fall short, showing a notable performance gap compared to training on the original data. In this work, we are the first to argue that the use of only one synthetic subset for distillation may not yield optimal generalization performance. This is because the training dynamics of deep networks drastically changes during training. Therefore, multiple synthetic subsets are required to capture the dynamics of training in different stages. To address this issue, we propose Progressive Dataset Distillation (PDD). PDD synthesizes multiple small sets of synthetic images, each conditioned on the previous sets, and trains the model on the cumulative union of these subsets without requiring additional training time. Our extensive experiments show that PDD can effectively improve the performance of existing dataset distillation methods by up to 4.3%. In addition, our method for the first time enables generating considerably larger synthetic datasets. Our codes are available at https://github.com/VITA-Group/ProgressiveDD."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9e441d8d82995f6fd1859104998e6b597e5f6bbb.pdf"}, "TLDR": {"value": "We propose a multi-stage dataset distillation framework to improve the quality of synthetic samples."}, "_bibtex": {"value": "@inproceedings{\nchen2024data,\ntitle={Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality},\nauthor={Xuxi Chen and Yu Yang and Zhangyang Wang and Baharan Mirzasoleiman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1NHgmKqOzZ}\n}"}, "paperhash": {"value": "chen|data_distillation_can_be_like_vodka_distilling_more_times_for_better_quality"}}, "number": 6473, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6473/-/Revision", "ICLR.cc/2024/Conference/Submission6473/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6473/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423832715, "cdate": 1695423832715, "tmdate": 1710999978602, "mdate": 1710999978602, "pdate": 1705410977032, "version": 2}, {"id": "r9FsiXZxZt", "forum": "r9FsiXZxZt", "signatures": ["ICLR.cc/2024/Conference/Submission6472/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6472/Authors"], "content": {"title": {"value": "Object centric architectures enable efficient causal representation learning"}, "authors": {"value": ["Amin Mansouri", "Jason Hartford", "Yan Zhang", "Yoshua Bengio"]}, "authorids": {"value": ["~Amin_Mansouri1", "~Jason_Hartford1", "~Yan_Zhang1", "~Yoshua_Bengio1"]}, "keywords": {"value": ["object centric learning", "representation learning", "disentanglement", "weakly supervised learning"]}, "TLDR": {"value": "Existing methods for causal representation learning fail on objects. Object-centric learning can fix it."}, "abstract": {"value": "Causal representation learning has showed a variety of settings in which we can disentangle latent variables with identifiability guarantees (up to some reasonable equivalence class). Common to all of these approaches is the assumption that (1) the latent variables are represented as $d$-dimensional vectors, and (2) that the observations are the output of some injective generative function of these latent variables. While these assumptions appear benign, we show that when the observations are of multiple objects, the generative function is no longer injective and disentanglement fails in practice. We can address this failure by combining recent developments in object-centric learning and causal representation learning. By modifying the Slot Attention architecture (Locatello et al., 2020), we develop an object-centric architecture that leverages weak supervision from sparse perturbations to disentangle each object's properties. This approach is more data-efficient in the sense that it requires significantly fewer perturbations than a comparable approach that encodes to a Euclidean space and we show that this approach successfully disentangles the properties of a set of objects in a series of simple image-based disentanglement experiments."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3d57a7aa7c838ea0afeff38494e03b1cf226aee4.pdf"}, "supplementary_material": {"value": "/attachment/06571a0ce54c2d14392d7a3ff40567404e2a9583.zip"}, "_bibtex": {"value": "@inproceedings{\nmansouri2024object,\ntitle={Object centric architectures enable efficient causal representation learning},\nauthor={Amin Mansouri and Jason Hartford and Yan Zhang and Yoshua Bengio},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=r9FsiXZxZt}\n}"}, "paperhash": {"value": "mansouri|object_centric_architectures_enable_efficient_causal_representation_learning"}}, "number": 6472, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6472/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6472/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423830623, "cdate": 1695423830623, "tmdate": 1710523555110, "mdate": 1710523555110, "pdate": 1705410976969, "version": 2}, {"id": "J1djqLAa6N", "forum": "J1djqLAa6N", "signatures": ["ICLR.cc/2024/Conference/Submission6469/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6469/Authors"], "content": {"title": {"value": "Efficient Score Matching with Deep Equilibrium Layers"}, "authors": {"value": ["Yuhao Huang", "Qingsong Wang", "Akwum Onwunta", "Bao Wang"]}, "authorids": {"value": ["~Yuhao_Huang5", "~Qingsong_Wang1", "ako221@lehigh.edu", "~Bao_Wang1"]}, "keywords": {"value": ["score matching", "deep equilibrium model", "density estimation"]}, "abstract": {"value": "Score matching methods -- estimate probability densities without computing the normalization constant -- are particularly useful in deep learning. However, computational and memory costs of score matching methods can be prohibitive for high-dimensional data or complex models, particularly due to the derivatives or Hessians of the log density function appearing in the objective function. Some existing approaches modify the objective function to reduce the quadratic computational complexity for Hessian computation. However, the memory bottleneck of score matching methods remains for deep learning. This study improves the memory efficiency of score matching by leveraging deep equilibrium models. We provide a theoretical analysis of deep equilibrium models for scoring matching and applying implicit differentiation to higher-order derivatives. Empirical evaluations demonstrate that our approach enables the development of deep and expressive models with improved performance and comparable computational and memory costs over shallow architectures."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5a1c744cb67c5bf5bf079113f4ba7d6825f45bd0.pdf"}, "supplementary_material": {"value": "/attachment/ef5315bfb84626bd08ac47eead7ee2f1f236f503.zip"}, "TLDR": {"value": "We improve the memory efficiency of score matching by leveraging deep equilibrium models"}, "_bibtex": {"value": "@inproceedings{\nhuang2024efficient,\ntitle={Efficient Score Matching with Deep Equilibrium Layers},\nauthor={Yuhao Huang and Qingsong Wang and Akwum Onwunta and Bao Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=J1djqLAa6N}\n}"}, "paperhash": {"value": "huang|efficient_score_matching_with_deep_equilibrium_layers"}}, "number": 6469, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6469/-/Revision", "ICLR.cc/2024/Conference/Submission6469/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6469/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423591674, "cdate": 1695423591674, "tmdate": 1709661531439, "mdate": 1709661531439, "pdate": 1705410976844, "version": 2}, {"id": "97Dl82avFs", "forum": "97Dl82avFs", "signatures": ["ICLR.cc/2024/Conference/Submission6459/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6459/Authors"], "content": {"title": {"value": "Alt-Text with Context: Improving Accessibility for Images on Twitter"}, "authors": {"value": ["Nikita Srivatsan", "Sofia Samaniego", "Omar Florez", "Taylor Berg-Kirkpatrick"]}, "authorids": {"value": ["~Nikita_Srivatsan1", "~Sofia_Samaniego1", "~Omar_Florez1", "~Taylor_Berg-Kirkpatrick1"]}, "keywords": {"value": ["alt-text", "social media", "twitter", "clip", "computer vision", "image captioning", "accessibility"]}, "TLDR": {"value": "We present a model for generating alt-text descriptions for images shared on Twitter, and put forward an accompanying dataset for this task"}, "abstract": {"value": "In this work we present an approach for generating alternative text (or alt-text) descriptions for images shared on social media, specifically Twitter. More than just a special case of image captioning, alt-text is both more literally descriptive and context-specific. Also critically, images posted to Twitter are often accompanied by user-written text that despite not necessarily describing the image may provide useful context that if properly leveraged can be informative. We address this task with a multimodal model that conditions on both textual information from the associated social media post as well as visual signal from the image, and demonstrate that the utility of these two information sources stacks. We put forward a new dataset of 371k images paired with alt-text and tweets scraped from Twitter and evaluate on it across a variety of automated metrics as well as human evaluation. We show that our approach of conditioning on both tweet text and visual information significantly outperforms prior work, by more than 2x on BLEU@4."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c1026cd07ff18150f89e055f2d06edfc22ba23f7.pdf"}, "_bibtex": {"value": "@inproceedings{\nsrivatsan2024alttext,\ntitle={Alt-Text with Context: Improving Accessibility for Images on Twitter},\nauthor={Nikita Srivatsan and Sofia Samaniego and Omar Florez and Taylor Berg-Kirkpatrick},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=97Dl82avFs}\n}"}, "paperhash": {"value": "srivatsan|alttext_with_context_improving_accessibility_for_images_on_twitter"}}, "number": 6459, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6459/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6459/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423076957, "cdate": 1695423076957, "tmdate": 1710454842379, "mdate": 1710454842379, "pdate": 1705410976681, "version": 2}, {"id": "1YPfmglNRU", "forum": "1YPfmglNRU", "signatures": ["ICLR.cc/2024/Conference/Submission6457/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6457/Authors"], "content": {"title": {"value": "Defining Expertise: Applications to Treatment Effect Estimation"}, "authors": {"value": ["Alihan H\u00fcy\u00fck", "Qiyao Wei", "Alicia Curth", "Mihaela van der Schaar"]}, "authorids": {"value": ["~Alihan_H\u00fcy\u00fck1", "~Qiyao_Wei1", "~Alicia_Curth1", "~Mihaela_van_der_Schaar2"]}, "keywords": {"value": ["expertise", "model selection", "balancing representations", "treatment effect estimation"]}, "abstract": {"value": "Decision-makers are often experts of their domain and take actions based on their domain knowledge. Doctors, for instance, may prescribe treatments by predicting the likely outcome of each available treatment. Actions of an expert thus naturally encode part of their domain knowledge, and can help make inferences within the same domain: Knowing doctors try to prescribe the best treatment for their patients, we can tell treatments prescribed more frequently are likely to be more effective. Yet in machine learning, the fact that most decision-makers are experts is often overlooked, and \u201cexpertise\u201d is seldom leveraged as an inductive bias. This is especially true for the literature on treatment effect estimation, where often the only assumption made about actions is that of overlap. In this paper, we argue that expertise\u2014particularly the type of expertise the decision-makers of a domain are likely to have\u2014can be informative in designing and selecting methods for treatment effect estimation. We formally define two types of expertise, predictive and prognostic, and demonstrate empirically that: (i) the prominent type of expertise in a domain significantly influences the performance of different methods in treatment effect estimation, and (ii) it is possible to predict the type of expertise present in a dataset, which can provide a quantitative basis for model selection."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/35dbc01121c44c86a33cf8d22866d22f5320a557.pdf"}, "_bibtex": {"value": "@inproceedings{\nh{\\\"u}y{\\\"u}k2024defining,\ntitle={Defining Expertise: Applications to Treatment Effect Estimation},\nauthor={Alihan H{\\\"u}y{\\\"u}k and Qiyao Wei and Alicia Curth and Mihaela van der Schaar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1YPfmglNRU}\n}"}, "paperhash": {"value": "h\u00fcy\u00fck|defining_expertise_applications_to_treatment_effect_estimation"}}, "number": 6457, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6457/-/Revision", "ICLR.cc/2024/Conference/Submission6457/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6457/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695422995833, "cdate": 1695422995833, "tmdate": 1709661531362, "mdate": 1709661531362, "pdate": 1705410976589, "version": 2}, {"id": "ZSD3MloKe6", "forum": "ZSD3MloKe6", "signatures": ["ICLR.cc/2024/Conference/Submission6453/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6453/Authors"], "content": {"title": {"value": "Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps"}, "authors": {"value": ["Mingxiao Li", "Tingyu Qu", "Ruicong Yao", "Wei Sun", "Marie-Francine Moens"]}, "authorids": {"value": ["~Mingxiao_Li1", "~Tingyu_Qu1", "~Ruicong_Yao1", "~Wei_Sun19", "~Marie-Francine_Moens1"]}, "keywords": {"value": ["diffusion models", "sampling methods", "exposure bias"]}, "abstract": {"value": "Diffusion Probabilistic Models (DPM) have shown remarkable efficacy in the synthesis of high-quality images. However, their inference process characteristically requires numerous, potentially hundreds, of iterative steps, which could exaggerate the problem of exposure bias due to the training and inference discrepancy. Previous work has attempted to mitigate this issue by perturbing inputs during training, which consequently mandates the retraining of the DPM. In this work, we conduct a systematic study of exposure bias in DPM and, intriguingly, we find that the exposure bias could be alleviated with a novel sampling method that we propose, without retraining the model. We empirically and theoretically show that, during inference, for each backward time step t and corresponding state \u02c6xt, there might exist another time step $t_s$ which exhibits superior coupling with $\\hat{x}_t$. Based on this finding, we introduce a sampling method\nnamed Time-Shift Sampler. Our framework can be seamlessly integrated to existing sampling algorithms, such as DDPM, DDIM and other high-order solvers, inducing merely minimal additional computations. Experimental results show our method brings significant and consistent improvements in FID scores on different datasets and sampling methods. For example, integrating Time-Shift Sampler to F-PNDM yields a FID=3.88, achieving 44.49% improvements as compared to F-PNDM, on CIFAR-10 with 10 sampling steps, which is more performant than the vanilla DDIM with 100 sampling steps. Our code is available at https://github.com/Mingxiao-Li/TS-DPM."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f903a547671f42a166043602f68eab7350998e6a.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024alleviating,\ntitle={Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps},\nauthor={Mingxiao Li and Tingyu Qu and Ruicong Yao and Wei Sun and Marie-Francine Moens},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZSD3MloKe6}\n}"}, "paperhash": {"value": "li|alleviating_exposure_bias_in_diffusion_models_through_sampling_with_shifted_time_steps"}}, "number": 6453, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6453/-/Revision", "ICLR.cc/2024/Conference/Submission6453/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6453/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695422598787, "cdate": 1695422598787, "tmdate": 1711030380110, "mdate": 1711030380110, "pdate": 1705410976497, "version": 2}, {"id": "mGHJAyR8w0", "forum": "mGHJAyR8w0", "signatures": ["ICLR.cc/2024/Conference/Submission6451/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6451/Authors"], "content": {"title": {"value": "Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks"}, "authors": {"value": ["Shih-Hsin Wang", "Yung-Chang Hsu", "Justin Baker", "Andrea L. Bertozzi", "Jack Xin", "Bao Wang"]}, "authorids": {"value": ["~Shih-Hsin_Wang1", "~Yung-Chang_Hsu1", "~Justin_Baker1", "~Andrea_L._Bertozzi2", "~Jack_Xin2", "~Bao_Wang1"]}, "keywords": {"value": ["Steerable features", "Equivariant graph neural networks", "Message passing"]}, "TLDR": {"value": "We discuss the benefits of steerable features of different types for 3D equivariant graph neural networks"}, "abstract": {"value": "Theoretical and empirical comparisons have been made to assess the expressive power and performance of invariant and equivariant GNNs. However, there is currently no theoretical result comparing the expressive power of $k$-hop invariant GNNs and equivariant GNNs. Additionally, little is understood about whether the performance of equivariant GNNs, employing steerable features up to type-$L$, increases as $L$ grows -- especially when the feature dimension is held constant. In this study, we introduce a key lemma that allows us to analyze steerable features by examining their corresponding invariant features. The lemma facilitates us in understanding the limitations of $k$-hop invariant GNNs, which fail to capture the global geometric structure due to the loss of geometric information between local structures. Furthermore, we investigate the invariant features associated with different types of steerable features and demonstrate that the expressiveness of steerable features is primarily determined by their dimension -- independent of their irreducible decomposition. This suggests that when the feature dimension is constant, increasing $L$ does not lead to essentially improved performance in equivariant GNNs employing steerable features up to type-$L$. We substantiate our theoretical insights with numerical evidence."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/74b784ba5dc8dddcc830faa9c5c2cc8f035fd123.pdf"}, "supplementary_material": {"value": "/attachment/0f2695a7074df05404f35ad452a29b3a5af1d80f.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024rethinking,\ntitle={Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks},\nauthor={Shih-Hsin Wang and Yung-Chang Hsu and Justin Baker and Andrea L. Bertozzi and Jack Xin and Bao Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mGHJAyR8w0}\n}"}, "paperhash": {"value": "wang|rethinking_the_benefits_of_steerable_features_in_3d_equivariant_graph_neural_networks"}}, "number": 6451, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6451/-/Revision", "ICLR.cc/2024/Conference/Submission6451/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6451/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695422553094, "cdate": 1695422553094, "tmdate": 1709661531273, "mdate": 1709661531273, "pdate": 1705410976381, "version": 2}, {"id": "rzF0R6GOd4", "forum": "rzF0R6GOd4", "signatures": ["ICLR.cc/2024/Conference/Submission6442/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6442/Authors"], "content": {"title": {"value": "Neural SDF Flow for 3D Reconstruction of Dynamic Scenes"}, "authors": {"value": ["Wei Mao", "Richard Hartley", "Mathieu Salzmann", "miaomiao Liu"]}, "authorids": {"value": ["~Wei_Mao1", "~Richard_Hartley1", "~Mathieu_Salzmann1", "~miaomiao_Liu2"]}, "keywords": {"value": ["3D reconstruction", "NeRF", "dynamic scene"]}, "abstract": {"value": "In this paper, we tackle the problem of 3D reconstruction of dynamic scenes from multi-view videos. Previous dynamic scene reconstruction works either attempt to model the motion of 3D points in space, which constrains them to handle a single articulated object or require depth maps as input. By contrast, we propose to directly estimate the change of Signed Distance Function (SDF), namely SDF\nflow, of the dynamic scene. We show that the SDF flow captures the evolution of the scene surface. We further derive the mathematical relation between the SDF flow and the scene flow, which allows us to calculate the scene flow from the SDF flow analytically by solving linear equations. Our experiments on real-world multi-view video datasets show that our reconstructions are better than those of the state-of-the-art methods. Our code is available at https://github.com/wei-mao-2019/SDFFlow.git."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4fa03f4bd4636ecf827be16f53f20c97dabbad1d.pdf"}, "supplementary_material": {"value": "/attachment/d3e2425ef057e442cd3ce967eba0f0c41df14ab7.zip"}, "_bibtex": {"value": "@inproceedings{\nmao2024neural,\ntitle={Neural {SDF} Flow for 3D Reconstruction of Dynamic Scenes},\nauthor={Wei Mao and Richard Hartley and Mathieu Salzmann and miaomiao Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rzF0R6GOd4}\n}"}, "paperhash": {"value": "mao|neural_sdf_flow_for_3d_reconstruction_of_dynamic_scenes"}}, "number": 6442, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6442/-/Revision", "ICLR.cc/2024/Conference/Submission6442/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6442/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421982678, "cdate": 1695421982678, "tmdate": 1709661531188, "mdate": 1709661531188, "pdate": 1705410976130, "version": 2}, {"id": "mliQ2huFrZ", "forum": "mliQ2huFrZ", "signatures": ["ICLR.cc/2024/Conference/Submission6441/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6441/Authors"], "content": {"title": {"value": "Class Probability Matching with Calibrated Networks for Label Shift Adaption"}, "authors": {"value": ["Hongwei Wen", "Annika Betken", "Hanyuan Hang"]}, "authorids": {"value": ["~Hongwei_Wen1", "~Annika_Betken1", "~Hanyuan_Hang1"]}, "keywords": {"value": ["Domain adaptation", "Label shift", "Matching methods"]}, "abstract": {"value": "We consider the domain adaptation problem in the context of label shift, where the label distributions  between source and target domain differ, but the conditional distributions of features given the label are the same. To solve the label shift adaption problem, we develop a novel matching framework named \\textit{class probability matching} (\\textit{CPM}). It is inspired by a new understanding of the source domain's class probability, as well as a specific relationship between class probability ratios and feature probability ratios between the source and target domains. CPM is able to maintain the same theoretical guarantee with the existing feature probability matching framework, while significantly improving the computational efficiency due to directly matching the probabilities of the label variable. Within the CPM framework, we propose an algorithm named \\textit{class probability matching with calibrated networks} (\\textit{CPMCN}) for target domain classification. From the theoretical perspective, we establish the generalization bound of the CPMCN method in order to explain the benefits of introducing calibrated networks. From the experimental perspective, real data comparisons show that CPMCN outperforms existing matching-based and EM-based algorithms."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f71e2de1b4ae7cf346b9a0e07e7fc9b9901ad681.pdf"}, "_bibtex": {"value": "@inproceedings{\nwen2024class,\ntitle={Class Probability Matching with Calibrated Networks for Label Shift Adaption},\nauthor={Hongwei Wen and Annika Betken and Hanyuan Hang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mliQ2huFrZ}\n}"}, "paperhash": {"value": "wen|class_probability_matching_with_calibrated_networks_for_label_shift_adaption"}}, "number": 6441, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6441/-/Revision", "ICLR.cc/2024/Conference/Submission6441/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6441/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421935463, "cdate": 1695421935463, "tmdate": 1712663937473, "mdate": 1712663937473, "pdate": 1705410976094, "version": 2}, {"id": "eJHnSg783t", "forum": "eJHnSg783t", "signatures": ["ICLR.cc/2024/Conference/Submission6440/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6440/Authors"], "content": {"title": {"value": "DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation"}, "authors": {"value": ["Zilin Si", "Gu Zhang", "Qingwei Ben", "Branden Romero", "Zhou Xian", "Chao Liu", "Chuang Gan"]}, "authorids": {"value": ["~Zilin_Si1", "~Gu_Zhang1", "~Qingwei_Ben1", "~Branden_Romero1", "~Zhou_Xian1", "~Chao_Liu9", "~Chuang_Gan1"]}, "keywords": {"value": ["Tactile sensing", "Simulation", "Robotic manipulation"]}, "abstract": {"value": "We introduce DIFFTACTILE, a physics-based differentiable tactile simulation system designed to enhance robotic manipulation with dense and physically accurate tactile feedback. In contrast to prior tactile simulators which primarily focus on manipulating rigid bodies and often rely on simplified approximations to model stress and deformations of materials in contact, DIFFTACTILE emphasizes physics-based contact modeling with high fidelity, supporting simulations of diverse contact modes and interactions with objects possessing a wide range of material properties. Our system incorporates several key components, including a Finite Element Method (FEM)-based soft body model for simulating the sensing elastomer, a multi-material simulator for modeling diverse object types (such as elastic, elastoplastic, cables) under manipulation, a penalty-based contact model for handling contact dynamics. The differentiable nature of our system facilitates gradient-based optimization for both 1) refining physical properties in simulation using real-world data, hence narrowing the sim-to-real gap and 2) efficient learning of tactile-assisted grasping and contact-rich manipulation skills. Additionally, we introduce a method to infer the optical response of our tactile sensor to contact using an efficient pixel-based neural module. We anticipate that DIFFTACTILE will serve as a useful platform for studying contact-rich manipulations, leveraging the benefits of dense tactile feedback and differentiable physics. Code and supplementary materials are available at the project website https://difftactile.github.io/."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ca114f69e2dc9d526e44fe9161eacd32eca35c8b.pdf"}, "_bibtex": {"value": "@inproceedings{\nsi2024difftactile,\ntitle={{DIFFTACTILE}: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation},\nauthor={Zilin Si and Gu Zhang and Qingwei Ben and Branden Romero and Zhou Xian and Chao Liu and Chuang Gan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eJHnSg783t}\n}"}, "paperhash": {"value": "si|difftactile_a_physicsbased_differentiable_tactile_simulator_for_contactrich_robotic_manipulation"}}, "number": 6440, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6440/-/Revision", "ICLR.cc/2024/Conference/Submission6440/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6440/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421928841, "cdate": 1695421928841, "tmdate": 1710344035052, "mdate": 1710344035052, "pdate": 1705410976065, "version": 2}, {"id": "VLFhbOCz5D", "forum": "VLFhbOCz5D", "signatures": ["ICLR.cc/2024/Conference/Submission6437/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6437/Authors"], "content": {"title": {"value": "Tangent Transformers for Composition,Privacy and Removal"}, "authors": {"value": ["Tian Yu Liu", "Aditya Golatkar", "Stefano Soatto"]}, "authorids": {"value": ["~Tian_Yu_Liu2", "~Aditya_Golatkar1", "~Stefano_Soatto1"]}, "keywords": {"value": ["Composition", "Forgetting", "Tangent Learning"]}, "abstract": {"value": "We introduce Tangent Attention Fine-Tuning (TAFT), a method for fine-tuning linearized transformers obtained by computing a First-order Taylor Expansion around a pre-trained initialization. We show that the Jacobian-Vector Product resulting from linearization can be computed efficiently in a single forward pass, reducing training and inference cost to the same order of magnitude as its original non-linear counterpart, while using the same number of parameters. Furthermore, we show that, when applied to various downstream visual classification tasks, the resulting Tangent Transformer fine-tuned with TAFT can perform comparably with fine-tuning the original non-linear network. Since Tangent Transformers are linear with respect to the new set of weights, and the resulting fine-tuning loss is convex, we show that TAFT enjoys several advantages compared to non-linear fine-tuning when it comes to model composition, parallel training, machine unlearning, and differential privacy. Our code is available at: https://github.com/tianyu139/tangent-model-composition"}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c77be697e6bc470f2fc4b8ddfbd306f34883f76e.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024tangent,\ntitle={Tangent Transformers for Composition,Privacy and Removal},\nauthor={Tian Yu Liu and Aditya Golatkar and Stefano Soatto},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VLFhbOCz5D}\n}"}, "paperhash": {"value": "liu|tangent_transformers_for_compositionprivacy_and_removal"}}, "number": 6437, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6437/-/Revision", "ICLR.cc/2024/Conference/Submission6437/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6437/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421765134, "cdate": 1695421765134, "tmdate": 1710441676416, "mdate": 1710441676416, "pdate": 1705410976010, "version": 2}, {"id": "yV6wwEbtkR", "forum": "yV6wwEbtkR", "signatures": ["ICLR.cc/2024/Conference/Submission6436/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6436/Authors"], "content": {"title": {"value": "Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information"}, "authors": {"value": ["Linfeng Ye", "Shayan Mohajer Hamidi", "Renhao Tan", "EN-HUI YANG"]}, "authorids": {"value": ["~Linfeng_Ye1", "~Shayan_Mohajer_Hamidi1", "~Renhao_Tan1", "~EN-HUI_YANG1"]}, "keywords": {"value": ["Knowledge distillation", "information theroy", "bayes conditional distribution estimation", "conditional mutual information"]}, "abstract": {"value": "It is believed that in knowledge distillation (KD), the role of the teacher is to provide an estimate for the unknown Bayes conditional probability distribution (BCPD) to be used in the student training process. Conventionally, this estimate is obtained by training the teacher using maximum log-likelihood (MLL) method. To improve this estimate for KD, in this paper we introduce the concept of conditional mutual information (CMI) into the estimation of BCPD and propose a novel estimator called the maximum CMI (MCMI) method. Specifically, in MCMI estimation, both the log-likelihood and CMI of the teacher are simultaneously maximized when the teacher is trained. In fact, maximizing the teacher's CMI value ensures that the teacher can effectively capture the contextual information within the images, and for visualizing this information, we deploy Eigen-CAM. Via conducting a thorough set of experiments, we show that by employing a teacher trained via MCMI estimation rather than one trained via MLL estimation in various state-of-the-art KD frameworks, the student's classification accuracy consistently increases, with the gain of up to 3.32\\%. This suggests that the teacher's BCPD estimate provided by MCMI method is more accurate than that provided by MLL method. In addition, we show that such improvements in the student's accuracy are more drastic in zero-shot and few-shot settings. Notably, the student's accuracy increases with the gain of up to 5.72\\% when 5\\% of the training samples are available to student (few-shot), and increases from 0\\% to as high as 84\\% for an omitted class (zero-shot)."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ef0ffe301e1cc1839e1ba8713066bf60c490d401.pdf"}, "_bibtex": {"value": "@inproceedings{\nye2024bayes,\ntitle={Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information},\nauthor={Linfeng Ye and Shayan Mohajer Hamidi and Renhao Tan and EN-HUI YANG},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yV6wwEbtkR}\n}"}, "paperhash": {"value": "ye|bayes_conditional_distribution_estimation_for_knowledge_distillation_based_on_conditional_mutual_information"}}, "number": 6436, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6436/-/Revision", "ICLR.cc/2024/Conference/Submission6436/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6436/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421726900, "cdate": 1695421726900, "tmdate": 1709661531023, "mdate": 1709661531023, "pdate": 1705410975973, "version": 2}, {"id": "RIu5lyNXjT", "forum": "RIu5lyNXjT", "signatures": ["ICLR.cc/2024/Conference/Submission6435/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6435/Authors"], "content": {"title": {"value": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting"}, "authors": {"value": ["Melanie Sclar", "Yejin Choi", "Yulia Tsvetkov", "Alane Suhr"]}, "authorids": {"value": ["~Melanie_Sclar1", "~Yejin_Choi1", "~Yulia_Tsvetkov1", "~Alane_Suhr1"]}, "keywords": {"value": ["large language models", "sensitivity analysis", "prompt engineering", "evaluation", "prompting", "robustness", "in-context learning", "spurious features"]}, "abstract": {"value": "As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FormatSpread, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a910e6eaf10d6525d1e4670038dc4e9c5a1081c1.pdf"}, "_bibtex": {"value": "@inproceedings{\nsclar2024quantifying,\ntitle={Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting},\nauthor={Melanie Sclar and Yejin Choi and Yulia Tsvetkov and Alane Suhr},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RIu5lyNXjT}\n}"}, "paperhash": {"value": "sclar|quantifying_language_models_sensitivity_to_spurious_features_in_prompt_design_or_how_i_learned_to_start_worrying_about_prompt_formatting"}}, "number": 6435, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6435/-/Revision", "ICLR.cc/2024/Conference/Submission6435/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6435/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421684988, "cdate": 1695421684988, "tmdate": 1710463309556, "mdate": 1710463309556, "pdate": 1705410975948, "version": 2}, {"id": "pzpWBbnwiJ", "forum": "pzpWBbnwiJ", "signatures": ["ICLR.cc/2024/Conference/Submission6432/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6432/Authors"], "content": {"title": {"value": "Universal Guidance for Diffusion Models"}, "authors": {"value": ["Arpit Bansal", "Hong-Min Chu", "Avi Schwarzschild", "Soumyadip Sengupta", "Micah Goldblum", "Jonas Geiping", "Tom Goldstein"]}, "authorids": {"value": ["~Arpit_Bansal1", "~Hong-Min_Chu1", "~Avi_Schwarzschild1", "~Soumyadip_Sengupta3", "~Micah_Goldblum1", "~Jonas_Geiping1", "~Tom_Goldstein1"]}, "keywords": {"value": ["Generative Models", "Computer Vision", "Diffusion Models"]}, "abstract": {"value": "Typical diffusion models are trained to accept a particular form of conditioning, most commonly text, and cannot be conditioned on other modalities without retraining. In this work, we propose a universal guidance algorithm that enables diffusion models to be controlled by arbitrary guidance modalities without the need to retrain any use-specific components. We show that our algorithm successfully generates quality images with guidance functions including segmentation, face recognition, object detection, style guidance and classifier signals."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/608a3985c70a7a2e3d455602773b08dc1af03df4.pdf"}, "supplementary_material": {"value": "/attachment/460c9190a7ae241539b1bb778ebc5af68ec23737.zip"}, "TLDR": {"value": "We propose universal guidance, an algorithm that achieves conditional generation with any base diffusion model and guidance functions without any retraining."}, "_bibtex": {"value": "@inproceedings{\nbansal2024universal,\ntitle={Universal Guidance for Diffusion Models},\nauthor={Arpit Bansal and Hong-Min Chu and Avi Schwarzschild and Soumyadip Sengupta and Micah Goldblum and Jonas Geiping and Tom Goldstein},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pzpWBbnwiJ}\n}"}, "paperhash": {"value": "bansal|universal_guidance_for_diffusion_models"}}, "number": 6432, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6432/-/Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421554512, "cdate": 1695421554512, "tmdate": 1707625631868, "mdate": 1707625631868, "pdate": 1705410975750, "version": 2}, {"id": "L4nOxziGf9", "forum": "L4nOxziGf9", "signatures": ["ICLR.cc/2024/Conference/Submission6424/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6424/Authors"], "content": {"title": {"value": "Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models"}, "authors": {"value": ["Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"]}, "authorids": {"value": ["~Archiki_Prasad1", "~Elias_Stengel-Eskin1", "~Mohit_Bansal2"]}, "keywords": {"value": ["visual question answering", "zero-shot", "large vision language models", "visual reasoning", "underspecification", "grounding language to vision"]}, "abstract": {"value": "An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs). While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to an LVLM can have a major impact on zero-shot model performance. In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity. Therefore, adding visually-grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references. Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer. To this end, we present **Rep**hrase, **A**ugment and **Re**ason (RepARe), a gradient-free framework that extracts salient details about the image using the underlying LVLM as a captioner and reasoner, in order to propose modifications to the original question. We then use the LVLM\u2019s confidence over a generated answer as an unsupervised scoring function to select the rephrased question most likely to improve zero-shot performance. Focusing on three visual question answering tasks, we show that RepARe can result in a 3.85% (absolute) increase in zero-shot accuracy on VQAv2, 6.41%, and 7.94% points increase on A-OKVQA, and VizWiz respectively. Additionally, we find that using gold answers for oracle question candidate selection achieves a substantial gain in VQA accuracy by up to 14.41%. Through extensive analysis, we demonstrate that outputs from RepARe increase syntactic complexity, and effectively utilize vision-language interaction and the frozen LLM."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fe817dd22b56d7497040cbec62fa674a30e15086.pdf"}, "supplementary_material": {"value": "/attachment/e7f0b76c868920fd44cd5a2fd7a18b50810a9ab9.zip"}, "_bibtex": {"value": "@inproceedings{\nprasad2024rephrase,\ntitle={Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models},\nauthor={Archiki Prasad and Elias Stengel-Eskin and Mohit Bansal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L4nOxziGf9}\n}"}, "paperhash": {"value": "prasad|rephrase_augment_reason_visual_grounding_of_questions_for_visionlanguage_models"}}, "number": 6424, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6424/-/Revision", "ICLR.cc/2024/Conference/Submission6424/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6424/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421057651, "cdate": 1695421057651, "tmdate": 1710514596448, "mdate": 1710514596448, "pdate": 1705410975630, "version": 2}, {"id": "LWuYsSD94h", "forum": "LWuYsSD94h", "signatures": ["ICLR.cc/2024/Conference/Submission6420/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6420/Authors"], "content": {"title": {"value": "A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning"}, "authors": {"value": ["Haozhe Jiang", "Qiwen Cui", "Zhihan Xiong", "Maryam Fazel", "Simon Shaolei Du"]}, "authorids": {"value": ["~Haozhe_Jiang1", "~Qiwen_Cui1", "~Zhihan_Xiong1", "~Maryam_Fazel1", "~Simon_Shaolei_Du1"]}, "keywords": {"value": ["regret analysis", "learning in non-stationary games", "bandit feedback"]}, "TLDR": {"value": "We propose a black-box no-regret algorithm applicable for various problems in multi-agent reinforcement learning, including general-sum games, potential games, and Markov games."}, "abstract": {"value": "We investigate learning the equilibria in non-stationary multi-agent systems and address the challenges that differentiate multi-agent learning from single-agent learning. Specifically, we focus on games with bandit feedback, where testing an equilibrium can result in substantial regret even when the gap to be tested is small, and the existence of multiple optimal solutions (equilibria) in stationary games poses extra challenges. To overcome these obstacles, we propose a versatile black-box approach applicable to a broad spectrum of problems, such as general-sum games, potential games, and Markov games, when equipped with appropriate learning and testing oracles for stationary environments. Our algorithms can achieve $\\widetilde{O}\\left(\\Delta^{1/4}T^{3/4}\\right)$ regret when the degree of nonstationarity, as measured by total variation $\\Delta$, is known, and $\\widetilde{O}\\left(\\Delta^{1/5}T^{4/5}\\right)$ regret when $\\Delta$ is unknown, where $T$ is the number of rounds. Meanwhile, our algorithm inherits the favorable dependence on number of agents from the oracles. As a side contribution that may be independent of interest, we show how to test for various types of equilibria by a black-box reduction to single-agent learning, which includes Nash equilibria, correlated equilibria, and coarse correlated equilibria."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/00629e2d8027ff1b24e2f194a565f5e266379060.pdf"}, "_bibtex": {"value": "@inproceedings{\njiang2024a,\ntitle={A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning},\nauthor={Haozhe Jiang and Qiwen Cui and Zhihan Xiong and Maryam Fazel and Simon Shaolei Du},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LWuYsSD94h}\n}"}, "paperhash": {"value": "jiang|a_blackbox_approach_for_nonstationary_multiagent_reinforcement_learning"}}, "number": 6420, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6420/-/Revision", "ICLR.cc/2024/Conference/Submission6420/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6420/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695420795872, "cdate": 1695420795872, "tmdate": 1710509206743, "mdate": 1710509206743, "pdate": 1705410975543, "version": 2}, {"id": "5tGGWOijvq", "forum": "5tGGWOijvq", "signatures": ["ICLR.cc/2024/Conference/Submission6411/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6411/Authors"], "content": {"title": {"value": "Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models"}, "authors": {"value": ["Thomas P Zollo", "Todd Morrill", "Zhun Deng", "Jake Snell", "Toniann Pitassi", "Richard Zemel"]}, "authorids": {"value": ["~Thomas_P_Zollo1", "~Todd_Morrill1", "~Zhun_Deng1", "~Jake_Snell1", "~Toniann_Pitassi3", "~Richard_Zemel1"]}, "keywords": {"value": ["distribution-free uncertainty quantification", "large language models", "responsible AI"]}, "abstract": {"value": "With the explosion of the zero-shot capabilities of (and thus interest in) pre-trained large language models, there has come accompanying interest in how best to prompt a language model to perform a given task. While it may be tempting to choose a prompt based on empirical results on a validation set, this can lead to a deployment where an unexpectedly high loss occurs. To mitigate this prospect, we propose a lightweight framework, Prompt Risk Control, for selecting a prompt based on rigorous upper bounds on families of informative risk measures. We provide and compare different methods for producing bounds on a diverse set of risk metrics like mean, CVaR, and the Gini coefficient of the loss distribution. In addition, we extend the underlying statistical bounding techniques to accommodate the possibility of distribution shifts in deployment. Extensive experiments on high-impact applications like chatbots, medical question answering, and news summarization highlight why such a framework is necessary to reduce exposure to the worst outcomes."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d6f813b1c7a57e7508709682bec4f4c104ac1ff5.pdf"}, "supplementary_material": {"value": "/attachment/3c5a3c65a364905473f9e6916dd413b2fa2576d4.zip"}, "_bibtex": {"value": "@inproceedings{\nzollo2024prompt,\ntitle={Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models},\nauthor={Thomas P Zollo and Todd Morrill and Zhun Deng and Jake Snell and Toniann Pitassi and Richard Zemel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5tGGWOijvq}\n}"}, "paperhash": {"value": "zollo|prompt_risk_control_a_rigorous_framework_for_responsible_deployment_of_large_language_models"}}, "number": 6411, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6411/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6411/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695420605102, "cdate": 1695420605102, "tmdate": 1710273197646, "mdate": 1710273197646, "pdate": 1705410975216, "version": 2}, {"id": "smy4DsUbBo", "forum": "smy4DsUbBo", "signatures": ["ICLR.cc/2024/Conference/Submission6408/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6408/Authors"], "content": {"title": {"value": "Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials"}, "authors": {"value": ["Ivan Grega", "Ilyes Batatia", "Gabor Csanyi", "Sri Karlapati", "Vikram Deshpande"]}, "authorids": {"value": ["~Ivan_Grega1", "~Ilyes_Batatia1", "~Gabor_Csanyi1", "~Sri_Karlapati1", "~Vikram_Deshpande1"]}, "keywords": {"value": ["mechanical metamaterials", "lattices", "elasticity", "GNN", "equivariant", "positive definite", "energy conservation"]}, "abstract": {"value": "Lattices are architected metamaterials whose properties strongly depend on their geometrical design. The analogy between lattices and graphs enables the use of graph neural networks (GNNs) as a faster surrogate model compared to traditional methods such as finite element modelling. In this work, we generate a big dataset of structure-property relationships for strut-based lattices. The dataset is made available to the community which can fuel the development of methods anchored in physical principles for the fitting of fourth-order tensors. In addition, we present a higher-order GNN model trained on this dataset. The key features of the model are (i) SE(3) equivariance, and (ii) consistency with the thermodynamic law of conservation of energy. We compare the model to non-equivariant models based on a number of error metrics and demonstrate its benefits in terms of predictive performance and reduced training requirements. Finally, we demonstrate an example application of the model to an architected material design task. The methods which we developed are applicable to fourth-order tensors beyond elasticity such as piezo-optical tensor etc."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f212b32b998e446e18e45760ca50a57187dfe6ba.pdf"}, "TLDR": {"value": "We present equivariant GNN model for prediction of fourth-order stiffness tensor of mechanical metamaterials which is consistent with the law of energy conservation."}, "_bibtex": {"value": "@inproceedings{\ngrega2024energyconserving,\ntitle={Energy-conserving equivariant {GNN} for elasticity of lattice architected metamaterials},\nauthor={Ivan Grega and Ilyes Batatia and Gabor Csanyi and Sri Karlapati and Vikram Deshpande},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=smy4DsUbBo}\n}"}, "paperhash": {"value": "grega|energyconserving_equivariant_gnn_for_elasticity_of_lattice_architected_metamaterials"}}, "number": 6408, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6408/-/Revision", "ICLR.cc/2024/Conference/Submission6408/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6408/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695420463069, "cdate": 1695420463069, "tmdate": 1710430628593, "mdate": 1710430628593, "pdate": 1705410975076, "version": 2}, {"id": "g0mlwqs8pi", "forum": "g0mlwqs8pi", "signatures": ["ICLR.cc/2024/Conference/Submission6403/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6403/Authors"], "content": {"title": {"value": "Adaptive Federated Learning with Auto-Tuned Clients"}, "authors": {"value": ["Junhyung Lyle Kim", "Taha Toghani", "Cesar A Uribe", "Anastasios Kyrillidis"]}, "authorids": {"value": ["~Junhyung_Lyle_Kim1", "~Taha_Toghani1", "~Cesar_A_Uribe1", "~Anastasios_Kyrillidis2"]}, "keywords": {"value": ["federated learning", "distributed optimization", "adaptive method"]}, "abstract": {"value": "Federated learning (FL) is a distributed machine learning framework where the global model of a central server is trained via multiple collaborative steps by participating clients without sharing their data. While being a flexible framework, where the distribution of local data, participation rate, and computing power of each client can greatly vary, such flexibility gives rise to many new challenges, especially in the hyperparameter tuning on the client side. We propose $\\Delta$-SGD, a simple step size rule for SGD that enables each client to use its own step size by adapting to the local smoothness of the function each client is optimizing. We provide theoretical and empirical results where the benefit of the client adaptivity is shown in various FL scenarios."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f869f039a481a63eaec2e48f104de6df7f089a16.pdf"}, "supplementary_material": {"value": "/attachment/78b652f6cc9993c675d7af0218622880707a4594.pdf"}, "_bibtex": {"value": "@inproceedings{\nkim2024adaptive,\ntitle={Adaptive Federated Learning with Auto-Tuned Clients},\nauthor={Junhyung Lyle Kim and Taha Toghani and Cesar A Uribe and Anastasios Kyrillidis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=g0mlwqs8pi}\n}"}, "TLDR": {"value": "We propose a simple step size rule for SGD that enables each client to use its own adaptive\u2028step size that shows great performance without additional tuning in different FL settings."}, "paperhash": {"value": "kim|adaptive_federated_learning_with_autotuned_clients"}}, "number": 6403, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6403/-/Revision", "ICLR.cc/2024/Conference/Submission6403/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6403/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695420325022, "cdate": 1695420325022, "tmdate": 1710619058221, "mdate": 1710619058221, "pdate": 1705410974963, "version": 2}, {"id": "UCfz492fM8", "forum": "UCfz492fM8", "signatures": ["ICLR.cc/2024/Conference/Submission6375/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6375/Authors"], "content": {"title": {"value": "CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning"}, "authors": {"value": ["Tianyu Li", "Hyunyoung Jung", "Matthew Gombolay", "Yong Cho", "Sehoon Ha"]}, "authorids": {"value": ["~Tianyu_Li10", "~Hyunyoung_Jung2", "~Matthew_Gombolay1", "~Yong_Cho1", "~Sehoon_Ha2"]}, "keywords": {"value": ["Human Motion Driven Control", "Legged Locomotion", "Unsupervised Reinforcement Learning"]}, "abstract": {"value": "Human motion driven control (HMDC) is an effective approach for generating natural and compelling robot motions while preserving high-level semantics. However, establishing the correspondence between humans and robots with different body structures is not straightforward due to the mismatches in kinematics and dynamics properties, which causes intrinsic ambiguity to the problem. Many previous algorithms approach this motion retargeting problem with unsupervised learning, which requires the prerequisite skill sets. However, it will be extremely costly to learn all the skills without understanding the given human motions, particularly for high-dimensional robots. In this work, we introduce CrossLoco, a guided unsupervised reinforcement learning framework that simultaneously learns robot skills and their correspondence to human motions. Our key innovation is to introduce a cycle-consistency-based reward term designed to maximize the mutual information between human motions and robot states. We demonstrate that the proposed framework can generate compelling robot motions by translating diverse human motions, such as running, hopping, and dancing. We quantitatively compare our CrossLoco against the manually engineered and unsupervised baseline algorithms along with the ablated versions of our framework and demonstrate that our method translates human motions with better accuracy, diversity, and user preference. We also showcase its utility in other applications, such as synthesizing robot movements from language input and enabling interactive robot control."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5dc2d26064e3720009a09cd274c6ff48e2c64fd2.pdf"}, "supplementary_material": {"value": "/attachment/546b2b1b9bb3fe36455316bb3849713452600fce.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024crossloco,\ntitle={CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning},\nauthor={Tianyu Li and Hyunyoung Jung and Matthew Gombolay and Yong Cho and Sehoon Ha},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UCfz492fM8}\n}"}, "TLDR": {"value": "a guided unsupervised reinforcement learning framework that simultaneously learns robot skills and their correspondence to human motions."}, "paperhash": {"value": "li|crossloco_human_motion_driven_control_of_legged_robots_via_guided_unsupervised_reinforcement_learning"}}, "number": 6375, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6375/-/Revision", "ICLR.cc/2024/Conference/Submission6375/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6375/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695419117803, "cdate": 1695419117803, "tmdate": 1709976146798, "mdate": 1709976146798, "pdate": 1705410974062, "version": 2}, {"id": "LY3ukUANko", "forum": "LY3ukUANko", "signatures": ["ICLR.cc/2024/Conference/Submission6370/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6370/Authors"], "content": {"title": {"value": "Zoology: Measuring and Improving  Recall in Efficient Language Models"}, "authors": {"value": ["Simran Arora", "Sabri Eyuboglu", "Aman Timalsina", "Isys Johnson", "Michael Poli", "James Zou", "Atri Rudra", "Christopher Re"]}, "authorids": {"value": ["~Simran_Arora1", "~Sabri_Eyuboglu1", "~Aman_Timalsina1", "~Isys_Johnson1", "~Michael_Poli1", "~James_Zou1", "~Atri_Rudra1", "~Christopher_Re1"]}, "keywords": {"value": ["nlp", "language models", "representation learning", "in-context learning"]}, "TLDR": {"value": "We show fundamental differences between attention-based language models and increasingly-popular gated-convolution based ones."}, "abstract": {"value": "Attention-free language models that combine gating and convolutions are growing in popularity due to their efficiency and increasingly competitive performance. To better understand these architectures, we pretrain a suite of 17 attention and gated-convolution language models, finding that SoTA gated-convolution architectures still underperform attention by up to 2.1 perplexity points on the Pile. In fine-grained analysis, we find 82% of the gap is explained by each model's ability to recall information that is previously mentioned in-context, e.g. \"Hakuna Matata means no worries Hakuna Matata it means no\" -> ??. On this task, termed \"associative recall\", we find that attention outperforms gated-convolutions by a large margin: a 70M parameter attention model outperforms a 1.4 billion parameter gated-convolution model on associative recall. This is surprising because prior work shows gated convolutions can perfectly solve synthetic tests for AR capability.  To close the gap between synthetics and real language, we develop a new formalization of the task called multi-query associative recall (MQAR) that better reflects actual language. We perform an empirical and theoretical study of MQAR that elucidates differences in the parameter-efficiency of attention and gated-convolution recall. Informed by our analysis, we evaluate simple convolution-attention hybrids and show that hybrids with input-dependent sparse attention patterns can close 97.4% of the gap to attention, while maintaining sub-quadratic scaling. Code is at: https://github.com/HazyResearch/zoology."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/80fadc4fc3c3c1a12600b7f7e0e3d13e04ac334b.pdf"}, "supplementary_material": {"value": "/attachment/698046794178f76cc5660ac57ab32e5d78503ea1.zip"}, "_bibtex": {"value": "@inproceedings{\narora2024on,\ntitle={On input-dependence and recall in convolutional language models},\nauthor={Simran Arora and Sabri Eyuboglu and Aman Timalsina and Isys Johnson and Michael Poli and James Zou and Atri Rudra and Christopher Re},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LY3ukUANko}\n}"}, "paperhash": {"value": "arora|zoology_measuring_and_improving_recall_in_efficient_language_models"}}, "number": 6370, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6370/-/Revision", "ICLR.cc/2024/Conference/Submission6370/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6370/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418932880, "cdate": 1695418932880, "tmdate": 1710477599092, "mdate": 1710477599092, "pdate": 1705410973845, "version": 2}, {"id": "sehRvaIPQQ", "forum": "sehRvaIPQQ", "signatures": ["ICLR.cc/2024/Conference/Submission6362/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6362/Authors"], "content": {"title": {"value": "Let Models Speak Ciphers: Multiagent Debate through Embeddings"}, "authors": {"value": ["Chau Pham", "Boyi Liu", "Yingxiang Yang", "Zhengyu Chen", "Tianyi Liu", "Jianbo Yuan", "Bryan A. Plummer", "Zhaoran Wang", "Hongxia Yang"]}, "authorids": {"value": ["~Chau_Pham1", "~Boyi_Liu1", "~Yingxiang_Yang2", "~Zhengyu_Chen6", "~Tianyi_Liu2", "~Jianbo_Yuan1", "~Bryan_A._Plummer1", "~Zhaoran_Wang1", "~Hongxia_Yang2"]}, "keywords": {"value": ["multiagent debate", "large language models", "inter-model communication", "embedding representation"]}, "abstract": {"value": "Discussion and debate among Large Language Models (LLMs) have gained considerable attention due to their potential to enhance the reasoning ability of LLMs. Although natural language is an obvious choice for communication due to LLM's language understanding capability, the token sampling step needed when generating natural language poses a potential risk of information loss, as it uses only one token to represent the model's belief across the entire vocabulary. In this paper, we introduce a communication regime named CIPHER (Communicative Inter-Model Protocol Through Embedding Representation) to address this issue. Specifically, we remove the token sampling step from LLMs and let them communicate their beliefs across the vocabulary through the expectation of the raw transformer output embeddings. Remarkably, by deviating from natural language, CIPHER offers an advantage of encoding a broader spectrum of information without any modification to the model weights, outperforming the state-of-the-art LLM debate methods using natural language by 0.5-5.0% across five reasoning tasks and multiple open-source LLMs of varying sizes. This showcases the superiority and robustness of embeddings as an alternative \"language\" for communication among LLMs. We anticipate that CIPHER will inspire further exploration for the design of interactions within LLM agent systems, offering a new direction that could significantly influence future developments in the field."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/44f4dae92e4c22176324d6eb9893ab81be3ad031.pdf"}, "TLDR": {"value": "We present a novel communication approach for Large Language Models (LLMs) by removing the token sampling step from LLMs and enabling them to convey their beliefs across the vocabulary through the expectation of raw transformer output embeddings."}, "_bibtex": {"value": "@inproceedings{\npham2024let,\ntitle={Let Models Speak Ciphers: Multiagent Debate through Embeddings},\nauthor={Chau Pham and Boyi Liu and Yingxiang Yang and Zhengyu Chen and Tianyi Liu and Jianbo Yuan and Bryan A. Plummer and Zhaoran Wang and Hongxia Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sehRvaIPQQ}\n}"}, "paperhash": {"value": "pham|let_models_speak_ciphers_multiagent_debate_through_embeddings"}}, "number": 6362, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6362/-/Revision", "ICLR.cc/2024/Conference/Submission6362/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6362/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418748659, "cdate": 1695418748659, "tmdate": 1709661530421, "mdate": 1709661530421, "pdate": 1705410973638, "version": 2}, {"id": "xhCZD9hiiA", "forum": "xhCZD9hiiA", "signatures": ["ICLR.cc/2024/Conference/Submission6359/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6359/Authors"], "content": {"title": {"value": "Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion"}, "authors": {"value": ["Alexandru Meterez", "Amir Joudaki", "Francesco Orabona", "Alexander Immer", "Gunnar Ratsch", "Hadi Daneshmand"]}, "authorids": {"value": ["~Alexandru_Meterez1", "~Amir_Joudaki1", "~Francesco_Orabona1", "~Alexander_Immer1", "~Gunnar_Ratsch1", "~Hadi_Daneshmand1"]}, "keywords": {"value": ["mlp", "batch-normalization", "optimization", "depth", "calculus", "theory", "deep-learning", "non-asymptotic"]}, "abstract": {"value": "Normalization layers are one of the key building blocks for deep neural networks. Several theoretical studies have shown that batch normalization improves the signal propagation, by avoiding the representations from becoming collinear across the layers. However, results on mean-field theory of batch normalization also conclude that this benefit comes at the expense of exploding gradients in depth. Motivated by these two aspects of batch normalization, in this study we pose the following question: \n*Can a batch-normalized network keep the optimal signal propagation properties, but avoid exploding gradients?* We answer this question in the affirmative by giving a particular construction of an *MLP with linear activations* and batch-normalization that provably has *bounded gradients* at any depth. Based on Weingarten calculus, we develop a rigorous and non-asymptotic theory for this constructed MLP that gives a precise characterization of forward signal propagation, while proving that gradients remain bounded for linearly independent input samples, which holds in most practical settings. Inspired by our theory, we also design an activation shaping scheme that empirically achieves the same properties for non-linear activations."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dc2ce6be716cc4581968f3e649e237525a011edc.pdf"}, "supplementary_material": {"value": "/attachment/daf0abc7fdfaa944e62f3d84851efffe521a7ef0.pdf"}, "TLDR": {"value": "We show that MLPs with orthogonal weights and batch normalization orthogonalize the inputs, without gradient explosion at arbitrary depths."}, "_bibtex": {"value": "@inproceedings{\nmeterez2024towards,\ntitle={Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion},\nauthor={Alexandru Meterez and Amir Joudaki and Francesco Orabona and Alexander Immer and Gunnar Ratsch and Hadi Daneshmand},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xhCZD9hiiA}\n}"}, "paperhash": {"value": "meterez|towards_training_without_depth_limits_batch_normalization_without_gradient_explosion"}}, "number": 6359, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6359/-/Revision", "ICLR.cc/2024/Conference/Submission6359/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6359/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418702157, "cdate": 1695418702157, "tmdate": 1710549274605, "mdate": 1710549274605, "pdate": 1705410973570, "version": 2}, {"id": "DASh78rJ7g", "forum": "DASh78rJ7g", "signatures": ["ICLR.cc/2024/Conference/Submission6357/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6357/Authors"], "content": {"title": {"value": "Plugin estimators for selective classification with out-of-distribution detection"}, "authors": {"value": ["Harikrishna Narasimhan", "Aditya Krishna Menon", "Wittawat Jitkrittum", "Sanjiv Kumar"]}, "authorids": {"value": ["~Harikrishna_Narasimhan1", "~Aditya_Krishna_Menon1", "~Wittawat_Jitkrittum1", "~Sanjiv_Kumar1"]}, "keywords": {"value": ["Selective classification", "Learning to reject", "Abstention", "OOD detection", "SCOD", "Loss functions", "Plug-in estimators", "Statistical consistency"]}, "TLDR": {"value": "Plugin estimators that are theoretically grounded, effective, and generalise approaches for selective classification and OOD detection"}, "abstract": {"value": "Real-world classifiers can benefit from the option of abstaining from predicting on samples where they have low confidence. Such abstention is particularly useful on samples which are close to the learned decision boundary, or which are outliers with respect to the training sample. These settings have been the subject of extensive but disjoint study in the selective classification (SC) and out-of-distribution (OOD) detection literature. Recent work on selective classification with OOD detection (SCOD) has argued for the unified study of these problems; however, the formal underpinnings of this problem are still nascent, and existing techniques are heuristic in nature. In this paper, we propose new plugin estimators for SCOD that are theoretically grounded, effective, and generalise existing approaches from the SC and OOD detection literature. In the course of our analysis, we formally explicate how na\u00efve use of existing SC and OOD detection baselines may be inadequate for SCOD. We empirically demonstrate that our approaches yields competitive SC and OOD detection trade-offs compared to common baselines."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/689d825fd5454be7b2029a0758b1a4af754d3afc.pdf"}, "_bibtex": {"value": "@inproceedings{\nnarasimhan2024plugin,\ntitle={Plugin estimators for selective classification with out-of-distribution detection},\nauthor={Harikrishna Narasimhan and Aditya Krishna Menon and Wittawat Jitkrittum and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DASh78rJ7g}\n}"}, "paperhash": {"value": "narasimhan|plugin_estimators_for_selective_classification_with_outofdistribution_detection"}}, "number": 6357, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6357/-/Revision", "ICLR.cc/2024/Conference/Submission6357/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6357/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418634320, "cdate": 1695418634320, "tmdate": 1710435006444, "mdate": 1710435006444, "pdate": 1705410973488, "version": 2}, {"id": "kOBkxFRKTA", "forum": "kOBkxFRKTA", "signatures": ["ICLR.cc/2024/Conference/Submission6355/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6355/Authors"], "content": {"title": {"value": "Dynamic Sparse Training with Structured Sparsity"}, "authors": {"value": ["Mike Lasby", "Anna Golubeva", "Utku Evci", "Mihai Nica", "Yani Ioannou"]}, "authorids": {"value": ["~Mike_Lasby1", "~Anna_Golubeva1", "~Utku_Evci1", "~Mihai_Nica1", "~Yani_Ioannou1"]}, "keywords": {"value": ["Machine Learning", "dynamic sparse training", "structured sparsity", "N:M sparsity", "efficient deep learning", "RigL", "SRigL", "constant fan-in", "dynamic neuron ablation", "neuron ablation", "structured and fine-grained sparsity", "online inference", "accelerating inference"]}, "TLDR": {"value": "SRigL: a dynamic sparse training method that learns structured and constant fan-in sparsity to match SOTA generalization performance while accelerating inference"}, "abstract": {"value": "Dynamic Sparse Training (DST) methods achieve state-of-the-art results in sparse neural network training, matching the generalization of dense models while enabling sparse training and inference. Although the resulting models are highly sparse and theoretically less computationally expensive, achieving speedups with unstructured sparsity on real-world hardware is challenging. In this work, we propose a sparse-to-sparse DST method, Structured RigL (SRigL), to learn a variant of fine-grained structured N:M sparsity by imposing a constant fan-in constraint. Using our empirical analysis of existing DST methods at high sparsity, we additionally employ a neuron ablation method which enables SRigL to achieve state-of-the-art sparse-to-sparse structured DST performance on a variety of Neural Network (NN) architectures. Using a 90% sparse linear layer, we demonstrate a real-world acceleration of 3.4\u00d7/2.5\u00d7 on CPU for online inference and 1.7\u00d7/13.0\u00d7 on GPU for inference with a batch size of 256 when compared to equivalent dense/unstructured (CSR) sparse layers, respectively."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/df0ecee276b46da96414263a1adb2d466de60dfc.pdf"}, "supplementary_material": {"value": "/attachment/4376ef03a99fb2d7635e3bd56023068affa04263.pdf"}, "_bibtex": {"value": "@inproceedings{\nlasby2024dynamic,\ntitle={Dynamic Sparse Training with Structured Sparsity},\nauthor={Mike Lasby and Anna Golubeva and Utku Evci and Mihai Nica and Yani Ioannou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kOBkxFRKTA}\n}"}, "paperhash": {"value": "lasby|dynamic_sparse_training_with_structured_sparsity"}}, "number": 6355, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6355/-/Revision", "ICLR.cc/2024/Conference/Submission6355/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6355/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418622742, "cdate": 1695418622742, "tmdate": 1712610499020, "mdate": 1712610499020, "pdate": 1705410973459, "version": 2}, {"id": "fkrYDQaHOJ", "forum": "fkrYDQaHOJ", "signatures": ["ICLR.cc/2024/Conference/Submission6354/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6354/Authors"], "content": {"title": {"value": "Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"}, "authors": {"value": ["Arnab Kumar Mondal", "Siba Smarak Panigrahi", "Sai Rajeswar", "Kaleem Siddiqi", "Siamak Ravanbakhsh"]}, "authorids": {"value": ["~Arnab_Kumar_Mondal1", "~Siba_Smarak_Panigrahi1", "~Sai_Rajeswar2", "~Kaleem_Siddiqi1", "~Siamak_Ravanbakhsh1"]}, "keywords": {"value": ["Koopman Theory", "Reinforcement Learning", "Dynamical System", "Planning", "Longe range dynamics prediction models", "Efficient forward dynamics"]}, "TLDR": {"value": "We propose to use a Diagonalized Koopman operator to model Interactive environments efficiently in the latent space as linear dynamical systems with a control input."}, "abstract": {"value": "The accurate modeling of dynamics in interactive environments is critical for successful long-range prediction. Such a capability could advance Reinforcement Learning (RL) and Planning algorithms, but achieving it is challenging. Inaccuracies in model estimates can compound, resulting in increased errors over long horizons.\nWe approach this problem from the lens of Koopman theory, where the nonlinear dynamics of the environment can be linearized in a high-dimensional latent space. This allows us to efficiently parallelize the sequential problem of long-range prediction using convolution while accounting for the agent's action at every time step.\nOur approach also enables stability analysis and better control over gradients through time. Taken together, these advantages result in significant improvement over the existing approaches, both in the efficiency and the accuracy of modeling dynamics over extended horizons. We also show that this model can be easily incorporated into dynamics modeling for model-based planning and model-free RL and report promising experimental results."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/04bd1740192430ffff275d12c5f99a21e157dad5.pdf"}, "supplementary_material": {"value": "/attachment/ba477243a1f52461755023d6a310db7ee59e19a9.zip"}, "_bibtex": {"value": "@inproceedings{\nmondal2024efficient,\ntitle={Efficient Dynamics Modeling in Interactive Environments with Koopman Theory},\nauthor={Arnab Kumar Mondal and Siba Smarak Panigrahi and Sai Rajeswar and Kaleem Siddiqi and Siamak Ravanbakhsh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fkrYDQaHOJ}\n}"}, "paperhash": {"value": "mondal|efficient_dynamics_modeling_in_interactive_environments_with_koopman_theory"}}, "number": 6354, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6354/-/Revision", "ICLR.cc/2024/Conference/Submission6354/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6354/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418578398, "cdate": 1695418578398, "tmdate": 1712353141169, "mdate": 1712353141169, "pdate": 1705410973297, "version": 2}, {"id": "MFCjgEOLJT", "forum": "MFCjgEOLJT", "signatures": ["ICLR.cc/2024/Conference/Submission6347/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6347/Authors"], "content": {"title": {"value": "Learning interpretable control inputs and dynamics underlying animal locomotion"}, "authors": {"value": ["Thomas Soares Mullen", "Marine Schimel", "Guillaume Hennequin", "Christian K. Machens", "Michael Orger", "Adrien Jouary"]}, "authorids": {"value": ["~Thomas_Soares_Mullen1", "~Marine_Schimel1", "~Guillaume_Hennequin1", "~Christian_K._Machens1", "~Michael_Orger1", "~Adrien_Jouary1"]}, "keywords": {"value": ["computational neuroscience", "interpretable dynamics", "motor control", "animal behavior", "dynamical systems", "system identification", "unsupervised learning", "zebrafish"]}, "TLDR": {"value": "We proposed a novel approach to modeling time series of behavior observations by combining two existing methods in order to learn a reduced and interpretable model of behavioral dynamics"}, "abstract": {"value": "A central objective in neuroscience is to understand how the brain orchestrates movement. Recent advances in automated tracking technologies have made it possible to document behavior with unprecedented temporal resolution and scale, generating rich datasets which can be exploited to gain insights into the neural control of movement. One common approach is to identify stereotypical motor primitives using cluster analysis. However, this categorical description can limit our ability to model the effect of more continuous control schemes. Here we take a control theoretic approach to behavioral modeling and argue that movements can be understood as the output of a controlled dynamical system. Previously, models of movement dynamics, trained solely on behavioral data, have been effective in reproducing observed features of neural activity. These models addressed specific scenarios where animals were trained to execute particular movements upon receiving a prompt. In this study, we extend this approach to analyze the full natural locomotor repertoire of an animal: the zebrafish larva. Our findings demonstrate that this repertoire can be effectively generated through a sparse control signal driving a latent Recurrent Neural Network (RNN). Our model's learned latent space preserves key kinematic features and disentangles different categories of movements. To further interpret the latent dynamics, we used balanced model reduction to yield a simplified model. Collectively, our methods serve as a case study for interpretable system identification, and offer a novel framework for understanding neural activity in relation to movement."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/44b4027edc563e0589bd44a76a7cdd91d74f932b.pdf"}, "supplementary_material": {"value": "/attachment/f52eae0fa708dd812a28d689565ca38208b325cd.zip"}, "_bibtex": {"value": "@inproceedings{\nmullen2024learning,\ntitle={Learning interpretable control inputs and dynamics underlying animal locomotion},\nauthor={Thomas Soares Mullen and Marine Schimel and Guillaume Hennequin and Christian K. Machens and Michael Orger and Adrien Jouary},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MFCjgEOLJT}\n}"}, "paperhash": {"value": "mullen|learning_interpretable_control_inputs_and_dynamics_underlying_animal_locomotion"}}, "number": 6347, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6347/-/Revision", "ICLR.cc/2024/Conference/Submission6347/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6347/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418404769, "cdate": 1695418404769, "tmdate": 1710521493863, "mdate": 1710521493863, "pdate": 1705410972989, "version": 2}, {"id": "nUBLhhVM1l", "forum": "nUBLhhVM1l", "signatures": ["ICLR.cc/2024/Conference/Submission6346/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6346/Authors"], "content": {"title": {"value": "Tight Rates in Supervised Outlier Transfer Learning"}, "authors": {"value": ["Mohammadreza Mousavi Kalan", "Samory Kpotufe"]}, "authorids": {"value": ["~Mohammadreza_Mousavi_Kalan1", "~Samory_Kpotufe3"]}, "keywords": {"value": ["Minimax rate", "outlier detection", "transfer learning", "Neyman-Pearson", "unbalanced classification"]}, "abstract": {"value": "A critical barrier to learning an accurate decision rule for outlier detection is the scarcity of outlier data. As such, practitioners often turn to the use of similar but imperfect outlier data from which they might \\emph{transfer} information to the target outlier detection task. Despite the recent empirical success of transfer learning in outlier detection, a fundamental understanding of when and how knowledge can be transferred from a source to a target in outlier detection remains elusive. In this work, we adopt the traditional framework of Neyman-Pearson classification---which formalizes \\emph{supervised outlier detection}, i.e., unbalanced classification---with the added assumption that we have access to both source and (some or no) target outlier data. Our main results are then as follows:\n\nWe first determine the information-theoretic limits of the problem under a measure of discrepancy that extends some existing notions from traditional balanced classification; interestingly, unlike in balanced classification, seemingly very dissimilar sources can provide much information about a target, thus resulting in fast transfer.\n\nWe then show that, in principle, these information-theoretic limits are achievable by \\emph{adaptive} procedures, i.e., procedures with no a priori information on the discrepancy between source and target distributions."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0421a646b97f3333e121cd90e499e5b17866e497.pdf"}, "_bibtex": {"value": "@inproceedings{\nkalan2024tight,\ntitle={Tight Rates in Supervised Outlier Transfer Learning},\nauthor={Mohammadreza Mousavi Kalan and Samory Kpotufe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nUBLhhVM1l}\n}"}, "paperhash": {"value": "kalan|tight_rates_in_supervised_outlier_transfer_learning"}}, "number": 6346, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6346/-/Revision", "ICLR.cc/2024/Conference/Submission6346/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6346/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418370537, "cdate": 1695418370537, "tmdate": 1712655768916, "mdate": 1712655768916, "pdate": 1705410972954, "version": 2}, {"id": "oAMArMMQxb", "forum": "oAMArMMQxb", "signatures": ["ICLR.cc/2024/Conference/Submission6339/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6339/Authors"], "content": {"title": {"value": "Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization"}, "authors": {"value": ["Frederic Koehler", "Thuy-Duong Vuong"]}, "authorids": {"value": ["~Frederic_Koehler1", "~Thuy-Duong_Vuong1"]}, "keywords": {"value": ["sampling", "score matching", "contrastive divergence", "langevin dynamics"]}, "TLDR": {"value": "We show that sampling multimodal distributions with the vanilla score is provably fixed by data-based initialization."}, "abstract": {"value": "There is a long history, as well as a recent explosion of interest, in statistical and generative modeling approaches based on \\emph{score functions} --- derivatives of the log-likelihood of a distribution. In seminal works, Hyv\\\"arinen proposed vanilla score matching as a way to learn distributions from data by computing an estimate of the score function of the underlying ground truth, and established connections between this method and established techniques like Contrastive Divergence and Pseudolikelihood estimation. It is by now well-known that vanilla score matching has significant difficulties learning multimodal distributions. Although there are various ways to overcome this difficulty, the following question has remained unanswered --- is there a natural way to sample multimodal distributions using just the vanilla score? Inspired by a long line of related experimental works, we prove that the Langevin diffusion with early stopping, initialized at the empirical distribution, and run on a score function estimated from data successfully generates natural multimodal distributions (mixtures of log-concave distributions)."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6f0085775eeca15b7adb6a504d6ec7a331dc1ee3.pdf"}, "supplementary_material": {"value": "/attachment/37c7cf2c20b6735cbfeb3be53b10dafdf4c66878.zip"}, "_bibtex": {"value": "@inproceedings{\nkoehler2024sampling,\ntitle={Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization},\nauthor={Frederic Koehler and Thuy-Duong Vuong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oAMArMMQxb}\n}"}, "paperhash": {"value": "koehler|sampling_multimodal_distributions_with_the_vanilla_score_benefits_of_databased_initialization"}}, "number": 6339, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6339/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6339/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418123229, "cdate": 1695418123229, "tmdate": 1710488151743, "mdate": 1710488151743, "pdate": 1705410972717, "version": 2}, {"id": "4KqkizXgXU", "forum": "4KqkizXgXU", "signatures": ["ICLR.cc/2024/Conference/Submission6325/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6325/Authors"], "content": {"title": {"value": "Curiosity-driven Red-teaming for Large Language Models"}, "authors": {"value": ["Zhang-Wei Hong", "Idan Shenfeld", "Tsun-Hsuan Wang", "Yung-Sung Chuang", "Aldo Pareja", "James R. Glass", "Akash Srivastava", "Pulkit Agrawal"]}, "authorids": {"value": ["~Zhang-Wei_Hong1", "~Idan_Shenfeld1", "~Tsun-Hsuan_Wang2", "~Yung-Sung_Chuang1", "~Aldo_Pareja1", "~James_R._Glass1", "~Akash_Srivastava1", "~Pulkit_Agrawal1"]}, "keywords": {"value": ["Curiosity-driven exploration", "Reinforcement learning", "Language model"]}, "TLDR": {"value": "We use curiosity-driven exploration to improve the diversity of the test cases generated for red teaming large language models."}, "abstract": {"value": "Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a $\\textit{red team}$ of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. \nHowever, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM.\nTo overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. \nOur method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods.\nOur method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. Code is available at https://github.com/Improbable-AI/curiosity_redteam."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3d980d9fedcf67ee1a60555b571fd716325f2f03.pdf"}, "supplementary_material": {"value": "/attachment/da3812c3dc922578aa3779e75911bd941e9e9d13.zip"}, "_bibtex": {"value": "@inproceedings{\nhong2024curiositydriven,\ntitle={Curiosity-driven Red-teaming for Large Language Models},\nauthor={Zhang-Wei Hong and Idan Shenfeld and Tsun-Hsuan Wang and Yung-Sung Chuang and Aldo Pareja and James R. Glass and Akash Srivastava and Pulkit Agrawal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4KqkizXgXU}\n}"}, "paperhash": {"value": "hong|curiositydriven_redteaming_for_large_language_models"}}, "number": 6325, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6325/-/Revision", "ICLR.cc/2024/Conference/Submission6325/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6325/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695417604016, "cdate": 1695417604016, "tmdate": 1709661530030, "mdate": 1709661530030, "pdate": 1705410972276, "version": 2}, {"id": "a745RnSFLT", "forum": "a745RnSFLT", "signatures": ["ICLR.cc/2024/Conference/Submission6321/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6321/Authors"], "content": {"title": {"value": "Understanding prompt engineering may not require rethinking generalization"}, "authors": {"value": ["Victor Akinwande", "Yiding Jiang", "Dylan Sam", "J Zico Kolter"]}, "authorids": {"value": ["~Victor_Akinwande2", "~Yiding_Jiang2", "~Dylan_Sam1", "~J_Zico_Kolter1"]}, "keywords": {"value": ["generalization", "prompt engineering", "PAC-Bayes", "foundation models"]}, "abstract": {"value": "Zero-shot learning in prompted vision-language models, the practice of crafting prompts to build classifiers without an explicit training process, has achieved impressive performance in many settings. This success presents a seemingly surprising observation: these methods suffer relatively little from overfitting, i.e., when a prompt is manually engineered to achieve low error on a given training set (thus rendering the method no longer actually zero-shot), the approach still performs well on held-out test data. In this paper, we show that we can explain such performance well via recourse to classical PAC-Bayes bounds.  Specifically, we show that the discrete nature of prompts, combined with a PAC-Bayes prior given by a language model, results in generalization bounds that are remarkably tight by the standards of the literature: for instance, the generalization bound of an ImageNet classifier is often within a few percentage points of the true test error. We demonstrate empirically that this holds for existing handcrafted prompts and prompts generated through simple greedy search. Furthermore, the resulting bound is well-suited for model selection: the models with the best bound typically also have the best test performance. This work thus provides a possible justification for the widespread practice of \"prompt engineering,\" even if it seems that such methods could potentially overfit the training data."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f83b13fb653621edd31d88604d65debf7713716.pdf"}, "TLDR": {"value": "We show that prompt engineering generalizes well via a PAC-Bayes analysis."}, "_bibtex": {"value": "@inproceedings{\nakinwande2024understanding,\ntitle={Understanding prompt engineering may not require rethinking generalization},\nauthor={Victor Akinwande and Yiding Jiang and Dylan Sam and J Zico Kolter},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=a745RnSFLT}\n}"}, "paperhash": {"value": "akinwande|understanding_prompt_engineering_may_not_require_rethinking_generalization"}}, "number": 6321, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6321/-/Revision", "ICLR.cc/2024/Conference/Submission6321/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6321/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695417239664, "cdate": 1695417239664, "tmdate": 1710251689270, "mdate": 1710251689270, "pdate": 1705410972211, "version": 2}, {"id": "DuQkqSe9en", "forum": "DuQkqSe9en", "signatures": ["ICLR.cc/2024/Conference/Submission6313/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6313/Authors"], "content": {"title": {"value": "Adversarial Imitation Learning via Boosting"}, "authors": {"value": ["Jonathan Daniel Chang", "Dhruv Sreenivas", "Yingbing Huang", "Kiant\u00e9 Brantley", "Wen Sun"]}, "authorids": {"value": ["~Jonathan_Daniel_Chang1", "~Dhruv_Sreenivas1", "~Yingbing_Huang1", "~Kiant\u00e9_Brantley2", "~Wen_Sun1"]}, "keywords": {"value": ["Adversarial Imitation Learning", "Boosting", "Reinforcement Learning"]}, "abstract": {"value": "Adversarial imitation learning (AIL) has stood out as a dominant framework across various imitation learning (IL) applications, with Discriminator Actor Critic (DAC) demonstrating the effectiveness of off-policy learning algorithms in improving sample efficiency and scalability to higher-dimensional observations. Despite DAC\u2019s empirical success, the original AIL objective is on-policy and DAC\u2019s ad-hoc application of off-policy training does not guarantee successful imitation. Follow-up work such as ValueDICE tackles this issue by deriving a fully off-policy AIL objective. Instead in this work, we develop a novel and principled AIL algorithm via the framework of boosting. Like boosting, our new algorithm, AILBoost, maintains an ensemble of weighted weak learners (i.e., policies) and trains a discriminator that witnesses the maximum discrepancy between the distributions of the ensemble and the expert policy. We maintain a weighted replay buffer to represent the state-action distribution induced by the ensemble, allowing us to train discriminators using the entire data collected so far. Empirically, we evaluate our algorithm on both controller state-based and pixel-based environments from the DeepMind Control Suite. AILBoost outperforms DAC on both types of environments, demonstrating the benefit of properly weighting replay buffer data for off-policy training. On state-based environments, AILBoost outperforms ValueDICE and IQ-Learn, achieving state-of-the-art performance with as little as one expert trajectory."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f8eb32fb211aadb88357aacb431c6831cdb1e0a6.pdf"}, "supplementary_material": {"value": "/attachment/f50f2041c7384cbdf95c822b4df59cb232531109.pdf"}, "_bibtex": {"value": "@inproceedings{\nchang2024adversarial,\ntitle={Adversarial Imitation Learning via Boosting},\nauthor={Jonathan Daniel Chang and Dhruv Sreenivas and Yingbing Huang and Kiant{\\'e} Brantley and Wen Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DuQkqSe9en}\n}"}, "paperhash": {"value": "chang|adversarial_imitation_learning_via_boosting"}}, "number": 6313, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6313/-/Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416832414, "cdate": 1695416832414, "tmdate": 1707625630945, "mdate": 1707625630945, "pdate": 1705410972006, "version": 2}, {"id": "1mjsP8RYAw", "forum": "1mjsP8RYAw", "signatures": ["ICLR.cc/2024/Conference/Submission6308/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6308/Authors"], "content": {"title": {"value": "Unsupervised Pretraining for Fact Verification by Language Model Distillation"}, "authors": {"value": ["Adri\u00e1n Bazaga", "Pietro Lio", "Gos Micklem"]}, "authorids": {"value": ["~Adri\u00e1n_Bazaga1", "~Pietro_Lio1", "~Gos_Micklem1"]}, "keywords": {"value": ["Unsupervised Learning", "Self-supervised Learning", "Deep Features", "Contrastive Learning", "Large Language Models", "Knowledge Distillation", "Multimodality", "Fact Verification"]}, "TLDR": {"value": "We propose a new framework for performing unsupervised pretraining for fact verification by distilling large language models knowledge for claim-evidence matching"}, "abstract": {"value": "Fact verification aims to verify a claim using evidence from a trustworthy knowledge base. To address this challenge, algorithms must produce features for every claim that are both semantically meaningful, and compact enough to find a semantic alignment with the source information. In contrast to previous work, which tackled the alignment problem by learning over annotated corpora of claims and their corresponding labels, we propose SFAVEL ($\\underline{S}$elf-supervised $\\underline{Fa}$ct $\\underline{Ve}$rification via $\\underline{L}$anguage Model Distillation), a novel unsupervised pretraining framework that leverages pre-trained language models to distil self-supervised features into high-quality claim-fact alignments without the need for annotations. This is enabled by a novel contrastive loss function that encourages features to attain high-quality claim and evidence alignments whilst preserving the semantic relationships across the corpora. Notably, we present results that achieve a new state-of-the-art on FB15k-237 (+5.3\\% Hits@1) and FEVER (+8\\% accuracy) with linear evaluation."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dbf5b4454088de9f62ada53f4c2765a0654867de.pdf"}, "_bibtex": {"value": "@inproceedings{\nbazaga2024unsupervised,\ntitle={Unsupervised Fact Verification by Language Model Distillation},\nauthor={Adri{\\'a}n Bazaga and Pietro Lio and Gos Micklem},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1mjsP8RYAw}\n}"}, "paperhash": {"value": "bazaga|unsupervised_pretraining_for_fact_verification_by_language_model_distillation"}}, "number": 6308, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6308/-/Revision", "ICLR.cc/2024/Conference/Submission6308/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6308/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416671379, "cdate": 1695416671379, "tmdate": 1709755707046, "mdate": 1709755707046, "pdate": 1705410971792, "version": 2}, {"id": "0w42S2Gp70", "forum": "0w42S2Gp70", "signatures": ["ICLR.cc/2024/Conference/Submission6307/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6307/Authors"], "content": {"title": {"value": "LipSim: A Provably Robust Perceptual Similarity Metric"}, "authors": {"value": ["Sara Ghazanfari", "Alexandre Araujo", "Prashanth Krishnamurthy", "Farshad Khorrami", "Siddharth Garg"]}, "authorids": {"value": ["~Sara_Ghazanfari1", "~Alexandre_Araujo3", "~Prashanth_Krishnamurthy1", "~Farshad_Khorrami1", "~Siddharth_Garg1"]}, "keywords": {"value": ["Perceptual similarity metric", "certified defense", "deep learning"]}, "abstract": {"value": "Recent years have seen growing interest in developing and applying perceptual similarity metrics. Research has shown the superiority of perceptual metrics over pixel-wise metrics in aligning with human perception and serving as a proxy for the human visual system.\nOn the other hand, as perceptual metrics rely on neural networks, there is a growing concern regarding their resilience, given the established vulnerability of neural networks to adversarial attacks. It is indeed logical to infer that perceptual metrics may inherit both the strengths and shortcomings of neural networks.\nIn this work, we demonstrate the vulnerability of state-of-the-art perceptual similarity metrics based on an ensemble of ViT-based feature extractors to adversarial attacks. We then propose a framework to train a robust perceptual similarity metric called LipSim (Lipschitz Similarity Metric) with provable guarantees. \nBy leveraging 1-Lipschitz neural networks as the backbone, LipSim provides guarded areas around each data point and certificates for all perturbations within an $\\ell_2$ ball. Finally, a comprehensive set of experiments shows the performance of LipSim in terms of natural and certified scores and on the image retrieval application."}, "primary_area": {"value": "metric learning, kernel learning, and sparse coding"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b61480257822a8f17a6f8675bfee38b41c10e2e4.pdf"}, "supplementary_material": {"value": "/attachment/ac1c68fa813678f31bc42d9bafc10c7a84a43cd6.zip"}, "_bibtex": {"value": "@inproceedings{\nghazanfari2024lipsim,\ntitle={LipSim: A Provably Robust Perceptual Similarity Metric},\nauthor={Sara Ghazanfari and Alexandre Araujo and Prashanth Krishnamurthy and Farshad Khorrami and Siddharth Garg},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0w42S2Gp70}\n}"}, "paperhash": {"value": "ghazanfari|lipsim_a_provably_robust_perceptual_similarity_metric"}}, "number": 6307, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6307/-/Revision", "ICLR.cc/2024/Conference/Submission6307/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6307/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416655523, "cdate": 1695416655523, "tmdate": 1710519443028, "mdate": 1710519443028, "pdate": 1705410971769, "version": 2}, {"id": "rhaQbS3K3R", "forum": "rhaQbS3K3R", "signatures": ["ICLR.cc/2024/Conference/Submission6304/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6304/Authors"], "content": {"title": {"value": "Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced, Global Data?"}, "authors": {"value": ["Megan Richards", "Polina Kirichenko", "Diane Bouchacourt", "Mark Ibrahim"]}, "authorids": {"value": ["~Megan_Richards1", "~Polina_Kirichenko1", "~Diane_Bouchacourt3", "~Mark_Ibrahim1"]}, "keywords": {"value": ["Benchmarks", "Fairness", "Generalization"]}, "TLDR": {"value": "We find generalization progress on crowdsourced global data lags behind standard object recognition benchmarks, and scaling exacerbates regional performance disparities."}, "abstract": {"value": "For more than a decade, researchers have measured progress in object recognition on the ImageNet dataset along with its associated generalization benchmarks such as ImageNet-A, -C, and -R. Recent advances in foundation models, trained on orders of magnitude more data, have begun to saturate performance on these benchmarks. Despite this progress, even today\u2019s best models are brittle in practice. As a step toward more holistic measurement of model reliability, we propose studying performance on crowdsourced, global datasets, which contain natural distribution shifts seen practically in deployment. We perform a comprehensive empirical study on two crowdsourced, globally representative datasets, evaluating nearly 100 vision models to uncover several concerning empirical trends: first, that progress on crowdsourced, global data has significantly lagged behind standard benchmarks, with advances on ImageNet occurring at $2.5x$ the rate of progress on crowdsourced, global data. Second, we find that progress on standard benchmarks has failed to improve or exacerbated geographic disparities: \\textit{geographic disparities between the least performant models and today's best models have more than tripled}. We showcase the promise of using more curated and/or representative training datasets for mitigating these trends, and emphasize curation of web-scale, geographically representative training datasets as a critical open problem for the research community."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c1b53b959a0293a7d8bfd6315666036aaf3b5c33.pdf"}, "_bibtex": {"value": "@inproceedings{\nrichards2024does,\ntitle={Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced, Global Data?},\nauthor={Megan Richards and Polina Kirichenko and Diane Bouchacourt and Mark Ibrahim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rhaQbS3K3R}\n}"}, "paperhash": {"value": "richards|does_progress_on_object_recognition_benchmarks_improve_generalization_on_crowdsourced_global_data"}}, "number": 6304, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6304/-/Revision", "ICLR.cc/2024/Conference/Submission6304/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6304/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416582664, "cdate": 1695416582664, "tmdate": 1712967037796, "mdate": 1712967037796, "pdate": 1705410971645, "version": 2}, {"id": "xtOydkE1Ku", "forum": "xtOydkE1Ku", "signatures": ["ICLR.cc/2024/Conference/Submission6303/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6303/Authors"], "content": {"title": {"value": "TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series"}, "authors": {"value": ["Arjun Ashok", "\u00c9tienne Marcotte", "Valentina Zantedeschi", "Nicolas Chapados", "Alexandre Drouin"]}, "authorids": {"value": ["~Arjun_Ashok1", "~\u00c9tienne_Marcotte1", "~Valentina_Zantedeschi2", "~Nicolas_Chapados1", "~Alexandre_Drouin2"]}, "keywords": {"value": ["time series", "forecasting", "probabilistic", "multivariate", "copula", "transformer", "density estimation"]}, "abstract": {"value": "We introduce a new model for multivariate probabilistic time series prediction, designed to flexibly address a range of tasks including forecasting, interpolation, and their combinations. Building on copula theory, we propose a simplified objective for the recently-introduced transformer-based attentional copulas (TACTiS), wherein the number of distributional parameters now scales linearly with the number of variables instead of factorially. The new objective requires the introduction of a training curriculum, which goes hand-in-hand with necessary changes to the original architecture. We show that the resulting model has significantly better training dynamics and achieves state-of-the-art performance across diverse real-world forecasting tasks, while maintaining the flexibility of prior work, such as seamless handling of unaligned and unevenly-sampled time series. Code is made available at https://github.com/ServiceNow/TACTiS."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f291d4209cc457a311b7e86d604ad0727f04943f.pdf"}, "TLDR": {"value": "A flexible model for multivariate probabilistic time series prediction, simplifying the training of attentional copulas, with state-of-the-art accuracy on diverse forecasting tasks, while supporting interpolation and learning from irregular data."}, "_bibtex": {"value": "@inproceedings{\nashok2024tactis,\ntitle={{TACT}iS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series},\nauthor={Arjun Ashok and {\\'E}tienne Marcotte and Valentina Zantedeschi and Nicolas Chapados and Alexandre Drouin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xtOydkE1Ku}\n}"}, "paperhash": {"value": "ashok|tactis2_better_faster_simpler_attentional_copulas_for_multivariate_time_series"}}, "number": 6303, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6303/-/Revision", "ICLR.cc/2024/Conference/Submission6303/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6303/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416421696, "cdate": 1695416421696, "tmdate": 1710606257762, "mdate": 1710606257762, "pdate": 1705410971589, "version": 2}, {"id": "zbOSJ3CATY", "forum": "zbOSJ3CATY", "signatures": ["ICLR.cc/2024/Conference/Submission6302/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6302/Authors"], "content": {"title": {"value": "A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER"}, "authors": {"value": ["Panagiotis Theodoropoulos", "Guan-Horng Liu", "Tianrong Chen", "Augustinos D Saravanos", "Evangelos Theodorou"]}, "authorids": {"value": ["~Panagiotis_Theodoropoulos1", "~Guan-Horng_Liu1", "~Tianrong_Chen1", "~Augustinos_D_Saravanos1", "~Evangelos_Theodorou1"]}, "keywords": {"value": ["Neural Optimizer", "Differential Dynamic Programming", "Adversarial Defense", "Game Theory"]}, "TLDR": {"value": "In this work we interpret Neural ODE optimization as a min-max optimal control problem, to present a robust game theoretic optimizer based on the principles of min-max Differential Dynamic Programming."}, "abstract": {"value": "Neural networks and neural ODEs tend to be vulnerable to adversarial attacks, rendering robust optimizers critical to curb the success of such attacks. In this regard, the key insight of this work is to interpret Neural ODE optimization as a min-max optimal control problem. More particularly, we present Game Theoretic Second-Order Neural Optimizer (GTSONO), a robust game theoretic optimizer based on the principles of min-max Differential Dynamic Programming.\nThe proposed method exhibits significant computational benefits due to efficient matrix decompositions and provides convergence guarantees to local saddle points.\nEmpirically, the robustness of the proposed optimizer is demonstrated through greater robust accuracy  compared to benchmark optimizers when trained on clean images. Additionally, its ability to provide a performance increase when adapted to an already existing adversarial defense technique is also illustrated.\nFinally, the superiority of the proposed update law over its gradient based counterpart highlights the potential benefits of incorporating robust optimal control paradigms into adversarial training methods."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0694ab21858f258a4bda6a372f84fcf448c719c9.pdf"}, "_bibtex": {"value": "@inproceedings{\ntheodoropoulos2024a,\ntitle={A {ROBUST} {DIFFERENTIAL} {NEURAL} {ODE} {OPTIMIZER}},\nauthor={Panagiotis Theodoropoulos and Guan-Horng Liu and Tianrong Chen and Augustinos D Saravanos and Evangelos Theodorou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zbOSJ3CATY}\n}"}, "paperhash": {"value": "theodoropoulos|a_robust_differential_neural_ode_optimizer"}}, "number": 6302, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6302/-/Revision", "ICLR.cc/2024/Conference/Submission6302/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6302/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416385677, "cdate": 1695416385677, "tmdate": 1710530865873, "mdate": 1710530865873, "pdate": 1705410971484, "version": 2}, {"id": "RsztjXcvUf", "forum": "RsztjXcvUf", "signatures": ["ICLR.cc/2024/Conference/Submission6289/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6289/Authors"], "content": {"title": {"value": "A Primal-Dual Approach to Solving Variational Inequalities with General Constraints"}, "authors": {"value": ["Tatjana Chavdarova", "Tong Yang", "Matteo Pagliardini", "Michael Jordan"]}, "authorids": {"value": ["~Tatjana_Chavdarova2", "~Tong_Yang4", "~Matteo_Pagliardini1", "~Michael_Jordan1"]}, "keywords": {"value": ["Variational Inequaly", "optimization", "constraints", "primal-dual", "interior-point method", "Monotone operator", "last iterate convergence"]}, "TLDR": {"value": "Novel first-order methods for solving constrained variational inequalities with convergence guarantees on monotone variational inequalities."}, "abstract": {"value": "Yang et al. (2023) recently showed how to use first-order gradient methods to solve general variational inequalities (VIs) under a limiting assumption that analytic solutions of specific subproblems are available.  In this paper, we circumvent this assumption via a warm-starting technique where we solve subproblems approximately and initialize variables with the approximate solution found at the previous iteration. \nWe prove the convergence of this method and show that the gap function of the last iterate of the method decreases at a rate of $\\mathcal{O}(\\frac{1}{\\sqrt{K}})$ when the operator is $L$-Lipschitz and monotone. \nIn numerical experiments, we show that this technique can converge much faster than its exact counterpart. \nFurthermore, for the cases when the inequality constraints are simple, we introduce an alternative variant of ACVI and establish its convergence under the same conditions.\nFinally, we relax the smoothness assumptions in Yang et al., yielding, to our knowledge, the first convergence result for VIs with general constraints that does not rely on the assumption that the operator is $L$-Lipschitz."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0d149caaf72505899168c0007b2b21c56e09a91b.pdf"}, "_bibtex": {"value": "@inproceedings{\nchavdarova2024a,\ntitle={A Primal-Dual Approach to Solving Variational Inequalities with General Constraints},\nauthor={Tatjana Chavdarova and Tong Yang and Matteo Pagliardini and Michael Jordan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RsztjXcvUf}\n}"}, "paperhash": {"value": "chavdarova|a_primaldual_approach_to_solving_variational_inequalities_with_general_constraints"}}, "number": 6289, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6289/-/Revision", "ICLR.cc/2024/Conference/Submission6289/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6289/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415752563, "cdate": 1695415752563, "tmdate": 1710758308140, "mdate": 1710758308140, "pdate": 1705410971105, "version": 2}, {"id": "TLADT8Wrhn", "forum": "TLADT8Wrhn", "signatures": ["ICLR.cc/2024/Conference/Submission6288/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6288/Authors"], "content": {"title": {"value": "TiC-CLIP: Continual Training of CLIP Models"}, "authors": {"value": ["Saurabh Garg", "Mehrdad Farajtabar", "Hadi Pouransari", "Raviteja Vemulapalli", "Sachin Mehta", "Oncel Tuzel", "Vaishaal Shankar", "Fartash Faghri"]}, "authorids": {"value": ["~Saurabh_Garg3", "~Mehrdad_Farajtabar1", "~Hadi_Pouransari1", "~Raviteja_Vemulapalli1", "~Sachin_Mehta1", "~Oncel_Tuzel2", "~Vaishaal_Shankar1", "~Fartash_Faghri1"]}, "keywords": {"value": ["CLIP", "Continual learning", "distribution shift", "benchmark"]}, "abstract": {"value": "Keeping large foundation models up to date on latest data is inherently expensive. To avoid the prohibitive costs of constantly retraining, it is imperative to continually train these models. This problem is exacerbated by the lack of any large scale continual learning benchmarks or baselines. We introduce the first set of web-scale Time-Continual (TiC) benchmarks for training vision-language models: TiC-DataComp, TiC-YFCC, and TiC-Redcaps. TiC-DataComp, our largest dataset, contains over 12.7B timestamped image-text pairs spanning 9 years (2014-2022). We first use our benchmarks to curate various dynamic evaluations to measure temporal robustness of existing models. We show OpenAI's CLIP (trained on data up to 2020) loses $\\approx 8\\%$ zero-shot accuracy on our curated retrieval task from 2021-2022 compared with more recently trained models in OpenCLIP repository. We then study how to efficiently train models on time-continuous data. We demonstrate that a simple rehearsal-based approach that continues training from the last checkpoint  and replays old data reduces compute by $2.5\\times$ when compared to the standard practice of retraining from scratch. Code is available at https://github.com/apple/ml-tic-clip."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4d1ee077cc2138ae7576c2f17c698c8d07a99895.pdf"}, "_bibtex": {"value": "@inproceedings{\ngarg2024ticclip,\ntitle={TiC-{CLIP}: Continual Training of {CLIP} Models},\nauthor={Saurabh Garg and Mehrdad Farajtabar and Hadi Pouransari and Raviteja Vemulapalli and Sachin Mehta and Oncel Tuzel and Vaishaal Shankar and Fartash Faghri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TLADT8Wrhn}\n}"}, "paperhash": {"value": "garg|ticclip_continual_training_of_clip_models"}}, "number": 6288, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6288/-/Revision", "ICLR.cc/2024/Conference/Submission6288/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6288/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415748507, "cdate": 1695415748507, "tmdate": 1710996312690, "mdate": 1710996312690, "pdate": 1705410971103, "version": 2}, {"id": "dLoAdIKENc", "forum": "dLoAdIKENc", "signatures": ["ICLR.cc/2024/Conference/Submission6287/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6287/Authors"], "content": {"title": {"value": "Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks"}, "authors": {"value": ["Mehrdad Saberi", "Vinu Sankar Sadasivan", "Keivan Rezaei", "Aounon Kumar", "Atoosa Chegini", "Wenxiao Wang", "Soheil Feizi"]}, "authorids": {"value": ["~Mehrdad_Saberi1", "~Vinu_Sankar_Sadasivan1", "~Keivan_Rezaei1", "~Aounon_Kumar1", "~Atoosa_Chegini1", "~Wenxiao_Wang1", "~Soheil_Feizi2"]}, "keywords": {"value": ["ai-image detection", "image watermark", "deepfake detection", "watermark attack", "generative models"]}, "abstract": {"value": "In light of recent advancements in generative AI models, it has become essential to distinguish genuine content from AI-generated one to prevent the malicious usage of fake materials as authentic ones and vice versa. Various techniques have been introduced for identifying AI-generated images, with watermarking emerging as a promising approach. In this paper, we analyze the robustness of various AI-image detectors including watermarking and classifier-based deepfake detectors. For watermarking methods that introduce subtle image perturbations (i.e., low perturbation budget methods), we reveal a fundamental trade-off between the evasion error rate (i.e., the fraction of watermarked images detected as non-watermarked ones) and the spoofing error rate (i.e., the fraction of non-watermarked images detected as watermarked ones) upon an application of a diffusion purification attack. In this regime, we also empirically show that diffusion purification effectively removes watermarks with minimal changes to images. For high perturbation watermarking methods where notable changes are applied to images, the diffusion purification attack is not effective. In this case, we develop a model substitution adversarial attack that can successfully remove watermarks. Moreover, we show that watermarking methods are vulnerable to spoofing attacks where the attacker aims to have real images (potentially obscene) identified as watermarked ones, damaging the reputation of the developers. In particular, by just having black-box access to the watermarking method, we show that one can generate a watermarked noise image which can be added to the real images to have them falsely flagged as watermarked ones. Finally, we extend our theory to characterize a fundamental trade-off between the robustness and reliability of classifier-based deep fake detectors and demonstrate it through experiments. Code is available at https://github.com/mehrdadsaberi/watermark_robustness."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c27ed3d4b062895eb6037f109a8345e569bab7f9.pdf"}, "supplementary_material": {"value": "/attachment/087d0aa8ac8debc44456637fbec4463d6ecec791.zip"}, "_bibtex": {"value": "@inproceedings{\nsaberi2024robustness,\ntitle={Robustness of {AI}-Image Detectors: Fundamental Limits and Practical Attacks},\nauthor={Mehrdad Saberi and Vinu Sankar Sadasivan and Keivan Rezaei and Aounon Kumar and Atoosa Chegini and Wenxiao Wang and Soheil Feizi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dLoAdIKENc}\n}"}, "paperhash": {"value": "saberi|robustness_of_aiimage_detectors_fundamental_limits_and_practical_attacks"}}, "number": 6287, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6287/-/Revision", "ICLR.cc/2024/Conference/Submission6287/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6287/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415645303, "cdate": 1695415645303, "tmdate": 1710537688018, "mdate": 1710537688018, "pdate": 1705410971083, "version": 2}, {"id": "DayPQKXaQk", "forum": "DayPQKXaQk", "signatures": ["ICLR.cc/2024/Conference/Submission6284/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6284/Authors"], "content": {"title": {"value": "Constrained Decoding for Cross-lingual Label Projection"}, "authors": {"value": ["Duong Minh Le", "Yang Chen", "Alan Ritter", "Wei Xu"]}, "authorids": {"value": ["~Duong_Minh_Le1", "~Yang_Chen10", "~Alan_Ritter1", "~Wei_Xu5"]}, "keywords": {"value": ["constrained decoding", "label projection"]}, "abstract": {"value": "Zero-shot cross-lingual transfer utilizing multilingual LLMs has become a popular learning paradigm for low-resource languages with no labeled training data. However, for NLP tasks that involve fine-grained predictions on words and phrases, the performance of zero-shot cross-lingual transfer learning lags far behind supervised fine-tuning methods. Therefore, it is common to exploit translation and label projection to further improve the performance by (1) translating training data that is available in a high-resource language (e.g., English) together with the gold labels into low-resource languages, and/or (2) translating test data in low-resource languages to a high-source language to run inference on, then projecting the predicted span-level labels back onto the original test data. However, state-of-the-art marker-based label projection methods suffer from translation quality degradation due to the extra label markers injected in the input to the translation model. In this work, we explore a new direction that leverages constrained decoding for label projection to overcome the aforementioned issues. Our new method not only can preserve the quality of translated texts but also has the versatility of being applicable to both translating training and translating test data strategies. This versatility is crucial as our experiments reveal that translating test data can lead to a considerable boost in performance compared to translating only training data. We evaluate on two cross-lingual transfer tasks, namely Named Entity Recognition and Event Argument Extraction, spanning 20 languages. The results demonstrate that our approach outperforms the state-of-the-art marker-based method by a large margin and also shows better performance than other label projection methods that rely on external word alignment."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e1e1f83484f5de8247ceaca832679cec78ea67ed.pdf"}, "_bibtex": {"value": "@inproceedings{\nle2024constrained,\ntitle={Constrained Decoding for Cross-lingual Label Projection},\nauthor={Duong Minh Le and Yang Chen and Alan Ritter and Wei Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DayPQKXaQk}\n}"}, "paperhash": {"value": "le|constrained_decoding_for_crosslingual_label_projection"}}, "number": 6284, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6284/-/Revision", "ICLR.cc/2024/Conference/Submission6284/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6284/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415549534, "cdate": 1695415549534, "tmdate": 1710857892183, "mdate": 1710857892183, "pdate": 1705410970865, "version": 2}, {"id": "CK5Hfb5hBG", "forum": "CK5Hfb5hBG", "signatures": ["ICLR.cc/2024/Conference/Submission6280/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6280/Authors"], "content": {"title": {"value": "Channel Vision Transformers: An Image Is Worth 1 x 16 x 16 Words"}, "authors": {"value": ["Yujia Bao", "Srinivasan Sivanandan", "Theofanis Karaletsos"]}, "authorids": {"value": ["~Yujia_Bao1", "~Srinivasan_Sivanandan1", "~Theofanis_Karaletsos1"]}, "keywords": {"value": ["vision transformer", "representation learning", "hyper spectral imaging"]}, "TLDR": {"value": "ChannelViT facilitates robust representation learning across different input channels."}, "abstract": {"value": "Vision Transformer (ViT) has emerged as a powerful architecture in the realm of modern computer vision. However, its application in certain imaging fields, such as microscopy and satellite imaging, presents unique challenges. In these domains, images often contain multiple channels, each carrying semantically distinct and independent information. Furthermore, the model must demonstrate robustness to sparsity in input channels, as they may not be densely available during training or testing. In this paper, we propose a modification to the ViT architecture that enhances reasoning across the input channels and introduce Hierarchical Channel Sampling (HCS) as an additional regularization technique to ensure robustness when only partial channels are presented during test time. Our proposed model, ChannelViT, constructs patch tokens independently from each input channel and utilizes a learnable channel embedding that is added to the patch tokens, similar to positional embeddings. We evaluate the performance of ChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat (satellite imaging). Our results show that ChannelViT outperforms ViT on classification tasks and generalizes well, even when a subset of input channels is used during testing. Across our experiments, HCS proves to be a powerful regularizer, independent of the architecture employed, suggesting itself as a straightforward technique for robust ViT training. Lastly, we find that ChannelViT generalizes effectively even when there is limited access to all channels during training, highlighting its potential for multi-channel imaging under real-world conditions with sparse sensors. Our code is available at https://github.com/insitro/ChannelViT."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d7d08775f142490ef0045c1080bd2fa5c6964f97.pdf"}, "_bibtex": {"value": "@inproceedings{\nbao2024channel,\ntitle={Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words},\nauthor={Yujia Bao and Srinivasan Sivanandan and Theofanis Karaletsos},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CK5Hfb5hBG}\n}"}, "paperhash": {"value": "bao|channel_vision_transformers_an_image_is_worth_1_x_16_x_16_words"}}, "number": 6280, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6280/-/Revision", "ICLR.cc/2024/Conference/Submission6280/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6280/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415433805, "cdate": 1695415433805, "tmdate": 1710540871749, "mdate": 1710540871749, "pdate": 1705410970686, "version": 2}, {"id": "VoLDkQ6yR3", "forum": "VoLDkQ6yR3", "signatures": ["ICLR.cc/2024/Conference/Submission6267/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6267/Authors"], "content": {"title": {"value": "Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation"}, "authors": {"value": ["Noel Loo", "Ramin Hasani", "Mathias Lechner", "Alexander Amini", "Daniela Rus"]}, "authorids": {"value": ["~Noel_Loo1", "~Ramin_Hasani1", "~Mathias_Lechner1", "~Alexander_Amini1", "~Daniela_Rus1"]}, "keywords": {"value": ["Dataset Distillation", "Reconstruction Attacks", "Neural Tangent Kernel"]}, "abstract": {"value": "Modern deep learning requires large volumes of data, which could contain sensitive or private information that cannot be leaked. Recent work has shown for homogeneous neural networks a large portion of this training data could be reconstructed with only access to the trained network parameters. While the attack was shown to work empirically, there exists little formal understanding of its effective regime and which datapoints are susceptible to reconstruction. In this work, we first build a stronger version of the dataset reconstruction attack and show how it can provably recover the \\emph{entire training set} in the infinite width regime. We then empirically study the characteristics of this attack on two-layer networks and reveal that its success heavily depends on deviations from the frozen infinite-width Neural Tangent Kernel limit. Next, we study the nature of easily-reconstructed images. We show that both theoretically and empirically, reconstructed images tend to ``outliers'' in the dataset, and that these reconstruction attacks can be used for \\textit{dataset distillation}, that is, we can retrain on reconstructed images and obtain high predictive accuracy."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/778929c5481ef5f0fae7f3bfdcb369dbbfb646bc.pdf"}, "supplementary_material": {"value": "/attachment/2b2dbf25518c58e3c43abbc90d881ef3746f619c.zip"}, "TLDR": {"value": "We analyze parameter-based reconstruction attacks from an NTK perspective and show that it is a variant of dataset distillation"}, "_bibtex": {"value": "@inproceedings{\nloo2024understanding,\ntitle={Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation},\nauthor={Noel Loo and Ramin Hasani and Mathias Lechner and Alexander Amini and Daniela Rus},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VoLDkQ6yR3}\n}"}, "paperhash": {"value": "loo|understanding_reconstruction_attacks_with_the_neural_tangent_kernel_and_dataset_distillation"}}, "number": 6267, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6267/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6267/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415076041, "cdate": 1695415076041, "tmdate": 1710367893712, "mdate": 1710367893712, "pdate": 1705410970444, "version": 2}, {"id": "iIT02bAKzv", "forum": "iIT02bAKzv", "signatures": ["ICLR.cc/2024/Conference/Submission6256/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6256/Authors"], "content": {"title": {"value": "ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models"}, "authors": {"value": ["Yi-Lin Sung", "Jaehong Yoon", "Mohit Bansal"]}, "authorids": {"value": ["~Yi-Lin_Sung1", "~Jaehong_Yoon1", "~Mohit_Bansal2"]}, "keywords": {"value": ["multi-modal learning", "model pruning", "layer-wise pruning"]}, "abstract": {"value": "Large Vision-Language Models (LVLMs) can understand the world comprehensively by integrating rich information from different modalities, achieving remarkable performance improvements on various multimodal downstream tasks. However, deploying LVLMs is often problematic due to their massive computational/energy costs and carbon consumption, making it infeasible to adopt conventional iterative global pruning, which is costly due to computing the Hessian matrix of the entire large model for sparsification. Alternatively, several studies have recently proposed layer-wise pruning approaches to avoid the expensive computation of global pruning and efficiently compress model weights according to their importance within a layer. However, these methods often suffer from suboptimal model compression due to their lack of a global perspective. To address this limitation in recent efficient pruning methods for large models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP), a two-stage coarse-to-fine weight pruning approach for LVLMs. We first determine the sparsity ratios of different layers or blocks by leveraging the global importance score, which is efficiently computed based on the zeroth-order approximation of the global model gradients. Then, the multimodal model performs layer-wise unstructured weight pruning. We validate our proposed method across various multi-modal and single-modal models and datasets, demonstrating significant performance improvements over prevalent pruning techniques in the high-sparsity regime."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bd2b53288bdfd2943c9c9cd616b586fb4204d401.pdf"}, "supplementary_material": {"value": "/attachment/2ab6fb70447999b79e5b746f7be72da062e6e8a6.zip"}, "_bibtex": {"value": "@inproceedings{\nsung2024ecoflap,\ntitle={{EC}o{FL}aP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models},\nauthor={Yi-Lin Sung and Jaehong Yoon and Mohit Bansal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iIT02bAKzv}\n}"}, "paperhash": {"value": "sung|ecoflap_efficient_coarsetofine_layerwise_pruning_for_visionlanguage_models"}}, "number": 6256, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6256/-/Revision", "ICLR.cc/2024/Conference/Submission6256/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6256/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414758386, "cdate": 1695414758386, "tmdate": 1710179311686, "mdate": 1710179311686, "pdate": 1705410970191, "version": 2}, {"id": "qup9xD8mW4", "forum": "qup9xD8mW4", "signatures": ["ICLR.cc/2024/Conference/Submission6255/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6255/Authors"], "content": {"title": {"value": "Behaviour Distillation"}, "authors": {"value": ["Andrei Lupu", "Chris Lu", "Jarek Luca Liesen", "Robert Tjarko Lange", "Jakob Nicolaus Foerster"]}, "authorids": {"value": ["~Andrei_Lupu1", "~Chris_Lu1", "~Jarek_Luca_Liesen1", "~Robert_Tjarko_Lange1", "~Jakob_Nicolaus_Foerster1"]}, "keywords": {"value": ["knowledge distillation", "evolutionary strategies", "reinforcement learning", "dataset distillation"]}, "TLDR": {"value": "We train RL policies by evolving a small synthetic dataset of state-action pairs and doing behaviour cloning on the dataset."}, "abstract": {"value": "Dataset distillation aims to condense large datasets into a small number of synthetic examples that can be used as drop-in replacements when training new models. It has applications to interpretability, neural architecture search, privacy, and continual learning. Despite strong successes in supervised domains, such methods have not yet been extended to reinforcement learning, where the lack of a fixed dataset renders most distillation methods unusable.\nFilling the gap, we formalize $\\textit{behaviour distillation}$, a setting that aims to discover and then condense the information required for training an expert policy into a synthetic dataset of state-action pairs, $\\textit{without access to expert data}$. \nWe then introduce Hallucinating Datasets with Evolution Strategies (HaDES), a method for behaviour distillation that can discover datasets of $\\textit{just four}$ state-action pairs which, under supervised learning, train agents to competitive performance levels in continuous control tasks.\nWe show that these datasets generalize out of distribution to training policies with a wide range of architectures and hyperparameters. We also demonstrate application to a downstream task, namely training multi-task agents in a zero-shot fashion.\nBeyond behaviour distillation, HaDES provides significant improvements in neuroevolution for RL over previous approaches and achieves SoTA results on one standard supervised dataset distillation task. Finally, we show that visualizing the synthetic datasets can provide human-interpretable task insights."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c401434987a8b2aa4b593e8609ec6cc7085d772b.pdf"}, "supplementary_material": {"value": "/attachment/507ef919f37698790aac0c6fbe7d1db7939d4874.pdf"}, "_bibtex": {"value": "@inproceedings{\nlupu2024behaviour,\ntitle={Behaviour Distillation},\nauthor={Andrei Lupu and Chris Lu and Jarek Luca Liesen and Robert Tjarko Lange and Jakob Nicolaus Foerster},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qup9xD8mW4}\n}"}, "paperhash": {"value": "lupu|behaviour_distillation"}}, "number": 6255, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6255/-/Revision", "ICLR.cc/2024/Conference/Submission6255/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6255/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414746893, "cdate": 1695414746893, "tmdate": 1713145565475, "mdate": 1713145565475, "pdate": 1705410970155, "version": 2}, {"id": "NLPzL6HWNl", "forum": "NLPzL6HWNl", "signatures": ["ICLR.cc/2024/Conference/Submission6253/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6253/Authors"], "content": {"title": {"value": "Improving LoRA in Privacy-preserving Federated Learning"}, "authors": {"value": ["Youbang Sun", "Zitao Li", "Yaliang Li", "Bolin Ding"]}, "authorids": {"value": ["~Youbang_Sun1", "~Zitao_Li1", "~Yaliang_Li1", "~Bolin_Ding3"]}, "keywords": {"value": ["Federated Learning", "Parameter-efficient Fine-tuning", "Differential Privacy", "Large Language Model"]}, "TLDR": {"value": "We proposed a modification to LoRA, FFA-LoRA, in privacy-preserved federated learning with better performance, reliability and efficiency."}, "abstract": {"value": "Low-rank adaptation (LoRA) is one of the most popular task-specific parameter-efficient fine-tuning (PEFT) methods on pre-trained language models for its good performance and computational efficiency.\nLoRA injects a product of two trainable rank decomposition matrices over the top of each frozen pre-trained model module.\nHowever, when applied in the setting of privacy-preserving federated learning (FL), LoRA may become unstable due to the following facts: 1) the effects of data heterogeneity and multi-step local updates are non-negligible, 2) additive noise enforced on updating gradients to guarantee differential privacy (DP) can be amplified and 3) the final performance is susceptible to hyper-parameters.\nA key factor leading to these phenomena is the discordance between jointly optimizing the two low-rank matrices by local clients and separately aggregating them by the central server.\nThus, this paper proposes an efficient and effective version of LoRA, Federated Freeze A LoRA (FFA-LoRA), to alleviate these challenges and further halve the communication cost of federated fine-tuning LLMs.\nThe core idea of FFA-LoRA is to fix the randomly initialized non-zero matrices and only fine-tune the zero-initialized matrices.\nCompared to LoRA, FFA-LoRA is motivated by practical and theoretical benefits in privacy-preserved FL. \nOur experiments demonstrate that FFA-LoRA provides more consistent performance with better computational efficiency over vanilla LoRA in various FL tasks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/26c9acdf2008d3bd05b07eb6fb8b84fdbac9fe76.pdf"}, "supplementary_material": {"value": "/attachment/cb07f43869532c7d26677f0ce985be34d2dfe8b4.pdf"}, "_bibtex": {"value": "@inproceedings{\nsun2024improving,\ntitle={Improving Lo{RA} in Privacy-preserving Federated Learning},\nauthor={Youbang Sun and Zitao Li and Yaliang Li and Bolin Ding},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NLPzL6HWNl}\n}"}, "paperhash": {"value": "sun|improving_lora_in_privacypreserving_federated_learning"}}, "number": 6253, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6253/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6253/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414607925, "cdate": 1695414607925, "tmdate": 1710513463328, "mdate": 1710513463328, "pdate": 1705410970104, "version": 2}, {"id": "hB7SlfEmze", "forum": "hB7SlfEmze", "signatures": ["ICLR.cc/2024/Conference/Submission6250/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6250/Authors"], "content": {"title": {"value": "PhyloGFN: Phylogenetic inference with generative flow networks"}, "authors": {"value": ["Ming Yang Zhou", "Zichao Yan", "Elliot Layne", "Nikolay Malkin", "Dinghuai Zhang", "Moksh Jain", "Mathieu Blanchette", "Yoshua Bengio"]}, "authorids": {"value": ["~Ming_Yang_Zhou1", "~Zichao_Yan1", "~Elliot_Layne2", "~Nikolay_Malkin1", "~Dinghuai_Zhang1", "~Moksh_Jain1", "~Mathieu_Blanchette1", "~Yoshua_Bengio1"]}, "keywords": {"value": ["Phylogenetic Inference", "GFlowNets", "Bayesian Inference", "Deep Generative Modeling"]}, "abstract": {"value": "Phylogenetics is a branch of computational biology that studies the evolutionary relationships among biological entities. Its long history and numerous applications notwithstanding, inference of phylogenetic trees from sequence data remains challenging: the high complexity of tree space poses a significant obstacle for the current combinatorial and probabilistic techniques. In this paper, we adopt the framework of generative flow networks (GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and Bayesian phylogenetic inference. Because GFlowNets are well-suited for sampling complex combinatorial structures, they are a natural choice for exploring and sampling from the multimodal posterior distribution over tree topologies and evolutionary distances. We demonstrate that our amortized posterior sampler, PhyloGFN, produces diverse and high-quality evolutionary hypotheses on real benchmark datasets. PhyloGFN is competitive with prior works in marginal likelihood estimation and achieves a closer fit to the target distribution than state-of-the-art variational inference methods."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b4781fd6d520a4f8a680109906f1ea01fc2cac78.pdf"}, "supplementary_material": {"value": "/attachment/3efbe4edfb02b45867f340f8904f345d30c21a3c.zip"}, "TLDR": {"value": "We use generative flow networks as amortized samplers of phylogenetic trees, achieving strong results in both Bayesian and parsimony-based phylogenetic inference."}, "_bibtex": {"value": "@inproceedings{\nzhou2024phylogfn,\ntitle={Phylo{GFN}: Phylogenetic inference with generative flow networks},\nauthor={Ming Yang Zhou and Zichao Yan and Elliot Layne and Nikolay Malkin and Dinghuai Zhang and Moksh Jain and Mathieu Blanchette and Yoshua Bengio},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hB7SlfEmze}\n}"}, "paperhash": {"value": "zhou|phylogfn_phylogenetic_inference_with_generative_flow_networks"}}, "number": 6250, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6250/-/Revision", "ICLR.cc/2024/Conference/Submission6250/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6250/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414557128, "cdate": 1695414557128, "tmdate": 1711326490619, "mdate": 1711326490619, "pdate": 1705410970024, "version": 2}, {"id": "TskzCtpMEO", "forum": "TskzCtpMEO", "signatures": ["ICLR.cc/2024/Conference/Submission6249/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6249/Authors"], "content": {"title": {"value": "Training Bayesian Neural Networks with Sparse Subspace Variational Inference"}, "authors": {"value": ["Junbo Li", "Zichen Miao", "Qiang Qiu", "Ruqi Zhang"]}, "authorids": {"value": ["~Junbo_Li3", "~Zichen_Miao1", "~Qiang_Qiu1", "~Ruqi_Zhang1"]}, "keywords": {"value": ["Bayesian neural networks", "sparse Bayesian learning", "variational inference"]}, "TLDR": {"value": "We propose the first fully sparse Bayesian training framework that achieves state-of-the-art performance in the realm of sparse Bayesian neural networks."}, "abstract": {"value": "Bayesian neural networks (BNNs) offer uncertainty quantification but come with the downside of substantially increased training and inference costs. Sparse BNNs have been investigated for efficient inference, typically by either slowly introducing sparsity throughout the training or by post-training compression of dense BNNs. The dilemma of how to cut down massive training costs remains, particularly given the requirement to learn about the uncertainty. To solve this challenge, we introduce Sparse Subspace Variational Inference (SSVI), the first fully sparse BNN framework that maintains a consistently sparse Bayesian model throughout the training and inference phases. Starting from a randomly initialized low-dimensional sparse subspace, our approach alternately optimizes the sparse subspace basis selection and its associated parameters. While basis selection is characterized as a non-differentiable problem, we approximate the optimal solution with a removal-and-addition strategy, guided by novel criteria based on weight distribution statistics. Our extensive experiments show that SSVI sets new benchmarks in crafting sparse BNNs, achieving, for instance, a 10-20\u00d7 compression in model size with under 3\\% performance drop, and up to 20\u00d7 FLOPs reduction during training. Remarkably, SSVI also demonstrates enhanced robustness to hyperparameters, reducing the need for intricate tuning in VI and occasionally even surpassing VI-trained dense BNNs."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2ff233f7714dc0c785818a1865f9150733782db9.pdf"}, "supplementary_material": {"value": "/attachment/07f792b3717720c65e4b2b7a8985b19dfbc677c0.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024training,\ntitle={Training Bayesian Neural Networks with Sparse Subspace Variational Inference},\nauthor={Junbo Li and Zichen Miao and Qiang Qiu and Ruqi Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TskzCtpMEO}\n}"}, "paperhash": {"value": "li|training_bayesian_neural_networks_with_sparse_subspace_variational_inference"}}, "number": 6249, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6249/-/Revision", "ICLR.cc/2024/Conference/Submission6249/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6249/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414549097, "cdate": 1695414549097, "tmdate": 1709661529098, "mdate": 1709661529098, "pdate": 1705410969974, "version": 2}, {"id": "4Ua4hKiAJX", "forum": "4Ua4hKiAJX", "signatures": ["ICLR.cc/2024/Conference/Submission6245/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6245/Authors"], "content": {"title": {"value": "Locality-Aware Graph Rewiring in GNNs"}, "authors": {"value": ["Federico Barbero", "Ameya Velingker", "Amin Saberi", "Michael M. Bronstein", "Francesco Di Giovanni"]}, "authorids": {"value": ["~Federico_Barbero1", "~Ameya_Velingker1", "~Amin_Saberi1", "~Michael_M._Bronstein1", "~Francesco_Di_Giovanni1"]}, "keywords": {"value": ["Graph Neural Networks", "Message Passing Neural Networks", "Over-squashing", "Graph Rewiring"]}, "abstract": {"value": "Graph Neural Networks (GNNs) are popular models for machine learning on graphs that typically follow the message-passing paradigm, whereby the feature of a node is updated recursively upon aggregating information over its neighbors. While exchanging messages over the input graph endows GNNs with a strong inductive bias, it can also make GNNs susceptible to over-squashing, thereby preventing them from capturing long-range interactions in the given graph. To rectify this issue, graph rewiring techniques have been proposed as a means of improving information flow by altering the graph connectivity. In this work, we identify three desiderata for graph-rewiring: (i) reduce over-squashing, (ii) respect the locality of the graph, and \n(iii) preserve the sparsity of the graph. We highlight fundamental trade-offs that occur between spatial and spectral rewiring techniques; while the former often satisfy (i) and (ii) but not (iii), the latter generally satisfy (i) and (iii) at the expense of (ii). We propose a novel rewiring framework that satisfies all of (i)--(iii) through a locality-aware sequence of rewiring operations. We then discuss a specific instance of such rewiring framework and \nvalidate its effectiveness on several real-world benchmarks, showing that it either matches or significantly outperforms existing rewiring approaches."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ec32fc1573d4d7796b7dabdc959f2472ba2fb4e8.pdf"}, "supplementary_material": {"value": "/attachment/387291a37c07ba744d2e44457c8089aa6c05ad87.zip"}, "_bibtex": {"value": "@inproceedings{\nbarbero2024localityaware,\ntitle={Locality-Aware Graph Rewiring in {GNN}s},\nauthor={Federico Barbero and Ameya Velingker and Amin Saberi and Michael M. Bronstein and Francesco Di Giovanni},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4Ua4hKiAJX}\n}"}, "paperhash": {"value": "barbero|localityaware_graph_rewiring_in_gnns"}}, "number": 6245, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6245/-/Revision", "ICLR.cc/2024/Conference/Submission6245/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6245/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695414497792, "cdate": 1695414497792, "tmdate": 1710428130223, "mdate": 1710428130223, "pdate": 1705410969907, "version": 2}, {"id": "sSaN4gxuEf", "forum": "sSaN4gxuEf", "signatures": ["ICLR.cc/2024/Conference/Submission6230/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6230/Authors"], "content": {"title": {"value": "Adapting to Distribution Shift by Visual Domain Prompt Generation"}, "authors": {"value": ["Zhixiang Chi", "Li Gu", "Tao Zhong", "Huan Liu", "YUANHAO YU", "Konstantinos N Plataniotis", "Yang Wang"]}, "authorids": {"value": ["~Zhixiang_Chi1", "~Li_Gu1", "~Tao_Zhong1", "~Huan_Liu4", "~YUANHAO_YU2", "~Konstantinos_N_Plataniotis1", "~Yang_Wang1"]}, "keywords": {"value": ["Distribution shfts", "Domain generalization", "Visual prompt", "Foundation model", "Test-time adaptation"]}, "TLDR": {"value": "We propose powerful domain prompt generator to generate domain-specific knolwedge from a few unlabeled data to guide the CLIP visual feature toward different distributions."}, "abstract": {"value": "In this paper, we aim to adapt a model at test-time using a few unlabeled data to address distribution shifts. \nTo tackle the challenges of extracting domain knowledge from a limited amount of data, it is crucial to utilize correlated information from pre-trained backbones and source domains. Previous studies fail to utilize recent foundation models with strong out-of-distribution generalization. Additionally, domain-centric designs are not flavored in their works. Furthermore, they employ the process of modelling source domains and the process of learning to adapt independently into disjoint training stages. In this work, we propose an approach on top of the pre-computed features of the foundation model. Specifically, we build a knowledge bank to learn the transferable knowledge from source domains. Conditioned on few-shot target data, we introduce a domain prompt generator to condense the knowledge bank into a domain-specific prompt. The domain prompt then directs the visual features towards a particular domain via a guidance module. Moreover, we propose a domain-aware contrastive loss and employ meta-learning to facilitate domain knowledge extraction. Extensive experiments are conducted to validate the domain knowledge extraction. The proposed method outperforms previous work on 5 large-scale benchmarks including WILDS and DomainNet."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/207fec35761d86a18b58976f946fa4e9945496ca.pdf"}, "_bibtex": {"value": "@inproceedings{\nchi2024adapting,\ntitle={Adapting to Distribution Shift by Visual Domain Prompt Generation},\nauthor={Zhixiang Chi and Li Gu and Tao Zhong and Huan Liu and YUANHAO YU and Konstantinos N Plataniotis and Yang Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sSaN4gxuEf}\n}"}, "paperhash": {"value": "chi|adapting_to_distribution_shift_by_visual_domain_prompt_generation"}}, "number": 6230, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6230/-/Revision", "ICLR.cc/2024/Conference/Submission6230/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6230/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413711695, "cdate": 1695413711695, "tmdate": 1710460990333, "mdate": 1710460990333, "pdate": 1705410969682, "version": 2}, {"id": "Je5SHCKpPa", "forum": "Je5SHCKpPa", "signatures": ["ICLR.cc/2024/Conference/Submission6228/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6228/Authors"], "content": {"title": {"value": "Multimodal Patient Representation Learning with Missing Modalities and Labels"}, "authors": {"value": ["Zhenbang Wu", "Anant Dadu", "Nicholas Tustison", "Brian Avants", "Mike Nalls", "Jimeng Sun", "Faraz Faghri"]}, "authorids": {"value": ["~Zhenbang_Wu1", "~Anant_Dadu1", "~Nicholas_Tustison1", "~Brian_Avants2", "michael.nalls@nih.gov", "~Jimeng_Sun3", "~Faraz_Faghri1"]}, "keywords": {"value": ["multi-modal learning", "missing modalities", "missing labels", "clinical predictive modeling", "patient representation learning"]}, "abstract": {"value": "Multimodal patient representation learning aims to integrate information from multiple modalities and generate comprehensive patient representations for subsequent clinical predictive tasks. However, many existing approaches either presuppose the availability of all modalities and labels for each patient or only deal with missing modalities. In reality, patient data often comes with both missing modalities and labels for various reasons (i.e., the missing modality and label issue). Moreover, multimodal models might over-rely on certain modalities, causing sub-optimal performance when these modalities are absent (i.e., the modality collapse issue). To address these issues, we introduce MUSE: a mutual-consistent graph contrastive learning method. MUSE uses a flexible bipartite graph to represent the patient-modality relationship, which can adapt to various missing modality patterns. To tackle the modality collapse issue, MUSE learns to focus on modality-general and label-decisive features via a mutual-consistent contrastive learning loss. Notably, the unsupervised component of the contrastive objective only requires self-supervision signals, thereby broadening the training scope to incorporate patients with missing labels. We evaluate MUSE on three publicly available datasets: MIMIC-IV, eICU, and ADNI. Results show that MUSE outperforms all baselines, and MUSE+ further elevates the absolute improvement to ~4% by extending the training scope to patients with absent labels."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/69771720175aee975e307b2eeda7643824f0a5d8.pdf"}, "TLDR": {"value": "We propose MUSE to effectively learn representations for patients with missing modalities and labels."}, "_bibtex": {"value": "@inproceedings{\nwu2024multimodal,\ntitle={Multimodal Patient Representation Learning with Missing Modalities and Labels},\nauthor={Zhenbang Wu and Anant Dadu and Nicholas Tustison and Brian Avants and Mike Nalls and Jimeng Sun and Faraz Faghri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Je5SHCKpPa}\n}"}, "paperhash": {"value": "wu|multimodal_patient_representation_learning_with_missing_modalities_and_labels"}}, "number": 6228, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6228/-/Revision", "ICLR.cc/2024/Conference/Submission6228/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6228/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413687083, "cdate": 1695413687083, "tmdate": 1713154017393, "mdate": 1713154017393, "pdate": 1705410969582, "version": 2}, {"id": "h4pNROsO06", "forum": "h4pNROsO06", "signatures": ["ICLR.cc/2024/Conference/Submission6227/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6227/Authors"], "content": {"title": {"value": "Improved sampling via learned diffusions"}, "authors": {"value": ["Lorenz Richter", "Julius Berner"]}, "authorids": {"value": ["~Lorenz_Richter1", "~Julius_Berner1"]}, "keywords": {"value": ["Schr\u00f6dinger bridge", "sampling from densities", "stochastic optimal control", "diffusion-based generative modeling"]}, "abstract": {"value": "Recently, a series of papers proposed deep learning-based approaches to sample from target distributions using controlled diffusion processes, being trained only on the unnormalized target densities without access to samples. Building on previous work, we identify these approaches as special cases of a generalized Schr\u00f6dinger bridge problem, seeking a stochastic evolution between a given prior distribution and the specified target. We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes. This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases. At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse. In particular, we propose the so-called \\textit{log-variance loss}, which exhibits favorable numerical properties and leads to significantly improved performance across all considered approaches."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/93da314ee777be5e9c037bd0b18deb91ff4ab68b.pdf"}, "TLDR": {"value": "We propose a unifying framework to improve diffusion-based samplers."}, "_bibtex": {"value": "@inproceedings{\nrichter2024improved,\ntitle={Improved sampling via learned diffusions},\nauthor={Lorenz Richter and Julius Berner},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=h4pNROsO06}\n}"}, "paperhash": {"value": "richter|improved_sampling_via_learned_diffusions"}}, "number": 6227, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6227/-/Revision", "ICLR.cc/2024/Conference/Submission6227/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6227/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413684112, "cdate": 1695413684112, "tmdate": 1713157423501, "mdate": 1713157423501, "pdate": 1705410969532, "version": 2}, {"id": "1tZbq88f27", "forum": "1tZbq88f27", "signatures": ["ICLR.cc/2024/Conference/Submission6224/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6224/Authors"], "content": {"title": {"value": "MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"}, "authors": {"value": ["Deyao Zhu", "Jun Chen", "Xiaoqian Shen", "Xiang Li", "Mohamed Elhoseiny"]}, "authorids": {"value": ["~Deyao_Zhu1", "~Jun_Chen11", "~Xiaoqian_Shen3", "~Xiang_Li18", "~Mohamed_Elhoseiny1"]}, "keywords": {"value": ["large language models", "vision language models"]}, "abstract": {"value": "The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed.\nWe believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). \nTo examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. \nOur work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, \nsuch as detailed image description generation and website creation from hand-drawn drafts.\nFurthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. \nIn our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2a8800abfa9599958bc3a14cd49aabf9ad0709a5.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhu2024minigpt,\ntitle={Mini{GPT}-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},\nauthor={Deyao Zhu and Jun Chen and Xiaoqian Shen and Xiang Li and Mohamed Elhoseiny},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1tZbq88f27}\n}"}, "paperhash": {"value": "zhu|minigpt4_enhancing_visionlanguage_understanding_with_advanced_large_language_models"}}, "number": 6224, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6224/-/Revision", "ICLR.cc/2024/Conference/Submission6224/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6224/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413679593, "cdate": 1695413679593, "tmdate": 1710246922598, "mdate": 1710246922598, "pdate": 1705410969417, "version": 2}, {"id": "6tqgL8VluV", "forum": "6tqgL8VluV", "signatures": ["ICLR.cc/2024/Conference/Submission6210/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6210/Authors"], "content": {"title": {"value": "Towards Establishing Guaranteed Error for Learned Database Operations"}, "authors": {"value": ["Sepanta Zeighami", "Cyrus Shahabi"]}, "authorids": {"value": ["~Sepanta_Zeighami2", "~Cyrus_Shahabi1"]}, "keywords": {"value": ["Learned Indexing", "Learned Cardinality Estimation", "Machine learning for Data Management"]}, "TLDR": {"value": "We present the first known bounds on the model size required when using machine learning to perform indexing, cardinality and range-sum estimation"}, "abstract": {"value": "Machine learning models have demonstrated substantial performance enhancements over non-learned alternatives in various fundamental data management operations, including indexing (locating items in an array), cardinality estimation (estimating the number of matching records in a database), and range-sum estimation (estimating aggregate attribute values for query-matched records). However, real-world systems frequently favor less efficient non-learned methods due to their ability to offer (worst-case) error guarantees \u2014 an aspect where learned approaches often fall short. The primary objective of these guarantees is to ensure system reliability, ensuring that the chosen approach consistently delivers the desired level of accuracy across all databases. In this paper, we embark on the first theoretical study of such guarantees for learned methods, presenting the necessary conditions for such guarantees to hold when using machine learning to perform indexing, cardinality estimation and range-sum estimation. Specifically, we present the first known lower bounds on the model size required to achieve the desired accuracy for these three key database operations. Our results bound the required model size for given average and worst-case errors in performing database operations, serving as the first theoretical guidelines governing how model size must change based on data size to be able to guarantee an accuracy level. More broadly, our established guarantees pave the way for the broader adoption and integration of learned models into real-world systems."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4f5ce342ab109afcc3e7a9b8916244d531915409.pdf"}, "_bibtex": {"value": "@inproceedings{\nzeighami2024towards,\ntitle={Towards Establishing Guaranteed Error for Learned Database Operations},\nauthor={Sepanta Zeighami and Cyrus Shahabi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6tqgL8VluV}\n}"}, "paperhash": {"value": "zeighami|towards_establishing_guaranteed_error_for_learned_database_operations"}}, "number": 6210, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6210/-/Revision", "ICLR.cc/2024/Conference/Submission6210/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6210/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413173878, "cdate": 1695413173878, "tmdate": 1710458499204, "mdate": 1710458499204, "pdate": 1705410969075, "version": 2}, {"id": "XTHfNGI3zT", "forum": "XTHfNGI3zT", "signatures": ["ICLR.cc/2024/Conference/Submission6208/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6208/Authors"], "content": {"title": {"value": "Quantifying the Plausibility of Context Reliance in Neural Machine Translation"}, "authors": {"value": ["Gabriele Sarti", "Grzegorz Chrupa\u0142a", "Malvina Nissim", "Arianna Bisazza"]}, "authorids": {"value": ["~Gabriele_Sarti1", "~Grzegorz_Chrupa\u0142a1", "~Malvina_Nissim1", "~Arianna_Bisazza1"]}, "keywords": {"value": ["explainable AI", "interpretability", "feature attribution", "machine translation", "document-level machine translation", "natural language generation"]}, "TLDR": {"value": "We introduce PECoRe, an end-to-end interpretability framework to evaluate the plausibility of context usage in language models generations."}, "abstract": {"value": "Establishing whether language models can use contextual information in a human-plausible way is important to ensure their safe adoption in real-world settings. However, the questions of $\\textit{when}$ and $\\textit{which parts}$ of the context affect model generations are typically tackled separately, and current plausibility evaluations are practically limited to a handful of artificial benchmarks. To address this, we introduce $\\textbf{P}$lausibility $\\textbf{E}$valuation of $\\textbf{Co}$ntext $\\textbf{Re}$liance (PECoRe), an end-to-end interpretability framework designed to quantify context usage in language models' generations. Our approach leverages model internals to (i) contrastively identify context-sensitive target tokens in generated texts and (ii) link them to contextual cues justifying their prediction. We use PECoRe to quantify the plausibility of context-aware machine translation models, comparing model rationales with human annotations across several discourse-level phenomena. Finally, we apply our method to unannotated model translations to identify context-mediated predictions and highlight instances of (im)plausible context usage throughout generation."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8a8d8cc53b4f5d799b75f6a14b1aa0b7f8ba12cf.pdf"}, "_bibtex": {"value": "@inproceedings{\nsarti2024quantifying,\ntitle={Quantifying the Plausibility of Context Reliance in Neural Machine Translation},\nauthor={Gabriele Sarti and Grzegorz Chrupa{\\l}a and Malvina Nissim and Arianna Bisazza},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XTHfNGI3zT}\n}"}, "paperhash": {"value": "sarti|quantifying_the_plausibility_of_context_reliance_in_neural_machine_translation"}}, "number": 6208, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6208/-/Revision", "ICLR.cc/2024/Conference/Submission6208/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6208/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413125482, "cdate": 1695413125482, "tmdate": 1710319730319, "mdate": 1710319730319, "pdate": 1705410969025, "version": 2}, {"id": "9j1RD9LlWH", "forum": "9j1RD9LlWH", "signatures": ["ICLR.cc/2024/Conference/Submission6205/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6205/Authors"], "content": {"title": {"value": "Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data"}, "authors": {"value": ["Yongsheng Mei", "Mahdi Imani", "Tian Lan"]}, "authorids": {"value": ["~Yongsheng_Mei1", "~Mahdi_Imani3", "~Tian_Lan4"]}, "keywords": {"value": ["Bayesian optimization", "Gaussian Cox process"]}, "abstract": {"value": "Bayesian optimization (BO) has established itself as a leading strategy for efficiently optimizing expensive-to-evaluate functions. Existing BO methods mostly rely on Gaussian process (GP) surrogate models and are not applicable to (doubly-stochastic) Gaussian Cox processes, where the observation process is modulated by a latent intensity function modeled as a GP. In this paper, we propose a novel maximum *a posteriori* inference of Gaussian Cox processes. It leverages the Laplace approximation and change of kernel technique to transform the problem into a new reproducing kernel Hilbert space, where it becomes more tractable computationally. It enables us to obtain both a functional posterior of the latent intensity function and the covariance of the posterior, thus extending existing works that often focus on specific link functions or estimating the posterior mean. Using the result, we propose a BO framework based on the Gaussian Cox process model and further develop a Nystr\u00f6m approximation for efficient computation. Extensive evaluations on various synthetic and real-world datasets demonstrate significant improvement over state-of-the-art inference solutions for Gaussian Cox processes, as well as effective BO with a wide range of acquisition functions designed through the underlying Gaussian Cox process model."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4ffbca1e4135f360cd7a821d180b18971c1d4025.pdf"}, "TLDR": {"value": "Bayesian optimization method on Gaussian Cox process stochastic models for spatial temporal data analysis."}, "_bibtex": {"value": "@inproceedings{\nmei2024bayesian,\ntitle={Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data},\nauthor={Yongsheng Mei and Mahdi Imani and Tian Lan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9j1RD9LlWH}\n}"}, "paperhash": {"value": "mei|bayesian_optimization_through_gaussian_cox_process_models_for_spatiotemporal_data"}}, "number": 6205, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6205/-/Revision", "ICLR.cc/2024/Conference/Submission6205/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6205/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413001264, "cdate": 1695413001264, "tmdate": 1710550356194, "mdate": 1710550356194, "pdate": 1705410968966, "version": 2}, {"id": "C4CxQmp9wc", "forum": "C4CxQmp9wc", "signatures": ["ICLR.cc/2024/Conference/Submission6204/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6204/Authors"], "content": {"title": {"value": "Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX"}, "authors": {"value": ["Cl\u00e9ment Bonnet", "Daniel Luo", "Donal John Byrne", "Shikha Surana", "Sasha Abramowitz", "Paul Duckworth", "Vincent Coyette", "Laurence Illing Midgley", "Elshadai Tegegn", "Tristan Kalloniatis", "Omayma Mahjoub", "Matthew Macfarlane", "Andries Petrus Smit", "Nathan Grinsztajn", "Raphael Boige", "Cemlyn Neil Waters", "Mohamed Ali Ali Mimouni", "Ulrich Armel Mbou Sob", "Ruan John de Kock", "Siddarth Singh", "Daniel Furelos-Blanco", "Victor Le", "Arnu Pretorius", "Alexandre Laterre"]}, "authorids": {"value": ["~Cl\u00e9ment_Bonnet1", "~Daniel_Luo1", "~Donal_John_Byrne1", "~Shikha_Surana1", "~Sasha_Abramowitz1", "~Paul_Duckworth1", "~Vincent_Coyette1", "~Laurence_Illing_Midgley1", "~Elshadai_Tegegn1", "~Tristan_Kalloniatis1", "~Omayma_Mahjoub1", "~Matthew_Macfarlane1", "~Andries_Petrus_Smit1", "~Nathan_Grinsztajn1", "~Raphael_Boige1", "~Cemlyn_Neil_Waters1", "~Mohamed_Ali_Ali_Mimouni1", "~Ulrich_Armel_Mbou_Sob1", "~Ruan_John_de_Kock1", "~Siddarth_Singh2", "~Daniel_Furelos-Blanco1", "~Victor_Le1", "~Arnu_Pretorius1", "~Alexandre_Laterre1"]}, "keywords": {"value": ["reinforcement learning", "jax", "combinatorial", "research"]}, "TLDR": {"value": "We introduce Jumanji, an open-source, diverse suite of RL environments, designed to be fast, flexible, and scalable."}, "abstract": {"value": "Open-source reinforcement learning (RL) environments have played a crucial role in driving progress in the development of AI algorithms.\nIn modern RL research, there is a need for simulated environments that are performant, scalable, and modular to enable their utilization in a wider range of potential real-world applications.\nTherefore, we present Jumanji, a suite of diverse RL environments specifically designed to be fast, flexible, and scalable.\nJumanji provides a suite of environments focusing on combinatorial problems frequently encountered in industry, as well as challenging general decision-making tasks.\nBy leveraging the efficiency of JAX and hardware accelerators like GPUs and TPUs, Jumanji enables rapid iteration of research ideas and large-scale experimentation, ultimately empowering more capable agents.\nUnlike existing RL environment suites, Jumanji is highly customizable, allowing users to tailor the initial state distribution and problem complexity to their needs.\nFurthermore, we provide actor-critic baselines for each environment, accompanied by preliminary findings on scaling and generalization scenarios.\nJumanji aims to set a new standard for speed, adaptability, and scalability of RL environments."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6e98848b7cc0fcbe27dd8490b8d2cd2f7175911b.pdf"}, "_bibtex": {"value": "@inproceedings{\nbonnet2024jumanji,\ntitle={Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in {JAX}},\nauthor={Cl{\\'e}ment Bonnet and Daniel Luo and Donal John Byrne and Shikha Surana and Paul Duckworth and Vincent Coyette and Laurence Illing Midgley and Sasha Abramowitz and Elshadai Tegegn and Tristan Kalloniatis and Omayma Mahjoub and Matthew Macfarlane and Andries Petrus Smit and Nathan Grinsztajn and Raphael Boige and Cemlyn Neil Waters and Mohamed Ali Ali Mimouni and Ulrich Armel Mbou Sob and Ruan John de Kock and Siddarth Singh and Daniel Furelos-Blanco and Victor Le and Arnu Pretorius and Alexandre Laterre},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=C4CxQmp9wc}\n}"}, "paperhash": {"value": "bonnet|jumanji_a_diverse_suite_of_scalable_reinforcement_learning_environments_in_jax"}}, "number": 6204, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6204/-/Revision", "ICLR.cc/2024/Conference/Submission6204/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6204/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695412888837, "cdate": 1695412888837, "tmdate": 1710541839196, "mdate": 1710541839196, "pdate": 1705410968901, "version": 2}, {"id": "nqlymMx42E", "forum": "nqlymMx42E", "signatures": ["ICLR.cc/2024/Conference/Submission6203/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6203/Authors"], "content": {"title": {"value": "Searching for High-Value Molecules Using Reinforcement Learning and Transformers"}, "authors": {"value": ["Raj Ghugare", "Santiago Miret", "Adriana Hugessen", "Mariano Phielipp", "Glen Berseth"]}, "authorids": {"value": ["~Raj_Ghugare1", "~Santiago_Miret1", "~Adriana_Hugessen1", "~Mariano_Phielipp2", "~Glen_Berseth1"]}, "keywords": {"value": ["chemistry", "reinforcement learning", "language models"]}, "TLDR": {"value": "A new RL algorithm for better molecular discovery."}, "abstract": {"value": "Reinforcement learning (RL) over text representations can be effective for finding high-value policies that can search over graphs. However, RL requires careful structuring of the search space and algorithm design to be effective in this challenge. Through extensive experiments, we explore how different design choices for text grammar and algorithmic choices for training can affect an RL policy's ability to generate molecules with desired properties. We arrive at a new RL-based molecular design algorithm (ChemRLformer) and perform a thorough analysis using 25 molecule design tasks, including computationally complex protein docking simulations. From this analysis, we discover unique insights in this problem space and show that ChemRLformer achieves state-of-the-art performance while being more straightforward than prior work by demystifying which design choices are actually helpful for text-based molecule design."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1536dce0a07e69ff3b042ce3f39be77644440bd0.pdf"}, "_bibtex": {"value": "@inproceedings{\nghugare2024searching,\ntitle={Searching for High-Value Molecules Using Reinforcement Learning and Transformers},\nauthor={Raj Ghugare and Santiago Miret and Adriana Hugessen and Mariano Phielipp and Glen Berseth},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nqlymMx42E}\n}"}, "paperhash": {"value": "ghugare|searching_for_highvalue_molecules_using_reinforcement_learning_and_transformers"}}, "number": 6203, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6203/-/Revision", "ICLR.cc/2024/Conference/Submission6203/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6203/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695412835178, "cdate": 1695412835178, "tmdate": 1710189157268, "mdate": 1710189157268, "pdate": 1705410968876, "version": 2}, {"id": "MO632iPq3I", "forum": "MO632iPq3I", "signatures": ["ICLR.cc/2024/Conference/Submission6202/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6202/Authors"], "content": {"title": {"value": "Differentiable Euler Characteristic Transforms for Shape Classification"}, "authors": {"value": ["Ernst R\u00f6ell", "Bastian Rieck"]}, "authorids": {"value": ["~Ernst_R\u00f6ell1", "~Bastian_Rieck1"]}, "keywords": {"value": ["Differentiable Euler Characteristic Transforms for Shape Classification"]}, "abstract": {"value": "The _Euler Characteristic Transform_ (ECT) is a powerful\n  invariant, combining geometrical and topological characteristics\n  of shapes and graphs.\n  However, the ECT was hitherto unable to learn task-specific\n  representations.\n  We overcome this issue and develop a novel computational layer that\n  enables learning the ECT in an end-to-end fashion.\n  Our method, the _Differentiable Euler Characteristic Transform_ (DECT) \n  is fast and computationally efficient, while exhibiting performance on a par with \n  more complex models in both graph and point cloud classification tasks.\n  Moreover, we show that this seemingly simple statistic\n  provides the same topological expressivity as more complex topological\n  deep learning layers."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/69ed57298a15789a135ef990a9cb3151f96f49fe.pdf"}, "_bibtex": {"value": "@inproceedings{\nroell2024differentiable,\ntitle={Differentiable Euler Characteristic Transforms for Shape Classification},\nauthor={Ernst R\u00f6ell and Bastian Rieck},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MO632iPq3I}\n}"}, "paperhash": {"value": "r\u00f6ell|differentiable_euler_characteristic_transforms_for_shape_classification"}}, "number": 6202, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6202/-/Revision", "ICLR.cc/2024/Conference/Submission6202/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6202/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695412736168, "cdate": 1695412736168, "tmdate": 1710869819850, "mdate": 1710869819850, "pdate": 1705410968843, "version": 2}, {"id": "hp4yOjhwTs", "forum": "hp4yOjhwTs", "signatures": ["ICLR.cc/2024/Conference/Submission6200/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6200/Authors"], "content": {"title": {"value": "Causally Aligned Curriculum Learning"}, "authors": {"value": ["Mingxuan Li", "Junzhe Zhang", "Elias Bareinboim"]}, "authorids": {"value": ["~Mingxuan_Li1", "~Junzhe_Zhang3", "~Elias_Bareinboim2"]}, "keywords": {"value": ["Causal Inference", "Curriculum Learning", "Reinforcement Learning"]}, "abstract": {"value": "A pervasive challenge in Reinforcement Learning (RL) is the ``curse of dimensionality'' which is the exponential growth in the state-action space when optimizing a high-dimensional target task. The framework of curriculum learning trains the agent in a curriculum composed of a sequence of related and more manageable source tasks. The expectation is that when some optimal decision rules are shared across source tasks and the target task, the agent could more quickly pick up the necessary skills to behave optimally in the environment, thus accelerating the learning process. \nHowever, this critical assumption of invariant optimal decision rules does not necessarily hold in many practical applications, specifically when the underlying environment contains unobserved confounders. This paper studies the problem of curriculum RL through causal lenses. We derive a sufficient graphical condition characterizing causally aligned source tasks, i.e., the invariance of optimal decision rules holds. We further develop an efficient algorithm to generate a causally aligned curriculum, provided with qualitative causal knowledge of the target environment. Finally, we validate our proposed methodology through experiments in confounded environments."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/28ead16581ff051e12b88a668528adc8ee43b400.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024causally,\ntitle={Causally Aligned Curriculum Learning},\nauthor={Mingxuan Li and Junzhe Zhang and Elias Bareinboim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hp4yOjhwTs}\n}"}, "paperhash": {"value": "li|causally_aligned_curriculum_learning"}}, "number": 6200, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6200/-/Revision", "ICLR.cc/2024/Conference/Submission6200/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6200/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695412722994, "cdate": 1695412722994, "tmdate": 1710557571987, "mdate": 1710557571987, "pdate": 1705410968788, "version": 2}, {"id": "v63GWletn8", "forum": "v63GWletn8", "signatures": ["ICLR.cc/2024/Conference/Submission6187/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6187/Authors"], "content": {"title": {"value": "Faster Sampling from Log-Concave Densities over Polytopes via Efficient Linear Solvers"}, "authors": {"value": ["Oren Mangoubi", "Nisheeth K. Vishnoi"]}, "authorids": {"value": ["~Oren_Mangoubi1", "~Nisheeth_K._Vishnoi2"]}, "keywords": {"value": ["Logconcave sampling", "Dikin walk", "Markov chain Monte Carlo", "Interior point methods"]}, "abstract": {"value": "We consider the problem of sampling from a logconcave distribution $\\pi(\\theta) \\propto e^{-f(\\theta)}$ constrained to a polytope $K:=${$\\theta \\in \\mathbb{R}^d: A\\theta \\leq b$}, where $A\\in   \\mathbb{R}^{m\\times d}$ and $b \\in \\mathbb{R}^m$. The fastest-known algorithm for the setting when $f$ is $O(1)$-Lipschitz or $O(1)$-smooth runs in roughly $O(md \\times md^{\\omega -1})$ arithmetic operations, where the $md^{\\omega -1}$ term arises because each Markov chain step requires computing a matrix inversion and determinant ($\\omega \\approx 2.37$ is the matrix multiplication constant). We present a nearly-optimal implementation of this Markov chain with per-step complexity that is roughly the number of non-zero entries of $A$ while the number of Markov chain steps remains the same. The key technical ingredients are 1) to show that the matrices that arise in this Dikin walk change slowly, 2) to deploy efficient linear solvers which can leverage this slow change to speed up matrix inversion by using information computed in previous steps, and 3) to speed up the computation of the determinantal term in the Metropolis filter step via a randomized Taylor series-based estimator. This result directly improves the runtime for applications that involve sampling from Gibbs distributions constrained to polytopes that arise in Bayesian statistics and private optimization."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f5305134c7df4f832257ceff0686328db82b539.pdf"}, "_bibtex": {"value": "@inproceedings{\nmangoubi2024faster,\ntitle={Faster Sampling from Log-Concave Densities over Polytopes via Efficient Linear Solvers},\nauthor={Oren Mangoubi and Nisheeth K. Vishnoi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=v63GWletn8}\n}"}, "paperhash": {"value": "mangoubi|faster_sampling_from_logconcave_densities_over_polytopes_via_efficient_linear_solvers"}}, "number": 6187, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6187/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6187/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695412052855, "cdate": 1695412052855, "tmdate": 1712946766081, "mdate": 1712946766081, "pdate": 1705410968409, "version": 2}, {"id": "v1VvCWJAL8", "forum": "v1VvCWJAL8", "signatures": ["ICLR.cc/2024/Conference/Submission6182/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6182/Authors"], "content": {"title": {"value": "Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models"}, "authors": {"value": ["Zeyu Zhou", "Ruqi Bai", "Sean Kulinski", "Murat Kocaoglu", "David I. Inouye"]}, "authorids": {"value": ["~Zeyu_Zhou1", "~Ruqi_Bai1", "~Sean_Kulinski1", "~Murat_Kocaoglu1", "~David_I._Inouye1"]}, "keywords": {"value": ["counterfactual", "domain", "causal representation learning"]}, "TLDR": {"value": "We build generative models by learning latent causal models from data observed from different domains for the purpose of generating domain counterfactuals."}, "abstract": {"value": "Answering counterfactual queries has important applications such as explainability, robustness, and fairness but is challenging when the causal variables are unobserved and the observations are non-linear mixtures of these latent variables, such as pixels in images.\nOne approach is to recover the latent Structural Causal Model (SCM), which may be infeasible in practice due to requiring strong assumptions, e.g., linearity of the causal mechanisms or perfect atomic interventions.\nMeanwhile, more practical ML-based approaches using naive domain translation models to generate counterfactual samples lack theoretical grounding and may construct invalid counterfactuals.\nIn this work, we strive to strike a balance between practicality and theoretical guarantees by analyzing a specific type of causal query called *domain counterfactuals*, which hypothesizes what a sample would have looked like if it had been generated in a different domain (or environment).\nWe show that recovering the latent SCM is unnecessary for estimating domain counterfactuals, thereby sidestepping some of the theoretic challenges.\nBy assuming invertibility and sparsity of intervention, we prove domain counterfactual estimation error can be bounded by a data fit term and intervention sparsity term.\nBuilding upon our theoretical results, we develop a theoretically grounded practical algorithm that simplifies the modeling process to generative model estimation under autoregressive and shared parameter constraints that enforce intervention sparsity.\nFinally, we show an improvement in counterfactual estimation over baseline methods through extensive simulated and image-based experiments."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/82798bd26dba629968e475108998135f769de862.pdf"}, "supplementary_material": {"value": "/attachment/7cec109388478abb7c6faf51ecc1498ca75ff0ba.zip"}, "_bibtex": {"value": "@inproceedings{\nkulinski2024towards,\ntitle={Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models},\nauthor={Sean Kulinski and Zeyu Zhou and Ruqi Bai and Murat Kocaoglu and David I. Inouye},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=v1VvCWJAL8}\n}"}, "paperhash": {"value": "zhou|towards_characterizing_domain_counterfactuals_for_invertible_latent_causal_models"}}, "number": 6182, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6182/-/Revision", "ICLR.cc/2024/Conference/Submission6182/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6182/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695411945203, "cdate": 1695411945203, "tmdate": 1713043499920, "mdate": 1713043499920, "pdate": 1705410968332, "version": 2}, {"id": "vt5mnLVIVo", "forum": "vt5mnLVIVo", "signatures": ["ICLR.cc/2024/Conference/Submission6180/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6180/Authors"], "content": {"title": {"value": "Grokking as the transition from lazy to rich training dynamics"}, "authors": {"value": ["Tanishq Kumar", "Blake Bordelon", "Samuel J. Gershman", "Cengiz Pehlevan"]}, "authorids": {"value": ["~Tanishq_Kumar1", "~Blake_Bordelon1", "~Samuel_J._Gershman1", "~Cengiz_Pehlevan2"]}, "keywords": {"value": ["Grokking", "Feature Learning", "Neural Tangent Kernel", "Generalization", "Training Dynamics"]}, "TLDR": {"value": "A theory of grokking based on delayed feature learning."}, "abstract": {"value": "We propose that the grokking phenomenon, where the train loss of a neural network decreases much earlier than its test loss, can arise due to a neural network transitioning from lazy training dynamics to a rich, feature learning regime. To illustrate this mechanism, we study the simple setting of vanilla gradient descent on a polynomial regression problem with a two layer neural network which exhibits grokking without regularization in a way that cannot be explained by existing theories. We identify sufficient statistics for the test loss of such a network, and tracking these over training reveals that grokking arises in this setting when the network first attempts to fit a kernel regression solution with its initial features, followed by late-time feature learning where a generalizing solution is identified after train loss is already low. We find that the key determinants of grokking are the rate of feature learning---which can be controlled precisely by parameters that scale the network output---and the alignment of the initial features with the target function $y(x)$. We argue this delayed generalization arises when (1) the top eigenvectors of the initial neural tangent kernel and the task labels $y(x)$ are misaligned, but (2) the dataset size is large enough so that it is possible for the network to generalize eventually, but not so large that train loss perfectly tracks test loss at all epochs, and (3) the network begins training in the lazy regime so does not learn features immediately. We conclude with evidence that this transition from lazy (linear model) to rich training (feature learning) can control grokking in more general settings, like on MNIST, one-layer Transformers, and student-teacher networks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7234569d5729cb29c90979a56635327e1789c3a6.pdf"}, "supplementary_material": {"value": "/attachment/17845b3357ef80059733da1e2267de17efee8444.zip"}, "_bibtex": {"value": "@inproceedings{\nkumar2024grokking,\ntitle={Grokking as the transition from lazy to rich training dynamics},\nauthor={Tanishq Kumar and Blake Bordelon and Samuel J. Gershman and Cengiz Pehlevan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vt5mnLVIVo}\n}"}, "paperhash": {"value": "kumar|grokking_as_the_transition_from_lazy_to_rich_training_dynamics"}}, "number": 6180, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6180/-/Revision", "ICLR.cc/2024/Conference/Submission6180/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6180/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695411840861, "cdate": 1695411840861, "tmdate": 1709661528560, "mdate": 1709661528560, "pdate": 1705410968251, "version": 2}, {"id": "M0xK8nPGvt", "forum": "M0xK8nPGvt", "signatures": ["ICLR.cc/2024/Conference/Submission6174/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6174/Authors"], "content": {"title": {"value": "Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning"}, "authors": {"value": ["Mirco Mutti", "Riccardo De Santi", "Marcello Restelli", "Alexander Marx", "Giorgia Ramponi"]}, "authorids": {"value": ["~Mirco_Mutti1", "~Riccardo_De_Santi1", "~Marcello_Restelli1", "~Alexander_Marx1", "~Giorgia_Ramponi1"]}, "keywords": {"value": ["Reinforcement learning", "Posterior sampling", "Causality"]}, "abstract": {"value": "Posterior sampling allows exploitation of prior knowledge on the environment's transition dynamics to improve the sample efficiency of reinforcement learning. The prior is typically specified as a class of parametric distributions, the design of which can be cumbersome in practice, often resulting in the choice of uninformative priors. In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables. The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study. Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level. We provide an analysis of the Bayesian regret of C-PSRL that explicitly connects the regret rate with the degree of prior knowledge. Our numerical evaluation conducted in illustrative domains confirms that C-PSRL strongly improves the efficiency of posterior sampling with an uninformative prior while performing close to posterior sampling with the full causal graph."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e1855e2abd067d42d9cd6076af71eb313492a804.pdf"}, "supplementary_material": {"value": "/attachment/c9f56bf03de8a4082b5e0420c8ed380f8e8a1e96.zip"}, "_bibtex": {"value": "@inproceedings{\nmutti2024exploiting,\ntitle={Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning},\nauthor={Mirco Mutti and Riccardo De Santi and Marcello Restelli and Alexander Marx and Giorgia Ramponi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=M0xK8nPGvt}\n}"}, "paperhash": {"value": "mutti|exploiting_causal_graph_priors_with_posterior_sampling_for_reinforcement_learning"}}, "number": 6174, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6174/-/Revision", "ICLR.cc/2024/Conference/Submission6174/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6174/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695411652748, "cdate": 1695411652748, "tmdate": 1710576020387, "mdate": 1710576020387, "pdate": 1705410967972, "version": 2}, {"id": "KgaBScZ4VI", "forum": "KgaBScZ4VI", "signatures": ["ICLR.cc/2024/Conference/Submission6173/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6173/Authors"], "content": {"title": {"value": "Language Model Cascades: Token-Level Uncertainty And Beyond"}, "authors": {"value": ["Neha Gupta", "Harikrishna Narasimhan", "Wittawat Jitkrittum", "Ankit Singh Rawat", "Aditya Krishna Menon", "Sanjiv Kumar"]}, "authorids": {"value": ["~Neha_Gupta1", "~Harikrishna_Narasimhan1", "~Wittawat_Jitkrittum1", "~Ankit_Singh_Rawat1", "~Aditya_Krishna_Menon1", "~Sanjiv_Kumar1"]}, "keywords": {"value": ["Cascades", "Efficient Inference", "Language Models"]}, "abstract": {"value": "Recent advances in language models (LMs) have led to significant improvements in quality on complex NLP tasks, but at the expense of increased inference costs. A simple strategy to achieve more favorable cost-quality tradeoffs is cascading: here, a small model is invoked for most \u201ceasy\u201d instances, while a few \u201chard\u201d instances are deferred to the large model. While the principles underpinning effective cascading are well-studied for classification tasks \u2014 with deferral based on predicted class uncertainty favored theoretically and practically \u2014 a similar understanding is lacking for generative LM tasks. In this work, we initiate a systematic study of deferral rules for LM cascades. We begin by examining the natural extension of predicted class uncertainty to generative LM tasks, namely, the predicted sequence uncertainty. We show that this measure suffers from the length bias problem, either over- or under-emphasizing outputs based on their lengths. This is because LMs produce a sequence of uncertainty values, one for each output token; and moreover, the number of output tokens is variable across different examples. To mitigate the length bias, we propose to exploit the richer token-level uncertainty information implicit in generative LMs. We argue that naive predicted sequence uncertainty corresponds to a simple aggregation of these uncertainties. By contrast, we show that incorporating token-level uncertainty through learned post-hoc deferral rules can significantly outperform such simple aggregation strategies, via experiments on a range of natural language benchmarks with FLAN-T5 models. We further show that incorporating embeddings from the smaller model and intermediate layers of the larger model can give an additional boost in the overall cost-quality tradeoff."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c12ed09310cf9e30337a888bd967a35d838624dc.pdf"}, "TLDR": {"value": "Exploiting token-level uncertainty can significantly improve cost-quality tradeoff for language model cascades."}, "_bibtex": {"value": "@inproceedings{\ngupta2024language,\ntitle={Language Model Cascades: Token-Level Uncertainty And Beyond},\nauthor={Neha Gupta and Harikrishna Narasimhan and Wittawat Jitkrittum and Ankit Singh Rawat and Aditya Krishna Menon and Sanjiv Kumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KgaBScZ4VI}\n}"}, "paperhash": {"value": "gupta|language_model_cascades_tokenlevel_uncertainty_and_beyond"}}, "number": 6173, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6173/-/Revision", "ICLR.cc/2024/Conference/Submission6173/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6173/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695411644059, "cdate": 1695411644059, "tmdate": 1712958311172, "mdate": 1712958311172, "pdate": 1705410967879, "version": 2}, {"id": "3JjJezzVkT", "forum": "3JjJezzVkT", "signatures": ["ICLR.cc/2024/Conference/Submission6171/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6171/Authors"], "content": {"title": {"value": "The Marginal Value of Momentum for Small Learning Rate SGD"}, "authors": {"value": ["Runzhe Wang", "Sadhika Malladi", "Tianhao Wang", "Kaifeng Lyu", "Zhiyuan Li"]}, "authorids": {"value": ["~Runzhe_Wang2", "~Sadhika_Malladi2", "~Tianhao_Wang1", "~Kaifeng_Lyu2", "~Zhiyuan_Li2"]}, "keywords": {"value": ["momentum", "SGD", "dynamics"]}, "TLDR": {"value": "We prove that momentum has no optimization and generalization benefits for small learning-rate and high gradient-noise SGD."}, "abstract": {"value": "Momentum is known to accelerate the convergence of gradient descent in strongly convex settings without stochastic gradient noise. In stochastic optimization, such as training neural networks, folklore suggests that momentum may help deep learning optimization by reducing the variance of the stochastic gradient update, but previous theoretical analyses do not find momentum to offer any provable acceleration. Theoretical results in this paper clarify the role of momentum in stochastic settings where the learning rate is small and gradient noise is the dominant source of instability, suggesting that SGD with and without momentum behave similarly in the short and long time horizons. Experiments show that momentum indeed has limited benefits for both optimization and generalization in practical training regimes where the optimal learning rate is not very large, including small- to medium-batch training from scratch on ImageNet and fine-tuning language models on downstream tasks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6b99c76635bffac8a7dbc067062dae6143657606.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024the,\ntitle={The Marginal Value of Momentum for Small Learning Rate {SGD}},\nauthor={Runzhe Wang and Sadhika Malladi and Tianhao Wang and Kaifeng Lyu and Zhiyuan Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3JjJezzVkT}\n}"}, "paperhash": {"value": "wang|the_marginal_value_of_momentum_for_small_learning_rate_sgd"}}, "number": 6171, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6171/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6171/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695411531526, "cdate": 1695411531526, "tmdate": 1711168474352, "mdate": 1711168474352, "pdate": 1705410967858, "version": 2}, {"id": "gyfXuRfxW2", "forum": "gyfXuRfxW2", "signatures": ["ICLR.cc/2024/Conference/Submission6163/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6163/Authors"], "content": {"title": {"value": "Learning Polynomial Problems with $SL(2, \\mathbb{R})$-Equivariance"}, "authors": {"value": ["Hannah Lawrence", "Mitchell Tong Harris"]}, "authorids": {"value": ["~Hannah_Lawrence1", "~Mitchell_Tong_Harris1"]}, "keywords": {"value": ["equivariance", "invariance", "polynomials", "non-compact", "special linear group", "data augmentation", "universality"]}, "TLDR": {"value": "We propose machine learning approaches, which are equivariant with respect to the non-compact group of area-preserving transformations SL(2,R), for learning to solve polynomial optimization problems."}, "abstract": {"value": "Optimizing and certifying the positivity of polynomials are fundamental primitives across mathematics and engineering applications, from dynamical systems to operations research. However, solving these problems in practice requires large semidefinite programs, with poor scaling in dimension and degree. In this work, we demonstrate for the first time that neural networks can effectively solve such problems in a data-driven fashion, achieving tenfold speedups while retaining high accuracy. Moreover, we observe that these polynomial learning problems are equivariant to the non-compact group $SL(2,\\mathbb{R})$, which consists of area-preserving linear transformations. We therefore adapt our learning pipelines to accommodate this structure, including data augmentation, a new $SL(2,\\mathbb{R})$-equivariant architecture, and an architecture equivariant with respect to its maximal compact subgroup, $SO(2, \\mathbb{R})$. Surprisingly, the most successful approaches in practice do not enforce equivariance to the entire group, which we prove arises from an unusual lack of architecture universality for $SL(2,\\mathbb{R})$ in particular. A consequence of this result, which is of independent interest, is that there exists an equivariant function for which there is no sequence of equivariant polynomials multiplied by arbitrary invariants that approximates the original function. This is a rare example of a symmetric problem where data augmentation outperforms a fully equivariant architecture, and provides interesting lessons in both theory and practice for other problems with non-compact symmetries."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/eb555a545e6faf35eb426d297e554f50d4687419.pdf"}, "supplementary_material": {"value": "/attachment/59c229fe444969b30be8da29dbecfc8339616f83.zip"}, "_bibtex": {"value": "@inproceedings{\nlawrence2024learning,\ntitle={Learning Polynomial Problems with \\${SL}(2, {\\textbackslash}mathbb\\{R\\})\\$-Equivariance},\nauthor={Hannah Lawrence and Mitchell Tong Harris},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gyfXuRfxW2}\n}"}, "paperhash": {"value": "lawrence|learning_polynomial_problems_with_sl2_\\mathbbrequivariance"}}, "number": 6163, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6163/-/Revision", "ICLR.cc/2024/Conference/Submission6163/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6163/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410932158, "cdate": 1695410932158, "tmdate": 1710518678225, "mdate": 1710518678225, "pdate": 1705410967543, "version": 2}, {"id": "wYvuY60SdD", "forum": "wYvuY60SdD", "signatures": ["ICLR.cc/2024/Conference/Submission6162/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6162/Authors"], "content": {"title": {"value": "Mixture of Weak and Strong Experts on Graphs"}, "authors": {"value": ["Hanqing Zeng", "Hanjia Lyu", "Diyi Hu", "Yinglong Xia", "Jiebo Luo"]}, "authorids": {"value": ["~Hanqing_Zeng1", "~Hanjia_Lyu1", "~Diyi_Hu1", "~Yinglong_Xia1", "~Jiebo_Luo1"]}, "keywords": {"value": ["Graph Neural Networks", "Mixture of experts", "Node classification"]}, "TLDR": {"value": "We propose a system to combine a weak MLP expert and a strong GNN expert, so that the powerful GNN model can be better optimized by decoupling the feature and structure modalities of the graph."}, "abstract": {"value": "Realistic graphs contain both rich self-features and informative neighborhood structures, jointly handled by a GNN in the typical setup. \nWe propose to decouple the two modalities by mixture of weak and strong experts (Mowst), where the weak expert is a light-weight Multi-layer Perceptron (MLP) , and the strong expert is an off-the-shelf Graph Neural Network (GNN). To adapt the experts' collaboration to different target nodes, we propose a \"confidence\" mechanism based on the dispersion of the weak expert's prediction logits. The strong expert is conditionally activated in the low-confidence region when either the node's classification relies on neighborhood information, or the weak expert has low model quality. We reveal interesting training dynamics by analyzing the influence of the confidence function on loss: our training algorithm encourages specialization of each expert by effectively generating a soft splitting of the graph. In addition, our \"confidence\" design imposes a desirable bias towards the strong expert to benefit from the better generalization capability of GNNs. Mowst is easy to optimize and achieves strong expressive power, with computation cost comparable to a single GNN. Empirically, Mowst shows significant accuracy improvement on 6 standard node classification benchmarks (including both homophilous and heterophilous graphs)."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/be9127227c44152f9e3080b617c9f5a02a78db21.pdf"}, "supplementary_material": {"value": "/attachment/2eda620329937ee866be0e85741ad82ce6a85297.pdf"}, "_bibtex": {"value": "@inproceedings{\nzeng2024mixture,\ntitle={Mixture of Weak and Strong Experts on Graphs},\nauthor={Hanqing Zeng and Hanjia Lyu and Diyi Hu and Yinglong Xia and Jiebo Luo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wYvuY60SdD}\n}"}, "paperhash": {"value": "zeng|mixture_of_weak_and_strong_experts_on_graphs"}}, "number": 6162, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6162/-/Revision", "ICLR.cc/2024/Conference/Submission6162/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410876859, "cdate": 1695410876859, "tmdate": 1707625629420, "mdate": 1707625629420, "pdate": 1705410967542, "version": 2}, {"id": "sLkj91HIZU", "forum": "sLkj91HIZU", "signatures": ["ICLR.cc/2024/Conference/Submission6154/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6154/Authors"], "content": {"title": {"value": "Transformers can optimally learn regression mixture models"}, "authors": {"value": ["Reese Pathak", "Rajat Sen", "Weihao Kong", "Abhimanyu Das"]}, "authorids": {"value": ["~Reese_Pathak1", "~Rajat_Sen1", "~Weihao_Kong1", "~Abhimanyu_Das2"]}, "keywords": {"value": ["transformers", "mixture models", "linear regression"]}, "TLDR": {"value": "We show transformers are capable of achieving near-optimal performance on mixtures of regressions data"}, "abstract": {"value": "Mixture models arise in many regression problems, but most methods have seen limited adoption partly due to these algorithms' highly-tailored and model-specific nature. On the other hand, transformers are flexible, neural sequence models that present the intriguing possibility of providing general-purpose prediction methods, even in this mixture setting. In this work, we investigate the hypothesis that transformers can learn an optimal predictor for mixtures of regressions. We construct a generative process for a mixture of linear regressions for which the decision-theoretic optimal procedure is given by data-driven exponential weights on a finite set of parameters. We observe that transformers achieve low mean-squared error on data generated via this process. By probing the transformer's output at inference time, we also show that transformers typically make predictions that are close to the optimal predictor. Our experiments also demonstrate that transformers can learn mixtures of regressions in a sample-efficient fashion and are somewhat robust to distribution shifts. We complement our experimental observations by proving constructively that the decision-theoretic optimal procedure is indeed implementable by a transformer."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6cf0b6fc5b7e7a16d74637bc03aa6db831376f33.pdf"}, "supplementary_material": {"value": "/attachment/30066d478180b9f9848cf541e13eee2d9d2fbdb8.zip"}, "_bibtex": {"value": "@inproceedings{\npathak2024transformers,\ntitle={Transformers can optimally learn regression mixture models},\nauthor={Reese Pathak and Rajat Sen and Weihao Kong and Abhimanyu Das},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sLkj91HIZU}\n}"}, "paperhash": {"value": "pathak|transformers_can_optimally_learn_regression_mixture_models"}}, "number": 6154, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6154/-/Revision", "ICLR.cc/2024/Conference/-/PC_Revision", "ICLR.cc/2024/Conference/Submission6154/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6154/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410453920, "cdate": 1695410453920, "tmdate": 1710864668700, "mdate": 1710864668700, "pdate": 1705410967089, "version": 2}, {"id": "iCNOK45Csv", "forum": "iCNOK45Csv", "signatures": ["ICLR.cc/2024/Conference/Submission6151/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6151/Authors"], "content": {"title": {"value": "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective"}, "authors": {"value": ["Ming-Yu Chung", "Sheng-Yen Chou", "Chia-Mu Yu", "Pin-Yu Chen", "Sy-Yen Kuo", "Tsung-Yi Ho"]}, "authorids": {"value": ["~Ming-Yu_Chung1", "~Sheng-Yen_Chou2", "~Chia-Mu_Yu1", "~Pin-Yu_Chen1", "~Sy-Yen_Kuo2", "~Tsung-Yi_Ho2"]}, "keywords": {"value": ["Backdoor", "Trigger", "Dataset Condensation", "Dataset Distillation"]}, "TLDR": {"value": "We theoretically analyze the backdoor attack using dataset condensation and then propose a trigger pattern generation algorithm."}, "abstract": {"value": "Dataset distillation offers a potential means to enhance data efficiency in deep learning. Recent studies have shown its ability to counteract backdoor risks present in original training samples. In this study, we delve into the theoretical aspects of backdoor attacks and dataset distillation based on kernel methods. We introduce two new theory-driven trigger pattern generation methods specialized for dataset distillation. Following a comprehensive set of analyses and experiments, we show that our optimization-based trigger design framework informs effective backdoor attacks on dataset distillation. Notably, datasets poisoned by our designed trigger prove resilient against conventional backdoor attack detection and mitigation methods.  Our empirical results validate that the triggers developed using our approaches are proficient at executing resilient backdoor attacks."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4c64e7f5aff452ccdcb224065bc7e520dd06f1fe.pdf"}, "supplementary_material": {"value": "/attachment/16c565fa7379d6df36c29e19eb841d402844f4c5.pdf"}, "_bibtex": {"value": "@inproceedings{\nchung2024rethinking,\ntitle={Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective},\nauthor={Ming-Yu Chung and Sheng-Yen Chou and Chia-Mu Yu and Pin-Yu Chen and Sy-Yen Kuo and Tsung-Yi Ho},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=iCNOK45Csv}\n}"}, "paperhash": {"value": "chung|rethinking_backdoor_attacks_on_dataset_distillation_a_kernel_method_perspective"}}, "number": 6151, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6151/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6151/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410369179, "cdate": 1695410369179, "tmdate": 1709661528244, "mdate": 1709661528244, "pdate": 1705410966911, "version": 2}, {"id": "6pPYRXKPpw", "forum": "6pPYRXKPpw", "signatures": ["ICLR.cc/2024/Conference/Submission6147/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6147/Authors"], "content": {"title": {"value": "Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations"}, "authors": {"value": ["Xiaogang Jia", "Denis Blessing", "Xinkai Jiang", "Moritz Reuss", "Atalay Donat", "Rudolf Lioutikov", "Gerhard Neumann"]}, "authorids": {"value": ["~Xiaogang_Jia1", "~Denis_Blessing1", "~Xinkai_Jiang1", "~Moritz_Reuss1", "~Atalay_Donat1", "~Rudolf_Lioutikov1", "~Gerhard_Neumann2"]}, "keywords": {"value": ["Imitation Learning", "Benchmark", "Datasets", "Diverse Behaviors"]}, "abstract": {"value": "Imitation learning with human data has demonstrated remarkable success in teaching robots in a wide range of skills. However, the inherent diversity in human behavior leads to the emergence of multi-modal data distributions, thereby presenting a formidable challenge for existing imitation learning algorithms. Quantifying a model's capacity to capture and replicate this diversity effectively is still an open problem. In this work, we introduce simulation benchmark environments and the corresponding *Datasets with Diverse human Demonstrations for Imitation Learning (D3IL)*, designed explicitly to evaluate a model's ability to learn multi-modal behavior. Our environments are designed to involve multiple sub-tasks that need to be solved, consider manipulation of multiple objects which increases the diversity of the behavior and can only be solved by policies that rely on closed loop sensory feedback. Other available datasets are missing at least one of these challenging properties.\nTo address the challenge of diversity quantification, we introduce tractable metrics that provide valuable insights into a model's ability to acquire and reproduce diverse behaviors. These metrics offer a practical means to assess the robustness and versatility of imitation learning algorithms. Furthermore, we conduct a thorough evaluation of state-of-the-art methods on the proposed task suite. This evaluation serves as a benchmark for assessing their capability to learn diverse behaviors. Our findings shed light on the effectiveness of these methods in tackling the intricate problem of capturing and generalizing multi-modal human behaviors, offering a valuable reference for the design of future imitation learning algorithms."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2f3fdf0514ecf5071b833dfeb74b36176a0de0db.pdf"}, "supplementary_material": {"value": "/attachment/cd40700eabe3ab1ed74ee745d330703687a0bd4f.zip"}, "TLDR": {"value": "A simulation benchmark with diverse human demonstrations, and tractable metrics to evaluate imitation learning's ability to capture multi-modal behavior."}, "_bibtex": {"value": "@inproceedings{\njia2024towards,\ntitle={Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations},\nauthor={Xiaogang Jia and Denis Blessing and Xinkai Jiang and Moritz Reuss and Atalay Donat and Rudolf Lioutikov and Gerhard Neumann},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6pPYRXKPpw}\n}"}, "paperhash": {"value": "jia|towards_diverse_behaviors_a_benchmark_for_imitation_learning_with_human_demonstrations"}}, "number": 6147, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6147/-/Revision", "ICLR.cc/2024/Conference/Submission6147/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6147/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410237679, "cdate": 1695410237679, "tmdate": 1710496063024, "mdate": 1710496063024, "pdate": 1705410966805, "version": 2}, {"id": "odY3PkI5VB", "forum": "odY3PkI5VB", "signatures": ["ICLR.cc/2024/Conference/Submission6144/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6144/Authors"], "content": {"title": {"value": "Reconciling Spatial and Temporal Abstractions for Goal Representation"}, "authors": {"value": ["Mehdi Zadem", "Sergio Mover", "Sao Mai Nguyen"]}, "authorids": {"value": ["~Mehdi_Zadem1", "~Sergio_Mover1", "~Sao_Mai_Nguyen1"]}, "keywords": {"value": ["Hierarchical Reinforcement Learning", "Goal Representation", "Reachability Analysis"]}, "abstract": {"value": "Goal representation affects the performance of Hierarchical Reinforcement Learn- ing (HRL) algorithms by decomposing the complex learning problem into easier subtasks. Recent studies show that representations that preserve temporally ab- stract environment dynamics are successful in solving difficult problems and pro- vide theoretical guarantees for optimality. These methods however cannot scale to tasks where environment dynamics increase in complexity i.e. the temporally abstract transition relations depend on larger number of variables. On the other hand, other efforts have tried to use spatial abstraction to mitigate the previous issues. Their limitations include scalability to high dimensional environments and dependency on prior knowledge.\n\nIn this paper, we propose a novel three-layer HRL algorithm that introduces, at different levels of the hierarchy, both a spatial and a temporal goal abstraction. We provide a theoretical study of the regret bounds of the learned policies. We evaluate the approach on complex continuous control tasks, demonstrating the effectiveness of spatial and temporal abstractions learned by this approach."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6d1c5e32fc9f897f49b7619f173deefc81d86e9c.pdf"}, "supplementary_material": {"value": "/attachment/efd4d11ce22956eacbe3d118b1e674e7a7c66c76.zip"}, "_bibtex": {"value": "@inproceedings{\nzadem2024reconciling,\ntitle={Reconciling Spatial and Temporal Abstractions for Goal Representation},\nauthor={Mehdi Zadem and Sergio Mover and Sao Mai Nguyen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=odY3PkI5VB}\n}"}, "paperhash": {"value": "zadem|reconciling_spatial_and_temporal_abstractions_for_goal_representation"}}, "number": 6144, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6144/-/Revision", "ICLR.cc/2024/Conference/Submission6144/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6144/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410190402, "cdate": 1695410190402, "tmdate": 1710505410743, "mdate": 1710505410743, "pdate": 1705410966760, "version": 2}, {"id": "Oju2Qu9jvn", "forum": "Oju2Qu9jvn", "signatures": ["ICLR.cc/2024/Conference/Submission6140/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6140/Authors"], "content": {"title": {"value": "Estimating Conditional Mutual Information for Dynamic Feature Selection"}, "authors": {"value": ["Soham Gadgil", "Ian Connick Covert", "Su-In Lee"]}, "authorids": {"value": ["~Soham_Gadgil1", "~Ian_Connick_Covert1", "~Su-In_Lee2"]}, "keywords": {"value": ["dynamic feature selection", "adaptive", "feature selection", "mutual information", "information theory"]}, "TLDR": {"value": "We develop a method for dynamic feature selection by directly predicting the conditional mutual information with the response variable"}, "abstract": {"value": "Dynamic feature selection, where we sequentially query features to make accurate predictions with a minimal budget, is a promising paradigm to reduce feature acquisition costs and provide transparency into the prediction process. The problem is challenging, however, as it requires both making predictions with arbitrary feature sets and learning a policy to identify the most valuable selections. Here, we take an information-theoretic perspective and prioritize features based on their mutual information with the response variable. The main challenge is implementing this policy, and we design a new approach that estimates the mutual information in a discriminative rather than a generative fashion. Building on our learning approach, we introduce several further improvements: allowing variable feature budgets across samples, enabling non-uniform costs between features, incorporating prior information, and exploring modern architectures to handle partial input information. We find that our method provides consistent gains over recent state-of-the-art methods across a variety of datasets."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d27c0b9e152ca6e70d6be8b8d3402b85e83dad3e.pdf"}, "supplementary_material": {"value": "/attachment/b722fcd7c9bab66f79ca7928895cd8210ca2c116.zip"}, "_bibtex": {"value": "@inproceedings{\ngadgil2024estimating,\ntitle={Estimating Conditional Mutual Information for Dynamic Feature Selection},\nauthor={Soham Gadgil and Ian Connick Covert and Su-In Lee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Oju2Qu9jvn}\n}"}, "paperhash": {"value": "gadgil|estimating_conditional_mutual_information_for_dynamic_feature_selection"}}, "number": 6140, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6140/-/Revision", "ICLR.cc/2024/Conference/Submission6140/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6140/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410029096, "cdate": 1695410029096, "tmdate": 1709841945252, "mdate": 1709841945252, "pdate": 1705410966559, "version": 2}, {"id": "jjA4O1vJRz", "forum": "jjA4O1vJRz", "signatures": ["ICLR.cc/2024/Conference/Submission6139/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6139/Authors"], "content": {"title": {"value": "LLM Augmented LLMs: Expanding Capabilities through Composition"}, "authors": {"value": ["Rachit Bansal", "Bidisha Samanta", "Siddharth Dalmia", "Nitish Gupta", "Sriram Ganapathy", "Abhishek Bapna", "Prateek Jain", "Partha Talukdar"]}, "authorids": {"value": ["~Rachit_Bansal1", "~Bidisha_Samanta2", "~Siddharth_Dalmia1", "~Nitish_Gupta1", "~Sriram_Ganapathy1", "~Abhishek_Bapna1", "~Prateek_Jain1", "~Partha_Talukdar1"]}, "keywords": {"value": ["Large Language Models", "Model Composition", "Knowledge Augmentation"]}, "abstract": {"value": "Foundational models with billions of parameters which have been trained on large corpus of data have demonstrated non-trivial skills in a variety of domains. However, due to their monolithic structure, it is challenging and expensive to augment them or impart new skills. On the other hand, due to their adaptation abilities,several new instances of these models are being trained towards new domains and tasks.  In this work, we study the problem of efficient and practical composition of existing foundation models with more specific models to enable newer capabilities. To this end,  we propose CALM\u2014Composition to Augment Language Models\u2014which introduces cross-attention between models to compose their representations and enable new capabilities. Salient features of CALM are: (i) Scales up LLMs on new tasks by \u2018re-using\u2019 existing LLMs along with a few additional parameters and data, (ii) Existing model weights are kept intact, and hence preserves existing capabilities, and (iii) Applies to diverse domains and settings. We illustrate that augmenting PaLM2-S with a smaller model trained on low-resource languages results in an absolute improvement of up to 13% on tasks like translation into English and arithmetic reasoning for low-resource languages. Similarly,when PaLM2-S is augmented with a code-specific model, we see a relative improvement of 40% over the base model for code generation and explanation tasks\u2014on-par with fully fine-tuned counterparts."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d0316195c2919ffce4f1eddace8ffdb6fdc491cc.pdf"}, "_bibtex": {"value": "@inproceedings{\nbansal2024llm,\ntitle={{LLM} Augmented {LLM}s: Expanding Capabilities through Composition},\nauthor={Rachit Bansal and Bidisha Samanta and Siddharth Dalmia and Nitish Gupta and Sriram Ganapathy and Abhishek Bapna and Prateek Jain and Partha Talukdar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jjA4O1vJRz}\n}"}, "paperhash": {"value": "bansal|llm_augmented_llms_expanding_capabilities_through_composition"}}, "number": 6139, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6139/-/Revision", "ICLR.cc/2024/Conference/Submission6139/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6139/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410022672, "cdate": 1695410022672, "tmdate": 1710475096439, "mdate": 1710475096439, "pdate": 1706844948825, "version": 2}, {"id": "PvJnX3dwsD", "forum": "PvJnX3dwsD", "signatures": ["ICLR.cc/2024/Conference/Submission6138/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6138/Authors"], "content": {"title": {"value": "Quadratic models for understanding catapult dynamics of neural networks"}, "authors": {"value": ["Libin Zhu", "Chaoyue Liu", "Adityanarayanan Radhakrishnan", "Mikhail Belkin"]}, "authorids": {"value": ["~Libin_Zhu1", "~Chaoyue_Liu2", "~Adityanarayanan_Radhakrishnan1", "~Mikhail_Belkin1"]}, "keywords": {"value": ["quadratic models", "wide neural networks", "catapult phase", "optimization dynamics"]}, "TLDR": {"value": "Quadratic models capture properties of wide neural networks in both optimization and generalization."}, "abstract": {"value": "While neural networks can be approximated by linear models as their width increases, certain properties of wide neural networks cannot be captured by linear models. In this work we show that recently proposed Neural Quadratic Models can exhibit the \"catapult phase\" Lewkowycz et al. (2020) that arises when training such models with large learning rates. We then empirically show that the behaviour of quadratic models parallels that of neural networks in generalization, especially in the catapult phase regime. Our analysis further demonstrates that quadratic models are an effective tool for analysis of neural networks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/94bfde955d41c60ddbb6b7ed27b2e07991efe18d.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhu2024quadratic,\ntitle={Quadratic models for understanding neural network dynamics},\nauthor={Libin Zhu and Chaoyue Liu and Adityanarayanan Radhakrishnan and Mikhail Belkin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PvJnX3dwsD}\n}"}, "paperhash": {"value": "zhu|quadratic_models_for_understanding_catapult_dynamics_of_neural_networks"}}, "number": 6138, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6138/-/Revision", "ICLR.cc/2024/Conference/Submission6138/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6138/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695410022028, "cdate": 1695410022028, "tmdate": 1710463386940, "mdate": 1710463386940, "pdate": 1705410966437, "version": 2}, {"id": "sTYuRVrdK3", "forum": "sTYuRVrdK3", "signatures": ["ICLR.cc/2024/Conference/Submission6130/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6130/Authors"], "content": {"title": {"value": "Evaluating Representation Learning on the Protein Structure Universe"}, "authors": {"value": ["Arian Rokkum Jamasb", "Alex Morehead", "Zuobai Zhang", "Chaitanya K. Joshi", "Kieran Didi", "Simon V Mathis", "Charles Harris", "Jian Tang", "Jianlin Cheng", "Pietro Lio", "Tom Leon Blundell"]}, "authorids": {"value": ["~Arian_Rokkum_Jamasb1", "~Alex_Morehead1", "~Zuobai_Zhang1", "~Chaitanya_K._Joshi1", "~Kieran_Didi1", "~Simon_V_Mathis1", "~Charles_Harris2", "~Jian_Tang1", "~Jianlin_Cheng1", "~Pietro_Lio1", "~Tom_Leon_Blundell1"]}, "keywords": {"value": ["Protein", "Representation", "Learning", "Protein Structure"]}, "TLDR": {"value": "Benchmark for evaluating pre-training and representation learning on protein structures."}, "abstract": {"value": "Protein structure representation learning is the foundation for promising applications in drug discovery, protein design, and protein function prediction. However, there remains a need for a robust, standardised benchmark to track the progress of new and established methods with greater granularity and relevance to downstream applications. In this work, we introduce a comprehensive and open benchmark suite for evaluating protein structure representation learning methods.\n\nWe provide several pre-training methods, downstream tasks and pre-training corpora comprised of both experimental and predicted structures, offering a balanced challenge to representation learning algorithms. These tasks enable the systematic evaluation of the quality of the learned embeddings, the structural and functional relationships captured, and their usefulness in downstream tasks. We benchmark state-of-the-art protein-specific and generic geometric Graph Neural Networks and the extent to which they benefit from different types of pre-training. We find that pre-training consistently improves the performance of both rotation-invariant and equivariant models, and that equivariant models seem to benefit even more from pre-training compared to invariant models.\n\nWe aim to establish a common ground for the machine learning and computational biology communities to collaborate, compare, and advance protein structure representation learning. By providing a standardised and rigorous evaluation platform, we expect to accelerate the development of novel methodologies and improve our understanding of protein structures and their functions. The codebase incorporates several engineering contributions which considerably reduces the barrier to entry for pre-training and working with large structure-based datasets. Our benchmark is available at: https://anonymous.4open.science/r/ProteinWorkshop-B8F5/"}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f122c5bae20979f9080e0232a339fc31ba7995fc.pdf"}, "supplementary_material": {"value": "/attachment/444ec4941bf0bf5837312565698b9e1d56071df2.pdf"}, "_bibtex": {"value": "@inproceedings{\njamasb2024evaluating,\ntitle={Evaluating Representation Learning on the Protein Structure Universe},\nauthor={Arian Rokkum Jamasb and Alex Morehead and Zuobai Zhang and Chaitanya K. Joshi and Kieran Didi and Simon V Mathis and Charles Harris and Jian Tang and Jianlin Cheng and Pietro Lio and Tom Leon Blundell},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sTYuRVrdK3}\n}"}, "paperhash": {"value": "jamasb|evaluating_representation_learning_on_the_protein_structure_universe"}}, "number": 6130, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6130/-/Revision", "ICLR.cc/2024/Conference/Submission6130/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409731104, "cdate": 1695409731104, "tmdate": 1707625629152, "mdate": 1707625629152, "pdate": 1705410966154, "version": 2}, {"id": "ViPtjIVzUw", "forum": "ViPtjIVzUw", "signatures": ["ICLR.cc/2024/Conference/Submission6128/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6128/Authors"], "content": {"title": {"value": "T-MARS: Improving Visual Representations by Circumventing Text Feature Learning"}, "authors": {"value": ["Pratyush Maini", "Sachin Goyal", "Zachary Chase Lipton", "J Zico Kolter", "Aditi Raghunathan"]}, "authorids": {"value": ["~Pratyush_Maini1", "~Sachin_Goyal1", "~Zachary_Chase_Lipton1", "~J_Zico_Kolter1", "~Aditi_Raghunathan1"]}, "keywords": {"value": ["Data Cleaning", "CLIP", "Image-caption", "Hard examples", "representation learning", "Web Scale", "LAION"]}, "TLDR": {"value": "We propose an algorithm to filter web datasets used to training CLIP, for learning better visual representations and improving zeroshot accuracy."}, "abstract": {"value": "Large web-crawled multimodal datasets have powered a slew of new methods for learning general-purpose visual representations, advancing the state of the art in computer vision and revolutionizing zero- and few-shot recognition. One crucial decision facing practitioners is how, if at all, to curate these ever-larger datasets. For example, the creators of the LAION-5B dataset chose to retain only image-caption pairs whose CLIP similarity score exceeded a designated threshold. In this paper, we propose a new state-of-the-art data filtering approach motivated by our observation that nearly $40\\%$ of LAION's images contain text that overlaps significantly with the caption. Intuitively, such data could be wasteful as it incentivizes models to perform optical character recognition rather than learning visual features. However, naively removing all such data could also be wasteful, as it throws away images that contain visual features (in addition to overlapping text). Our simple and scalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those pairs where the text dominates the remaining visual features---by first masking out the text and then filtering out those with a low CLIP similarity score of the masked image with original captions. Experimentally, T-MARS is the top ranked approach on Imagenet at ``medium scale'' of DataComp (a data filtering benchmark), and outperforms CLIP filtering by a margin of $6.5\\%$ on ImageNet and $4.7\\%$ on VTAB. Additionally, we show that the accuracy gains enjoyed by T-MARS linearly increase as data and compute are scaled exponentially."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/005e4cf730479d9444395283ce9cdc93c46738de.pdf"}, "supplementary_material": {"value": "/attachment/076ec1f762a988e568d1c4ea3a680eabdfea7972.zip"}, "_bibtex": {"value": "@inproceedings{\nmaini2024tmars,\ntitle={T-{MARS}: Improving Visual Representations by Circumventing Text Feature Learning},\nauthor={Pratyush Maini and Sachin Goyal and Zachary Chase Lipton and J Zico Kolter and Aditi Raghunathan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ViPtjIVzUw}\n}"}, "paperhash": {"value": "maini|tmars_improving_visual_representations_by_circumventing_text_feature_learning"}}, "number": 6128, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6128/-/Revision", "ICLR.cc/2024/Conference/Submission6128/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6128/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409699578, "cdate": 1695409699578, "tmdate": 1710532721093, "mdate": 1710532721093, "pdate": 1705410966107, "version": 2}, {"id": "fUtxNAKpdV", "forum": "fUtxNAKpdV", "signatures": ["ICLR.cc/2024/Conference/Submission6127/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6127/Authors"], "content": {"title": {"value": "Nougat: Neural Optical Understanding for Academic Documents"}, "authors": {"value": ["Lukas Blecher", "Guillem Cucurull", "Thomas Scialom", "Robert Stojnic"]}, "authorids": {"value": ["~Lukas_Blecher1", "~Guillem_Cucurull1", "~Thomas_Scialom1", "~Robert_Stojnic1"]}, "keywords": {"value": ["Visual Document Understanding", "Optical Character Recognition", "Mathematical Expression Recognition", "Information Extraction"]}, "TLDR": {"value": "A transformer-based model trained to convert document images to formatted markup text, focusing on extracting mathematical expressions and tables from scientific papers."}, "abstract": {"value": "Scientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs. However, the PDF format leads to a loss of semantic information, particularly for mathematical expressions. We propose Nougat (Neural Optical Understanding for Academic Documents), a Visual Transformer model that performs an Optical Character Recognition (OCR) task for processing scientific documents into a markup language, and demonstrate the effectiveness of our model on a new dataset of scientific documents. The proposed approach offers a promising solution to enhance the accessibility of scientific knowledge in the digital age, by bridging the gap between human- readable documents and machine-readable text. We release the models and code to accelerate future work on scientific text recognition."}, "pdf": {"value": "/pdf/661c0ec6ddf4baaba38565b44443cdde429862ad.pdf"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nblecher2024nougat,\ntitle={Nougat: Neural Optical Understanding for Academic Documents},\nauthor={Lukas Blecher and Guillem Cucurull and Thomas Scialom and Robert Stojnic},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fUtxNAKpdV}\n}"}, "paperhash": {"value": "blecher|nougat_neural_optical_understanding_for_academic_documents"}}, "number": 6127, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6127/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6127/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409663279, "cdate": 1695409663279, "tmdate": 1710423201403, "mdate": 1710423201403, "pdate": 1705410965936, "version": 2}, {"id": "STUGfUz8ob", "forum": "STUGfUz8ob", "signatures": ["ICLR.cc/2024/Conference/Submission6121/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6121/Authors"], "content": {"title": {"value": "When can transformers reason with abstract symbols?"}, "authors": {"value": ["Enric Boix-Adser\u00e0", "Omid Saremi", "Emmanuel Abbe", "Samy Bengio", "Etai Littwin", "Joshua M. Susskind"]}, "authorids": {"value": ["~Enric_Boix-Adser\u00e01", "~Omid_Saremi1", "~Emmanuel_Abbe1", "~Samy_Bengio1", "~Etai_Littwin1", "~Joshua_M._Susskind1"]}, "keywords": {"value": ["transformers", "language models", "reasoning", "theoretical analysis", "variable binding"]}, "abstract": {"value": "We investigate the capabilities of transformer models on relational reasoning tasks. In these tasks, models are trained on a set of strings encoding abstract relations, and are then tested out-of-distribution on data that contains symbols that did not appear in the training dataset. We prove that for any relational reasoning task in a large family of tasks, transformers learn the abstract relations and generalize to the test set when trained by gradient descent on sufficiently large quantities of training data. This is in contrast to classical fully-connected networks, which we prove fail to learn to reason. Our results inspire modifications of the transformer architecture that add only two trainable parameters per head, and that we empirically demonstrate improve data efficiency for learning to reason."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/971493669152ed11539340cedaab1323c6449cde.pdf"}, "supplementary_material": {"value": "/attachment/71626da1d5c816dec304d5efd9f5442c6d0be645.zip"}, "_bibtex": {"value": "@inproceedings{\nboix-adser{\\`a}2024when,\ntitle={When can transformers reason with abstract symbols?},\nauthor={Enric Boix-Adser{\\`a} and Omid Saremi and Emmanuel Abbe and Samy Bengio and Etai Littwin and Joshua M. Susskind},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=STUGfUz8ob}\n}"}, "TLDR": {"value": "Transformers learn to reason relationally given enough data, and we improve data efficiency with theory-inspired architecture modifications."}, "paperhash": {"value": "boixadser\u00e0|when_can_transformers_reason_with_abstract_symbols"}}, "number": 6121, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6121/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6121/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409376627, "cdate": 1695409376627, "tmdate": 1713162481694, "mdate": 1713162481694, "pdate": 1705410965709, "version": 2}, {"id": "IcR1OOFzxm", "forum": "IcR1OOFzxm", "signatures": ["ICLR.cc/2024/Conference/Submission6119/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6119/Authors"], "content": {"title": {"value": "Towards Generative Abstract Reasoning: Completing Raven\u2019s Progressive Matrix via Rule Abstraction and Selection"}, "authors": {"value": ["Fan Shi", "Bin Li", "Xiangyang Xue"]}, "authorids": {"value": ["~Fan_Shi1", "~Bin_Li4", "~Xiangyang_Xue2"]}, "keywords": {"value": ["Deep Latent Variable Models", "Generative Models", "Raven\u2019s Progressive Matrix", "Abstract Visual Reasoning"]}, "abstract": {"value": "Endowing machines with abstract reasoning ability has been a long-term research topic in artificial intelligence. Raven's Progressive Matrix (RPM) is widely used to probe abstract visual reasoning in machine intelligence, where models will analyze the underlying rules and select one image from candidates to complete the image matrix. Participators of RPM tests can show powerful reasoning ability by inferring and combining attribute-changing rules and imagining the missing images at arbitrary positions of a matrix. However, existing solvers can hardly manifest such an ability in realistic RPM tests. In this paper, we propose a deep latent variable model for answer generation problems through Rule AbstractIon and SElection (RAISE). RAISE can encode image attributes into latent concepts and abstract atomic rules that act on the latent concepts. When generating answers, RAISE selects one atomic rule out of the global knowledge set for each latent concept to constitute the underlying rule of an RPM. In the experiments of bottom-right and arbitrary-position answer generation, RAISE outperforms the compared solvers in most configurations of realistic RPM datasets. In the odd-one-out task and two held-out configurations, RAISE can leverage acquired latent concepts and atomic rules to find the rule-breaking image in a matrix and handle problems with unseen combinations of rules and attributes."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/10210b56a86ee6d0a6d1466b06d0e877eb9aa498.pdf"}, "supplementary_material": {"value": "/attachment/51c0bcedce6b677fa81d0395cd300b87837c827d.zip"}, "_bibtex": {"value": "@inproceedings{\nshi2024towards,\ntitle={Towards Generative Abstract Reasoning: Completing Raven{\\textquoteright}s Progressive Matrix via Rule Abstraction and Selection},\nauthor={Fan Shi and Bin Li and Xiangyang Xue},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IcR1OOFzxm}\n}"}, "TLDR": {"value": "This paper proposes a novel deep latent variable model to solve generative RPM problems through rule abstraction and selection."}, "paperhash": {"value": "shi|towards_generative_abstract_reasoning_completing_ravens_progressive_matrix_via_rule_abstraction_and_selection"}}, "number": 6119, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6119/-/Revision", "ICLR.cc/2024/Conference/Submission6119/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6119/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409348132, "cdate": 1695409348132, "tmdate": 1713091066069, "mdate": 1713091066069, "pdate": 1705410965573, "version": 2}, {"id": "79FVDdfoSR", "forum": "79FVDdfoSR", "signatures": ["ICLR.cc/2024/Conference/Submission6118/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6118/Authors"], "content": {"title": {"value": "A Characterization Theorem for Equivariant Networks with Point-wise Activations"}, "authors": {"value": ["Marco Pacini", "Xiaowen Dong", "Bruno Lepri", "Gabriele Santin"]}, "authorids": {"value": ["~Marco_Pacini1", "~Xiaowen_Dong1", "~Bruno_Lepri1", "gabriele.santin@unive.it"]}, "keywords": {"value": ["Geometric Deep Learning", "Equivariant Neural Networks", "Characterization Theorem", "Point-wise Activations"]}, "TLDR": {"value": "A characterization theorem describing admissibile combinations of representations and activation functions for equivariant layers with point-wise activations"}, "abstract": {"value": "Equivariant neural networks have shown improved performance, expressiveness and sample complexity on symmetrical domains. \nBut for some specific symmetries, representations, and choice of coordinates, the most common point-wise activations, such as ReLU, are not equivariant, hence they cannot be employed in the design of equivariant neural networks. \nThe theorem we present in this paper describes all possibile combinations of representations, choice of coordinates and point-wise activations to obtain an equivariant layer, generalizing and strengthening existing characterizations.\nNotable cases of practical relevance are discussed as corollaries. Indeed, we prove that rotation-equivariant networks can only be invariant, as it happens for any network which is equivariant with respect to connected compact groups. Then, we discuss implications of our findings when applied to important instances of equivariant networks. First, we completely characterize permutation equivariant networks such as Invariant Graph Networks with point-wise nonlinearities and their geometric counterparts, highlighting a plethora of models whose expressive power and performance are still unknown. \nSecond, we show that feature spaces of disentangled steerable convolutional neural networks are trivial representations."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6a2574965789ab10d9f1148fdd8e13ba2da7e9c0.pdf"}, "_bibtex": {"value": "@inproceedings{\npacini2024a,\ntitle={A Characterization Theorem for Equivariant Networks with Point-wise Activations},\nauthor={Marco Pacini and Xiaowen Dong and Bruno Lepri and Gabriele Santin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=79FVDdfoSR}\n}"}, "paperhash": {"value": "pacini|a_characterization_theorem_for_equivariant_networks_with_pointwise_activations"}}, "number": 6118, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6118/-/Revision", "ICLR.cc/2024/Conference/Submission6118/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6118/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409286692, "cdate": 1695409286692, "tmdate": 1710344529723, "mdate": 1710344529723, "pdate": 1705410965496, "version": 2}, {"id": "ph04CRkPdC", "forum": "ph04CRkPdC", "signatures": ["ICLR.cc/2024/Conference/Submission6107/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6107/Authors"], "content": {"title": {"value": "Think before you speak: Training Language Models With Pause Tokens"}, "authors": {"value": ["Sachin Goyal", "Ziwei Ji", "Ankit Singh Rawat", "Aditya Krishna Menon", "Sanjiv Kumar", "Vaishnavh Nagarajan"]}, "authorids": {"value": ["~Sachin_Goyal1", "~Ziwei_Ji1", "~Ankit_Singh_Rawat1", "~Aditya_Krishna_Menon1", "~Sanjiv_Kumar1", "~Vaishnavh_Nagarajan3"]}, "keywords": {"value": ["LLM training and inference", "Downstream finetuning"]}, "TLDR": {"value": "We explore delaying model's prediction of next token, by appending (learnable) pause tokens to allow increased inference-time computations ."}, "abstract": {"value": "Language models generate responses by producing a series of tokens in immediate succession: the $(K+1)^{\\rm th}$ token is an outcome of manipulating $K$ hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, $K+10$ hidden vectors, before it outputs the $(K+1)^{\\rm th}$ token? We operationalize this idea by performing\n training and inference on language models with a (learnable) $\\textit{pause}$ token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate $\\textit{pause-training}$ on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that inference-time delays show gains when the model is both pre-trained and finetuned with delays. For the 1B model, we witness gains on 8 of 9 tasks, most prominently, a gain of $18\\\\%$ EM score on the QA task of SQuAD, $8\\\\%$ on CommonSenseQA and $1\\\\%$ accuracy on the reasoning task of GSM8k. Our work raises a range of conceptual and practical future research questions on making delayed next-token prediction a widely applicable new paradigm."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dd53d7b0142af5b4022b4a4522482152efa9b661.pdf"}, "_bibtex": {"value": "@inproceedings{\ngoyal2024think,\ntitle={Think before you speak: Training Language Models With Pause Tokens},\nauthor={Sachin Goyal and Ziwei Ji and Ankit Singh Rawat and Aditya Krishna Menon and Sanjiv Kumar and Vaishnavh Nagarajan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ph04CRkPdC}\n}"}, "paperhash": {"value": "goyal|think_before_you_speak_training_language_models_with_pause_tokens"}}, "number": 6107, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6107/-/Revision", "ICLR.cc/2024/Conference/Submission6107/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6107/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409105401, "cdate": 1695409105401, "tmdate": 1710645568178, "mdate": 1710645568178, "pdate": 1705410964922, "version": 2}, {"id": "IuXR1CCrSi", "forum": "IuXR1CCrSi", "signatures": ["ICLR.cc/2024/Conference/Submission6105/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6105/Authors"], "content": {"title": {"value": "Talk like a Graph: Encoding Graphs for Large Language Models"}, "authors": {"value": ["Bahare Fatemi", "Jonathan Halcrow", "Bryan Perozzi"]}, "authorids": {"value": ["~Bahare_Fatemi1", "~Jonathan_Halcrow1", "~Bryan_Perozzi1"]}, "keywords": {"value": ["Graph problems", "large language models", "encoding graphs", "generative models"]}, "abstract": {"value": "Graphs are a powerful tool for representing and analyzing complex relationships in real-world applications such as social networks, recommender systems, and computational finance. Reasoning on graphs is essential for drawing inferences about the relationships between entities in a complex system, and to identify hidden patterns and trends. Despite the remarkable progress in automated reasoning with natural text, reasoning on graphs with large language models (LLMs) remains an understudied problem. In this work, we perform the first comprehensive study of encoding graph-structured data as text for consumption by LLMs. We show that LLM performance on graph reasoning tasks varies on three fundamental levels: (1) the graph encoding method, (2) the nature of the graph task itself, and (3) interestingly, the very structure of the graph considered. These novel results provide valuable insight on strategies for encoding graphs as text. Using these insights we illustrate how the correct choice of encoders can boost performance on graph reasoning tasks inside LLMs by 4.8% to 61.8%, depending on the task."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ef301edfe05ea96f66b94b4ffcf33ee657cd4af2.pdf"}, "supplementary_material": {"value": "/attachment/d6cb4ff68ef36170c02ac326120076393a2814e3.pdf"}, "_bibtex": {"value": "@inproceedings{\nfatemi2024talk,\ntitle={Talk like a Graph: Encoding Graphs for Large Language Models},\nauthor={Bahare Fatemi and Jonathan Halcrow and Bryan Perozzi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IuXR1CCrSi}\n}"}, "paperhash": {"value": "fatemi|talk_like_a_graph_encoding_graphs_for_large_language_models"}}, "number": 6105, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6105/-/Revision", "ICLR.cc/2024/Conference/Submission6105/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6105/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695409018870, "cdate": 1695409018870, "tmdate": 1709661527904, "mdate": 1709661527904, "pdate": 1705410964864, "version": 2}, {"id": "3d0OmYTNui", "forum": "3d0OmYTNui", "signatures": ["ICLR.cc/2024/Conference/Submission6097/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6097/Authors"], "content": {"title": {"value": "Privately Aligning Language Models with Reinforcement Learning"}, "authors": {"value": ["Fan Wu", "Huseyin A Inan", "Arturs Backurs", "Varun Chandrasekaran", "Janardhan Kulkarni", "Robert Sim"]}, "authorids": {"value": ["~Fan_Wu6", "~Huseyin_A_Inan1", "~Arturs_Backurs1", "~Varun_Chandrasekaran1", "~Janardhan_Kulkarni2", "~Robert_Sim1"]}, "keywords": {"value": ["Large Language Models", "RLHF", "Alignment", "Differential Privacy"]}, "abstract": {"value": "Positioned between pre-training and user deployment, aligning large language models (LLMs) through reinforcement learning (RL) has emerged as a prevailing strategy for training instruction following-models such as ChatGPT. In this work, we initiate the study of privacy-preserving alignment of LLMs through Differential Privacy (DP) in conjunction with RL. Following the influential work of Ziegler et al. (2020), we study two dominant paradigms: (i) alignment via RL without human in the loop (e.g., positive review generation) and (ii) alignment via RL from human feedback (RLHF) (e.g., summarization in a human-preferred way). We give a new DP framework to achieve alignment via RL, and prove its correctness. Our experimental results validate the effectiveness of our approach, offering competitive utility while ensuring strong privacy protections."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b9290f78e5b5e1b100344b9ffc088b82811bdadb.pdf"}, "supplementary_material": {"value": "/attachment/8533995075a0f8cc73da220bc27a7b4b58895d3f.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024privately,\ntitle={Privately Aligning Language Models with Reinforcement Learning},\nauthor={Fan Wu and Huseyin A Inan and Arturs Backurs and Varun Chandrasekaran and Janardhan Kulkarni and Robert Sim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3d0OmYTNui}\n}"}, "paperhash": {"value": "wu|privately_aligning_language_models_with_reinforcement_learning"}}, "number": 6097, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6097/-/Revision", "ICLR.cc/2024/Conference/Submission6097/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6097/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695408647503, "cdate": 1695408647503, "tmdate": 1709661527661, "mdate": 1709661527661, "pdate": 1705410964451, "version": 2}, {"id": "wHBfxhZu1u", "forum": "wHBfxhZu1u", "signatures": ["ICLR.cc/2024/Conference/Submission6096/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6096/Authors"], "content": {"title": {"value": "YaRN: Efficient Context Window Extension of Large Language Models"}, "authors": {"value": ["Bowen Peng", "Jeffrey Quesnelle", "Honglu Fan", "Enrico Shippole"]}, "authorids": {"value": ["~Bowen_Peng1", "~Jeffrey_Quesnelle1", "~Honglu_Fan1", "~Enrico_Shippole1"]}, "keywords": {"value": ["transformers", "nlp", "fine-tuning", "context window", "attention", "rotary embedding"]}, "abstract": {"value": "Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. The models fine-tuned using YaRN has been made available and reproduced online up to 128k context length."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e1ffb77d65ae757d3e897e2d117d87fdb46bd509.pdf"}, "supplementary_material": {"value": "/attachment/0228d73b37d847170cfdb58dc6af360620eb089f.zip"}, "TLDR": {"value": "We build on Positional Interpolation and achieve SOTA performance in extending the context window of decoder-only transformer using Rotary Embedding, both with and without finetuning."}, "_bibtex": {"value": "@inproceedings{\npeng2024yarn,\ntitle={Ya{RN}: Efficient Context Window Extension of Large Language Models},\nauthor={Bowen Peng and Jeffrey Quesnelle and Honglu Fan and Enrico Shippole},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wHBfxhZu1u}\n}"}, "paperhash": {"value": "peng|yarn_efficient_context_window_extension_of_large_language_models"}}, "number": 6096, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6096/-/Revision", "ICLR.cc/2024/Conference/Submission6096/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6096/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695408644451, "cdate": 1695408644451, "tmdate": 1709965154429, "mdate": 1709965154429, "pdate": 1705410964433, "version": 2}, {"id": "Kuj5gVp5GQ", "forum": "Kuj5gVp5GQ", "signatures": ["ICLR.cc/2024/Conference/Submission6085/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6085/Authors"], "content": {"title": {"value": "Accelerating Sinkhorn algorithm with sparse Newton iterations"}, "authors": {"value": ["Xun Tang", "Michael Shavlovsky", "Holakou Rahmanian", "Elisa Tardini", "Kiran Koshy Thekumparampil", "Tesi Xiao", "Lexing Ying"]}, "authorids": {"value": ["xuntang@stanford.edu", "~Michael_Shavlovsky1", "~Holakou_Rahmanian2", "ettardin@amazon.com", "~Kiran_Koshy_Thekumparampil1", "~Tesi_Xiao1", "~Lexing_Ying1"]}, "keywords": {"value": ["Optimal transport", "Convex optimization", "Quasi-Newton methods", "Non-asymptotic analysis", "Extremal combinatorics"]}, "TLDR": {"value": "A quasi-Newton method with a sparse approximation of a Hessian matrix greatly accelerates entropic optimal transport in both iteration count and in runtime. Numerical analysis is provided which corroborates the algorithm."}, "abstract": {"value": "Computing the optimal transport distance between statistical distributions is a fundamental task in machine learning. One remarkable recent advancement is entropic regularization and the Sinkhorn algorithm, which utilizes only matrix scaling and guarantees an approximated solution with near-linear runtime. Despite the success of the Sinkhorn algorithm, its runtime may still be slow due to the potentially large number of iterations needed for convergence. To achieve possibly super-exponential convergence, we introduce Sinkhorn-Newton-Sparse (SNS), an extension to the Sinkhorn algorithm, by introducing early stopping for the matrix scaling steps and a second stage featuring a Newton-type subroutine. Adopting the variational viewpoint that the Sinkhorn algorithm maximizes a concave Lyapunov potential, we offer the insight that the Hessian matrix of the potential function is approximately sparse. Sparsification of the Hessian results in a fast $O(n^2)$ per-iteration complexity, the same as the Sinkhorn algorithm.  In terms of total iteration count, we observe that the SNS algorithm converges orders of magnitude faster across a wide range of practical cases, including optimal transportation between empirical distributions and calculating the Wasserstein $W_1, W_2$ distance of discretized continuous densities. The empirical performance is corroborated by a rigorous bound on the approximate sparsity of the Hessian matrix."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ad0c50781fe7c375ece5d9a170b96bf3e63272b4.pdf"}, "supplementary_material": {"value": "/attachment/37442484298915fe571ceb84896cce660bd2d434.zip"}, "_bibtex": {"value": "@inproceedings{\ntang2024accelerating,\ntitle={Accelerating Sinkhorn algorithm with sparse Newton iterations},\nauthor={Xun Tang and Michael Shavlovsky and Holakou Rahmanian and Elisa Tardini and Kiran Koshy Thekumparampil and Tesi Xiao and Lexing Ying},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Kuj5gVp5GQ}\n}"}, "paperhash": {"value": "tang|accelerating_sinkhorn_algorithm_with_sparse_newton_iterations"}}, "number": 6085, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6085/-/Revision", "ICLR.cc/2024/Conference/Submission6085/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6085/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695408453514, "cdate": 1695408453514, "tmdate": 1709661527567, "mdate": 1709661527567, "pdate": 1705410964101, "version": 2}, {"id": "rR03qFesqk", "forum": "rR03qFesqk", "signatures": ["ICLR.cc/2024/Conference/Submission6081/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6081/Authors"], "content": {"title": {"value": "Functional Interpolation for Relative Positions improves Long Context Transformers"}, "authors": {"value": ["Shanda Li", "Chong You", "Guru Guruganesh", "Joshua Ainslie", "Santiago Ontanon", "Manzil Zaheer", "Sumit Sanghai", "Yiming Yang", "Sanjiv Kumar", "Srinadh Bhojanapalli"]}, "authorids": {"value": ["~Shanda_Li1", "~Chong_You2", "~Guru_Guruganesh1", "~Joshua_Ainslie1", "~Santiago_Ontanon1", "~Manzil_Zaheer1", "~Sumit_Sanghai1", "~Yiming_Yang1", "~Sanjiv_Kumar1", "~Srinadh_Bhojanapalli1"]}, "keywords": {"value": ["Transformers", "positional encoding", "long context", "length generalization"]}, "abstract": {"value": "Preventing the performance decay of Transformers on inputs longer than those used for training has been an important challenge in extending the context length of these models. Though the Transformer architecture has fundamentally no limits on the input sequence lengths it can process, the choice of position encoding used during training can limit the performance of these models on longer inputs. We propose a novel functional relative position encoding with progressive interpolation, FIRE, to improve Transformer generalization to longer contexts. We theoretically prove that this can represent some of the popular relative position encodings, such as T5's RPE, Alibi, and Kerple. We next empirically show that FIRE models have better generalization to longer contexts on both zero-shot language modeling and long text benchmarks."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1f132a732fc9a26438768ff4457100d39234a220.pdf"}, "TLDR": {"value": "We propose a novel functional relative position encoding with progressive interpolation to improve Transformer generalization to longer contexts."}, "_bibtex": {"value": "@inproceedings{\nli2024functional,\ntitle={Functional Interpolation for Relative Positions improves Long Context Transformers},\nauthor={Shanda Li and Chong You and Guru Guruganesh and Joshua Ainslie and Santiago Ontanon and Manzil Zaheer and Sumit Sanghai and Yiming Yang and Sanjiv Kumar and Srinadh Bhojanapalli},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rR03qFesqk}\n}"}, "paperhash": {"value": "li|functional_interpolation_for_relative_positions_improves_long_context_transformers"}}, "number": 6081, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6081/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6081/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695408287819, "cdate": 1695408287819, "tmdate": 1709661527531, "mdate": 1709661527531, "pdate": 1705410963989, "version": 2}, {"id": "GkJiNn2QDF", "forum": "GkJiNn2QDF", "signatures": ["ICLR.cc/2024/Conference/Submission6071/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6071/Authors"], "content": {"title": {"value": "FeatUp: A Model-Agnostic Framework for Features at Any Resolution"}, "authors": {"value": ["Stephanie Fu", "Mark Hamilton", "Laura E. Brandt", "Axel Feldmann", "Zhoutong Zhang", "William T. Freeman"]}, "authorids": {"value": ["~Stephanie_Fu1", "~Mark_Hamilton1", "~Laura_E._Brandt1", "~Axel_Feldmann1", "~Zhoutong_Zhang1", "~William_T._Freeman1"]}, "keywords": {"value": ["deep learning", "deep features", "computer vision", "feature upsampling"]}, "TLDR": {"value": "We introduce a method for obtaining high-resolution features from any vision model, trainable end-to-end with the model itself and producing high-quality results on vision tasks."}, "abstract": {"value": "Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-training. We show that FeatUp significantly outperforms other feature upsampling and image super-resolution approaches in class activation map generation, transfer learning for segmentation and depth prediction, and end-to-end training for semantic segmentation."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d36dba375a7e2fae92d0b4db81ebd3ad444f06dc.pdf"}, "_bibtex": {"value": "@inproceedings{\nfu2024featup,\ntitle={FeatUp: A Model-Agnostic Framework for Features at Any Resolution},\nauthor={Stephanie Fu and Mark Hamilton and Laura E. Brandt and Axel Feldmann and Zhoutong Zhang and William T. Freeman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GkJiNn2QDF}\n}"}, "paperhash": {"value": "fu|featup_a_modelagnostic_framework_for_features_at_any_resolution"}}, "number": 6071, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6071/-/Revision", "ICLR.cc/2024/Conference/Submission6071/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6071/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695407760234, "cdate": 1695407760234, "tmdate": 1710476308053, "mdate": 1710476308053, "pdate": 1705410963661, "version": 2}, {"id": "Q53QLftNkA", "forum": "Q53QLftNkA", "signatures": ["ICLR.cc/2024/Conference/Submission6063/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6063/Authors"], "content": {"title": {"value": "Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners"}, "authors": {"value": ["Sarthak Yadav", "Sergios Theodoridis", "Lars Kai Hansen", "Zheng-Hua Tan"]}, "authorids": {"value": ["~Sarthak_Yadav1", "~Sergios_Theodoridis1", "~Lars_Kai_Hansen1", "~Zheng-Hua_Tan1"]}, "keywords": {"value": ["self-supervised learning", "masked autoencoder", "audio representation learning"]}, "TLDR": {"value": "Masked Autoencoders fitted with Multi-Window Multi-Head Attention (MW-MAEs) explicitly model local-global context in all transformer blocks, and outperform standard Masked Autoencoders for learning a general-purpose audio representation."}, "abstract": {"value": "In this work, we propose a Multi-Window Masked Autoencoder (MW-MAE) fitted with a novel Multi-Window Multi-Head Attention (MW-MHA) module that facilitates the modelling of local-global interactions in every decoder transformer block through attention heads of several distinct local and global windows. Empirical results on ten downstream audio tasks show that MW-MAEs consistently outperform standard MAEs in overall performance and learn better general-purpose audio representations, along with demonstrating considerably better scaling characteristics. Investigating attention distances and entropies reveals that MW-MAE encoders learn heads with broader local and global attention. Analyzing attention head feature representations through Projection Weighted Canonical Correlation Analysis (PWCCA) shows that attention heads with the same window sizes across the decoder layers of the MW-MAE learn correlated feature representations which enables each block to independently capture local and global information, leading to a decoupled decoder feature hierarchy."}, "pdf": {"value": "/pdf/32eaf080ff18fa29d704c6a92e34555ed55c0fb7.pdf"}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nyadav2024masked,\ntitle={Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners},\nauthor={Sarthak Yadav and Sergios Theodoridis and Lars Kai Hansen and Zheng-Hua Tan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Q53QLftNkA}\n}"}, "paperhash": {"value": "yadav|masked_autoencoders_with_multiwindow_localglobal_attention_are_better_audio_learners"}}, "number": 6063, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6063/-/Revision", "ICLR.cc/2024/Conference/Submission6063/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6063/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695407256673, "cdate": 1695407256673, "tmdate": 1709661527355, "mdate": 1709661527355, "pdate": 1705410963503, "version": 2}, {"id": "J2TZgj3Tac", "forum": "J2TZgj3Tac", "signatures": ["ICLR.cc/2024/Conference/Submission6059/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6059/Authors"], "content": {"title": {"value": "Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games"}, "authors": {"value": ["Stephen Marcus McAleer", "JB Lanier", "Kevin A. Wang", "Pierre Baldi", "Tuomas Sandholm", "Roy Fox"]}, "authorids": {"value": ["~Stephen_Marcus_McAleer1", "~JB_Lanier1", "~Kevin_A._Wang1", "~Pierre_Baldi1", "~Tuomas_Sandholm1", "~Roy_Fox1"]}, "keywords": {"value": ["PSRO", "game theory", "deep RL", "Nash", "population"]}, "TLDR": {"value": "We improve PSRO by not increasing exploitability and adding mixed strategies"}, "abstract": {"value": "In competitive two-agent environments, deep reinforcement learning (RL) methods like Policy Space Response Oracles (PSRO) often increase exploitability between iterations, which is problematic when training in large games. To address this issue, we introduce anytime double oracle (ADO), an algorithm that ensures exploitability does not increase between iterations, and its approximate extensive-form version, anytime PSRO (APSRO). ADO converges to a Nash equilibrium while iteratively reducing exploitability. However, convergence in these algorithms may require adding all of a game's deterministic policies. To improve this, we propose Self-Play PSRO (SP-PSRO), which incorporates an approximately optimal stochastic policy into the population in each iteration. APSRO and SP-PSRO demonstrate lower exploitability and near-monotonic exploitability reduction in games like Leduc poker and Liar's Dice. Empirically, SP-PSRO often converges much faster than APSRO and PSRO, requiring only a few iterations in many games."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9d7e6c1fae422bdb43e5530382eec1661be2b3e1.pdf"}, "_bibtex": {"value": "@inproceedings{\nmcaleer2024toward,\ntitle={Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games},\nauthor={Stephen Marcus McAleer and JB Lanier and Kevin A. Wang and Pierre Baldi and Tuomas Sandholm and Roy Fox},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=J2TZgj3Tac}\n}"}, "paperhash": {"value": "mcaleer|toward_optimal_policy_population_growth_in_twoplayer_zerosum_games"}}, "number": 6059, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6059/-/Revision", "ICLR.cc/2024/Conference/Submission6059/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6059/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695406974459, "cdate": 1695406974459, "tmdate": 1712013866104, "mdate": 1712013866104, "pdate": 1705410963363, "version": 2}, {"id": "F76bwRSLeK", "forum": "F76bwRSLeK", "signatures": ["ICLR.cc/2024/Conference/Submission6054/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6054/Authors"], "content": {"title": {"value": "Sparse Autoencoders Find Highly Interpretable Features in Language Models"}, "authors": {"value": ["Robert Huben", "Hoagy Cunningham", "Logan Riggs Smith", "Aidan Ewart", "Lee Sharkey"]}, "authorids": {"value": ["~Robert_Huben1", "~Hoagy_Cunningham1", "~Logan_Riggs_Smith1", "~Aidan_Ewart1", "~Lee_Sharkey1"]}, "keywords": {"value": ["language model", "interpretability", "representation learning", "sparsity", "dictionary learning", "unsupervised learning"]}, "TLDR": {"value": "We use a scalable and unsupervised method called Sparse Autoencoders to find interpretable, monosemantic features in the residual streams of real LLMs (Pythia-70M/410M)."}, "abstract": {"value": "One of the roadblocks to a better understanding of neural networks' internals is \\textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \\textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Moreover, we show that with our learned set of features, we can pinpoint the features that are causally responsible for counterfactual behaviour on the indirect object identification task \\citep{wang2022interpretability} to a finer degree than previous decompositions. This work indicates that it is possible to resolve superposition in language models using a scalable, unsupervised method. Our method may serve as a foundation for future mechanistic interpretability work, which we hope will enable greater model transparency and steerability."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/032ca516cd5bf1a6f63a5997b2386a41240a72a6.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuben2024sparse,\ntitle={Sparse Autoencoders Find Highly Interpretable Features in Language Models},\nauthor={Robert Huben and Hoagy Cunningham and Logan Riggs Smith and Aidan Ewart and Lee Sharkey},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=F76bwRSLeK}\n}"}, "paperhash": {"value": "huben|sparse_autoencoders_find_highly_interpretable_features_in_language_models"}}, "number": 6054, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6054/-/Revision", "ICLR.cc/2024/Conference/Submission6054/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695406757715, "cdate": 1695406757715, "tmdate": 1707625628495, "mdate": 1707625628495, "pdate": 1705410963206, "version": 2}, {"id": "FbuyDzZTPt", "forum": "FbuyDzZTPt", "signatures": ["ICLR.cc/2024/Conference/Submission6042/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6042/Authors"], "content": {"title": {"value": "OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning"}, "authors": {"value": ["Wei-Cheng Huang", "Chun-Fu Chen", "Hsiang Hsu"]}, "authorids": {"value": ["~Wei-Cheng_Huang1", "~Chun-Fu_Chen1", "~Hsiang_Hsu1"]}, "keywords": {"value": ["Rehearsal-free continual learning", "Class-incremental learning", "Parameter-efficient fine-tuning", "Outlier regularization"]}, "abstract": {"value": "Recent works have shown that by using large pre-trained models along with learnable prompts, rehearsal-free methods\nfor class-incremental learning (CIL) settings can achieve superior performance to prominent rehearsal-based ones.\nRehearsal-free CIL methods struggle with distinguishing classes from different tasks, as those are not trained together.\nIn this work we propose a regularization method based on virtual outliers to tighten decision boundaries of the classifier,\nsuch that confusion of classes among different tasks is mitigated.\nRecent prompt-based methods often require a pool of task-specific prompts, in order to prevent overwriting knowledge\nof previous tasks with that of the new task, leading to extra computation in querying and composing an\nappropriate prompt from the pool.\nThis additional cost can be eliminated, without sacrificing accuracy, as we reveal in the paper.\nWe illustrate that a simplified prompt-based method can achieve results comparable to\nprevious state-of-the-art (SOTA) methods equipped with a prompt pool, using much less learnable parameters and lower inference cost.\nOur regularization method has demonstrated its compatibility with different prompt-based methods, boosting\nthose previous SOTA rehearsal-free CIL methods' accuracy on the ImageNet-R and CIFAR-100 benchmarks. Our source code is available at https://github.com/jpmorganchase/ovor."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/aad94b4172d7b69a2fb7313c1d3cec1e05918376.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024ovor,\ntitle={{OVOR}: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning},\nauthor={Wei-Cheng Huang and Chun-Fu Chen and Hsiang Hsu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FbuyDzZTPt}\n}"}, "paperhash": {"value": "huang|ovor_oneprompt_with_virtual_outlier_regularization_for_rehearsalfree_classincremental_learning"}}, "number": 6042, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6042/-/Revision", "ICLR.cc/2024/Conference/Submission6042/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6042/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695405995855, "cdate": 1695405995855, "tmdate": 1709661527121, "mdate": 1709661527121, "pdate": 1705410962901, "version": 2}, {"id": "yiMB2DOjsR", "forum": "yiMB2DOjsR", "signatures": ["ICLR.cc/2024/Conference/Submission6039/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6039/Authors"], "content": {"title": {"value": "Chain of Log-Concave Markov Chains"}, "authors": {"value": ["Saeed Saremi", "Ji Won Park", "Francis Bach"]}, "authorids": {"value": ["~Saeed_Saremi1", "~Ji_Won_Park1", "~Francis_Bach1"]}, "keywords": {"value": ["Langevin diffusion", "log-concave distribution", "kernel smoothing"]}, "abstract": {"value": "We introduce a theoretical framework for sampling from unnormalized densities based on a smoothing scheme that uses an isotropic Gaussian kernel with a single fixed noise scale. We prove one can decompose sampling from a density (minimal assumptions made on the density) into a sequence of sampling from log-concave conditional densities via accumulation of noisy measurements with equal noise levels. Our construction is unique in that it keeps track of a history of samples, making it non-Markovian as a whole, but it is lightweight algorithmically as the history only shows up in the form of a running empirical mean of samples. Our sampling algorithm generalizes walk-jump sampling (Saremi & Hyv\u00e4rinen, 2019). The \"walk\" phase becomes a (non-Markovian) chain of (log-concave) Markov chains. The \"jump\" from the accumulated measurements is obtained by empirical Bayes. We study our sampling algorithm quantitatively using the 2-Wasserstein metric and compare it with various Langevin MCMC algorithms. We also report a remarkable capacity of our algorithm to \"tunnel\" between modes of a distribution."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9108c3cd40a2dd4f1017064c615f08e961b62082.pdf"}, "_bibtex": {"value": "@inproceedings{\nsaremi2024chain,\ntitle={Chain of Log-Concave Markov Chains},\nauthor={Saeed Saremi and Ji Won Park and Francis Bach},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yiMB2DOjsR}\n}"}, "paperhash": {"value": "saremi|chain_of_logconcave_markov_chains"}}, "number": 6039, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6039/-/Revision", "ICLR.cc/2024/Conference/Submission6039/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695405941556, "cdate": 1695405941556, "tmdate": 1707625628341, "mdate": 1707625628341, "pdate": 1705410962846, "version": 2}, {"id": "BxHgpC6FNv", "forum": "BxHgpC6FNv", "signatures": ["ICLR.cc/2024/Conference/Submission6036/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6036/Authors"], "content": {"title": {"value": "Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data"}, "authors": {"value": ["Zhiwei Xu", "Yutong Wang", "Spencer Frei", "Gal Vardi", "Wei Hu"]}, "authorids": {"value": ["~Zhiwei_Xu6", "~Yutong_Wang1", "~Spencer_Frei1", "~Gal_Vardi1", "~Wei_Hu1"]}, "keywords": {"value": ["benign overfitting", "grokking", "neural networks", "feature learning", "interpolation", "theory"]}, "abstract": {"value": "Neural networks trained by gradient descent (GD) have exhibited a number of surprising generalization behaviors. First, they can achieve a perfect fit to noisy training data and still generalize near-optimally, showing that overfitting can sometimes be benign. Second, they can undergo a period of classical, harmful overfitting---achieving a perfect fit to training data with near-random performance on test data---before transitioning (''grokking'') to near-optimal generalization later in training. In this work, we show that both of these phenomena provably occur in two-layer ReLU networks trained by GD on XOR cluster data where a constant fraction of the training labels are flipped. In this setting, we show that after the first step of GD, the network achieves 100\\% training accuracy, perfectly fitting the noisy labels in the training data, but achieves near-random test accuracy. At a later training step, the network achieves near-optimal test accuracy while still fitting the random labels in the training data, exhibiting a ''grokking'' phenomenon. This provides the first theoretical result of benign overfitting in neural network classification when the data distribution is not linearly separable. Our proofs rely on analyzing the feature learning process under GD, which reveals that the network implements a non-generalizable linear classifier after one step and gradually learns generalizable features in later steps."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/39dd4b0c8c813b57e8116197b229d998b5770c44.pdf"}, "_bibtex": {"value": "@inproceedings{\nxu2024benign,\ntitle={Benign Overfitting and Grokking in Re{LU} Networks for {XOR} Cluster Data},\nauthor={Zhiwei Xu and Yutong Wang and Spencer Frei and Gal Vardi and Wei Hu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BxHgpC6FNv}\n}"}, "paperhash": {"value": "xu|benign_overfitting_and_grokking_in_relu_networks_for_xor_cluster_data"}}, "number": 6036, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6036/-/Revision", "ICLR.cc/2024/Conference/Submission6036/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6036/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695405872060, "cdate": 1695405872060, "tmdate": 1710561447107, "mdate": 1710561447107, "pdate": 1705410962599, "version": 2}, {"id": "EArTDUmILF", "forum": "EArTDUmILF", "signatures": ["ICLR.cc/2024/Conference/Submission6021/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6021/Authors"], "content": {"title": {"value": "VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"}, "authors": {"value": ["Chenyu Liu", "XINLIANG ZHOU", "Zhengri Zhu", "Liming Zhai", "Ziyu Jia", "Yang Liu"]}, "authorids": {"value": ["~Chenyu_Liu5", "~XINLIANG_ZHOU1", "~Zhengri_Zhu1", "~Liming_Zhai1", "~Ziyu_Jia1", "~Yang_Liu36"]}, "keywords": {"value": ["EEG", "Emotion Recognition", "Multi-modal", "Domain Adaptation", "Cross-subject"]}, "abstract": {"value": "The research on human emotion under electroencephalogram (EEG) is an emerging field in which cross-subject emotion recognition (ER) is a promising but challenging task. Many approaches attempt to find emotionally relevant domain-invariant features using domain adaptation (DA) to improve the accuracy of cross-subject ER. However, two problems still exist with these methods. First, only single-modal data (EEG) is utilized, ignoring the complementarity between multi-modal physiological signals. Second, these methods aim to completely match the signal features between different domains, which is difficult due to the extreme individual differences of EEG. To solve these problems, we introduce the complementarity of multi-modal physiological signals and propose a new method for cross-subject ER that does not align the distribution of signal features but rather the distribution of spatio-temporal relationships between features. We design a Variational Bayesian Heterogeneous Graph Neural Network (VBH-GNN) with Relationship Distribution Adaptation (RDA). The RDA first aligns the domains by expressing the model space as a posterior distribution of a heterogeneous graph for a given source domain. Then, the RDA transforms the heterogeneous graph into an emotion-specific graph to further align the domains for the downstream ER task. Extensive experiments on two public datasets, DEAP and Dreamer, show that our VBH-GNN outperforms state-of-the-art methods in cross-subject scenarios."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8a045a606abf89ad24e81dea7ff199c2cb5fe88a.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024vbhgnn,\ntitle={{VBH}-{GNN}: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition},\nauthor={Chenyu Liu and XINLIANG ZHOU and Zhengri Zhu and Liming Zhai and Ziyu Jia and Yang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EArTDUmILF}\n}"}, "paperhash": {"value": "liu|vbhgnn_variational_bayesian_heterogeneous_graph_neural_networks_for_crosssubject_emotion_recognition"}}, "number": 6021, "odate": 1697213872796, "pdate": 1705410962214, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6021/-/Revision", "ICLR.cc/2024/Conference/Submission6021/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6021/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695405327812, "cdate": 1695405327812, "tmdate": 1710319255552, "mdate": 1710319255552, "version": 2}, {"id": "WNQjN5HzXt", "forum": "WNQjN5HzXt", "signatures": ["ICLR.cc/2024/Conference/Submission6015/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6015/Authors"], "content": {"title": {"value": "AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images"}, "authors": {"value": ["Prithvijit Chattopadhyay", "Bharat Goyal", "Boglarka Ecsedi", "Viraj Uday Prabhu", "Judy Hoffman"]}, "authorids": {"value": ["~Prithvijit_Chattopadhyay1", "~Bharat_Goyal1", "~Boglarka_Ecsedi1", "~Viraj_Uday_Prabhu1", "~Judy_Hoffman1"]}, "keywords": {"value": ["Unsupervised Domain Adaptation", "Sim2Real"]}, "TLDR": {"value": "A method to reduce miscalibration for unsupervised Sim2Real adaptation by optimizing for calibrated predictions on augmented synthetic data."}, "abstract": {"value": "Synthetic data (Sim) drawn from simulators have emerged as a popular alternativefor training models where acquiring annotated real-world images is difficult. However, transferring models trained on synthetic images to real-world applicationscan be challenging due to appearance disparities. A commonly employed solution to counter this Sim2Real gap is unsupervised domain adaptation, where models are trained using labeled Sim data and unlabeled Real data. Mispredictions made by such Sim2Real adapted models are often associated with miscalibration \u2013 stemming from overconfident predictions on real data. In this paper, we introduce AUGCAL, a simple training-time patch for unsupervised adaptation that improves Sim2Real adapted models by \u2013 (1) reducing overall miscalibration, (2) reducing overconfidence in incorrect predictions and (3) improving confidence score reliability by better guiding misclassification detection \u2013 all while retaining or improving Sim2Real performance. Given a base Sim2Real adaptation algorithm, at training time, AUGCAL involves replacing vanilla Sim images with strongly augmented views (AUG intervention) and additionally optimizing for a training time calibration loss on augmented Sim predictions (CAL intervention). We motivate AUGCAL using a brief analytical justification of how to reduce miscalibration on unlabeled REAL data. Through our experiments, we empirically show the efficacy of AUGCAL across multiple adaptation methods, backbones, tasks and shifts."}, "pdf": {"value": "/pdf/4f20af9c38d0b7f42f702485207a3f1ec51ee183.pdf"}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nchattopadhyay2024augcal,\ntitle={{AUGCAL}: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images},\nauthor={Prithvijit Chattopadhyay and Bharat Goyal and Boglarka Ecsedi and Viraj Uday Prabhu and Judy Hoffman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WNQjN5HzXt}\n}"}, "paperhash": {"value": "chattopadhyay|augcal_improving_sim2real_adaptation_by_uncertainty_calibration_on_augmented_synthetic_images"}}, "number": 6015, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6015/-/Revision", "ICLR.cc/2024/Conference/Submission6015/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6015/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695405054339, "cdate": 1695405054339, "tmdate": 1710521116820, "mdate": 1710521116820, "pdate": 1705410961876, "version": 2}, {"id": "owokKCrGYr", "forum": "owokKCrGYr", "signatures": ["ICLR.cc/2024/Conference/Submission6013/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6013/Authors"], "content": {"title": {"value": "Quality-Diversity through AI Feedback"}, "authors": {"value": ["Herbie Bradley", "Andrew Dai", "Hannah Benita Teufel", "Jenny Zhang", "Koen Oostermeijer", "Marco Bellagente", "Jeff Clune", "Kenneth Stanley", "Gregory Schott", "Joel Lehman"]}, "authorids": {"value": ["~Herbie_Bradley1", "~Andrew_Dai1", "~Hannah_Benita_Teufel1", "~Jenny_Zhang1", "~Koen_Oostermeijer1", "~Marco_Bellagente1", "~Jeff_Clune3", "~Kenneth_Stanley1", "~Gregory_Schott1", "~Joel_Lehman1"]}, "keywords": {"value": ["quality diversity", "large language models", "derivative-free optimization", "AI feedback"]}, "abstract": {"value": "In many text-generation problems, users may prefer not only a single response, but a diverse range of high-quality outputs from which to choose. Quality-diversity (QD) search algorithms aim at such outcomes, by continually improving and diversifying a population of candidates. However, the applicability of QD to qualitative domains, like creative writing, has been limited by the difficulty of algorithmically specifying measures of quality and diversity. Interestingly, recent developments in language models (LMs) have enabled guiding search through \\emph{AI feedback}, wherein LMs are prompted in natural language to evaluate qualitative aspects of text. Leveraging this development, we introduce Quality-Diversity through AI Feedback (QDAIF), wherein an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. When assessed on creative writing domains, QDAIF covers more of a specified search space with high-quality samples than do non-QD controls. Further, human evaluation of QDAIF-generated creative texts validates reasonable agreement between AI and human evaluation. Our results thus highlight the potential of AI feedback to guide open-ended search for creative and original solutions, providing a recipe that seemingly generalizes to many domains and modalities. In this way, QDAIF is a step towards AI systems that can independently search, diversify, evaluate, and improve, which are among the core skills underlying human society's capacity for innovation."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/54561bdbacad96eca2110e27a66213f904e88070.pdf"}, "_bibtex": {"value": "@inproceedings{\nbradley2024qualitydiversity,\ntitle={Quality-Diversity through {AI} Feedback},\nauthor={Herbie Bradley and Andrew Dai and Hannah Benita Teufel and Jenny Zhang and Koen Oostermeijer and Marco Bellagente and Jeff Clune and Kenneth Stanley and Gregory Schott and Joel Lehman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=owokKCrGYr}\n}"}, "paperhash": {"value": "bradley|qualitydiversity_through_ai_feedback"}}, "number": 6013, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6013/-/Revision", "ICLR.cc/2024/Conference/Submission6013/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6013/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695405012014, "cdate": 1695405012014, "tmdate": 1712931784265, "mdate": 1712931784265, "pdate": 1705410961760, "version": 2}, {"id": "4WM0OogPTx", "forum": "4WM0OogPTx", "signatures": ["ICLR.cc/2024/Conference/Submission6012/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6012/Authors"], "content": {"title": {"value": "Learning from Sparse Offline Datasets via Conservative Density Estimation"}, "authors": {"value": ["Zhepeng Cen", "Zuxin Liu", "Zitong Wang", "Yihang Yao", "Henry Lam", "Ding Zhao"]}, "authorids": {"value": ["~Zhepeng_Cen1", "~Zuxin_Liu1", "~Zitong_Wang1", "~Yihang_Yao1", "~Henry_Lam1", "~Ding_Zhao1"]}, "keywords": {"value": ["offline reinforcement learning", "stationary distribution correction estimation"]}, "TLDR": {"value": "We develop an offline RL method Conservative Density Estimation for scarce data and sparse reward settings."}, "abstract": {"value": "Offline reinforcement learning (RL) offers a promising direction for learning policies from pre-collected datasets without requiring further interactions with the environment. However, existing methods struggle to handle out-of-distribution (OOD) extrapolation errors, especially in sparse reward or scarce data settings. In this paper, we propose a novel training algorithm called Conservative Density Estimation (CDE), which addresses this challenge by explicitly imposing constraints on the state-action occupancy stationary distribution. CDE overcomes the limitations of existing approaches, such as the stationary distribution correction method, by addressing the support mismatch issue in marginal importance sampling. Our method achieves state-of-the-art performance on the D4RL benchmark. Notably, CDE consistently outperforms baselines in challenging tasks with sparse rewards or insufficient data, demonstrating the advantages of our approach in addressing the extrapolation error problem in offline RL."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bc48543c894de80d0ba2eed4f42e60bbff764985.pdf"}, "_bibtex": {"value": "@inproceedings{\ncen2024learning,\ntitle={Learning from Sparse Offline Datasets via Conservative Density Estimation},\nauthor={Zhepeng Cen and Zuxin Liu and Zitong Wang and Yihang Yao and Henry Lam and Ding Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4WM0OogPTx}\n}"}, "paperhash": {"value": "cen|learning_from_sparse_offline_datasets_via_conservative_density_estimation"}}, "number": 6012, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6012/-/Revision", "ICLR.cc/2024/Conference/Submission6012/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6012/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404971877, "cdate": 1695404971877, "tmdate": 1710169425239, "mdate": 1710169425239, "pdate": 1705410961743, "version": 2}, {"id": "qr4ECbGcSj", "forum": "qr4ECbGcSj", "signatures": ["ICLR.cc/2024/Conference/Submission6003/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6003/Authors"], "content": {"title": {"value": "On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning"}, "authors": {"value": ["Rohan Subramani", "Marcus Williams", "Max Heitmann", "Halfdan Holm", "Charlie Griffin", "Joar Max Viktor Skalse"]}, "authorids": {"value": ["~Rohan_Subramani1", "~Marcus_Williams1", "~Max_Heitmann1", "~Halfdan_Holm1", "~Charlie_Griffin1", "~Joar_Max_Viktor_Skalse1"]}, "keywords": {"value": ["reward hypothesis", "Markov reward", "multi-objective reinforcement learning", "linear temporal logic", "reward machines"]}, "abstract": {"value": "Most algorithms in reinforcement learning (RL) require that the objective is formalised with a Markovian reward function. However, it is well-known that certain tasks cannot be expressed by means of an objective in the Markov rewards formalism, motivating the study of alternative objective-specification formalisms in RL such as Linear Temporal Logic and Multi-Objective Reinforcement Learning. To date, there has not yet been any thorough analysis of how these formalisms relate to each other in terms of their expressivity. We fill this gap in the existing literature by providing a comprehensive comparison of 17 salient objective-specification formalisms. We place these formalisms in a preorder based on their expressive power, and present this preorder as a Hasse diagram. We find a variety of limitations for the different formalisms, and argue that no formalism is both dominantly expressive and straightforward to optimise with current techniques. For example, we prove that each of Regularised RL, (Outer) Nonlinear Markov Rewards, Reward Machines, Linear Temporal Logic, and Limit Average Rewards can express a task that the others cannot. The significance of our results is twofold. First, we identify important expressivity limitations to consider when specifying objectives for policy optimization. Second, our results highlight the need for future research which adapts reward learning to work with a greater variety of formalisms, since many existing reward learning methods assume that the desired objective takes a Markovian form. Our work contributes towards a more cohesive understanding of the costs and benefits of different RL objective-specification formalisms."}, "pdf": {"value": "/pdf/f2d5834dbd03ec4ae433785ac6a4ad914f56d6a6.pdf"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We comprehensively compare the expressivities of seventeen formalisms for specifying objectives in reinforcement learning."}, "_bibtex": {"value": "@inproceedings{\nsubramani2024on,\ntitle={On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning},\nauthor={Rohan Subramani and Marcus Williams and Max Heitmann and Halfdan Holm and Charlie Griffin and Joar Max Viktor Skalse},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qr4ECbGcSj}\n}"}, "paperhash": {"value": "subramani|on_the_expressivity_of_objectivespecification_formalisms_in_reinforcement_learning"}}, "number": 6003, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6003/-/Revision", "ICLR.cc/2024/Conference/Submission6003/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6003/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404770017, "cdate": 1695404770017, "tmdate": 1709661526934, "mdate": 1709661526934, "pdate": 1705410961323, "version": 2}, {"id": "auUngos7eR", "forum": "auUngos7eR", "signatures": ["ICLR.cc/2024/Conference/Submission6002/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6002/Authors"], "content": {"title": {"value": "Implicit Maximum a Posteriori Filtering via Adaptive Optimization"}, "authors": {"value": ["Gianluca Bencomo", "Jake Snell", "Thomas L. Griffiths"]}, "authorids": {"value": ["~Gianluca_Bencomo1", "~Jake_Snell1", "~Thomas_L._Griffiths1"]}, "keywords": {"value": ["Bayesian filtering", "optimization", "neural networks"]}, "TLDR": {"value": "We can define the Bayesian filtering problem as optimization over a time-varying objective, which makes it possible to define implicit filters based on optimization that perform well."}, "abstract": {"value": "Bayesian filtering approximates the true underlying behavior of a time-varying system by inverting an explicit generative model to convert noisy measurements into state estimates. This process typically requires matrix storage, inversion, and multiplication or Monte Carlo estimation, none of which are practical in high-dimensional state spaces such as the weight spaces of artificial neural networks. Here, we consider the standard Bayesian filtering problem as optimization over a time-varying objective. Instead of maintaining matrices for the filtering equations or simulating particles, we specify an optimizer that defines the Bayesian filter implicitly. In the linear-Gaussian setting, we show that every Kalman filter has an equivalent formulation using K steps of gradient descent. In the nonlinear setting, our experiments demonstrate that our framework results in filters that are effective, robust, and scalable to high-dimensional systems, comparing well against the standard toolbox of Bayesian filtering solutions. We suggest that it is easier to fine-tune an optimizer than it is to specify the correct filtering equations, making our framework an attractive option for high-dimensional filtering problems."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d2aed4c74551cad3f1c952f10a85be61674493ea.pdf"}, "supplementary_material": {"value": "/attachment/0dc611706644351a3f63b602444998241808d9b0.zip"}, "_bibtex": {"value": "@inproceedings{\nbencomo2024implicit,\ntitle={Implicit Maximum a Posteriori Filtering via Adaptive Optimization},\nauthor={Gianluca Bencomo and Jake Snell and Thomas L. Griffiths},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=auUngos7eR}\n}"}, "paperhash": {"value": "bencomo|implicit_maximum_a_posteriori_filtering_via_adaptive_optimization"}}, "number": 6002, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6002/-/Revision", "ICLR.cc/2024/Conference/Submission6002/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6002/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404759762, "cdate": 1695404759762, "tmdate": 1710352591376, "mdate": 1710352591376, "pdate": 1705410961321, "version": 2}, {"id": "93LoCyww8o", "forum": "93LoCyww8o", "signatures": ["ICLR.cc/2024/Conference/Submission5999/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5999/Authors"], "content": {"title": {"value": "Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response"}, "authors": {"value": ["Junfeng Long", "ZiRui Wang", "Quanyi Li", "Liu Cao", "Jiawei Gao", "Jiangmiao Pang"]}, "authorids": {"value": ["~Junfeng_Long1", "~ZiRui_Wang8", "~Quanyi_Li1", "~Liu_Cao1", "~Jiawei_Gao1", "~Jiangmiao_Pang1"]}, "keywords": {"value": ["Reinforcement Learning", "Quadrupedal Locomotion", "Internal Model"]}, "abstract": {"value": "Robust locomotion control depends on accurate state estimations. However, the sensors of most legged robots can only provide partial and noisy observations, making the estimation particularly challenging, especially for external states like terrain frictions and elevation maps. Inspired by the classical Internal Model Control principle, we consider these external states as disturbances and introduce Hybrid Internal Model (HIM) to estimate them according to the response of the robot. The response, which we refer to as the hybrid internal embedding, contains the robot\u2019s explicit velocity and implicit stability representation, corresponding to two primary goals for locomotion tasks: explicitly tracking velocity and implicitly maintaining stability. We use contrastive learning to optimize the embedding to be close to the robot\u2019s successor state, in which the response is naturally embedded. HIM has several appealing benefits: It only needs the robot\u2019s proprioceptions, i.e., those from joint encoders and IMU as observations. It innovatively maintains consistent observations between simulation reference and reality that avoids information loss in mimicking learning. It exploits batch-level information that is more robust to noises and keeps better sample efficiency. It only requires 1 hour of training on an RTX 4090 to enable a quadruped robot to traverse any terrain under any disturbances. A wealth of real-world experiments demonstrates its agility, even in high-difficulty tasks and cases never occurred during the training process, revealing remarkable open-world generalizability."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7ebfa7daae934eacc0cd05b7ee6107d2ac5b30dd.pdf"}, "_bibtex": {"value": "@inproceedings{\nlong2024the,\ntitle={The {HIM} Solution for Legged Locomotion: Minimal Sensors, Efficient Learning, and Substantial Agility},\nauthor={Junfeng Long and ZiRui Wang and Quanyi Li and Liu Cao and Jiawei Gao and Jiangmiao Pang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=93LoCyww8o}\n}"}, "paperhash": {"value": "long|hybrid_internal_model_learning_agile_legged_locomotion_with_simulated_robot_response"}}, "number": 5999, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5999/-/Revision", "ICLR.cc/2024/Conference/Submission5999/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5999/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404589686, "cdate": 1695404589686, "tmdate": 1710504029280, "mdate": 1710504029280, "pdate": 1705410961191, "version": 2}, {"id": "rAHcTCMaLc", "forum": "rAHcTCMaLc", "signatures": ["ICLR.cc/2024/Conference/Submission5997/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5997/Authors"], "content": {"title": {"value": "S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic"}, "authors": {"value": ["Safa Messaoud", "Billel Mokeddem", "Zhenghai Xue", "Linsey Pang", "Bo An", "Haipeng Chen", "Sanjay Chawla"]}, "authorids": {"value": ["~Safa_Messaoud1", "~Billel_Mokeddem1", "~Zhenghai_Xue1", "~Linsey_Pang1", "~Bo_An2", "~Haipeng_Chen1", "~Sanjay_Chawla1"]}, "keywords": {"value": ["Max-Entropy RL", "Entropy", "Energy-Based-Models"]}, "TLDR": {"value": "We derive a closed for expression of the entropy of Energy-Based-Models and use it to learn multi-modal RL policies."}, "abstract": {"value": "Learning expressive stochastic policies instead of deterministic ones has been proposed to achieve better stability, sample complexity and robustness. Notably, in Maximum Entropy reinforcement learning (MaxEnt RL), the policy is modeled as an expressive energy-based model (EBM) over the Q-values. However, this formulation requires the estimation of the entropy of such EBM distributions which is an open problem. To address this, previous MaxEnt RL methods either implicitly estimate the entropy, yielding high computational complexity and variance (SQL), or follow a variational inference approach that fits simplified distributions (e.g., Gaussian) for tractability (SAC). We propose Sein Soft Actor-Critic (S$^2$AC), a MaxEnt RL algorithm that learns expressive policies without compromising efficiency. S$^2$AC uses parameterized Stein Variational Gradient Descent (SVGD) as the underlying policy. At the core of S$^2$AC is a new solution to the above open challenge of entropy computation for EBMs. Our entropy formula is computationally efficient and only depends on first-order derivatives and vector products. Empirical results show that S$^2$AC yields more optimal solutions to the MaxEnt objective than SQL and SAC in the multi-goal environment, and outperforms SAC and SQL on the MuJoCo benchmark. Our code is available at: https://anonymous.4open.science/r/Stein-Soft-Actor-Critic/"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/19d6054c4a589b634b5706a71a5882726427b66d.pdf"}, "supplementary_material": {"value": "/attachment/c2a316ab12cd30542f6bb5f6c0db5d03f0091146.pdf"}, "_bibtex": {"value": "@inproceedings{\nmessaoud2024sac,\ntitle={S\\$2\\${AC}: Energy-Based Reinforcement Learning with Stein Soft Actor Critic},\nauthor={Safa Messaoud and Billel Mokeddem and Zhenghai Xue and Linsey Pang and Bo An and Haipeng Chen and Sanjay Chawla},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rAHcTCMaLc}\n}"}, "paperhash": {"value": "messaoud|s2ac_energybased_reinforcement_learning_with_stein_soft_actor_critic"}}, "number": 5997, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5997/-/Revision", "ICLR.cc/2024/Conference/Submission5997/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5997/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404540536, "cdate": 1695404540536, "tmdate": 1710168624844, "mdate": 1710168624844, "pdate": 1705410961176, "version": 2}, {"id": "qhkEOCcVX9", "forum": "qhkEOCcVX9", "signatures": ["ICLR.cc/2024/Conference/Submission5993/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5993/Authors"], "content": {"title": {"value": "A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines"}, "authors": {"value": ["Manju Garimella", "Denizhan Pak", "Justin Newell Wood", "Samantha Marie Waters Wood"]}, "authorids": {"value": ["~Manju_Garimella1", "denpak@iu.edu", "~Justin_Newell_Wood1", "~Samantha_Marie_Waters_Wood1"]}, "keywords": {"value": ["newborn", "controlled rearing", "object recognition", "object segmentation", "reinforcement learning", "benchmark", "Turing test", "development"]}, "abstract": {"value": "Newborn brains rapidly learn to solve challenging object recognition tasks, including segmenting objects from backgrounds and recognizing objects across novel backgrounds and viewpoints. Conversely, modern machine-learning (ML) algorithms are \"data hungry,\" requiring more training data than brains to reach similar performance levels. How do we close this learning gap between brains and machines? Here we introduce a new benchmark\u2014a Newborn Embodied Turing Test (NETT) for object segmentation\u2014in which newborn animals and machines are raised in the same environments and tested with the same tasks, permitting direct comparison of their learning abilities. First, we raised newborn chicks in controlled environments containing a single object rotating on a single background, then tested their ability to recognize that object across new backgrounds and viewpoints. Second, we performed \u201cdigital twin\u201d experiments in which we reared and tested artificial chicks in virtual environments that mimicked the rearing and testing conditions of the biological chicks. We inserted a variety of ML \u201cbrains\u201d into the artificial chicks and measured whether those algorithms learned common object recognition behavior as biological chicks. All biological chicks solved this one-shot object segmentation task, successfully learning background-invariant object representations that generalized across new backgrounds and viewpoints. In contrast, none of the artificial chicks solved this object segmentation task, instead learning background-dependent representations that failed to generalize across new backgrounds and viewpoints. This digital twin design exposes core limitations in current ML algorithms in achieving brain-like object perception. Our NETT is publicly available for comparing ML algorithms with newborn chicks. Ultimately, we anticipate that NETT benchmarks will allow researchers to build embodied AI systems that learn as efficiently and robustly as newborn brains."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/98de7745ff23ab989d6a9673385fd567767af8f8.pdf"}, "_bibtex": {"value": "@inproceedings{\ngarimella2024a,\ntitle={A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines},\nauthor={Manju Garimella and Denizhan Pak and Justin Newell Wood and Samantha Marie Waters Wood},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qhkEOCcVX9}\n}"}, "paperhash": {"value": "garimella|a_newborn_embodied_turing_test_for_comparing_object_segmentation_across_animals_and_machines"}}, "number": 5993, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5993/-/Revision", "ICLR.cc/2024/Conference/Submission5993/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5993/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404430759, "cdate": 1695404430759, "tmdate": 1710856411875, "mdate": 1710856411875, "pdate": 1705410961175, "version": 2}, {"id": "xhEN0kJh4q", "forum": "xhEN0kJh4q", "signatures": ["ICLR.cc/2024/Conference/Submission5990/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5990/Authors"], "content": {"title": {"value": "Robust Model-Based Optimization for Challenging Fitness Landscapes"}, "authors": {"value": ["Saba Ghaffari", "Ehsan Saleh", "Alex Schwing", "Yu-Xiong Wang", "Martin D. Burke", "Saurabh Sinha"]}, "authorids": {"value": ["~Saba_Ghaffari1", "~Ehsan_Saleh1", "~Alex_Schwing1", "~Yu-Xiong_Wang1", "~Martin_D._Burke1", "~Saurabh_Sinha4"]}, "keywords": {"value": ["Model based optimization", "protein engineering"]}, "abstract": {"value": "Protein design, a grand challenge of the day, involves optimization on a fitness landscape, and leading methods adopt a model-based approach where a model is trained on a training set (protein sequences and fitness) and proposes candidates to explore next. These methods are challenged by sparsity of high-fitness samples in the training set, a problem that has been in the literature. A less recognized but equally important problem stems from the distribution of training samples in the design space: leading methods are not designed for scenarios where the desired optimum is in a region that is not only poorly represented in training data, but also relatively far from the highly represented low-fitness regions. We show that this problem of \u201cseparation\u201d in the design space is a significant bottleneck in existing model-based optimization tools and propose a new approach that uses a novel VAE as its search model to overcome the problem. We demonstrate its advantage over prior methods in robustly finding improved samples, regardless of the imbalance and separation between low- and high-fitness samples. Our comprehensive benchmark on real and semi-synthetic protein datasets as well as solution design for physics-informed neural networks, showcases the generality of our approach in discrete and continuous design spaces. Our implementation is available at https://github.com/sabagh1994/PGVAE."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fb0639e5f082d1a2381a60dc9bb079cb3f5de709.pdf"}, "_bibtex": {"value": "@inproceedings{\nghaffari2024robust,\ntitle={Robust Model-Based Optimization for Challenging Fitness Landscapes},\nauthor={Saba Ghaffari and Ehsan Saleh and Alex Schwing and Yu-Xiong Wang and Martin D. Burke and Saurabh Sinha},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xhEN0kJh4q}\n}"}, "paperhash": {"value": "ghaffari|robust_modelbased_optimization_for_challenging_fitness_landscapes"}}, "number": 5990, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5990/-/Revision", "ICLR.cc/2024/Conference/Submission5990/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5990/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404360338, "cdate": 1695404360338, "tmdate": 1710454664290, "mdate": 1710454664290, "pdate": 1705410961039, "version": 2}, {"id": "q4AEBLHuA6", "forum": "q4AEBLHuA6", "signatures": ["ICLR.cc/2024/Conference/Submission5989/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5989/Authors"], "content": {"title": {"value": "Solving High Frequency and Multi-Scale PDEs with Gaussian Processes"}, "authors": {"value": ["Shikai Fang", "Madison Cooley", "Da Long", "Shibo Li", "Mike Kirby", "Shandian Zhe"]}, "authorids": {"value": ["~Shikai_Fang2", "~Madison_Cooley1", "~Da_Long1", "~Shibo_Li1", "~Mike_Kirby1", "~Shandian_Zhe1"]}, "keywords": {"value": ["ML PDE solver", "gaussian process", "PINN"]}, "abstract": {"value": "Machine learning based solvers have garnered much attention in physical simulation and scientific computing, with a prominent example, physics-informed neural networks (PINNs). However, PINNs often struggle to solve high-frequency and multi-scale PDEs, which can be due to spectral bias during neural network training. To address this problem, we resort to the Gaussian process (GP) framework. To flexibly capture the dominant frequencies, we model the power spectrum of the PDE solution with a student $t$ mixture or Gaussian mixture. We apply the inverse Fourier transform to obtain the covariance function (by  Wiener-Khinchin theorem). The covariance derived from the Gaussian mixture spectrum corresponds to the known spectral mixture kernel. Next,  we estimate the mixture weights in the log domain, which we show is equivalent to placing a Jeffreys prior. It automatically induces sparsity, prunes excessive frequencies, and adjusts the remaining toward the ground truth. Third, to enable efficient and scalable computation on massive collocation points, which are critical to capture high frequencies, we place the collocation points on a grid, and multiply our covariance function at each input dimension. We use the GP conditional mean to predict the solution and its derivatives so as to fit the boundary condition and the equation itself. \nAs a result, we can derive a Kronecker product structure in the covariance matrix. We use Kronecker product properties and multilinear algebra to promote computational efficiency and scalability, without low-rank approximations. We show the advantage of our method in systematic experiments. The code is released at {https://github.com/xuangu-fang/Gaussian-Process-Slover-for-High-Freq-PDE}."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/76e862d3a8b7e1e2b17390f88070152bfd1bc40a.pdf"}, "_bibtex": {"value": "@inproceedings{\nfang2024solving,\ntitle={Solving High Frequency and Multi-Scale {PDE}s with Gaussian Processes},\nauthor={Shikai Fang and Madison Cooley and Da Long and Shibo Li and Mike Kirby and Shandian Zhe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=q4AEBLHuA6}\n}"}, "paperhash": {"value": "fang|solving_high_frequency_and_multiscale_pdes_with_gaussian_processes"}}, "number": 5989, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5989/-/Revision", "ICLR.cc/2024/Conference/Submission5989/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5989/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404249748, "cdate": 1695404249748, "tmdate": 1710303568396, "mdate": 1710303568396, "pdate": 1705410961035, "version": 2}, {"id": "jKHmjlpViu", "forum": "jKHmjlpViu", "signatures": ["ICLR.cc/2024/Conference/Submission5983/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5983/Authors"], "content": {"title": {"value": "OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text"}, "authors": {"value": ["Keiran Paster", "Marco Dos Santos", "Zhangir Azerbayev", "Jimmy Ba"]}, "authorids": {"value": ["~Keiran_Paster1", "~Marco_Dos_Santos1", "~Zhangir_Azerbayev1", "~Jimmy_Ba1"]}, "keywords": {"value": ["web-scale dataset", "natural language processing", "large language model", "reasoning", "AI for math"]}, "TLDR": {"value": "We open-source a large-scale mathematical dataset extracted from the web."}, "abstract": {"value": "There is growing evidence that pretraining on high quality, carefully thought-out tokens such as code or mathematics plays an important role in improving the reasoning abilities of large language models. For example, Minerva, a PaLM model finetuned on billions of tokens of mathematical documents from arXiv and the web, reported dramatically improved performance on problems that require quantitative reasoning. However, because all known open source web datasets employ preprocessing that does not faithfully preserve mathematical notation, the benefits of large scale training on quantitive web documents are unavailable to the research community. We introduce OpenWebMath, an open dataset inspired by these works containing 14.7B tokens of mathematical webpages from Common Crawl. We describe in detail our method for extracting text and LaTeX content and removing boilerplate from HTML documents, as well as our methods for quality filtering and deduplication. Additionally, we run small-scale experiments by training 1.4B language models on OpenWebMath, showing that models trained on 14.7B tokens of our dataset surpass the performance of models trained on over 20x the amount of general language data. We hope that our dataset, open-sourced and released on the Hugging Face Hub, will help spur advances in the reasoning abilities of large language models."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/50b73568b958d08494c43e6d23be4be76f859f62.pdf"}, "supplementary_material": {"value": "/attachment/d869e6dda8bd1840ebd71f4eec1443eee48cce81.zip"}, "_bibtex": {"value": "@inproceedings{\npaster2024openwebmath,\ntitle={OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text},\nauthor={Keiran Paster and Marco Dos Santos and Zhangir Azerbayev and Jimmy Ba},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jKHmjlpViu}\n}"}, "paperhash": {"value": "paster|openwebmath_an_open_dataset_of_highquality_mathematical_web_text"}}, "number": 5983, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5983/-/Revision", "ICLR.cc/2024/Conference/Submission5983/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5983/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695404044261, "cdate": 1695404044261, "tmdate": 1710555095722, "mdate": 1710555095722, "pdate": 1705410960897, "version": 2}, {"id": "Nf4Lm6fXN8", "forum": "Nf4Lm6fXN8", "signatures": ["ICLR.cc/2024/Conference/Submission5980/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5980/Authors"], "content": {"title": {"value": "Replay across Experiments: A Natural Extension of Off-Policy RL"}, "authors": {"value": ["Dhruva Tirumala", "Thomas Lampe", "Jose Enrique Chen", "Tuomas Haarnoja", "Sandy Huang", "Guy Lever", "Ben Moran", "Tim Hertweck", "Leonard Hasenclever", "Martin Riedmiller", "Nicolas Heess", "Markus Wulfmeier"]}, "authorids": {"value": ["~Dhruva_Tirumala1", "~Thomas_Lampe1", "~Jose_Enrique_Chen1", "~Tuomas_Haarnoja1", "~Sandy_Huang1", "~Guy_Lever1", "~Ben_Moran2", "~Tim_Hertweck1", "~Leonard_Hasenclever1", "~Martin_Riedmiller1", "~Nicolas_Heess1", "~Markus_Wulfmeier1"]}, "keywords": {"value": ["reinforcement learning", "robotics", "data transfer"]}, "abstract": {"value": "Replaying data is a principal mechanism underlying the stability and data efficiency of off-policy reinforcement learning (RL).\nWe present an effective yet simple framework to extend the use of replays across multiple experiments, minimally adapting the RL workflow for sizeable improvements in controller performance and research iteration times.\nAt its core, Replay across Experiments (RaE) involves reusing experience from previous experiments to improve exploration and bootstrap learning while reducing required changes to a minimum in comparison to prior work. \nWe empirically show benefits across a number of RL algorithms and challenging control domains spanning both locomotion and manipulation, including hard exploration tasks from egocentric vision. \nThrough comprehensive ablations, we demonstrate  robustness to the quality and amount of data available and various hyperparameter choices. Finally, we discuss how our approach can be applied more broadly across research life cycles and can increase resilience by reloading data across random seeds or hyperparameter variations."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/92dfcf81b3ef440f1e519a9a7b48c3bdcd93046f.pdf"}, "_bibtex": {"value": "@inproceedings{\ntirumala2024replay,\ntitle={Replay across Experiments: A Natural Extension of Off-Policy {RL}},\nauthor={Dhruva Tirumala and Thomas Lampe and Jose Enrique Chen and Tuomas Haarnoja and Sandy Huang and Guy Lever and Ben Moran and Tim Hertweck and Leonard Hasenclever and Martin Riedmiller and Nicolas Heess and Markus Wulfmeier},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Nf4Lm6fXN8}\n}"}, "paperhash": {"value": "tirumala|replay_across_experiments_a_natural_extension_of_offpolicy_rl"}}, "number": 5980, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5980/-/Revision", "ICLR.cc/2024/Conference/Submission5980/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5980/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695403918647, "cdate": 1695403918647, "tmdate": 1709661526573, "mdate": 1709661526573, "pdate": 1705410960777, "version": 2}, {"id": "S5yOuNfSA0", "forum": "S5yOuNfSA0", "signatures": ["ICLR.cc/2024/Conference/Submission5970/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5970/Authors"], "content": {"title": {"value": "Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP"}, "authors": {"value": ["Zixiang Chen", "Yihe Deng", "Yuanzhi Li", "Quanquan Gu"]}, "authorids": {"value": ["~Zixiang_Chen1", "~Yihe_Deng1", "~Yuanzhi_Li1", "~Quanquan_Gu1"]}, "keywords": {"value": ["Representation Learning", "Multimodal learning", "Learning Theory"]}, "abstract": {"value": "Multi-modal learning has become increasingly popular due to its ability to leverage information from different data sources (e.g., text and images) to improve the model performance. Recently, CLIP has emerged as an effective approach that employs vision-language contrastive pretraining to learn joint image and text representations and exhibits remarkable performance in zero-shot learning and text-guided natural image generation. Despite the substantial practical success of CLIP, its theoretical understanding remains elusive. In this paper, we formally study transferrable representation learning underlying CLIP and demonstrate how features from different modalities get aligned. We also analyze its zero-shot transfer performance on the downstream tasks. In addition, we conduct empirical evaluations on real data to back\nup our theory. Inspired by our analysis, we propose a new CLIP-type approach, which achieves better performance than CLIP and other state-of-the-art methods on benchmark datasets."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3bad38ac3e98564428b4763e3ed623931291fed9.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024understanding,\ntitle={Understanding Transferable Representation Learning and Zero-shot Transfer in {CLIP}},\nauthor={Zixiang Chen and Yihe Deng and Yuanzhi Li and Quanquan Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=S5yOuNfSA0}\n}"}, "paperhash": {"value": "chen|understanding_transferable_representation_learning_and_zeroshot_transfer_in_clip"}}, "number": 5970, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5970/-/Revision", "ICLR.cc/2024/Conference/Submission5970/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5970/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695403424132, "cdate": 1695403424132, "tmdate": 1710482098940, "mdate": 1710482098940, "pdate": 1705410960347, "version": 2}, {"id": "YOKnEkIuoi", "forum": "YOKnEkIuoi", "signatures": ["ICLR.cc/2024/Conference/Submission5967/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5967/Authors"], "content": {"title": {"value": "Conditional Variational Diffusion Models"}, "authors": {"value": ["Gabriel Della Maggiora", "Luis Alberto Croquevielle", "Nikita Deshpande", "Harry Horsley", "Thomas Heinis", "Artur Yakimovich"]}, "authorids": {"value": ["~Gabriel_Della_Maggiora1", "~Luis_Alberto_Croquevielle1", "~Nikita_Deshpande1", "~Harry_Horsley1", "~Thomas_Heinis1", "~Artur_Yakimovich1"]}, "keywords": {"value": ["Denoising Diffusion Probabilistic Models", "Inverse Problems", "Generative Models", "Super Resolution", "Phase Quantification", "Variational Methods"]}, "TLDR": {"value": "We introduce a method to automatically learn the schedule for diffusion models during training, improving results in various applications without the need for manual schedule fine-tuning."}, "abstract": {"value": "Inverse problems aim to determine parameters from observations, a crucial task in engineering and science. Lately, generative models, especially diffusion models, have gained popularity in this area for their ability to produce realistic solutions and their good mathematical properties. Despite their success, an important drawback of diffusion models is their sensitivity to the choice of variance schedule, which controls the dynamics of the diffusion process. Fine-tuning this schedule for specific applications is crucial but time-consuming and does not guarantee an optimal result. We propose a novel approach for learning the schedule as part of the training process. Our method supports probabilistic conditioning on data, provides high-quality solutions, and is flexible, proving able to adapt to different applications with minimum overhead. This approach is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior results to previous methods and fine-tuned diffusion models. We conclude that fine-tuning the schedule by experimentation should be avoided because it can be learned during training in a stable way that yields better results. The code is available on https://github.com/casus/cvdm"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/04a7d1a5d5426b70949eff32045a90eb7a00cf82.pdf"}, "_bibtex": {"value": "@inproceedings{\nmaggiora2024conditional,\ntitle={Conditional Variational Diffusion Models},\nauthor={Gabriel Della Maggiora and Luis Alberto Croquevielle and Nikita Deshpande and Harry Horsley and Thomas Heinis and Artur Yakimovich},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YOKnEkIuoi}\n}"}, "paperhash": {"value": "maggiora|conditional_variational_diffusion_models"}}, "number": 5967, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5967/-/Revision", "ICLR.cc/2024/Conference/Submission5967/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5967/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695403365461, "cdate": 1695403365461, "tmdate": 1710519430952, "mdate": 1710519430952, "pdate": 1705410960163, "version": 2}, {"id": "hj9ZuNimRl", "forum": "hj9ZuNimRl", "signatures": ["ICLR.cc/2024/Conference/Submission5965/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5965/Authors"], "content": {"title": {"value": "Better Neural PDE Solvers Through Data-Free Mesh Movers"}, "authors": {"value": ["Peiyan Hu", "Yue Wang", "Zhi-Ming Ma"]}, "authorids": {"value": ["~Peiyan_Hu1", "~Yue_Wang15", "~Zhi-Ming_Ma1"]}, "keywords": {"value": ["neural PDE solvers", "adaptive moving mesh", "neural operators", "Monge-Amp\u00e8re equation"]}, "abstract": {"value": "Recently, neural networks have been extensively employed to solve partial differential equations (PDEs) in physical system modeling. While major studies focus on learning system evolution on predefined static mesh discretizations, some methods utilize reinforcement learning or supervised learning techniques to create adaptive and dynamic meshes, due to the dynamic nature of these systems. However, these approaches face two primary challenges: (1) the need for expensive optimal mesh data, and (2) the change of the solution space's degree of freedom and topology during mesh refinement. To address these challenges, this paper proposes a neural PDE solver with a neural mesh adapter. To begin with, we introduce a novel data-free neural mesh adaptor, called Data-free Mesh Mover (DMM), with two main innovations. Firstly, it is an operator that maps the solution to adaptive meshes and is trained using the Monge-Amp\u00e8re equation without optimal mesh data. Secondly, it dynamically changes the mesh by moving existing nodes rather than adding or deleting nodes and edges. Theoretical analysis shows that meshes generated by DMM have the lowest interpolation error bound. Based on DMM, to efficiently and accurately model dynamic systems, we develop a moving mesh based neural PDE solver (MM-PDE) that embeds the moving mesh with a two-branch architecture and a learnable interpolation framework to preserve information within the data. Empirical experiments demonstrate that our method generates suitable meshes and considerably enhances accuracy when modeling widely considered PDE systems. The code can be found at: https://github.com/Peiyannn/MM-PDE.git."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "This paper introduces a neural-network-based mesh adapter called Data-free Mesh Mover (DMM), which is trained in a physics-informed data-free way. The DMM can be embedded into the neural PDE solver through proper architectural design, called MM-PDE."}, "pdf": {"value": "/pdf/db83251c909344e4855c213a4a9734d179f9dc32.pdf"}, "_bibtex": {"value": "@inproceedings{\nhu2024better,\ntitle={Better Neural {PDE} Solvers Through Data-Free Mesh Movers},\nauthor={Peiyan Hu and Yue Wang and Zhi-Ming Ma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hj9ZuNimRl}\n}"}, "paperhash": {"value": "hu|better_neural_pde_solvers_through_datafree_mesh_movers"}}, "number": 5965, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5965/-/Revision", "ICLR.cc/2024/Conference/Submission5965/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5965/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695403339915, "cdate": 1695403339915, "tmdate": 1709661526430, "mdate": 1709661526430, "pdate": 1705410960048, "version": 2}, {"id": "0JsRZEGZ7L", "forum": "0JsRZEGZ7L", "signatures": ["ICLR.cc/2024/Conference/Submission5956/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5956/Authors"], "content": {"title": {"value": "From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module"}, "authors": {"value": ["Claudio Battiloro", "Indro Spinelli", "Lev Telyatnikov", "Michael M. Bronstein", "Simone Scardapane", "Paolo Di Lorenzo"]}, "authorids": {"value": ["~Claudio_Battiloro1", "~Indro_Spinelli1", "~Lev_Telyatnikov1", "~Michael_M._Bronstein1", "~Simone_Scardapane1", "~Paolo_Di_Lorenzo1"]}, "keywords": {"value": ["Topological Deep Learning", "Geometric Deep Learning", "Latent Topology Inference", "Latent Graph Inference", "Cell Complexes"]}, "TLDR": {"value": "We study Latent Topology Inference (LTI) for learning higher-order cell complexes (with sparse and not regular topology) describing multi-way interactions between data points."}, "abstract": {"value": "Latent Graph Inference (LGI) relaxed the reliance of Graph Neural Networks (GNNs) on a given graph topology by dynamically learning it. However, most of LGI methods assume to have a (noisy, incomplete, improvable, ...) input graph to rewire and can solely learn regular graph topologies. In the wake of the success of  Topological Deep Learning (TDL), we study Latent Topology Inference (LTI) for learning higher-order cell complexes (with sparse and not regular topology) describing multi-way interactions between data points. To this aim, we introduce the Differentiable Cell Complex Module (DCM), a novel learnable function that computes cell probabilities in the complex to improve the downstream task. We show how to integrate DCM with cell complex message-passing networks layers and train it in an end-to-end fashion, thanks to a two-step inference procedure that avoids an exhaustive search across all possible cells in the input, thus maintaining scalability. Our model is tested on several homophilic and heterophilic graph datasets and it is shown to outperform other state-of-the-art techniques, offering significant improvements especially in cases where an input graph is not provided."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/356b65e71c2efdf7bdd176a1ddc577ce576e7d0c.pdf"}, "_bibtex": {"value": "@inproceedings{\nbattiloro2024from,\ntitle={From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module},\nauthor={Claudio Battiloro and Indro Spinelli and Lev Telyatnikov and Michael M. Bronstein and Simone Scardapane and Paolo Di Lorenzo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0JsRZEGZ7L}\n}"}, "paperhash": {"value": "battiloro|from_latent_graph_to_latent_topology_inference_differentiable_cell_complex_module"}}, "number": 5956, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5956/-/Revision", "ICLR.cc/2024/Conference/Submission5956/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5956/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695403013585, "cdate": 1695403013585, "tmdate": 1710155548749, "mdate": 1710155548749, "pdate": 1705410959747, "version": 2}, {"id": "uKB4cFNQFg", "forum": "uKB4cFNQFg", "signatures": ["ICLR.cc/2024/Conference/Submission5937/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5937/Authors"], "content": {"title": {"value": "BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks"}, "authors": {"value": ["Frederikke Isa Marin", "Felix Teufel", "Marc Horlacher", "Dennis Madsen", "Dennis Pultz", "Ole Winther", "Wouter Boomsma"]}, "authorids": {"value": ["~Frederikke_Isa_Marin1", "~Felix_Teufel1", "~Marc_Horlacher1", "~Dennis_Madsen2", "~Dennis_Pultz1", "~Ole_Winther1", "~Wouter_Boomsma1"]}, "keywords": {"value": ["Biological sequence analysis", "enhancer annotation", "gene finding", "gene annotation", "Language model", "genome modelling", "benchmark", "LLM", "embeddings", "representations", "DNA"]}, "TLDR": {"value": "A dataset and downstream tasks for benchmarking emerging DNA language models with realistic and biologically meaningful tasks"}, "abstract": {"value": "The genome sequence contains the blueprint for governing cellular processes. \n  While the availability of genomes has vastly increased over the last decades, experimental annotation of the various functional, non-coding and regulatory elements encoded in the DNA sequence remains both expensive and challenging. This has sparked interest in unsupervised language modeling of genomic DNA, a paradigm that has seen great success for protein sequence data. \n  Although various DNA language models have been proposed, evaluation tasks often differ between individual works, and might not fully recapitulate the fundamental challenges of genome annotation, including the length, scale and sparsity of the data. In this study, we introduce **BEND**, a **BEN**chmark for **D**NA language models, featuring\n  a collection of realistic and biologically meaningful downstream tasks defined on the human genome.\n  We find that embeddings from current DNA LMs can approach performance of expert methods on some tasks, but only capture limited information about long-range features.\n  BEND is available at https://github.com/frederikkemarin/BEND."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ef699ce2b03bcd92efdb2210e63bb16cdad849e4.pdf"}, "supplementary_material": {"value": "/attachment/3e7650c1510eba0a7106057399613de120aaded6.pdf"}, "_bibtex": {"value": "@inproceedings{\nmarin2024bend,\ntitle={{BEND}: Benchmarking {DNA} Language Models on Biologically Meaningful Tasks},\nauthor={Frederikke Isa Marin and Felix Teufel and Marc Horlacher and Dennis Madsen and Dennis Pultz and Ole Winther and Wouter Boomsma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uKB4cFNQFg}\n}"}, "paperhash": {"value": "marin|bend_benchmarking_dna_language_models_on_biologically_meaningful_tasks"}}, "number": 5937, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5937/-/Revision", "ICLR.cc/2024/Conference/Submission5937/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5937/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695402561660, "cdate": 1695402561660, "tmdate": 1712659607066, "mdate": 1712659607066, "pdate": 1705410959013, "version": 2}, {"id": "up6hr4hIQH", "forum": "up6hr4hIQH", "signatures": ["ICLR.cc/2024/Conference/Submission5905/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5905/Authors"], "content": {"title": {"value": "Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks"}, "authors": {"value": ["Xu Zheng", "Farhad Shirani", "Tianchun Wang", "Wei Cheng", "Zhuomin Chen", "Haifeng Chen", "Hua Wei", "Dongsheng Luo"]}, "authorids": {"value": ["~Xu_Zheng3", "~Farhad_Shirani1", "~Tianchun_Wang1", "~Wei_Cheng1", "~Zhuomin_Chen1", "~Haifeng_Chen1", "~Hua_Wei1", "~Dongsheng_Luo1"]}, "keywords": {"value": ["Graph Neural Networks", "Graph Explanation", "XAI"]}, "abstract": {"value": "Graph Neural Networks (GNNs) are neural models that leverage the dependency structure in graphical data via message passing among the graph nodes. GNNs have emerged as pivotal architectures in analyzing graph-structured data, and their expansive application in sensitive domains requires a comprehensive understanding of their decision-making processes --- necessitating a framework for GNN explainability. An explanation function for GNNs takes a pre-trained GNN along with a graph as input, to produce a `sufficient statistic' subgraph with respect to the graph label. A main challenge in studying GNN explainability is to provide fidelity measures that evaluate the performance of these explanation functions. This paper studies this foundational challenge, spotlighting the inherent limitations of prevailing fidelity metrics, including $Fid_+$, $Fid_-$, and $Fid_\\Delta$. Specifically, a formal, information-theoretic definition of explainability is introduced and it is shown that existing metrics often fail to align with this definition across various statistical scenarios. The reason is due to potential distribution shifts when subgraphs are removed in computing these fidelity measures. Subsequently, a robust class of fidelity measures are introduced, and it is shown analytically that they are resilient to distribution shift issues and are applicable in a wide range of scenarios. Extensive empirical analysis on both synthetic and real datasets are provided to illustrate that the proposed metrics are more coherent with gold standard metrics."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fae3ff8c249e4f09e8ee94b743c1708a7901c3a2.pdf"}, "supplementary_material": {"value": "/attachment/0c66af86dbd97efb54a6356b15ec091b83a4175f.zip"}, "_bibtex": {"value": "@inproceedings{\nzheng2024towards,\ntitle={Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks},\nauthor={Xu Zheng and Farhad Shirani and Tianchun Wang and Wei Cheng and Zhuomin Chen and Haifeng Chen and Hua Wei and Dongsheng Luo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=up6hr4hIQH}\n}"}, "paperhash": {"value": "zheng|towards_robust_fidelity_for_evaluating_explainability_of_graph_neural_networks"}}, "number": 5905, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5905/-/Revision", "ICLR.cc/2024/Conference/Submission5905/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5905/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695401123015, "cdate": 1695401123015, "tmdate": 1710431550840, "mdate": 1710431550840, "pdate": 1705410957995, "version": 2}, {"id": "hOMVq57Ce0", "forum": "hOMVq57Ce0", "signatures": ["ICLR.cc/2024/Conference/Submission5901/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5901/Authors"], "content": {"title": {"value": "Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning"}, "authors": {"value": ["Maxime Wabartha", "Joelle Pineau"]}, "authorids": {"value": ["~Maxime_Wabartha1", "~Joelle_Pineau1"]}, "keywords": {"value": ["Reinforcement learning", "interpretability", "control", "navigation", "transparency", "discrete"]}, "TLDR": {"value": "We propose a neural policy constrained to express a small number of linear behaviors, and show that it leads to improved interpretability while performing comparably to baselines in several control and navigation tasks."}, "abstract": {"value": "Learning inherently interpretable policies is a central challenge in the path to developing autonomous agents that humans can trust. Linear policies can justify their decisions while interacting in a dynamic environment, but their reduced expressivity prevents them from solving hard tasks. Instead, we argue for the use of piecewise-linear policies. We carefully study to what extent they can retain the interpretable properties of linear policies while reaching competitive performance with neural baselines. In particular, we propose the HyperCombinator (HC), a piecewise-linear neural architecture expressing a policy with a controllably small number of sub-policies. Each sub-policy is linear with respect to interpretable features, shedding light on the decision process of the agent without requiring an additional explanation model. We evaluate HC policies in control and navigation experiments, visualize the improved interpretability of the agent and highlight its trade-off with performance. Moreover, we validate that the restricted model class that the HyperCombinator belongs to is compatible with the algorithmic constraints of various reinforcement learning algorithms."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cb305ec5434269909160a55bf4f4affcda145ff6.pdf"}, "_bibtex": {"value": "@inproceedings{\nwabartha2024piecewise,\ntitle={Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning},\nauthor={Maxime Wabartha and Joelle Pineau},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hOMVq57Ce0}\n}"}, "paperhash": {"value": "wabartha|piecewise_linear_parametrization_of_policies_towards_interpretable_deep_reinforcement_learning"}}, "number": 5901, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5901/-/Revision", "ICLR.cc/2024/Conference/Submission5901/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5901/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400935304, "cdate": 1695400935304, "tmdate": 1710892780691, "mdate": 1710892780691, "pdate": 1705410957521, "version": 2}, {"id": "Jc0FssXh2R", "forum": "Jc0FssXh2R", "signatures": ["ICLR.cc/2024/Conference/Submission5900/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5900/Authors"], "content": {"title": {"value": "Optimal criterion for feature learning of two-layer linear neural network in high dimensional interpolation regime"}, "authors": {"value": ["Keita Suzuki", "Taiji Suzuki"]}, "authorids": {"value": ["~Keita_Suzuki2", "~Taiji_Suzuki1"]}, "keywords": {"value": ["two-layer linear neural network", "feature learning", "optimal criterion", "multi-output linear reggression", "high-dimensional setting"]}, "abstract": {"value": "Deep neural networks with feature learning have shown surprising generalization performance in high dimensional settings, but it has not been fully understood how and when they enjoy the benefit of feature learning. In this paper, we theoretically analyze the statistical properties of the benefits from feature learning in a two-layer linear neural network with multiple outputs in a high-dimensional setting. For that purpose, we propose a new criterion that allows feature learning of a two-layer linear neural network in a high-dimensional setting. Interestingly, we can show that models with smaller values of the criterion generalize even in situations where normal ridge regression fails to generalize. This is because the proposed criterion contains a proper regularization for the feature mapping and acts as an upper bound on the predictive risk. As an important characterization of the criterion, the two-layer linear neural network that minimizes this criterion can achieve the optimal Bayes risk that is determined by the distribution of the true signals across the multiple outputs. To the best of our knowledge, this is the first study to specifically identify the conditions under which a model obtained by proper feature learning can outperform normal ridge regression in a high-dimensional multiple-output linear regression problem."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7c0dc8a2ea528a8c9b2c17d59948793587390a0b.pdf"}, "supplementary_material": {"value": "/attachment/920a4470cbe1224070b0f21f732408b909222390.pdf"}, "_bibtex": {"value": "@inproceedings{\nsuzuki2024optimal,\ntitle={Optimal criterion for feature learning of two-layer linear neural network in high dimensional interpolation regime},\nauthor={Keita Suzuki and Taiji Suzuki},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Jc0FssXh2R}\n}"}, "paperhash": {"value": "suzuki|optimal_criterion_for_feature_learning_of_twolayer_linear_neural_network_in_high_dimensional_interpolation_regime"}}, "number": 5900, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5900/-/Revision", "ICLR.cc/2024/Conference/Submission5900/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5900/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400866059, "cdate": 1695400866059, "tmdate": 1711462500938, "mdate": 1711462500938, "pdate": 1705410957322, "version": 2}, {"id": "gIiz7tBtYZ", "forum": "gIiz7tBtYZ", "signatures": ["ICLR.cc/2024/Conference/Submission5898/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5898/Authors"], "content": {"title": {"value": "Neural Optimal Transport with General Cost Functionals"}, "authors": {"value": ["Arip Asadulaev", "Alexander Korotin", "Vage Egiazarian", "Petr Mokrov", "Evgeny Burnaev"]}, "authorids": {"value": ["~Arip_Asadulaev1", "~Alexander_Korotin2", "~Vage_Egiazarian1", "~Petr_Mokrov1", "~Evgeny_Burnaev1"]}, "keywords": {"value": ["Optimal Transport", "Neural Networks", "Generative Modelling"]}, "abstract": {"value": "We introduce a novel neural network-based algorithm to compute optimal transport (OT) plans for general cost functionals. In contrast to common Euclidean costs, i.e., $\\ell^1$ or $\\ell^2$, such functionals provide more flexibility and allow using auxiliary information, such as class labels, to construct the required transport map. Existing methods for general cost functionals are discrete and do not provide an out-of-sample estimation. We address the challenge of designing a continuous OT approach for general cost functionals in high-dimensional spaces, such as images. We construct two example functionals: one to map distributions while preserving the class-wise structure and the other one to preserve the given data pairs. Additionally, we provide the theoretical error analysis for our recovered transport plans. Our implementation is available at \\url{https://github.com/machinestein/gnot}"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dd1d24cf95e927f8d922d1f76a46f0957b8e7169.pdf"}, "_bibtex": {"value": "@inproceedings{\nasadulaev2024neural,\ntitle={Neural Optimal Transport with General Cost Functionals},\nauthor={Arip Asadulaev and Alexander Korotin and Vage Egiazarian and Petr Mokrov and Evgeny Burnaev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gIiz7tBtYZ}\n}"}, "paperhash": {"value": "asadulaev|neural_optimal_transport_with_general_cost_functionals"}}, "number": 5898, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5898/-/Revision", "ICLR.cc/2024/Conference/Submission5898/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5898/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400854229, "cdate": 1695400854229, "tmdate": 1710894131612, "mdate": 1710894131612, "pdate": 1705410957049, "version": 2}, {"id": "apA6SSXx2e", "forum": "apA6SSXx2e", "signatures": ["ICLR.cc/2024/Conference/Submission5889/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5889/Authors"], "content": {"title": {"value": "A Topological Perspective on Demystifying GNN-Based Link Prediction Performance"}, "authors": {"value": ["Yu Wang", "Tong Zhao", "Yuying Zhao", "Yunchao Liu", "Xueqi Cheng", "Neil Shah", "Tyler Derr"]}, "authorids": {"value": ["~Yu_Wang41", "~Tong_Zhao3", "~Yuying_Zhao1", "~Yunchao_Liu2", "~Xueqi_Cheng2", "~Neil_Shah2", "~Tyler_Derr1"]}, "keywords": {"value": ["Link prediction; Graph Topology; Graph Neural Network ; Cold-start Issues"]}, "TLDR": {"value": "We propose a new node-level topological metric, Topological Concentration, to understand the relationship between node local topology and its GNNs' link prediction performance"}, "abstract": {"value": "Graph Neural Networks (GNNs) have shown great promise in learning node embeddings for link prediction (LP). While numerous studies improve the overall GNNs' LP performance, none have explored their varying performance across different nodes and the underlying reasons. To this end, we demystify which nodes perform better from the perspective of their local topology. Despite the widespread belief that low-degree nodes exhibit worse LP performance, we surprisingly observe an inconsistent performance trend. This prompts us to propose a node-level metric, Topological Concentration (TC), based on the intersection of the local subgraph of each node with the ones of its neighbors. We empirically demonstrate that TC correlates with LP performance more than other node-level topological metrics, better identifying low-performing nodes than using degree. With TC, we discover a novel topological distribution shift issue in which nodes' newly joined neighbors tend to become less interactive with their existing neighbors, compromising the generalizability of node embeddings for LP at testing time. To make the computation of TC scalable, We further propose Approximated Topological Concentration (ATC) and justify its efficacy in approximating TC with reduced computation complexity. Given the positive correlation between node TC and its LP performance, we explore the potential of boosting LP performance via enhancing TC by re-weighting edges in the message-passing and discuss its effectiveness with limitations. Our code is publicly available at https://github.com/YuWVandy/Topo_LP_GNN."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d37ec99f62e1fefb02a0529938f97c0eb3719b22.pdf"}, "supplementary_material": {"value": "/attachment/9674cb8e22a02e2e6f72b99a96a332d1dbb8165f.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024a,\ntitle={A Topological Perspective on Demystifying {GNN}-Based Link Prediction Performance},\nauthor={Yu Wang and Tong Zhao and Yuying Zhao and Yunchao Liu and Xueqi Cheng and Neil Shah and Tyler Derr},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=apA6SSXx2e}\n}"}, "paperhash": {"value": "wang|a_topological_perspective_on_demystifying_gnnbased_link_prediction_performance"}}, "number": 5889, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5889/-/Revision", "ICLR.cc/2024/Conference/Submission5889/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5889/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400600112, "cdate": 1695400600112, "tmdate": 1710555392741, "mdate": 1710555392741, "pdate": 1705410956725, "version": 2}, {"id": "5liV2xUdJL", "forum": "5liV2xUdJL", "signatures": ["ICLR.cc/2024/Conference/Submission5888/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5888/Authors"], "content": {"title": {"value": "Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"}, "authors": {"value": ["Firas Al-Hafez", "Guoping Zhao", "Jan Peters", "Davide Tateo"]}, "authorids": {"value": ["~Firas_Al-Hafez1", "~Guoping_Zhao1", "~Jan_Peters3", "~Davide_Tateo2"]}, "keywords": {"value": ["reinforcement learning", "recurrent neural networks", "stateful policies", "backpropagation through time", "imitation learning"]}, "TLDR": {"value": "Our novel gradient estimator makes training of stateful policies simpler and faster."}, "abstract": {"value": "Stateful policies play an important role in reinforcement learning, such as handling partially observable environments, enhancing robustness, or imposing an inductive bias directly into the policy structure. The conventional method for training stateful policies is Backpropagation Through Time (BPTT), which comes with significant drawbacks, such as slow training due to sequential gradient propagation and the occurrence of vanishing or exploding gradients. The gradient is often truncated to address these issues, resulting in a biased policy update. We present a novel approach for training stateful policies by decomposing the latter into a stochastic internal state kernel and a stateless policy, jointly optimized by following the stateful policy gradient. We introduce different versions of the stateful policy gradient theorem, enabling us to easily instantiate stateful variants of popular reinforcement learning and imitation learning algorithms. Furthermore, we provide a theoretical analysis of our new gradient estimator and compare it with BPTT. We evaluate our approach on complex continuous control tasks, e.g. humanoid locomotion, and demonstrate that our gradient estimator scales effectively with task complexity while offering a faster and simpler alternative to BPTT."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/86cbfbad955977732c31c18baacb8cfab00a804a.pdf"}, "_bibtex": {"value": "@inproceedings{\nal-hafez2024timeefficient,\ntitle={Time-Efficient Reinforcement Learning with Stochastic Stateful Policies},\nauthor={Firas Al-Hafez and Guoping Zhao and Jan Peters and Davide Tateo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5liV2xUdJL}\n}"}, "paperhash": {"value": "alhafez|timeefficient_reinforcement_learning_with_stochastic_stateful_policies"}}, "number": 5888, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5888/-/Revision", "ICLR.cc/2024/Conference/Submission5888/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5888/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400549999, "cdate": 1695400549999, "tmdate": 1710550132075, "mdate": 1710550132075, "pdate": 1705410956615, "version": 2}, {"id": "mnipav175N", "forum": "mnipav175N", "signatures": ["ICLR.cc/2024/Conference/Submission5877/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5877/Authors"], "content": {"title": {"value": "Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning"}, "authors": {"value": ["Ge Li", "Hongyi Zhou", "Dominik Roth", "Serge Thilges", "Fabian Otto", "Rudolf Lioutikov", "Gerhard Neumann"]}, "authorids": {"value": ["~Ge_Li3", "~Hongyi_Zhou1", "~Dominik_Roth1", "~Serge_Thilges1", "~Fabian_Otto1", "~Rudolf_Lioutikov1", "~Gerhard_Neumann2"]}, "keywords": {"value": ["Reinforcement Learning", "Trajectory Correlation Modeling", "Robot Manipulation", "Movement Primitives"]}, "TLDR": {"value": "We introduce an efficient Reinforcement Learning (RL) method for robot trajectory generation that effectively captures temporal movement correlations."}, "abstract": {"value": "Current advancements in reinforcement learning (RL) have predominantly focused on learning step-based policies that generate actions for each perceived state. While these methods efficiently leverage step information from environmental interaction, they often ignore the temporal correlation between actions, resulting in inefficient exploration and unsmooth trajectories that are challenging to implement on real hardware. Episodic RL (ERL) seeks to overcome these challenges by exploring in parameters space that capture the correlation of actions. However, these approaches typically compromise data efficiency, as they treat trajectories as opaque black boxes. In this work, we introduce a novel ERL algorithm, Temporally-Correlated Episodic RL (TCE), which effectively utilizes step information in episodic policy updates, opening the 'black box' in existing ERL methods while retaining the smooth and consistent exploration in parameter space. TCE synergistically combines the advantages of step-based and episodic RL, achieving comparable performance to recent ERL methods while maintaining data efficiency akin to state-of-the-art (SoTA) step-based RL."}, "pdf": {"value": "/pdf/0cc127d1ae1c9418c3765818578fba6a538fe366.pdf"}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "supplementary_material": {"value": "/attachment/ce524f8996bd138af0e8437b330e3ba8d2b0adac.zip"}, "_bibtex": {"value": "@inproceedings{\nli2024open,\ntitle={Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning},\nauthor={Ge Li and Hongyi Zhou and Dominik Roth and Serge Thilges and Fabian Otto and Rudolf Lioutikov and Gerhard Neumann},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mnipav175N}\n}"}, "paperhash": {"value": "li|open_the_black_box_stepbased_policy_updates_for_temporallycorrelated_episodic_reinforcement_learning"}}, "number": 5877, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5877/-/Revision", "ICLR.cc/2024/Conference/Submission5877/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5877/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400201732, "cdate": 1695400201732, "tmdate": 1709661525715, "mdate": 1709661525715, "pdate": 1705410955791, "version": 2}, {"id": "Sy8upuD6Bw", "forum": "Sy8upuD6Bw", "signatures": ["ICLR.cc/2024/Conference/Submission5874/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5874/Authors"], "content": {"title": {"value": "Emergent Communication with Conversational Repair"}, "authors": {"value": ["Mitja Nikolaus"]}, "authorids": {"value": ["~Mitja_Nikolaus1"]}, "keywords": {"value": ["emergent communication", "conversation", "signaling games", "language evolution"]}, "abstract": {"value": "Research on conversation has put emphasis on the importance of a multi-level communication system, in which the interlocutors aim to establish and maintain common ground. In natural conversations, repair mechanisms such as clarification requests are frequently used to improve mutual understanding.\nHere we explore the effects of conversational repair on languages emerging in signaling games. We extend the basic Lewis signaling game setup with a feedback channel that allows for the transmission of messages backwards from the receiver to the sender. Further, we add noise to the communication channel so that repair mechanisms become necessary for optimal performance.\n\nWe find that languages emerging in setups with feedback channel are less compositional.\nHowever, the models still achieve a substantially higher generalization performance in conditions with noise, putting to question the role of compositionality for generalization.\nThese findings generalize also to a more realistic case involving a guessing game with naturalistic images.\n\nMore broadly speaking, this study provides an important step towards the creation of signaling games that more closely resemble the conditions under which human languages emerged."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/aa87e0d2b9fc128d1f0d11023565943ecee06b46.pdf"}, "_bibtex": {"value": "@inproceedings{\nnikolaus2024emergent,\ntitle={Emergent Communication with Conversational Repair},\nauthor={Mitja Nikolaus},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Sy8upuD6Bw}\n}"}, "paperhash": {"value": "nikolaus|emergent_communication_with_conversational_repair"}}, "number": 5874, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5874/-/Revision", "ICLR.cc/2024/Conference/Submission5874/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5874/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400113853, "cdate": 1695400113853, "tmdate": 1709661525807, "mdate": 1709661525807, "pdate": 1705410955550, "version": 2}, {"id": "lGUyAuuTYZ", "forum": "lGUyAuuTYZ", "signatures": ["ICLR.cc/2024/Conference/Submission5872/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5872/Authors"], "content": {"title": {"value": "Can we get the best of both Binary Neural Networks and Spiking Neural Networks for Efficient Computer Vision?"}, "authors": {"value": ["Gourav Datta", "Zeyu Liu", "Peter Anthony Beerel"]}, "authorids": {"value": ["~Gourav_Datta1", "~Zeyu_Liu2", "~Peter_Anthony_Beerel1"]}, "keywords": {"value": ["BNN", "Hoyer regularizer", "gradient descent", "FLOPs", "object detection"]}, "TLDR": {"value": "We present a novel training framework for sparse binary activation neural networks (BANN) that achieves the state-of-the-art in the trade-off between performance and compute efficiency."}, "abstract": {"value": "Binary Neural networks (BNN) have emerged as an attractive computing paradigm for a wide range of low-power vision tasks. However, state-of-the-art (SOTA) BNNs do not yield any sparsity, and induce a significant number of non-binary operations. On the other hand, activation sparsity can be provided by spiking neural networks (SNN), that too have gained significant traction in recent times. Thanks to this sparsity, SNNs when implemented on neuromorphic hardware, have the potential to be significantly more power-efficient compared to traditional artifical neural networks (ANN). However, SNNs incur multiple time steps to achieve close to SOTA accuracy. Ironically, this increases latency and energy---costs that SNNs were proposed to reduce---and presents itself as a major hurdle in realizing SNNs\u2019 theoretical gains in practice. This raises an intriguing question: *Can we obtain SNN-like sparsity and BNN-like accuracy and enjoy the energy-efficiency benefits of both?* To answer this question, in this paper, we present a training framework for sparse binary activation neural networks (BANN) using a novel variant of the Hoyer regularizer. We estimate the threshold of each BANN layer as the Hoyer extremum of a clipped version of its activation map, where the clipping value is trained using gradient descent with our Hoyer regularizer. \nThis approach shifts the activation values away from the threshold, thereby mitigating the effect of noise that can otherwise degrade the BANN accuracy. Our approach outperforms existing BNNs, SNNs, and adder neural networks (that also avoid energy-expensive multiplication operations similar to BNNs and SNNs) in terms of the accuracy-FLOPs trade-off for complex image recognition tasks. Downstream experiments on object detection further demonstrate the efficacy of our approach. Lastly, we demonstrate the portability of our approach to SNNs with multiple time steps. Codes are publicly available [here](https://github.com/godatta/Ultra-Low-Latency-SNN)."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8a08398d95a693b450c9d6bfa194584f81c57cb0.pdf"}, "supplementary_material": {"value": "/attachment/043135c3e554a6f0f9c023d4dedcddb146a40021.zip"}, "_bibtex": {"value": "@inproceedings{\ndatta2024bridging,\ntitle={Bridging the Gap between Binary Neural Networks and Spiking Neural Networks for Efficient Computer Vision},\nauthor={Gourav Datta and Zeyu Liu and Peter Anthony Beerel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lGUyAuuTYZ}\n}"}, "paperhash": {"value": "datta|can_we_get_the_best_of_both_binary_neural_networks_and_spiking_neural_networks_for_efficient_computer_vision"}}, "number": 5872, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5872/-/Revision", "ICLR.cc/2024/Conference/Submission5872/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5872/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400068711, "cdate": 1695400068711, "tmdate": 1709661525624, "mdate": 1709661525624, "pdate": 1705410955360, "version": 2}, {"id": "lROh08eK6n", "forum": "lROh08eK6n", "signatures": ["ICLR.cc/2024/Conference/Submission5870/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5870/Authors"], "content": {"title": {"value": "Node2ket: Efficient High-Dimensional Network Embedding in Quantum Hilbert Space"}, "authors": {"value": ["Hao Xiong", "Yehui Tang", "Yunlin He", "Wei Tan", "Junchi Yan"]}, "authorids": {"value": ["~Hao_Xiong5", "~Yehui_Tang3", "~Yunlin_He1", "~Wei_Tan4", "~Junchi_Yan2"]}, "keywords": {"value": ["high-dimensional network embedding", "quantum mechanics"]}, "abstract": {"value": "Network embedding (NE) is a prominent technique for network analysis where the nodes are represented as vectorized embeddings in a continuous space. Existing works tend to resort to the low-dimensional embedding space for efficiency and less risk of over-fitting. In this paper, we explore a new NE paradigm whose embedding dimension goes exponentially high w.r.t. the number of parameters, yet being very efficient and effective. Specifically, the node embeddings are represented as product states that lie in a super high-dimensional (e.g. $2^{32}$-dim) quantum Hilbert space, with a carefully designed optimization approach to guarantee the robustness to work in different scenarios. In the experiments, we show diverse virtues of our methods, including but not limited to: the overwhelming performance on downstream tasks against conventional low-dimensional NE baselines with the similar amount of computing resources, the super high efficiency for a fixed low embedding dimension (e.g. 512) with less than 1/200 memory usage, the robustness when equipped with different objectives and sampling strategies as a fundamental tool for future NE research. As a relatively unexplored topic in literature, the high-dimensional NE paradigm is demonstrated effective both experimentally and theoretically."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/dd8c05ec3fe5d799140c65c3cc39109b14c406bb.pdf"}, "supplementary_material": {"value": "/attachment/f630b26b26072200911418c791ad6ae64e3df9ed.pdf"}, "_bibtex": {"value": "@inproceedings{\nxiong2024efficient,\ntitle={Efficient Network Embedding in the Exponentially Large Quantum Hilbert Space: A High-Dimensional Perspective on Embedding},\nauthor={Hao Xiong and Yehui Tang and Yunlin He and Wei Tan and Junchi Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lROh08eK6n}\n}"}, "paperhash": {"value": "xiong|node2ket_efficient_highdimensional_network_embedding_in_quantum_hilbert_space"}}, "number": 5870, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5870/-/Revision", "ICLR.cc/2024/Conference/Submission5870/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5870/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695400022430, "cdate": 1695400022430, "tmdate": 1710482399005, "mdate": 1710482399005, "pdate": 1705410955021, "version": 2}, {"id": "bH6T0Jjw5y", "forum": "bH6T0Jjw5y", "signatures": ["ICLR.cc/2024/Conference/Submission5860/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5860/Authors"], "content": {"title": {"value": "Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck"}, "authors": {"value": ["Marco Federici", "Patrick Forr\u00e9", "Ryota Tomioka", "Bastiaan S. Veeling"]}, "authorids": {"value": ["~Marco_Federici1", "~Patrick_Forr\u00e91", "~Ryota_Tomioka1", "~Bastiaan_S._Veeling1"]}, "keywords": {"value": ["Markov Processes", "Information Theory", "Information Bottleneck", "Latent Simulation"]}, "TLDR": {"value": "We introduce a tractable objective to represent, simplify and simulate Markov processes based on the Information Bottleneck principle. We motivate our model both theoretically and empirically on synthetic data and molecular dynamics."}, "abstract": {"value": "Markov processes are widely used mathematical models for describing dynamic systems in various fields. However, accurately simulating large-scale systems at long time scales is computationally expensive due to the short time steps required for accurate integration. In this paper, we introduce an inference process that maps complex systems into a simplified representational space and models large jumps in time. To achieve this, we propose Time-lagged Information Bottleneck (T-IB), a principled objective rooted in information theory, which aims to capture relevant temporal features while discarding high-frequency information to simplify the simulation task and minimize the inference error. Our experiments demonstrate that T-IB learns information-optimal representations for accurately modeling the statistical properties and dynamics of the original process at a selected time lag, outperforming existing time-lagged dimensionality reduction methods."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/551ed062f57f723c34b919667149f628113491f9.pdf"}, "supplementary_material": {"value": "/attachment/3cbc8e409279195b6404412d53f70a801db3ef61.pdf"}, "_bibtex": {"value": "@inproceedings{\nfederici2024latent,\ntitle={Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck},\nauthor={Marco Federici and Patrick Forr{\\'e} and Ryota Tomioka and Bastiaan S. Veeling},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bH6T0Jjw5y}\n}"}, "paperhash": {"value": "federici|latent_representation_and_simulation_of_markov_processes_via_timelagged_information_bottleneck"}}, "number": 5860, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5860/-/Revision", "ICLR.cc/2024/Conference/Submission5860/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5860/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399779778, "cdate": 1695399779778, "tmdate": 1712051649298, "mdate": 1712051649298, "pdate": 1705410953448, "version": 2}, {"id": "j511LaqEeP", "forum": "j511LaqEeP", "signatures": ["ICLR.cc/2024/Conference/Submission5857/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5857/Authors"], "content": {"title": {"value": "Non-Exchangeable Conformal Risk Control"}, "authors": {"value": ["Ant\u00f3nio Farinhas", "Chrysoula Zerva", "Dennis Thomas Ulmer", "Andre Martins"]}, "authorids": {"value": ["~Ant\u00f3nio_Farinhas1", "~Chrysoula_Zerva1", "~Dennis_Thomas_Ulmer1", "~Andre_Martins1"]}, "keywords": {"value": ["conformal prediction", "conformal risk control", "non-exchangeable data", "uncertainty"]}, "abstract": {"value": "Split conformal prediction has recently sparked great interest due to its ability to provide formally guaranteed uncertainty sets or intervals for predictions made by black-box neural models, ensuring a predefined probability of containing the actual ground truth. While the original formulation assumes data exchangeability, some extensions handle non-exchangeable data, which is often the case in many real-world scenarios. In parallel, some progress has been made in conformal methods that provide statistical guarantees for a broader range of objectives, such as bounding the best $F_1$-score or minimizing the false negative rate in expectation. In this paper, we leverage and extend these two lines of work by proposing non-exchangeable conformal risk control, which allows controlling the expected value of any monotone loss function when the data is not exchangeable. Our framework is flexible, makes very few assumptions, and allows weighting the data based on its relevance for a given test example; a careful choice of weights may result in tighter bounds, making our framework useful in the presence of change points, time series, or other forms of distribution drift. Experiments with both synthetic and real world data show the usefulness of our method."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ab193b1a0d582e0dc8095741222c1b4912c9d193.pdf"}, "_bibtex": {"value": "@inproceedings{\nfarinhas2024nonexchangeable,\ntitle={Non-Exchangeable Conformal Risk Control},\nauthor={Ant{\\'o}nio Farinhas and Chrysoula Zerva and Dennis Thomas Ulmer and Andre Martins},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=j511LaqEeP}\n}"}, "paperhash": {"value": "farinhas|nonexchangeable_conformal_risk_control"}}, "number": 5857, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5857/-/Revision", "ICLR.cc/2024/Conference/Submission5857/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5857/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399713389, "cdate": 1695399713389, "tmdate": 1709661525464, "mdate": 1709661525464, "pdate": 1705410952981, "version": 2}, {"id": "jId5PXbBbX", "forum": "jId5PXbBbX", "signatures": ["ICLR.cc/2024/Conference/Submission5853/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5853/Authors"], "content": {"title": {"value": "Provably Efficient UCB-type Algorithms For Learning Predictive State Representations"}, "authors": {"value": ["Ruiquan Huang", "Yingbin Liang", "Jing Yang"]}, "authorids": {"value": ["~Ruiquan_Huang1", "~Yingbin_Liang1", "~Jing_Yang3"]}, "keywords": {"value": ["Reinforcement learning", "Sequential decision-making problem", "Predictive state representation", "POMDP", "UCB", "online and offline"]}, "abstract": {"value": "The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are computationally intractable. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the total variation distance between the estimated and true models. We further characterize the sample complexity bounds for our designed UCB-type algorithms for both online and offline PSRs. In contrast to existing approaches for PSRs, our UCB-type algorithms enjoy computational tractability, last-iterate guaranteed near-optimal policy, and guaranteed model accuracy."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We developed a provably efficient upper confidence bound algorithm for online and offline low rank decision-making problem, which is modeled by predictive state representation."}, "pdf": {"value": "/pdf/39de55911a38ed1d41a8e513211631fc2d12108a.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024provably,\ntitle={Provably Efficient {UCB}-type Algorithms For Learning Predictive State Representations},\nauthor={Ruiquan Huang and Yingbin Liang and Jing Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jId5PXbBbX}\n}"}, "paperhash": {"value": "huang|provably_efficient_ucbtype_algorithms_for_learning_predictive_state_representations"}}, "number": 5853, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5853/-/Revision", "ICLR.cc/2024/Conference/Submission5853/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5853/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399600613, "cdate": 1695399600613, "tmdate": 1710179467012, "mdate": 1710179467012, "pdate": 1705410952643, "version": 2}, {"id": "kBNIx4Biq4", "forum": "kBNIx4Biq4", "signatures": ["ICLR.cc/2024/Conference/Submission5851/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5851/Authors"], "content": {"title": {"value": "Lifting Architectural Constraints of Injective Flows"}, "authors": {"value": ["Peter Sorrenson", "Felix Draxler", "Armand Rousselot", "Sander Hummerich", "Lea Zimmermann", "Ullrich Koethe"]}, "authorids": {"value": ["~Peter_Sorrenson1", "~Felix_Draxler1", "~Armand_Rousselot1", "~Sander_Hummerich1", "~Lea_Zimmermann1", "~Ullrich_Koethe1"]}, "keywords": {"value": ["normalizing flows", "injective flows", "manifold learning", "maximum likelihood", "generative model", "auto encoder"]}, "abstract": {"value": "Normalizing Flows explicitly maximize a full-dimensional likelihood on the training data. However, real data is typically only supported on a lower-dimensional manifold leading the model to expend significant compute on modeling noise. Injective Flows fix this by jointly learning a manifold and the distribution on it. So far, they have been limited by restrictive architectures and/or high computational cost. We lift both constraints by a new efficient estimator for the maximum likelihood loss, compatible with free-form bottleneck architectures. We further show that naively learning both the data manifold and the distribution on it can lead to divergent solutions, and use this insight to motivate a stable maximum likelihood training objective. We perform extensive experiments on toy, tabular and image data, demonstrating the competitive performance of the resulting model."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2d4a5d2dd06dc212416848cb30c083b786562327.pdf"}, "_bibtex": {"value": "@inproceedings{\nsorrenson2024lifting,\ntitle={Lifting Architectural Constraints of Injective Flows},\nauthor={Peter Sorrenson and Felix Draxler and Armand Rousselot and Sander Hummerich and Lea Zimmermann and Ullrich Koethe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kBNIx4Biq4}\n}"}, "paperhash": {"value": "sorrenson|lifting_architectural_constraints_of_injective_flows"}}, "number": 5851, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5851/-/Revision", "ICLR.cc/2024/Conference/Submission5851/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5851/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399593244, "cdate": 1695399593244, "tmdate": 1710501604176, "mdate": 1710501604176, "pdate": 1705410952641, "version": 2}, {"id": "ptCIlV24YZ", "forum": "ptCIlV24YZ", "signatures": ["ICLR.cc/2024/Conference/Submission5846/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5846/Authors"], "content": {"title": {"value": "Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models"}, "authors": {"value": ["Tianzhe Chu", "Shengbang Tong", "Tianjiao Ding", "Xili Dai", "Benjamin David Haeffele", "Rene Vidal", "Yi Ma"]}, "authorids": {"value": ["~Tianzhe_Chu1", "~Shengbang_Tong1", "~Tianjiao_Ding1", "~Xili_Dai2", "~Benjamin_David_Haeffele1", "~Rene_Vidal1", "~Yi_Ma4"]}, "keywords": {"value": ["image clustering", "pretrained models", "rate reduction", "principled methods"]}, "TLDR": {"value": "This paper proposes a novel image clustering pipeline that integrates pre-trained models and rate reduction, enhancing clustering accuracy and introducing an effective self-labeling algorithm for unlabeled datasets at scale."}, "abstract": {"value": "The advent of large pre-trained models has brought about a paradigm shift in both visual representation learning and natural language processing. However, clustering unlabeled images, as a fundamental and classic machine learning problem, still lacks an effective solution, particularly for large-scale datasets. In this paper, we propose a novel image clustering pipeline that leverages the powerful feature representation of large pre-trained models such as CLIP and cluster images effectively and efficiently at scale. We first developed a novel algorithm to estimate the number of clusters in a given dataset. We then show that the pre-trained features are significantly more structured by further optimizing the rate reduction objective. The resulting features may significantly improve the clustering accuracy, e.g., from 57\\% to  66\\% on ImageNet-1k. Furthermore, by leveraging CLIP's multimodality bridge between image and text, we develop a simple yet effective self-labeling algorithm that produces meaningful text labels for the clusters. Through extensive experiments, we show that our pipeline works well on standard datasets such as CIFAR-10, CIFAR-100, and ImageNet-1k. It also extends to datasets without predefined labels, such as LAION-Aesthetics and WikiArts."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b6df28d9404e7c9194ee552836a8404aa5248431.pdf"}, "supplementary_material": {"value": "/attachment/ccd78cab37d29c8acf23ea5cba4be701b0696334.pdf"}, "_bibtex": {"value": "@inproceedings{\nchu2024image,\ntitle={Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models},\nauthor={Tianzhe Chu and Shengbang Tong and Tianjiao Ding and Xili Dai and Benjamin David Haeffele and Rene Vidal and Yi Ma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ptCIlV24YZ}\n}"}, "paperhash": {"value": "chu|image_clustering_via_the_principle_of_rate_reduction_in_the_age_of_pretrained_models"}}, "number": 5846, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5846/-/Revision", "ICLR.cc/2024/Conference/Submission5846/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5846/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399383641, "cdate": 1695399383641, "tmdate": 1713164160068, "mdate": 1713164160068, "pdate": 1705410952348, "version": 2}, {"id": "khAE1sTMdX", "forum": "khAE1sTMdX", "signatures": ["ICLR.cc/2024/Conference/Submission5845/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5845/Authors"], "content": {"title": {"value": "Towards Unified Multi-Modal Personalization: Large Vision-Language Models for Generative Recommendation and Beyond"}, "authors": {"value": ["Tianxin Wei", "Bowen Jin", "Ruirui Li", "Hansi Zeng", "Zhengyang Wang", "Jianhui Sun", "Qingyu Yin", "Hanqing Lu", "Suhang Wang", "Jingrui He", "Xianfeng Tang"]}, "authorids": {"value": ["~Tianxin_Wei1", "~Bowen_Jin1", "~Ruirui_Li3", "~Hansi_Zeng1", "~Zhengyang_Wang1", "~Jianhui_Sun1", "~Qingyu_Yin2", "~Hanqing_Lu3", "~Suhang_Wang1", "~Jingrui_He1", "~Xianfeng_Tang1"]}, "keywords": {"value": ["multimodal personalization", "user modeling", "generative modeling", "instruction tuning", "large vision-language model"]}, "abstract": {"value": "Developing a universal model that can effectively harness heterogeneous resources and respond to a wide range of personalized needs has been a longstanding community aspiration. Our daily choices, especially in domains like fashion and retail, are substantially shaped by multi-modal data, such as pictures and textual descriptions. These modalities not only offer intuitive guidance but also cater to personalized user preferences. However, the predominant personalization approaches mainly focus on ID or text-based recommendation problems, failing to comprehend the information spanning various tasks or modalities. In this paper, our goal is to establish a Unified paradigm for Multi-modal Personalization systems (UniMP), which effectively leverages multi-modal data while eliminating the complexities associated with task- and modality-specific customization. We argue that the advancements in foundational generative modeling have provided the flexibility and effectiveness necessary to achieve the objective. In light of this, we develop a generic and extensible personalization generative framework, that can handle a wide range of personalized needs including item recommendation, product search, preference prediction, explanation generation, and further user-guided image generation. Our methodology enhances the capabilities of foundational language models for personalized tasks by seamlessly ingesting interleaved cross-modal user history information, ensuring a more precise and customized experience for users. To train and evaluate the proposed multi-modal personalized tasks, we also introduce a novel and comprehensive benchmark covering a variety of user requirements. Our experiments on the real-world benchmark showcase the model's potential, outperforming competitive methods specialized for each task."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b9aee597cef45808ad16abe521bea524f6ca3090.pdf"}, "TLDR": {"value": "Developing a universal model that can effectively harness heterogeneous resources and respond to a wide range of personalized needs in the e-commerce domain."}, "_bibtex": {"value": "@inproceedings{\nwei2024towards,\ntitle={Towards Universal Multi-Modal Personalization: A Language Model Empowered Generative Paradigm},\nauthor={Tianxin Wei and Bowen Jin and Ruirui Li and Hansi Zeng and Zhengyang Wang and Jianhui Sun and Qingyu Yin and Hanqing Lu and Suhang Wang and Jingrui He and Xianfeng Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=khAE1sTMdX}\n}"}, "paperhash": {"value": "wei|towards_unified_multimodal_personalization_large_visionlanguage_models_for_generative_recommendation_and_beyond"}}, "number": 5845, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5845/-/Revision", "ICLR.cc/2024/Conference/Submission5845/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5845/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399381216, "cdate": 1695399381216, "tmdate": 1711573510137, "mdate": 1711573510137, "pdate": 1705410952125, "version": 2}, {"id": "GkJOCga62u", "forum": "GkJOCga62u", "signatures": ["ICLR.cc/2024/Conference/Submission5840/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5840/Authors"], "content": {"title": {"value": "Orbit-Equivariant Graph Neural Networks"}, "authors": {"value": ["Matthew Morris", "Bernardo Cuenca Grau", "Ian Horrocks"]}, "authorids": {"value": ["~Matthew_Morris1", "~Bernardo_Cuenca_Grau1", "~Ian_Horrocks1"]}, "keywords": {"value": ["graph neural networks", "equivariance", "expressivity", "graph orbits"]}, "TLDR": {"value": "We define orbit-equivariance, a relaxation of equivariance, to enable solving a new class of problems and propose some orbit-equivariant GNNs"}, "abstract": {"value": "Equivariance is an important structural property that is captured by architectures such as graph neural networks (GNNs). However, equivariant graph functions cannot produce different outputs for similar nodes, which may be undesirable when the function is trying to optimize some global graph property. In this paper, we define orbit-equivariance, a relaxation of equivariance which allows for such functions whilst retaining important structural inductive biases. We situate the property in the hierarchy of graph functions, define a taxonomy of orbit-equivariant functions, and provide four different ways to achieve non-equivariant GNNs. For each, we analyze their expressivity with respect to orbit-equivariance and evaluate them on two novel datasets, one of which stems from a real-world use-case of designing optimal bioisosteres."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0bdb56da70e5e990e2bc0fbd1a033c6a30831244.pdf"}, "supplementary_material": {"value": "/attachment/0370ad204f90a8960e724e1b9de9cf6271545c29.zip"}, "_bibtex": {"value": "@inproceedings{\nmorris2024orbitequivariant,\ntitle={Orbit-Equivariant Graph Neural Networks},\nauthor={Matthew Morris and Bernardo Cuenca Grau and Ian Horrocks},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GkJOCga62u}\n}"}, "paperhash": {"value": "morris|orbitequivariant_graph_neural_networks"}}, "number": 5840, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5840/-/Revision", "ICLR.cc/2024/Conference/Submission5840/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5840/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399303361, "cdate": 1695399303361, "tmdate": 1709661525238, "mdate": 1709661525238, "pdate": 1705410951943, "version": 2}, {"id": "aBUidW4Nkd", "forum": "aBUidW4Nkd", "signatures": ["ICLR.cc/2024/Conference/Submission5838/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5838/Authors"], "content": {"title": {"value": "Object-Centric Learning with Slot Mixture Module"}, "authors": {"value": ["Daniil Kirilenko", "Vitaliy Vorobyov", "Alexey Kovalev", "Aleksandr Panov"]}, "authorids": {"value": ["~Daniil_Kirilenko1", "~Vitaliy_Vorobyov1", "~Alexey_Kovalev3", "~Aleksandr_Panov1"]}, "keywords": {"value": ["Object-centric representations", "Gaussian Mixture Model", "Slot Attention", "Set Prediction Task"]}, "TLDR": {"value": "We proposed a generalization of a slot-based approach for object-centric representations as a Slot Mixture Model that allows state-of-the-art performance in the set property prediction and object discovery tasks."}, "abstract": {"value": "Object-centric architectures usually apply a differentiable module to the entire feature map to decompose it into sets of entity representations called slots. Some of these methods structurally resemble clustering algorithms, where the cluster's center in latent space serves as a slot representation. Slot Attention is an example of such a method, acting as a learnable analog of the soft k-means algorithm. Our work employs a learnable clustering method based on the Gaussian Mixture Model. Unlike other approaches, we represent slots not only as centers of clusters but also incorporate information about the distance between clusters and assigned vectors, leading to more expressive slot representations. Our experiments demonstrate that using this approach instead of Slot Attention improves performance in object-centric scenarios, achieving state-of-the-art results in the set property prediction task."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0abbf39f825ea3bbaf39585a586bbfc3c545cab1.pdf"}, "supplementary_material": {"value": "/attachment/902ec25757c483b569a553c54585d306cd358a38.pdf"}, "_bibtex": {"value": "@inproceedings{\nkirilenko2024objectcentric,\ntitle={Object-Centric Learning with Slot Mixture Module},\nauthor={Daniil Kirilenko and Vitaliy Vorobyov and Alexey Kovalev and Aleksandr Panov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=aBUidW4Nkd}\n}"}, "paperhash": {"value": "kirilenko|objectcentric_learning_with_slot_mixture_module"}}, "number": 5838, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5838/-/Revision", "ICLR.cc/2024/Conference/Submission5838/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5838/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399285947, "cdate": 1695399285947, "tmdate": 1710421173967, "mdate": 1710421173967, "pdate": 1705410951819, "version": 2}, {"id": "lm7MRcsFiS", "forum": "lm7MRcsFiS", "signatures": ["ICLR.cc/2024/Conference/Submission5834/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5834/Authors"], "content": {"title": {"value": "Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?"}, "authors": {"value": ["Yu-Lin Tsai", "Chia-Yi Hsu", "Chulin Xie", "Chih-Hsun Lin", "Jia You Chen", "Bo Li", "Pin-Yu Chen", "Chia-Mu Yu", "Chun-Ying Huang"]}, "authorids": {"value": ["~Yu-Lin_Tsai1", "~Chia-Yi_Hsu1", "~Chulin_Xie1", "~Chih-Hsun_Lin2", "~Jia_You_Chen1", "~Bo_Li19", "~Pin-Yu_Chen1", "~Chia-Mu_Yu1", "~Chun-Ying_Huang1"]}, "keywords": {"value": ["redteaming", "stable diffusion", "text-to-image model"]}, "abstract": {"value": "Diffusion models for text-to-image (T2I) synthesis, such as Stable Diffusion (SD), have recently demonstrated exceptional capabilities for generating high-quality content. However, this progress has raised several concerns of potential misuse, particularly in creating copyrighted, prohibited, and restricted content, or NSFW (not safe for work) images. While efforts have been made to mitigate such problems, either by implementing a safety filter at the evaluation stage or by fine-tuning models to eliminate undesirable concepts or styles, the effectiveness of these safety measures in dealing with a wide range of prompts remains largely unexplored. In this work, we aim to investigate these safety mechanisms by proposing one novel concept retrieval algorithm for evaluation. We introduce Ring-A-Bell, a model-agnostic red-teaming scheme for T2I diffusion models, where the whole evaluation can be prepared in advance without prior knowledge of the target model.\nSpecifically, Ring-A-Bell first performs concept extraction to obtain holistic representations for sensitive and inappropriate concepts. Subsequently, by leveraging the extracted concept, Ring-A-Bell automatically identifies problematic prompts for diffusion models with the corresponding generation of inappropriate content, allowing the user to assess the reliability of deployed safety mechanisms. Finally, we empirically validate our method by testing online services such as Midjourney and various methods of concept removal. Our results show that Ring-A-Bell, by manipulating safe prompting benchmarks, can transform prompts that were originally regarded as safe to evade existing safety mechanisms, thus revealing the defects of the so-called safety mechanisms which could practically lead to the generation of harmful contents. In essence, Ring-A-Bell could serve as a red-teaming tool to understand the limitations of deployed safety mechanisms and to explore the risk under plausible attacks. Our codes are available at https://github.com/chiayi-hsu/Ring-A-Bell."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3b967bf67645ee9bf80b3237f3be90b79afcf58a.pdf"}, "supplementary_material": {"value": "/attachment/1afc545a6fc6f8f4110d4cb715f1ed6d8439ecf5.pdf"}, "_bibtex": {"value": "@inproceedings{\ntsai2024ringabell,\ntitle={Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?},\nauthor={Yu-Lin Tsai and Chia-Yi Hsu and Chulin Xie and Chih-Hsun Lin and Jia You Chen and Bo Li and Pin-Yu Chen and Chia-Mu Yu and Chun-Ying Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lm7MRcsFiS}\n}"}, "paperhash": {"value": "tsai|ringabell_how_reliable_are_concept_removal_methods_for_diffusion_models"}}, "number": 5834, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5834/-/Revision", "ICLR.cc/2024/Conference/Submission5834/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5834/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399238930, "cdate": 1695399238930, "tmdate": 1709661525135, "mdate": 1709661525135, "pdate": 1705410951575, "version": 2}, {"id": "2Oiee202rd", "forum": "2Oiee202rd", "signatures": ["ICLR.cc/2024/Conference/Submission5829/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5829/Authors"], "content": {"title": {"value": "PerceptionCLIP: Visual Classification by Inferring and Conditioning on Contexts"}, "authors": {"value": ["Bang An", "Sicheng Zhu", "Michael-Andrei Panaitescu-Liess", "Chaithanya Kumar Mummadi", "Furong Huang"]}, "authorids": {"value": ["~Bang_An1", "~Sicheng_Zhu1", "~Michael-Andrei_Panaitescu-Liess1", "~Chaithanya_Kumar_Mummadi1", "~Furong_Huang1"]}, "keywords": {"value": ["vision-language model", "CLIP", "zero-shot", "image classification", "human perception", "contexts", "contextual attributes", "spurious feature"]}, "TLDR": {"value": "We propose PerceptionCLIP, a zero-shot classification method that emulates the human perception process, achieving better generatlization, group robustness and interpretability."}, "abstract": {"value": "Vision-language models like CLIP are widely used in zero-shot image classification due to their ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better performance is still an open question. This paper draws inspiration from the human visual perception process: when classifying an object, humans first infer contextual attributes (e.g., background and orientation) which help separate the foreground object from the background, and then classify the object based on this information. Inspired by it, we observe that providing CLIP with contextual attributes improves zero-shot image classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and interpretability."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/97093f7f61ff746daccfe08eb2b103ddeba0bcb6.pdf"}, "_bibtex": {"value": "@inproceedings{\nan2024more,\ntitle={More Context, Less Distraction: Zero-shot Visual Classification by Inferring and Conditioning on Contextual Attributes},\nauthor={Bang An and Sicheng Zhu and Michael-Andrei Panaitescu-Liess and Chaithanya Kumar Mummadi and Furong Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2Oiee202rd}\n}"}, "paperhash": {"value": "an|perceptionclip_visual_classification_by_inferring_and_conditioning_on_contexts"}}, "number": 5829, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5829/-/Revision", "ICLR.cc/2024/Conference/Submission5829/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5829/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695399100426, "cdate": 1695399100426, "tmdate": 1710531803191, "mdate": 1710531803191, "pdate": 1705410951374, "version": 2}, {"id": "NjNfLdxr3A", "forum": "NjNfLdxr3A", "signatures": ["ICLR.cc/2024/Conference/Submission5820/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5820/Authors"], "content": {"title": {"value": "VeRA: Vector-based Random Matrix Adaptation"}, "authors": {"value": ["Dawid Jan Kopiczko", "Tijmen Blankevoort", "Yuki M Asano"]}, "authorids": {"value": ["~Dawid_Jan_Kopiczko1", "~Tijmen_Blankevoort1", "~Yuki_M_Asano1"]}, "keywords": {"value": ["Parameter-efficient fine-tuning", "Transfer learning", "Low-rank", "NLP"]}, "abstract": {"value": "Low-rank adapation (LoRA) is a popular method that reduces the number of trainable parameters when finetuning large language models, but still faces acute storage challenges when scaling to even larger models or deploying numerous per-user or per-task adapted models. In this work, we present Vector-based Random Matrix Adaptation (VeRA), which significantly reduces the number of trainable parameters compared to LoRA, yet maintains the same performance. It achieves this by using a single pair of low-rank matrices shared across all layers and learning small scaling vectors instead. We demonstrate its effectiveness on the GLUE and E2E benchmarks, image classification tasks, and show its application in instruction-tuning of 7B and 13B language models. Website: https://dkopi.github.io/vera"}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/84a522546151bef174f85406f80d260ea475fa1c.pdf"}, "supplementary_material": {"value": "/attachment/221b6211a6c0a2a90d3b2f97b78d7f088afbd46d.zip"}, "_bibtex": {"value": "@inproceedings{\nkopiczko2024elora,\ntitle={{EL}o{RA}: Efficient Low-Rank Adaptation with Random Matrices},\nauthor={Dawid Jan Kopiczko and Tijmen Blankevoort and Yuki M Asano},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NjNfLdxr3A}\n}"}, "paperhash": {"value": "kopiczko|vera_vectorbased_random_matrix_adaptation"}}, "number": 5820, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5820/-/Revision", "ICLR.cc/2024/Conference/Submission5820/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5820/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398844358, "cdate": 1695398844358, "tmdate": 1713028955084, "mdate": 1713028955084, "pdate": 1705410951068, "version": 2}, {"id": "Bb21JPnhhr", "forum": "Bb21JPnhhr", "signatures": ["ICLR.cc/2024/Conference/Submission5811/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5811/Authors"], "content": {"title": {"value": "AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?"}, "authors": {"value": ["Qi Zhao", "Shijie Wang", "Ce Zhang", "Changcheng Fu", "Minh Quan Do", "Nakul Agarwal", "Kwonjoon Lee", "Chen Sun"]}, "authorids": {"value": ["~Qi_Zhao8", "~Shijie_Wang2", "~Ce_Zhang7", "~Changcheng_Fu1", "minh_quan_do@brown.edu", "~Nakul_Agarwal2", "~Kwonjoon_Lee1", "~Chen_Sun1"]}, "keywords": {"value": ["long-term action anticipation", "multimodal learning"]}, "TLDR": {"value": "LLMs provide temporal dynamics priors of human behaviors for long-term action anticipation"}, "abstract": {"value": "Can we better anticipate an actor\u2019s future actions (e.g. mix eggs) by knowing what commonly happens after the current action (e.g. crack eggs)? What if the actor also shares the goal (e.g. make fried rice) with us? The long-term action anticipation (LTA) task aims to predict an actor\u2019s future behavior from video observations in the form of verb and noun sequences, and it is crucial for human-machine interaction.\nWe propose to formulate the LTA task from two perspectives: a bottom-up approach that predicts the next actions autoregressively by modeling temporal dynamics; and a top-down approach that infers the goal of the actor and plans the needed procedure to accomplish the goal. We hypothesize that large language models (LLMs), which have been pretrained on procedure text data (e.g. recipes, how-tos),\nhave the potential to help LTA from both perspectives. It can help provide the prior knowledge on the possible next actions, and infer the goal given the observed part of a procedure, respectively. We propose AntGPT, which represents video observations as sequences of human actions, and uses the action representation for an LLM to infer the goals and model temporal dynamics. AntGPT achieves state-\nof-the-art performance on Ego4D LTA v1 and v2, EPIC-Kitchens-55, as well as EGTEA GAZE+, thanks to LLMs\u2019 goal inference and temporal dynamics modeling capabilities. We further demonstrate that these capabilities can be effectively distilled into a compact neural network 1.3% of the original LLM model size. Code and model will be released upon acceptance."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8eba3ccf1ad05a26a911c4b48092118c27ff85ae.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhao2024antgpt,\ntitle={Ant{GPT}: Can Large Language Models Help Long-term Action Anticipation from Videos?},\nauthor={Qi Zhao and Shijie Wang and Ce Zhang and Changcheng Fu and Minh Quan Do and Nakul Agarwal and Kwonjoon Lee and Chen Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Bb21JPnhhr}\n}"}, "paperhash": {"value": "zhao|antgpt_can_large_language_models_help_longterm_action_anticipation_from_videos"}}, "number": 5811, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5811/-/Revision", "ICLR.cc/2024/Conference/Submission5811/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5811/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398620413, "cdate": 1695398620413, "tmdate": 1710372039109, "mdate": 1710372039109, "pdate": 1705410950522, "version": 2}, {"id": "DGez4B2a6Y", "forum": "DGez4B2a6Y", "signatures": ["ICLR.cc/2024/Conference/Submission5810/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5810/Authors"], "content": {"title": {"value": "A Plug-and-Play Image Registration Network"}, "authors": {"value": ["Junhao Hu", "Weijie Gan", "Zhixin Sun", "Hongyu An", "Ulugbek Kamilov"]}, "authorids": {"value": ["~Junhao_Hu2", "~Weijie_Gan1", "~Zhixin_Sun2", "~Hongyu_An3", "~Ulugbek_Kamilov1"]}, "keywords": {"value": ["deformable image registration", "plug-and-play priors", "deep equilibrium models", "iterative algorithms"]}, "TLDR": {"value": "We propose the first plug-and-play methods for deformable image registration: (a) PIRATE that uses deep denoiser trained on registration fields as prior, and (b) PIRATE+ that improves PIRATE by using deep equilibrium models to fine-tune the prior."}, "abstract": {"value": "Deformable image registration (DIR) is an active research topic in biomedical imaging. There is a growing interest in developing DIR methods based on deep learning (DL). A traditional DL approach to DIR is based on training a convolutional neural network (CNN) to estimate the registration field between two input images. While conceptually simple, this approach comes with a limitation that it exclusively relies on a pre-trained CNN without explicitly enforcing fidelity between the registered image and the reference. We present plug-and-play image registration network (PIRATE) as a new DIR method that addresses this issue by integrating an explicit data-fidelity penalty and a CNN prior. PIRATE pre-trains a CNN denoiser on the registration field and \"plugs\" it into an iterative method as a regularizer. We additionally present PIRATE+ that fine-tunes the CNN prior in PIRATE using deep equilibrium models (DEQ). PIRATE+ interprets the fixed-point iteration of PIRATE as a network with effectively infinite layers and then trains the resulting network end-to-end, enabling it to learn more task-specific information and boosting its performance. Our numerical results on OASIS and CANDI datasets show that our methods achieve state-of-the-art performance on DIR."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d98fabc1a6a00e6dbc481cf5174e9e41283e2989.pdf"}, "supplementary_material": {"value": "/attachment/17f39146523c65fadb15437ea9c03c424887a66c.zip"}, "_bibtex": {"value": "@inproceedings{\nhu2024a,\ntitle={A Plug-and-Play Image Registration Network},\nauthor={Junhao Hu and Weijie Gan and Zhixin Sun and Hongyu An and Ulugbek Kamilov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DGez4B2a6Y}\n}"}, "paperhash": {"value": "hu|a_plugandplay_image_registration_network"}}, "number": 5810, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5810/-/Revision", "ICLR.cc/2024/Conference/Submission5810/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5810/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398611230, "cdate": 1695398611230, "tmdate": 1709661524989, "mdate": 1709661524989, "pdate": 1705410950519, "version": 2}, {"id": "ZZTkLDRmkg", "forum": "ZZTkLDRmkg", "signatures": ["ICLR.cc/2024/Conference/Submission5809/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5809/Authors"], "content": {"title": {"value": "BENO: Boundary-embedded Neural Operators for Elliptic PDEs"}, "authors": {"value": ["Haixin Wang", "Jiaxin LI", "Anubhav Dwivedi", "Kentaro Hara", "Tailin Wu"]}, "authorids": {"value": ["~Haixin_Wang3", "~Jiaxin_LI11", "~Anubhav_Dwivedi1", "~Kentaro_Hara2", "~Tailin_Wu1"]}, "keywords": {"value": ["AI for PDEs; physical simulation", "neural operators", "boundary-embedded"]}, "abstract": {"value": "Elliptic partial differential equations (PDEs) are a major class of time-independent PDEs that play a key role in many scientific and engineering domains such as fluid dynamics, plasma physics, and solid mechanics. Recently, neural operators have emerged as a promising technique to solve elliptic PDEs more efficiently by directly mapping the input to solutions. However, existing networks typically neglect complex geometries and inhomogeneous boundary values  present in the real world. Here we introduce Boundary-Embedded Neural Operators (BENO), a novel neural operator architecture that embeds the complex geometries and inhomogeneous boundary values into the solving of elliptic PDEs. Inspired by classical Green's function, BENO consists of two Graph Neural Networks (GNNs) for interior source term and boundary values, respectively. Furthermore, a Transformer encoder maps the global boundary geometry into a latent vector which influences each message passing layer of the GNNs. We test our model and strong baselines extensively in elliptic PDEs with complex boundary conditions. We show that all existing baseline methods fail to learn the solution operator. In contrast, our model, endowed with boundary-embedded architecture, outperforms state-of-the-art neural operators and strong baselines by an average of 60.96%."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1244f224ed3c09aaa552fc1dc9c19848230f4365.pdf"}, "supplementary_material": {"value": "/attachment/2087428a7bebe2275fe191699c775381ba773d31.pdf"}, "TLDR": {"value": "We introduce a boundary-embedded neural operator that incorporates complex boundary shape and inhomogeneous boundary values into the solving of Elliptic PDEs"}, "_bibtex": {"value": "@inproceedings{\nwang2024beno,\ntitle={{BENO}: Boundary-embedded Neural Operators for Elliptic {PDE}s},\nauthor={Haixin Wang and Jiaxin LI and Anubhav Dwivedi and Kentaro Hara and Tailin Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZZTkLDRmkg}\n}"}, "paperhash": {"value": "wang|beno_boundaryembedded_neural_operators_for_elliptic_pdes"}}, "number": 5809, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5809/-/Revision", "ICLR.cc/2024/Conference/Submission5809/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5809/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398609173, "cdate": 1695398609173, "tmdate": 1709661524962, "mdate": 1709661524962, "pdate": 1705410950449, "version": 2}, {"id": "uwO71a8wET", "forum": "uwO71a8wET", "signatures": ["ICLR.cc/2024/Conference/Submission5806/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5806/Authors"], "content": {"title": {"value": "Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation"}, "authors": {"value": ["Konstantin Hess", "Valentyn Melnychuk", "Dennis Frauen", "Stefan Feuerriegel"]}, "authorids": {"value": ["~Konstantin_Hess1", "~Valentyn_Melnychuk1", "~Dennis_Frauen1", "~Stefan_Feuerriegel1"]}, "keywords": {"value": ["treatment effect estimation", "neural differential equation", "variational Bayes", "medicine"]}, "TLDR": {"value": "We develop a novel variational Bayesian method for uncertainty-aware treatment effect estimation in continuous time using neural controlled differential equations and neural stochastic differential equations."}, "abstract": {"value": "Treatment effect estimation in continuous time is crucial for personalized medicine. However, existing methods for this task are limited to point estimates of the potential outcomes, whereas uncertainty estimates have been ignored. Needless to say, uncertainty quantification is crucial for reliable decision-making in medical applications. To fill this gap, we propose a novel Bayesian neural controlled differential equation (BNCDE) for treatment effect estimation in continuous time. In our BNCDE, the time dimension is modeled through a coupled system of neural controlled differential equations and neural stochastic differential equations, where the neural stochastic differential equations allow for tractable variational Bayesian inference. Thereby, for an assigned sequence of treatments, our BNCDE provides meaningful posterior predictive distributions of the potential outcomes. To the best of our knowledge, ours is the first tailored neural method to provide uncertainty estimates of treatment effects in continuous time. As such, our method is of direct practical value for promoting reliable decision-making in medicine."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/93e036c0494321619e28e8957e25809638aeab40.pdf"}, "_bibtex": {"value": "@inproceedings{\nhess2024bayesian,\ntitle={Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation},\nauthor={Konstantin Hess and Valentyn Melnychuk and Dennis Frauen and Stefan Feuerriegel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uwO71a8wET}\n}"}, "paperhash": {"value": "hess|bayesian_neural_controlled_differential_equations_for_treatment_effect_estimation"}}, "number": 5806, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5806/-/Revision", "ICLR.cc/2024/Conference/Submission5806/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5806/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398477106, "cdate": 1695398477106, "tmdate": 1712154544561, "mdate": 1712154544561, "pdate": 1705410950301, "version": 2}, {"id": "NddKiWtdUm", "forum": "NddKiWtdUm", "signatures": ["ICLR.cc/2024/Conference/Submission5792/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5792/Authors"], "content": {"title": {"value": "Training Socially Aligned Language Models on Simulated Social Interactions"}, "authors": {"value": ["Ruibo Liu", "Ruixin Yang", "Chenyan Jia", "Ge Zhang", "Diyi Yang", "Soroush Vosoughi"]}, "authorids": {"value": ["~Ruibo_Liu1", "~Ruixin_Yang1", "~Chenyan_Jia1", "~Ge_Zhang5", "~Diyi_Yang2", "~Soroush_Vosoughi1"]}, "keywords": {"value": ["AI alignment", "AI safety", "Natural Language Processing"]}, "TLDR": {"value": "Aligning language models by training on recorded social simulation data."}, "abstract": {"value": "The goal of social alignment for AI systems is to make sure these models can conduct themselves appropriately following social values. Unlike humans who establish a consensus on value judgments through social interaction, current language models (LMs) are trained to rigidly recite the corpus in social isolation, which causes poor generalization in unfamiliar cases and the lack of robustness under adversarial attacks. In this work, we introduce a new training paradigm that enables LMs to learn from simulated social interactions. Compared with existing methods, our method is much more scalable and efficient, and shows superior performance in alignment benchmarks and human evaluation."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/23546de2f29fde5570f4b0253301a17db7c453cd.pdf"}, "supplementary_material": {"value": "/attachment/b3d44cc2ae546df84b29790eaee520c8490482e8.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024training,\ntitle={Training Socially Aligned Language Models on Simulated Social Interactions},\nauthor={Ruibo Liu and Ruixin Yang and Chenyan Jia and Ge Zhang and Diyi Yang and Soroush Vosoughi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NddKiWtdUm}\n}"}, "paperhash": {"value": "liu|training_socially_aligned_language_models_on_simulated_social_interactions"}}, "number": 5792, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5792/-/Revision", "ICLR.cc/2024/Conference/Submission5792/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5792/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398182106, "cdate": 1695398182106, "tmdate": 1710547905453, "mdate": 1710547905453, "pdate": 1705410950066, "version": 2}, {"id": "vE1e1mLJ0U", "forum": "vE1e1mLJ0U", "signatures": ["ICLR.cc/2024/Conference/Submission5789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5789/Authors"], "content": {"title": {"value": "The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks."}, "authors": {"value": ["Aaron Spieler", "Nasim Rahaman", "Georg Martius", "Bernhard Sch\u00f6lkopf", "Anna Levina"]}, "authorids": {"value": ["~Aaron_Spieler1", "~Nasim_Rahaman1", "~Georg_Martius1", "~Bernhard_Sch\u00f6lkopf1", "~Anna_Levina1"]}, "keywords": {"value": ["Computational Neuroscience", "Phenomenological Neuron Modeling", "Cortical Neurons", "Recurrent Neural Networks", "Machine Learning", "Biologically Inspired Modelling"]}, "TLDR": {"value": "We propose the ELM neuron, and show that it can efficiently fit a biophysical cortical neurons I/O and solve challanging long termporal dependency tasks."}, "abstract": {"value": "Biological cortical neurons are remarkably sophisticated computational devices, temporally integrating their vast synaptic input over an intricate dendritic tree, subject to complex, nonlinearly interacting internal biological processes. \nA recent study proposed to characterize this complexity by fitting accurate surrogate models to replicate the input-output relationship of a detailed biophysical cortical pyramidal neuron model and discovered it needed temporal convolutional networks (TCN) with millions of parameters. \nRequiring these many parameters, however, could stem from a misalignment between the inductive biases of the TCN and cortical neuron's computations.\nIn light of this, and to explore the computational implications of leaky memory units and nonlinear dendritic processing, we introduce the Expressive Leaky Memory (ELM) neuron model, a biologically inspired phenomenological model of a cortical neuron.\nRemarkably, by exploiting such slowly decaying memory-like hidden states and two-layered nonlinear integration of synaptic input, our ELM neuron can accurately match the aforementioned input-output relationship with under ten thousand trainable parameters.\nTo further assess the computational ramifications of our neuron design, we evaluate it on various tasks with demanding temporal structures, including the Long Range Arena (LRA) datasets, as well as a novel neuromorphic dataset based on the Spiking Heidelberg Digits dataset (SHD-Adding). Leveraging a larger number of memory units with sufficiently long timescales, and correspondingly sophisticated synaptic integration, the ELM neuron displays substantial long-range processing capabilities, reliably outperforming the classic Transformer or Chrono-LSTM architectures on LRA, and even solving the Pathfinder-X task with over 70\\% accuracy (16k context length). These findings raise further questions about the computational sophistication of individual cortical neurons and their role in extracting complex long-range temporal dependencies."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/af99137adf970a23c028e5d9a6ff438438cf9b64.pdf"}, "supplementary_material": {"value": "/attachment/3433b77519050f9c83ff37ffe0394035f6afff45.zip"}, "_bibtex": {"value": "@inproceedings{\nspieler2024the,\ntitle={The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.},\nauthor={Aaron Spieler and Nasim Rahaman and Georg Martius and Bernhard Sch{\\\"o}lkopf and Anna Levina},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vE1e1mLJ0U}\n}"}, "paperhash": {"value": "spieler|the_expressive_leaky_memory_neuron_an_efficient_and_expressive_phenomenological_neuron_model_can_solve_longhorizon_tasks"}}, "number": 5789, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5789/-/Revision", "ICLR.cc/2024/Conference/Submission5789/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5789/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695398120322, "cdate": 1695398120322, "tmdate": 1710327519210, "mdate": 1710327519210, "pdate": 1705410950005, "version": 2}, {"id": "ykEixGIJYb", "forum": "ykEixGIJYb", "signatures": ["ICLR.cc/2024/Conference/Submission5786/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5786/Authors"], "content": {"title": {"value": "Incentivized Truthful Communication for Federated Bandits"}, "authors": {"value": ["Zhepei Wei", "Chuanhao Li", "Tianze Ren", "Haifeng Xu", "Hongning Wang"]}, "authorids": {"value": ["~Zhepei_Wei1", "~Chuanhao_Li1", "tr2bx@virginia.edu", "~Haifeng_Xu1", "~Hongning_Wang1"]}, "keywords": {"value": ["Contextual bandit", "Federated learning", "Truthful mechanism design"]}, "TLDR": {"value": "We introduce the first truthful incentive mechanism for federated bandits, where clients are incentivized to truthfully report costs for their best interests. The proposed Truth-FedBan guarantees near-optimal regret, communication and social costs."}, "abstract": {"value": "To enhance the efficiency and practicality of federated bandit learning, recent advances have introduced incentives to motivate communication among clients, where a client participates only when the incentive offered by the server outweighs its participation cost. However, existing incentive mechanisms naively assume the clients are truthful: they all report their true cost and thus the higher cost one participating client claims, the more the server has to pay. Therefore, such mechanisms are vulnerable to strategic clients aiming to optimize their own utility by misreporting. To address this issue, we propose an incentive compatible (i.e., truthful) communication protocol, named Truth-FedBan, where the incentive for each participant is independent of its self-reported cost, and reporting the true cost is the only way to achieve the best utility. More importantly, Truth-FedBan still guarantees the sub-linear regret and communication cost without any overhead. In other words, the core conceptual contribution of this paper is, for the first time, demonstrating the possibility of simultaneously achieving incentive compatibility and nearly optimal regret in federated bandit learning. Extensive numerical studies further validate the effectiveness of our proposed solution."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9685d63d43ee450e4b084c84729956cc701d2a84.pdf"}, "supplementary_material": {"value": "/attachment/1f98a93a46d8beb43caab5eccbcdbebe155ec741.pdf"}, "_bibtex": {"value": "@inproceedings{\nwei2024incentivized,\ntitle={Incentivized Truthful Communication for Federated Bandits},\nauthor={Zhepei Wei and Chuanhao Li and Tianze Ren and Haifeng Xu and Hongning Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ykEixGIJYb}\n}"}, "paperhash": {"value": "wei|incentivized_truthful_communication_for_federated_bandits"}}, "number": 5786, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5786/-/Revision", "ICLR.cc/2024/Conference/Submission5786/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5786/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397937910, "cdate": 1695397937910, "tmdate": 1709661524834, "mdate": 1709661524834, "pdate": 1705410949934, "version": 2}, {"id": "pC3WJHf51j", "forum": "pC3WJHf51j", "signatures": ["ICLR.cc/2024/Conference/Submission5782/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5782/Authors"], "content": {"title": {"value": "Large-scale Training of Foundation Models for Wearable Biosignals"}, "authors": {"value": ["Salar Abbaspourazad", "Oussama Elachqar", "Andrew Miller", "Saba Emrani", "Udhyakumar Nallasamy", "Ian Shapiro"]}, "authorids": {"value": ["~Salar_Abbaspourazad1", "~Oussama_Elachqar1", "~Andrew_Miller1", "~Saba_Emrani1", "~Udhyakumar_Nallasamy1", "~Ian_Shapiro1"]}, "keywords": {"value": ["Self-supervised learning", "Representation learning", "Foundation models", "Biosignals", "Wearable devices", "Health", "Photoplethysmography", "PPG", "Electrocardiogram", "ECG"]}, "TLDR": {"value": "We employ self-supervised learning on the unlabeled wearable data from a large health study to train foundation models for two common biosignals, PPG and ECG, and show that these models encode participants' demographics and health conditions."}, "abstract": {"value": "Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for developing neural network models for biosignals. To address this challenge, we have employed self-supervised learning using the unlabeled sensor data collected under informed consent from the large longitudinal Apple Heart and Movement Study (AHMS) to train foundation models for two common biosignals: photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch. We curated PPG and ECG datasets from AHMS that include data from ${\\sim} 141$K participants spanning ${\\sim} 3$ years. Our self-supervised learning framework includes participant level positive pair selection, stochastic augmentation module and a regularized contrastive loss optimized with momentum training, and generalizes well to both PPG and ECG modalities. We show that the pre-trained foundation models readily encode information regarding participants' demographics and health conditions. To the best of our knowledge, this is the first study that builds foundation models using large-scale PPG and ECG data collected via wearable consumer devices $\\textendash$ prior works have commonly used smaller-size datasets collected in clinical and experimental settings. We believe PPG and ECG foundation models can enhance future wearable devices by reducing the reliance on labeled data and hold the potential to help the users improve their health."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/063277aada64f1bc138528850ccf26eab0796ccb.pdf"}, "_bibtex": {"value": "@inproceedings{\nabbaspourazad2024largescale,\ntitle={Large-scale training of foundation models for wearable biosignals},\nauthor={Salar Abbaspourazad and Oussama Elachqar and Andrew Miller and Saba Emrani and Udhyakumar Nallasamy and Ian Shapiro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pC3WJHf51j}\n}"}, "paperhash": {"value": "abbaspourazad|largescale_training_of_foundation_models_for_wearable_biosignals"}}, "number": 5782, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5782/-/Revision", "ICLR.cc/2024/Conference/Submission5782/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5782/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397800427, "cdate": 1695397800427, "tmdate": 1709748072862, "mdate": 1709748072862, "pdate": 1705410949826, "version": 2}, {"id": "OIsahq1UYC", "forum": "OIsahq1UYC", "signatures": ["ICLR.cc/2024/Conference/Submission5779/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5779/Authors"], "content": {"title": {"value": "Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization"}, "authors": {"value": ["Dinghuai Zhang", "Ricky T. Q. Chen", "Cheng-Hao Liu", "Aaron Courville", "Yoshua Bengio"]}, "authorids": {"value": ["~Dinghuai_Zhang1", "~Ricky_T._Q._Chen1", "~Cheng-Hao_Liu1", "~Aaron_Courville3", "~Yoshua_Bengio1"]}, "keywords": {"value": ["probabilistic inference", "sampling", "stochastic optimal control", "gflownets"]}, "abstract": {"value": "We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. \nWe extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities.  \nThe main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time.\nIn this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional ``flow function''.\nOur method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals.\nThrough various challenging experiments, we demonstrate that DGFS achieves more accurate estimates of the normalization constant than closely-related prior methods."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/de8c85381bfe2bb45303e6b306010705d7a2f519.pdf"}, "TLDR": {"value": "DGFS is an algorithm which learns a stochastic process to sample from unnormalized densities, and can update parameters without full specification of diffusion chains."}, "_bibtex": {"value": "@inproceedings{\nzhang2024diffusion,\ntitle={Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization},\nauthor={Dinghuai Zhang and Ricky T. Q. Chen and Cheng-Hao Liu and Aaron Courville and Yoshua Bengio},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OIsahq1UYC}\n}"}, "paperhash": {"value": "zhang|diffusion_generative_flow_samplers_improving_learning_signals_through_partial_trajectory_optimization"}}, "number": 5779, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5779/-/Revision", "ICLR.cc/2024/Conference/Submission5779/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5779/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397758995, "cdate": 1695397758995, "tmdate": 1709796369755, "mdate": 1709796369755, "pdate": 1705410949664, "version": 2}, {"id": "eMNN0wIyVw", "forum": "eMNN0wIyVw", "signatures": ["ICLR.cc/2024/Conference/Submission5773/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5773/Authors"], "content": {"title": {"value": "On Trajectory Augmentations for Off-Policy Evaluation"}, "authors": {"value": ["Ge Gao", "Qitong Gao", "Xi Yang", "Song Ju", "Miroslav Pajic", "Min Chi"]}, "authorids": {"value": ["~Ge_Gao4", "~Qitong_Gao1", "~Xi_Yang11", "~Song_Ju1", "~Miroslav_Pajic2", "~Min_Chi1"]}, "keywords": {"value": ["Trajectory augmentation", "Off-policy evaluation", "Sub-trajectory mining from offline dataset"]}, "abstract": {"value": "In the realm of reinforcement learning (RL), off-policy evaluation (OPE) holds a pivotal position, especially in high-stake human-involved scenarios such as e-learning and healthcare. Applying OPE to these domains is often challenging with scarce and underrepresentative offline training trajectories. Data augmentation has been a successful technique to enrich training data. However, directly employing existing data augmentation methods to OPE may not be feasible, due to the Markovian nature within the offline trajectories and the desire for generalizability across diverse target policies. In this work, we propose an offline trajectory augmentation approach to specifically facilitate OPE in human-involved scenarios. We propose sub-trajectory mining to extract potentially valuable sub-trajectories from offline data, and diversify the behaviors within those sub-trajectories by varying coverage of the state-action space. Our work was empirically evaluated in a wide array of environments, encompassing both simulated scenarios and real-world domains like robotic control, healthcare, and e-learning, where the training trajectories include varying levels of coverage of the state-action space. By enhancing the performance of a variety of OPE methods, our work offers a promising path forward for tackling OPE challenges in situations where data may be limited or underrepresentative."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8367960c358d27a6972674e436b78637669da0e3.pdf"}, "supplementary_material": {"value": "/attachment/5bc5195910214ff51cb07371bc708cfb92d74c46.zip"}, "_bibtex": {"value": "@inproceedings{\ngao2024on,\ntitle={On Trajectory Augmentations for Off-Policy Evaluation},\nauthor={Ge Gao and Qitong Gao and Xi Yang and Song Ju and Miroslav Pajic and Min Chi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eMNN0wIyVw}\n}"}, "paperhash": {"value": "gao|on_trajectory_augmentations_for_offpolicy_evaluation"}}, "number": 5773, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5773/-/Revision", "ICLR.cc/2024/Conference/Submission5773/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5773/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397620579, "cdate": 1695397620579, "tmdate": 1710444657023, "mdate": 1710444657023, "pdate": 1705410949420, "version": 2}, {"id": "rsg1mvUahT", "forum": "rsg1mvUahT", "signatures": ["ICLR.cc/2024/Conference/Submission5765/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5765/Authors"], "content": {"title": {"value": "Federated Wasserstein Distance"}, "authors": {"value": ["Alain Rakotomamonjy", "Kimia Nadjahi", "Liva Ralaivola"]}, "authorids": {"value": ["~Alain_Rakotomamonjy1", "~Kimia_Nadjahi1", "~Liva_Ralaivola1"]}, "keywords": {"value": ["Wasserstein distance", "Federated Learning ; Triangle inequality"]}, "TLDR": {"value": "We propose a federated manner of computing Wasserstein distance by exploiting its metric property and its geodesics"}, "abstract": {"value": "We introduce a principled way of computing the Wasserstein distance between two distributions in a federated manner.\nNamely, we show how to estimate the Wasserstein distance between two samples stored and\n kept on different devices/clients whilst a central entity/server orchestrates the computations \n (again, without having access to the samples). To achieve this feat, we take advantage of the geometric \nproperties of the Wasserstein distance -- in particular, the triangle inequality -- \n and that of the associated {\\em geodesics}: our algorithm, FedWad (for Federated Wasserstein Distance), iteratively approximates \n the Wasserstein distance by manipulating and exchanging distributions from the\n  space of geodesics in lieu of the input samples. \n  In addition to establishing the convergence properties of FedWad,\n   we provide empirical results on federated coresets and federate \n   optimal transport dataset distance, that we respectively exploit for\n   building a novel federated model and for boosting performance of popular federated learning algorithms."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/446095c988fb662bcc081d85ae97a8856db72dac.pdf"}, "supplementary_material": {"value": "/attachment/682ed64cee4a6aabb9ff16869c0d65cdf0280428.zip"}, "_bibtex": {"value": "@inproceedings{\nrakotomamonjy2024federated,\ntitle={Federated Wasserstein Distance},\nauthor={Alain Rakotomamonjy and Kimia Nadjahi and Liva Ralaivola},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rsg1mvUahT}\n}"}, "paperhash": {"value": "rakotomamonjy|federated_wasserstein_distance"}}, "number": 5765, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5765/-/Revision", "ICLR.cc/2024/Conference/Submission5765/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5765/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397455190, "cdate": 1695397455190, "tmdate": 1711747096597, "mdate": 1711747096597, "pdate": 1705410949288, "version": 2}, {"id": "UulwvAU1W0", "forum": "UulwvAU1W0", "signatures": ["ICLR.cc/2024/Conference/Submission5759/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5759/Authors"], "content": {"title": {"value": "Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"}, "authors": {"value": ["Haojie Huang", "Owen Lewis Howell", "Dian Wang", "Xupeng Zhu", "Robert Platt", "Robin Walters"]}, "authorids": {"value": ["~Haojie_Huang1", "~Owen_Lewis_Howell1", "~Dian_Wang1", "~Xupeng_Zhu1", "~Robert_Platt1", "~Robin_Walters1"]}, "keywords": {"value": ["Robot Learning", "Geometric Deep Learning", "Robotic Manipulation", "Equivariant deep learning"]}, "abstract": {"value": "Many complex robotic manipulation tasks can be decomposed as a sequence of pick and place actions. Training a robotic agent to learn this sequence over many different starting conditions typically requires many iterations or demonstrations, especially in 3D environments. In this work, we propose Fourier Transporter ($\\text{FourTran}$), which leverages the two-fold $\\mathrm{SE}(d)\\times\\mathrm{SE}(d)$  symmetry in the pick-place problem to achieve much higher sample efficiency. $\\text{FourTran}$ is an open-loop behavior cloning method trained using expert demonstrations to predict pick-place actions on new configurations. $\\text{FourTran}$ is constrained by the symmetries of the pick and place actions independently. Our method utilizes a fiber space Fourier transformation that allows for memory-efficient computation. Tests on the RLbench benchmark achieve state-of-the-art results across various tasks."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f56c749096b09d978aa51c7d16cb12dc4a128f65.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024fourier,\ntitle={Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D},\nauthor={Haojie Huang and Owen Lewis Howell and Dian Wang and Xupeng Zhu and Robert Platt and Robin Walters},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UulwvAU1W0}\n}"}, "TLDR": {"value": "Sample efficient policy learning for manipulation in 3D"}, "paperhash": {"value": "huang|fourier_transporter_biequivariant_robotic_manipulation_in_3d"}}, "number": 5759, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5759/-/Revision", "ICLR.cc/2024/Conference/Submission5759/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5759/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397362585, "cdate": 1695397362585, "tmdate": 1710541284817, "mdate": 1710541284817, "pdate": 1705410949181, "version": 2}, {"id": "Zz594UBNOH", "forum": "Zz594UBNOH", "signatures": ["ICLR.cc/2024/Conference/Submission5751/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5751/Authors"], "content": {"title": {"value": "Clifford Group Equivariant Simplicial Message Passing Networks"}, "authors": {"value": ["Cong Liu", "David Ruhe", "Floor Eijkelboom", "Patrick Forr\u00e9"]}, "authorids": {"value": ["~Cong_Liu9", "~David_Ruhe1", "~Floor_Eijkelboom1", "~Patrick_Forr\u00e91"]}, "keywords": {"value": ["Clifford Algebra", "Geometric Algebra", "Graph Neural Networks", "Simplicial Message Passing", "Topological Deep Learning", "Geometric Deep Learning", "Equivariance"]}, "abstract": {"value": "We introduce Clifford Group Equivariant Simplicial Message Passing Networks, a method for steerable $\\mathrm{E}(n)$-equivariant message passing on simplicial complexes. Our method integrates the expressivity of Clifford group-equivariant layers with simplicial message passing, which is topologically more intricate than regular graph message passing. Clifford algebras include higher-order objects such as bivectors and trivectors, which express geometric features (e.g., areas, volumes) derived from vectors. Using this knowledge, we represent simplex features through geometric products of their vertices. To achieve efficient simplicial message passing, we share the parameters of the message network across different dimensions. Additionally, we restrict the final message to an aggregation of the incoming messages from different dimensions, leading to what we term *shared* simplicial message passing. Experimental results show that our method is able to outperform both equivariant and simplicial graph neural networks on a variety of geometric tasks."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b36c2a5c88237ebfb655ca10f48c9ec5cdb3b24.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024clifford,\ntitle={Clifford Group Equivariant Simplicial Message Passing Networks},\nauthor={Cong Liu and David Ruhe and Floor Eijkelboom and Patrick Forr{\\'e}},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Zz594UBNOH}\n}"}, "paperhash": {"value": "liu|clifford_group_equivariant_simplicial_message_passing_networks"}}, "number": 5751, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5751/-/Revision", "ICLR.cc/2024/Conference/Submission5751/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5751/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695397030048, "cdate": 1695397030048, "tmdate": 1710247169584, "mdate": 1710247169584, "pdate": 1705410948912, "version": 2}, {"id": "NxoFmGgWC9", "forum": "NxoFmGgWC9", "signatures": ["ICLR.cc/2024/Conference/Submission5748/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5748/Authors"], "content": {"title": {"value": "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation"}, "authors": {"value": ["Hongtao Wu", "Ya Jing", "Chilam Cheang", "Guangzeng Chen", "Jiafeng Xu", "Xinghang Li", "Minghuan Liu", "Hang Li", "Tao Kong"]}, "authorids": {"value": ["~Hongtao_Wu2", "~Ya_Jing2", "~Chilam_Cheang1", "~Guangzeng_Chen1", "~Jiafeng_Xu2", "~Xinghang_Li1", "~Minghuan_Liu1", "~Hang_Li4", "~Tao_Kong3"]}, "keywords": {"value": ["Visual Robot Manipulation", "Video Generative Pre-Training", "Causal Transformer"]}, "abstract": {"value": "Generative pre-trained models have demonstrated remarkable effectiveness in language and vision domains by learning useful representations. In this paper, we extend the scope of this effectiveness by showing that visual robot manipulation can significantly benefit from large-scale video generative pre-training. We introduce GR-1, a GPT-style model designed for multi-task language-conditioned visual robot manipulation. GR-1 takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states. It predicts robot actions as well as future images in an end-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly finetuned on robot data after pre-trained on a large-scale video dataset. We perform extensive experiments on the challenging CALVIN benchmark and a real robot. On CALVIN benchmark, our method outperforms state-of-the-art baseline methods and improves the success rate from 88.9% to 94.9%. In the setting of zero-shot unseen scene generalization, GR-1 improves the success rate from 53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline methods and shows strong potentials in generalization to unseen scenes and objects. We provide inaugural evidence that a unified GPT-style transformer, augmented with large-scale video generative pre-training, exhibits remarkable generalization to multi-task visual robot manipulation. Project page: https://GR1-Manipulation.github.io"}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/aaad6a41f63d34aa186ee9635d74c908044d2aec.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024unleashing,\ntitle={Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation},\nauthor={Hongtao Wu and Ya Jing and Chilam Cheang and Guangzeng Chen and Jiafeng Xu and Xinghang Li and Minghuan Liu and Hang Li and Tao Kong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NxoFmGgWC9}\n}"}, "paperhash": {"value": "wu|unleashing_largescale_video_generative_pretraining_for_visual_robot_manipulation"}}, "number": 5748, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5748/-/Revision", "ICLR.cc/2024/Conference/Submission5748/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5748/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396950719, "cdate": 1695396950719, "tmdate": 1709696715987, "mdate": 1709696715987, "pdate": 1705410948800, "version": 2}, {"id": "EDPxCjXzSb", "forum": "EDPxCjXzSb", "signatures": ["ICLR.cc/2024/Conference/Submission5738/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5738/Authors"], "content": {"title": {"value": "Vision-by-Language for Training-Free Compositional Image Retrieval"}, "authors": {"value": ["Shyamgopal Karthik", "Karsten Roth", "Massimiliano Mancini", "Zeynep Akata"]}, "authorids": {"value": ["~Shyamgopal_Karthik1", "~Karsten_Roth1", "~Massimiliano_Mancini1", "~Zeynep_Akata1"]}, "keywords": {"value": ["Vision-Language Models", "Large Language Models"]}, "abstract": {"value": "Given an image and a target modification (e.g an image of the Eiffel tower and the text \u201cwithout people and at night-time\u201d), Compositional Image Retrieval (CIR) aims to retrieve the relevant target image in a database. While supervised approaches rely on annotating triplets that is costly (i.e. query image, textual modification, and target image), recent research sidesteps this need by using large-scale vision-language models (VLMs), performing Zero-Shot CIR (ZS-CIR). However, state-of-the-art approaches in ZS-CIR still require training task-specific, customized models over large amounts of image-text pairs. In this work, we proposeto tackle CIR in a training-free manner via our Compositional Image Retrieval through Vision-by-Language (CIReVL), a simple, yet human-understandable and scalable pipeline that effectively recombines large-scale VLMs with large language models (LLMs). By captioning the reference image using a pre-trained generative VLM and asking a LLM to recompose the caption based on the textual target modification for subsequent retrieval via e.g. CLIP, we achieve modular language reasoning. In four ZS-CIR benchmarks, we find competitive, in-part state-of-the-art performance - improving over supervised methods Moreover, the modularity of CIReVL offers simple scalability without re-training, allowing us to both investigate scaling laws and bottlenecks for ZS-CIR while easily scaling up to in parts more than double of previously reported results. Finally, we show that CIReVL makes CIR human-understandable by composing image and text in a modular fashion in the language domain, thereby making it intervenable, allowing to post-hoc re-align failure cases. Code will be released upon acceptance."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0f4e27a3a0c5ab1ab0875b9ae007336586ef0e0a.pdf"}, "TLDR": {"value": "A simple method using off-the-shelf foundation models for Composed Image Retrieval without any training"}, "_bibtex": {"value": "@inproceedings{\nkarthik2024visionbylanguage,\ntitle={Vision-by-Language for Training-Free Compositional Image Retrieval},\nauthor={Shyamgopal Karthik and Karsten Roth and Massimiliano Mancini and Zeynep Akata},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EDPxCjXzSb}\n}"}, "paperhash": {"value": "karthik|visionbylanguage_for_trainingfree_compositional_image_retrieval"}}, "number": 5738, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5738/-/Revision", "ICLR.cc/2024/Conference/Submission5738/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5738/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396628106, "cdate": 1695396628106, "tmdate": 1709661524464, "mdate": 1709661524464, "pdate": 1705410948461, "version": 2}, {"id": "wYmvN3sQpG", "forum": "wYmvN3sQpG", "signatures": ["ICLR.cc/2024/Conference/Submission5736/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5736/Authors"], "content": {"title": {"value": "Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate"}, "authors": {"value": ["Miao Lu", "Beining Wu", "Xiaodong Yang", "Difan Zou"]}, "authorids": {"value": ["~Miao_Lu3", "~Beining_Wu1", "~Xiaodong_Yang7", "~Difan_Zou1"]}, "keywords": {"value": ["deep learning theory; large learning rate; oscillation of stochastic gradient descent;"]}, "abstract": {"value": "In this work, we theoretically investigate the generalization properties of neural networks (NN) trained by stochastic gradient descent (SGD) with large learning rates. Under such a training regime, our finding is that, the oscillation of the NN weights caused by SGD with large learning rates turns out to be beneficial to the generalization of the NN, potentially improving over the same NN trained by SGD with small learning rates that converges more smoothly. In view of this finding, we call such a phenomenon \u201cbenign oscillation\u201d. Our theory towards demystifying such a phenomenon builds upon the feature learning perspective of deep learning. Specifically, we consider a feature-noise data generation model that consists of (i) weak features which have a small $\\ell_2$-norm and appear in each data point; (ii) strong features which have a large $\\ell_2$-norm but appear only in a certain fraction of all data points; and (iii) noise. We prove that NNs trained by oscillating SGD with a large learning rate can effectively learn the weak features in the presence of those strong features. In contrast, NNs trained by SGD with a small learning rate can only learn the strong features but make little progress in learning the weak features. Consequently, when it comes to the new testing data points that consist of only weak features, the NN trained by oscillating SGD with a large learning rate can still make correct predictions, while the NN trained by SGD with a small learning rate could not. Our theory sheds light on how large learning rate training benefits the generalization of NNs. Experimental results demonstrate our  findings on the phenomenon of \u201cbenign oscillation\u201d."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c1e68b675f4e8214a53f427de0bf2f2159682bfa.pdf"}, "supplementary_material": {"value": ""}, "_bibtex": {"value": "@inproceedings{\nlu2024benign,\ntitle={Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate},\nauthor={Miao Lu and Beining Wu and Xiaodong Yang and Difan Zou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wYmvN3sQpG}\n}"}, "TLDR": {"value": "We investigate the generalization properties of NN trained by SGD with large learning rates."}, "paperhash": {"value": "lu|benign_oscillation_of_stochastic_gradient_descent_with_large_learning_rate"}}, "number": 5736, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5736/-/Revision", "ICLR.cc/2024/Conference/Submission5736/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5736/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396575248, "cdate": 1695396575248, "tmdate": 1710229980196, "mdate": 1710229980196, "pdate": 1705410948420, "version": 2}, {"id": "ltZ9ianMth", "forum": "ltZ9ianMth", "signatures": ["ICLR.cc/2024/Conference/Submission5735/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5735/Authors"], "content": {"title": {"value": "RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies"}, "authors": {"value": ["Hao Cheng", "Qingsong Wen", "Yang Liu", "Liang Sun"]}, "authorids": {"value": ["~Hao_Cheng5", "~Qingsong_Wen2", "~Yang_Liu3", "~Liang_Sun2"]}, "keywords": {"value": ["Robust time series forecasting; learning with noisy labels"]}, "TLDR": {"value": "An simple and efficient algorithm to deal with anomalies in time series data"}, "abstract": {"value": "Time series forecasting is an important and forefront task whose techniques have been applied to electricity forecasting, trajectory prediction, labor planning, etc. However, most of time series forecasting techniques assume that the training data is clean without anomalies. This assumption is unrealistic since the collected time series data can be contaminated in practice. The forecasting model will be inferior if it is directly trained by time series with anomalies. Thus it is essential to develop methods to automatically learn a robust forecasting model from the contaminated data. In this paper, we first statistically define three types of anomalies, then theoretically and experimentally analyze the loss robustness and sample robustness when these anomalies exist. Based on our analyses, we propose a simple and efficient algorithm to learn a robust forecasting model. Extensive experiments show that our method is highly robust and outperforms all existing approaches. The code is available at https://github.com/haochenglouis/RobustTSF."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/26c803ecf9794f4827a2507c69698ecefa1c6960.pdf"}, "_bibtex": {"value": "@inproceedings{\ncheng2024robusttsf,\ntitle={Robust{TSF}: Towards Theory and Design of Robust Time Series Forecasting with Anomalies},\nauthor={Hao Cheng and Qingsong Wen and Yang Liu and Liang Sun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ltZ9ianMth}\n}"}, "paperhash": {"value": "cheng|robusttsf_towards_theory_and_design_of_robust_time_series_forecasting_with_anomalies"}}, "number": 5735, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5735/-/Revision", "ICLR.cc/2024/Conference/Submission5735/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5735/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396574910, "cdate": 1695396574910, "tmdate": 1710343415244, "mdate": 1710343415244, "pdate": 1705410948345, "version": 2}, {"id": "PXD3FAVHJT", "forum": "PXD3FAVHJT", "signatures": ["ICLR.cc/2024/Conference/Submission5728/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5728/Authors"], "content": {"title": {"value": "Understanding the Effects of RLHF on LLM Generalisation and Diversity"}, "authors": {"value": ["Robert Kirk", "Ishita Mediratta", "Christoforos Nalmpantis", "Jelena Luketina", "Eric Hambro", "Edward Grefenstette", "Roberta Raileanu"]}, "authorids": {"value": ["~Robert_Kirk1", "~Ishita_Mediratta1", "~Christoforos_Nalmpantis1", "~Jelena_Luketina1", "~Eric_Hambro1", "~Edward_Grefenstette1", "~Roberta_Raileanu2"]}, "keywords": {"value": ["reinforcement learning", "large language models", "rlhf", "ood generalisation", "diversity"]}, "TLDR": {"value": "We analyse the effects of RLHF fine-tuning on LLMs in terms of OOD generalisation and output diversity, finding that RLHF makes better-generalising but less diverse models"}, "abstract": {"value": "Large language models (LLMs) fine-tuned with reinforcement learning from human feedback (RLHF) have been used in some of the most widely deployed AI models to date, such as OpenAI's ChatGPT or Anthropic's Claude. While there has been significant work developing these methods, our understanding of the benefits and downsides of each stage in RLHF is still limited. To fill this gap, we present an extensive analysis of how each stage of the process (i.e. supervised fine-tuning (SFT), reward modelling, and RLHF) affects two key properties: out-of-distribution (OOD) generalisation and output diversity. OOD generalisation is crucial given the wide range of real-world scenarios in which these models are being used, while output diversity refers to the model's ability to generate varied outputs and is important for a variety of use cases. We perform our analysis across two base models on both summarisation and instruction following tasks, the latter being highly relevant for current LLM use cases. We find that RLHF generalises better than SFT to new inputs, particularly as the distribution shift between train and test becomes larger. However, RLHF significantly reduces output diversity compared to SFT across a variety of measures, implying a tradeoff in current LLM fine-tuning methods between generalisation and diversity. Our results provide guidance on which fine-tuning method should be used depending on the application, and show that more research is needed to improve the tradeoff between generalisation and diversity."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6f1e5006fcc3a70f6fecd669f989e44c7c7c8e08.pdf"}, "_bibtex": {"value": "@inproceedings{\nkirk2024understanding,\ntitle={Understanding the Effects of {RLHF} on {LLM} Generalisation and Diversity},\nauthor={Robert Kirk and Ishita Mediratta and Christoforos Nalmpantis and Jelena Luketina and Eric Hambro and Edward Grefenstette and Roberta Raileanu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PXD3FAVHJT}\n}"}, "paperhash": {"value": "kirk|understanding_the_effects_of_rlhf_on_llm_generalisation_and_diversity"}}, "number": 5728, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5728/-/Revision", "ICLR.cc/2024/Conference/Submission5728/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5728/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396482152, "cdate": 1695396482152, "tmdate": 1709661524333, "mdate": 1709661524333, "pdate": 1705410948159, "version": 2}, {"id": "ATEawsFUj4", "forum": "ATEawsFUj4", "signatures": ["ICLR.cc/2024/Conference/Submission5722/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5722/Authors"], "content": {"title": {"value": "GAIA: Zero-shot Talking Avatar Generation"}, "authors": {"value": ["Tianyu He", "Junliang Guo", "Runyi Yu", "Yuchi Wang", "jialiang zhu", "Kaikai An", "Leyi Li", "Xu Tan", "Chunyu Wang", "Han Hu", "HsiangTao Wu", "sheng zhao", "Jiang Bian"]}, "authorids": {"value": ["~Tianyu_He1", "~Junliang_Guo1", "~Runyi_Yu1", "~Yuchi_Wang1", "~jialiang_zhu2", "~Kaikai_An1", "~Leyi_Li1", "~Xu_Tan1", "~Chunyu_Wang1", "~Han_Hu1", "~HsiangTao_Wu1", "~sheng_zhao1", "~Jiang_Bian1"]}, "keywords": {"value": ["Talking Avatar Generation", "Video Generation", "Disentanglement", "Diffusion Models"]}, "abstract": {"value": "Zero-shot talking avatar generation aims at synthesizing natural talking videos from speech and a single portrait image. Previous methods have relied on domain-specific heuristics such as warping-based motion representation and 3D Morphable Models, which limit the naturalness and diversity of the generated avatars. In this work, we introduce GAIA (Generative AI for Avatar), which eliminates the domain priors in talking avatar generation. In light of the observation that the speech only drives the motion of the avatar while the appearance of the avatar and the background typically remain the same throughout the entire video, we divide our approach into two stages: 1) disentangling each frame into motion and appearance representations; 2) generating motion sequences conditioned on the speech and reference portrait image. We collect a large-scale high-quality talking avatar dataset and train the model on it with different scales (up to 2B parameters). Experimental results verify the superiority, scalability, and flexibility of GAIA as 1) the resulting model beats previous baseline models in terms of naturalness, diversity, lip-sync quality, and visual quality; 2) the framework is scalable since larger models yield better results; 3) it is general and enables different applications like controllable talking avatar generation and text-instructed avatar generation."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b2a0bcb53dd30b0eaf30797acfc1d2a0099a1a1.pdf"}, "supplementary_material": {"value": "/attachment/5e232f403fc3dd96d63591c6871d42425e9a6f46.zip"}, "_bibtex": {"value": "@inproceedings{\nhe2024gaia,\ntitle={{GAIA}: Data-driven Zero-shot Talking Avatar Generation},\nauthor={Tianyu He and Junliang Guo and Runyi Yu and Yuchi Wang and jialiang zhu and Kaikai An and Leyi Li and Xu Tan and Chunyu Wang and Han Hu and HsiangTao Wu and sheng zhao and Jiang Bian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ATEawsFUj4}\n}"}, "paperhash": {"value": "he|gaia_zeroshot_talking_avatar_generation"}}, "number": 5722, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5722/-/Revision", "ICLR.cc/2024/Conference/Submission5722/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5722/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695396314534, "cdate": 1695396314534, "tmdate": 1709661524238, "mdate": 1709661524238, "pdate": 1705410947873, "version": 2}, {"id": "skcTCdJz0f", "forum": "skcTCdJz0f", "signatures": ["ICLR.cc/2024/Conference/Submission5704/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5704/Authors"], "content": {"title": {"value": "Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization"}, "authors": {"value": ["Amirhossein Vahidi", "Simon Schosser", "Lisa Wimmer", "Yawei Li", "Bernd Bischl", "Eyke H\u00fcllermeier", "Mina Rezaei"]}, "authorids": {"value": ["~Amirhossein_Vahidi1", "~Simon_Schosser1", "~Lisa_Wimmer1", "~Yawei_Li2", "~Bernd_Bischl1", "~Eyke_H\u00fcllermeier1", "~Mina_Rezaei1"]}, "keywords": {"value": ["Self-supervised Learning", "Probablistic Machine Learning", "Proper Scoring Rule"]}, "TLDR": {"value": "We propose a novel probabilistic self-supervised learning via scoring rule minimization (ProSMin) to enhance representation quality and mitigate collapsing representations."}, "abstract": {"value": "%\nSelf-supervised learning methods have shown promising results across a wide range of tasks in computer vision, natural language processing, and multimodal analysis. However, self-supervised approaches come with a notable limitation, dimensional collapse, where a model doesn't fully utilize its capacity to encode information optimally. Motivated by this, we propose ProSMin, a novel probabilistic self-supervised learning approach that leverages the power of probabilistic models to enhance representation quality and mitigate collapsing representations. Our proposed approach involves two neural networks, the online network and the target network, which collaborate and learn the diverse distribution of representations from each other through probabilistic knowledge distillation. The two networks are trained via our new loss function based on proper scoring rules. We provide a theoretical justification for ProSMin and demonstrate its modified scoring rule. This insight validates the method's optimization process and contributes to its robustness and effectiveness in improving representation quality. We evaluate our probabilistic model on various downstream tasks, such as in-distribution generalization, out-of-distribution detection, dataset corruption, low-shot learning, and transfer learning. Our method achieves superior accuracy and calibration, outperforming the self-supervised baseline in a variety of experiments on large datasets such as ImageNet-O and ImageNet-C. ProSMin thus demonstrates its scalability and real-world applicability. Our code is publicly available: https://github.com/amirvhd/SSL-sore-rule."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a890fe173ee454dd20bc8d12ee039d25298b5ea7.pdf"}, "supplementary_material": {"value": "/attachment/9a823ca18a3c0fa7b3b250cb2d132ae572731d32.zip"}, "_bibtex": {"value": "@inproceedings{\nvahidi2024probabilistic,\ntitle={Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization},\nauthor={Amirhossein Vahidi and Simon Schosser and Lisa Wimmer and Yawei Li and Bernd Bischl and Eyke H{\\\"u}llermeier and Mina Rezaei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=skcTCdJz0f}\n}"}, "paperhash": {"value": "vahidi|probabilistic_selfsupervised_representation_learning_via_scoring_rules_minimization"}}, "number": 5704, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5704/-/Revision", "ICLR.cc/2024/Conference/Submission5704/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5704/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695395742261, "cdate": 1695395742261, "tmdate": 1710698065844, "mdate": 1710698065844, "pdate": 1705410947521, "version": 2}, {"id": "3zvB14IF6D", "forum": "3zvB14IF6D", "signatures": ["ICLR.cc/2024/Conference/Submission5701/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5701/Authors"], "content": {"title": {"value": "DORSal: Diffusion for Object-centric Representations of Scenes $\\textit{et al.}$"}, "authors": {"value": ["Allan Jabri", "Sjoerd van Steenkiste", "Emiel Hoogeboom", "Mehdi S. M. Sajjadi", "Thomas Kipf"]}, "authorids": {"value": ["~Allan_Jabri2", "~Sjoerd_van_Steenkiste1", "~Emiel_Hoogeboom1", "~Mehdi_S._M._Sajjadi1", "~Thomas_Kipf2"]}, "keywords": {"value": ["novel view synthesis", "object-centric scene representations", "camera control", "scene editing", "3D", "diffusion", "generative models"]}, "TLDR": {"value": "We propose DORSal, which adapts video diffusion models to 3D scene generation conditioned on object-centric, slot-based representations of scenes."}, "abstract": {"value": "Recent progress in 3D scene understanding enables scalable learning of representations across large datasets of diverse scenes. As a consequence, generalization to unseen scenes and objects, rendering novel views from just a single or a handful of input images, and controllable scene generation that supports editing, is now possible. However, training jointly on a large number of scenes typically compromises rendering quality when compared to single-scene optimized models such as NeRFs. In this paper, we leverage recent progress in diffusion models to equip 3D scene representation learning models with the ability to render high-fidelity novel views, while retaining benefits such as object-level scene editing to a large degree. In particular, we propose DORSal, which adapts a video diffusion architecture for 3D scene generation conditioned on frozen object-centric slot-based representations of scenes. On both complex synthetic multi-object scenes and on the real-world large-scale Street View dataset, we show that DORSal enables scalable neural rendering of 3D scenes with object-level editing and improves upon existing approaches."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/12268aed4b6839cd67ba4f54bf2535036ad671a2.pdf"}, "supplementary_material": {"value": "/attachment/ca67852edc6143b7cc616754dc453757a5449790.zip"}, "_bibtex": {"value": "@inproceedings{\njabri2024dorsal,\ntitle={{DORS}al: Diffusion for Object-centric Representations of Scenes \\${\\textbackslash}textit\\{et al.\\}\\$},\nauthor={Allan Jabri and Sjoerd van Steenkiste and Emiel Hoogeboom and Mehdi S. M. Sajjadi and Thomas Kipf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3zvB14IF6D}\n}"}, "paperhash": {"value": "jabri|dorsal_diffusion_for_objectcentric_representations_of_scenes_\\textitet_al"}}, "number": 5701, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5701/-/Revision", "ICLR.cc/2024/Conference/Submission5701/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5701/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695395695624, "cdate": 1695395695624, "tmdate": 1710443592192, "mdate": 1710443592192, "pdate": 1705410947399, "version": 2}, {"id": "3y2TfP966N", "forum": "3y2TfP966N", "signatures": ["ICLR.cc/2024/Conference/Submission5683/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5683/Authors"], "content": {"title": {"value": "T-Rep: Representation Learning for Time Series using Time-Embeddings"}, "authors": {"value": ["Archibald Felix Fraikin", "Adrien Bennetot", "Stephanie Allassonniere"]}, "authorids": {"value": ["~Archibald_Felix_Fraikin1", "~Adrien_Bennetot1", "~Stephanie_Allassonniere1"]}, "keywords": {"value": ["Multivariate time series", "Self-supervised", "Time series representations", "Temporal features", "Time-Embeddings", "Representation Learning", "Missing data"]}, "TLDR": {"value": "T-Rep is a self-supervised method to learn time series representations at a time-step granularity that outperforms existing self-supervised algorithms in classification, forecasting and anomaly detection tasks"}, "abstract": {"value": "Multivariate time series present challenges to standard machine learning techniques, as they are often unlabeled, high dimensional, noisy, and contain missing data. To address this, we propose T-Rep, a self-supervised method to learn time series representations at a timestep granularity. T-Rep learns vector embeddings of time alongside its feature extractor, to extract temporal features such as trend, periodicity, or distribution shifts from the signal. These time-embeddings are leveraged in pretext tasks, to incorporate smooth and fine-grained temporal dependencies in the representations, as well as reinforce robustness to missing data. We evaluate T-Rep on downstream classification, forecasting, and anomaly detection tasks. It is compared to existing self-supervised algorithms for time series, which it outperforms in all three tasks. We test T-Rep in missing data regimes, where it proves more resilient than its counterparts. Finally, we provide latent space visualisation experiments, highlighting the interpretability of the learned representations."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/26d2dcb3b19b6bbc380c5a483b1a363f0acbdf2b.pdf"}, "_bibtex": {"value": "@inproceedings{\nfraikin2024trep,\ntitle={T-Rep: Representation Learning for Time Series using Time-Embeddings},\nauthor={Archibald Felix Fraikin and Adrien Bennetot and Stephanie Allassonniere},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3y2TfP966N}\n}"}, "paperhash": {"value": "fraikin|trep_representation_learning_for_time_series_using_timeembeddings"}}, "number": 5683, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5683/-/Revision", "ICLR.cc/2024/Conference/Submission5683/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5683/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695395052199, "cdate": 1695395052199, "tmdate": 1710862615728, "mdate": 1710862615728, "pdate": 1705410947007, "version": 2}, {"id": "1VeQ6VBbev", "forum": "1VeQ6VBbev", "number": 5659, "cdate": 1695394297779, "tcdate": 1695394297779, "mdate": 1710493956506, "tmdate": 1710493956506, "signatures": ["ICLR.cc/2024/Conference/Submission5659/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5659/Authors"], "content": {"title": {"value": "Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods"}, "authors": {"value": ["Sara Klein", "Simon Weissmann", "Leif D\u00f6ring"]}, "authorids": {"value": ["~Sara_Klein1", "~Simon_Weissmann1", "~Leif_D\u00f6ring1"]}, "keywords": {"value": ["reinforcement learning", "policy gradient", "stochastic approximation", "finite-time MDP"]}, "abstract": {"value": "Markov Decision Processes (MDPs) are a formal framework for modeling and solving sequential decision-making problems. In finite time horizons such problems are relevant for instance for optimal stopping or specific supply chain problems, but also in the training of large language models. In contrast to infinite horizon MDPs optimal policies are not stationary, policies must be learned for every single epoch. In practice all parameters are often trained simultaneously, ignoring the inherent structure suggested by dynamic programming. This paper introduces a combination of dynamic programming and policy gradient called dynamical policy gradient, where the parameters are trained backwards in time. \n   \n   For the tabular softmax parametrisation we carry out the convergence analysis for simultaneous and dynamic policy gradient towards global optima, both in the exact and sampled gradient settings without regularisation. It turns out that the use of dynamic policy gradient training much better exploits the structure of finite-time problems which is reflected in improved convergence bounds."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9a94ff52e2cc5d06bcf5c029ea21897b3ffc4690.pdf"}, "supplementary_material": {"value": "/attachment/2c81ff9fb426afbf43cc32ae4539fee865a0d40b.pdf"}, "_bibtex": {"value": "@inproceedings{\nklein2024beyond,\ntitle={Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods},\nauthor={Sara Klein and Simon Weissmann and Leif D{\\\"o}ring},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1VeQ6VBbev}\n}"}, "paperhash": {"value": "klein|beyond_stationarity_convergence_analysis_of_stochastic_softmax_policy_gradient_methods"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5659/-/Revision", "ICLR.cc/2024/Conference/Submission5659/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5659/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410946317, "version": 2}, {"id": "vXxardq6db", "forum": "vXxardq6db", "number": 5654, "cdate": 1695394167790, "tcdate": 1695394167790, "mdate": 1710518861601, "tmdate": 1710518861601, "signatures": ["ICLR.cc/2024/Conference/Submission5654/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5654/Authors"], "content": {"title": {"value": "SliceGPT: Compress Large Language Models by Deleting Rows and Columns"}, "authors": {"value": ["Saleh Ashkboos", "Maximilian L. Croci", "Marcelo Gennari do Nascimento", "Torsten Hoefler", "James Hensman"]}, "authorids": {"value": ["~Saleh_Ashkboos2", "~Maximilian_L._Croci1", "~Marcelo_Gennari_do_Nascimento2", "~Torsten_Hoefler1", "~James_Hensman1"]}, "keywords": {"value": ["compression", "sparsification", "large language models"]}, "TLDR": {"value": "We compress large language models by replacing the weight matrices with smaller (dense) weight matrices, which leads to speedup and storage reduction."}, "abstract": {"value": "Large language models have become the cornerstone of natural language processing, but their use comes with substantial costs in terms of compute and memory resources. Sparsification provides a solution to alleviate these resource constraints, and recent works have shown that trained models can be sparsified post-hoc. Existing sparsification techniques face challenges as they need additional data structures and offer constrained speedup with current hardware. In this paper we present SliceGPT, a new post-training sparsification scheme which replaces each weight matrix with a smaller (dense) matrix, reducing the embedding dimension of the network. Through extensive experimentation we show that SliceGPT can remove up to 25% of the model parameters (including embeddings) for LLAMA-2 70B, OPT 66B and Phi-2 models while maintaining 99%, 99% and 90% zero-shot task performance of the dense model respectively. Our sliced models run on fewer GPUs and run faster without any additional code optimization: on 24GB consumer GPUs we reduce the total compute for inference on LLAMA-2 70B to 64% of that of the dense model; on 40GB A100 GPUs we reduce it to 66%. We offer a new insight, computational invariance in transformer networks, which enables SliceGPT and we hope it will inspire and enable future avenues to reduce memory and computation demands for pre-trained models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7e4c69ea77e2c064e8518ff279df569297ec8eba.pdf"}, "_bibtex": {"value": "@inproceedings{\nashkboos2024slicegpt,\ntitle={Slice{GPT}: Compress Large Language Models by Deleting Rows and Columns},\nauthor={Saleh Ashkboos and Maximilian L. Croci and Marcelo Gennari do Nascimento and Torsten Hoefler and James Hensman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vXxardq6db}\n}"}, "paperhash": {"value": "ashkboos|slicegpt_compress_large_language_models_by_deleting_rows_and_columns"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5654/-/Revision", "ICLR.cc/2024/Conference/Submission5654/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5654/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410946111, "version": 2}, {"id": "MloaGA6WwX", "forum": "MloaGA6WwX", "number": 5650, "cdate": 1695394096672, "tcdate": 1695394096672, "mdate": 1710499397438, "tmdate": 1710499397438, "signatures": ["ICLR.cc/2024/Conference/Submission5650/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5650/Authors"], "content": {"title": {"value": "Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection"}, "authors": {"value": ["Stefano B. Blumberg", "Paddy J. Slator", "Daniel C. Alexander"]}, "authorids": {"value": ["~Stefano_B._Blumberg1", "~Paddy_J._Slator1", "~Daniel_C._Alexander1"]}, "keywords": {"value": ["Experimental Design", "Supervised Feature Selection", "Multi-Channel Imaging", "Hyperspectral Imaging", "Magnetic Resonance Imaging (MRI)", "Task-based Image Channel Selection"]}, "TLDR": {"value": "This paper presents a data-driven, task-specific paradigm for experimental design, to shorten acquisition time, reduce costs, and accelerate the deployment of imaging devices."}, "abstract": {"value": "This paper presents a data-driven, task-specific paradigm for experimental design, to shorten acquisition time, reduce costs, and accelerate the deployment of imaging devices.  Current approaches in experimental design focus on model-parameter estimation and require specification of a particular model, whereas in imaging, other tasks may drive the design.  Furthermore, such approaches often lead to intractable optimization problems in real-world imaging applications. Here we present a new paradigm for experimental design that simultaneously optimizes the design (set of image channels) and trains a machine-learning model to execute a user-specified image-analysis task. The approach obtains data densely-sampled over the measurement space (many image channels) for a small number of acquisitions, then identifies a subset of channels of prespecified size that best supports the task.  We propose a method: TADRED for TAsk-DRiven Experimental Design in imaging, to identify the most informative channel-subset  whilst simultaneously training a network to execute the task given the subset. Experiments demonstrate the potential of TADRED in diverse imaging applications: several clinically-relevant tasks in magnetic resonance imaging; and remote sensing and physiological applications of hyperspectral imaging. Results show substantial improvement over classical experimental design, two recent application-specific methods within the new paradigm, and state-of-the-art approaches in supervised feature selection.  We anticipate further applications of our approach.  Code is available: https://github.com/sbb-gh/experimental-design-multichannel"}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/40758e44a35ee658f81eec070e7556108e298bb1.pdf"}, "_bibtex": {"value": "@inproceedings{\nblumberg2024experimental,\ntitle={Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection},\nauthor={Stefano B. Blumberg and Paddy J. Slator and Daniel C. Alexander},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MloaGA6WwX}\n}"}, "paperhash": {"value": "blumberg|experimental_design_for_multichannel_imaging_via_taskdriven_feature_selection"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5650/-/Revision", "ICLR.cc/2024/Conference/Submission5650/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5650/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410946000, "version": 2}, {"id": "1oqedRt6Z7", "forum": "1oqedRt6Z7", "number": 5645, "cdate": 1695393760252, "tcdate": 1695393760252, "mdate": 1709661523791, "tmdate": 1709661523791, "signatures": ["ICLR.cc/2024/Conference/Submission5645/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5645/Authors"], "content": {"title": {"value": "Convolutional Deep Kernel Machines"}, "authors": {"value": ["Edward Milsom", "Ben Anson", "Laurence Aitchison"]}, "authorids": {"value": ["~Edward_Milsom1", "~Ben_Anson1", "~Laurence_Aitchison1"]}, "keywords": {"value": ["Gaussian process", "infinite-width neural network", "NNGP", "Bayesian deep learning"]}, "TLDR": {"value": "We develop a convolutional version of the recently introduced deep kernel machine algorithm, using a novel inducing point scheme and NN inspired techniques to obtain a practical algorithm for CIFAR-10 size datasets."}, "abstract": {"value": "Standard infinite-width limits of neural networks sacrifice the ability for intermediate layers to learn representations from data. Recent work (\u201cA theory of representation learning gives a deep generalisation of kernel methods\u201d, Yang et al. 2023) modified the Neural Network Gaussian Process (NNGP) limit of Bayesian neural networks so that representation learning is retained. Furthermore, they found that applying this modified limit to a deep Gaussian process gives a practical learning algorithm which they dubbed the \u201cdeep kernel machine\u201d (DKM). However, they only considered the simplest possible setting: regression in small, fully connected networks with e.g. 10 input features. Here, we introduce convolutional deep kernel machines. This required us to develop a novel inter-domain inducing point approximation, as well as introducing and experimentally assessing a number of techniques not previously seen in DKMs, including analogues to batch normalisation, different likelihoods, and different types of top-layer. The resulting model trains in roughly 77 GPU hours, achieving around 99\\% test accuracy on MNIST, 72\\% on CIFAR-100, and 92.7\\% on CIFAR-10, which is SOTA for kernel methods."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/901d7f61b779f040a593509514bbc149e59dfc1b.pdf"}, "_bibtex": {"value": "@inproceedings{\nmilsom2024convolutional,\ntitle={Convolutional Deep Kernel Machines},\nauthor={Edward Milsom and Ben Anson and Laurence Aitchison},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1oqedRt6Z7}\n}"}, "paperhash": {"value": "milsom|convolutional_deep_kernel_machines"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5645/-/Revision", "ICLR.cc/2024/Conference/Submission5645/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5645/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945879, "version": 2}, {"id": "RJDjSXNuAZ", "forum": "RJDjSXNuAZ", "number": 5642, "cdate": 1695393685832, "tcdate": 1695393685832, "mdate": 1709727473547, "tmdate": 1709727473547, "signatures": ["ICLR.cc/2024/Conference/Submission5642/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5642/Authors"], "content": {"title": {"value": "Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images"}, "authors": {"value": ["Hannah Kniesel", "Leon Sick", "Tristan Payer", "Tim Bergner", "Kavitha Shaga Devan", "Clarissa Read", "Paul Walther", "Timo Ropinski", "Pedro Hermosilla"]}, "authorids": {"value": ["~Hannah_Kniesel1", "~Leon_Sick1", "~Tristan_Payer1", "~Tim_Bergner1", "~Kavitha_Shaga_Devan1", "~Clarissa_Read1", "~Paul_Walther1", "~Timo_Ropinski2", "~Pedro_Hermosilla1"]}, "keywords": {"value": ["Weakly Supervised Object Detection", "Limited Annotation Time", "Bounding Box Regression", "Electron Microscopy"]}, "TLDR": {"value": "We propose an optimization strategy with shrinking receptive field to extract virus capsids directly by bounding box regression from image level annotations."}, "abstract": {"value": "Current state-of-the-art methods for object detection rely on annotated bounding boxes of large data sets for training. However, obtaining such annotations is expensive and can require up to hundreds of hours of manual labor. This poses a challenge, especially since such annotations can only be provided by experts, as they require knowledge about the scientific domain. To tackle this challenge, we propose a domain-specific weakly supervised object detection algorithm that only relies on image-level annotations, which are significantly easier to acquire. Our method  distills the knowledge of a pre-trained model, on the task of predicting the presence or absence of a virus in an image, to obtain a set of pseudo-labels that can be used to later train a state-of-the-art object detection model. To do so, we use an optimization approach with a shrinking receptive field to extract virus particles directly without specific network architectures. Through a set of extensive studies, we show how the proposed pseudo-labels are easier to obtain, and, more importantly, are able to outperform other existing weak labeling methods, and even ground truth labels, in cases where the time to obtain the annotation is limited."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fe442557edba4729d8a17fa4b0a8b4b0fad92242.pdf"}, "supplementary_material": {"value": "/attachment/44c25469ea832f5d37b596337c52b6d389d5a4c7.zip"}, "_bibtex": {"value": "@inproceedings{\nkniesel2024weakly,\ntitle={Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images},\nauthor={Hannah Kniesel and Leon Sick and Tristan Payer and Tim Bergner and Kavitha Shaga Devan and Clarissa Read and Paul Walther and Timo Ropinski and Pedro Hermosilla},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=RJDjSXNuAZ}\n}"}, "paperhash": {"value": "kniesel|weakly_supervised_virus_capsid_detection_with_imagelevel_annotations_in_electron_microscopy_images"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5642/-/Revision", "ICLR.cc/2024/Conference/Submission5642/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5642/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945851, "version": 2}, {"id": "HobyL1B9CZ", "forum": "HobyL1B9CZ", "number": 5639, "cdate": 1695393655562, "tcdate": 1695393655562, "mdate": 1710514301069, "tmdate": 1710514301069, "signatures": ["ICLR.cc/2024/Conference/Submission5639/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5639/Authors"], "content": {"title": {"value": "Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"}, "authors": {"value": ["Ziyang Xiao", "Dongxiang Zhang", "Yangjun Wu", "Lilin Xu", "Yuan Jessica Wang", "Xiongwei Han", "Xiaojin Fu", "Tao Zhong", "Jia Zeng", "Mingli Song", "Gang Chen"]}, "authorids": {"value": ["~Ziyang_Xiao2", "~Dongxiang_Zhang2", "~Yangjun_Wu1", "~Lilin_Xu2", "~Yuan_Jessica_Wang1", "~Xiongwei_Han1", "~Xiaojin_Fu1", "~Tao_Zhong2", "~Jia_Zeng1", "~Mingli_Song1", "~Gang_Chen6"]}, "keywords": {"value": ["Large Language Model", "Operations Research"]}, "abstract": {"value": "Large language models (LLMs) have emerged as powerful techniques for various NLP tasks, such as mathematical reasoning and plan generation. In this paper, we study automatic modeling and programming for complex operation research (OR) problems, so as to alleviate the heavy dependence on domain experts and benefit a spectrum of industry sectors. We present the first LLM-based solution, namely Chain-of-Experts (CoE), a novel multi-agent cooperative framework to enhance reasoning capabilities. Specifically, each agent is assigned a specific role and endowed with domain knowledge related to OR. We also introduce a conductor to orchestrate these agents via forward thought construction and backward reflection mechanism. Furthermore, we release a benchmark dataset (ComplexOR) of complex OR problems to facilitate OR research and community development. Experimental results show that CoE significantly outperforms the state-of-the-art LLM-based approaches both on LPWP and ComplexOR."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1d98a47ecf1564e66c26b81cecaf16056a88e9c1.pdf"}, "supplementary_material": {"value": "/attachment/3f0d4c6ed8e2ba0732bc18a12b30fe3f624154c1.zip"}, "_bibtex": {"value": "@inproceedings{\nxiao2024chainofexperts,\ntitle={Chain-of-Experts: When {LLM}s Meet Complex Operations Research Problems},\nauthor={Ziyang Xiao and Dongxiang Zhang and Yangjun Wu and Lilin Xu and Yuan Jessica Wang and Xiongwei Han and Xiaojin Fu and Tao Zhong and Jia Zeng and Mingli Song and Gang Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HobyL1B9CZ}\n}"}, "TLDR": {"value": "This paper introduces Chain-of-Experts (CoE), a multi-agent LLM framework that boosts reasoning in complex operation research problems by integrating domain-specific agents under a conductor's guidance and reflection mechanism."}, "paperhash": {"value": "xiao|chainofexperts_when_llms_meet_complex_operations_research_problems"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5639/-/Revision", "ICLR.cc/2024/Conference/Submission5639/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5639/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945782, "version": 2}, {"id": "DEJIDCmWOz", "forum": "DEJIDCmWOz", "number": 5638, "cdate": 1695393591234, "tcdate": 1695393591234, "mdate": 1710710963583, "tmdate": 1710710963583, "signatures": ["ICLR.cc/2024/Conference/Submission5638/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5638/Authors"], "content": {"title": {"value": "On the Reliability of Watermarks for Large Language Models"}, "authors": {"value": ["John Kirchenbauer", "Jonas Geiping", "Yuxin Wen", "Manli Shu", "Khalid Saifullah", "Kezhi Kong", "Kasun Fernando", "Aniruddha Saha", "Micah Goldblum", "Tom Goldstein"]}, "authorids": {"value": ["~John_Kirchenbauer1", "~Jonas_Geiping1", "~Yuxin_Wen2", "~Manli_Shu1", "~Khalid_Saifullah1", "~Kezhi_Kong1", "~Kasun_Fernando1", "~Aniruddha_Saha1", "~Micah_Goldblum1", "~Tom_Goldstein1"]}, "keywords": {"value": ["Machine Learning", "LLM", "Watermark", "Language Model", "Natural Language Processing", "Generative AI"]}, "TLDR": {"value": "A study on the reliability of watermarks for large language models in realistic settings."}, "abstract": {"value": "As LLMs become commonplace, machine-generated text has the potential to flood the internet with spam, social media bots, and valueless content. _Watermarking_ is a simple and effective strategy for mitigating such harms by enabling the detection and documentation of LLM-generated text. Yet a crucial question remains: How reliable is watermarking in realistic settings in the wild? There, watermarked text may be modified to suit a user's needs, or entirely rewritten to avoid detection. We study the robustness of watermarked text after it is re-written by humans, paraphrased by a non-watermarked LLM, or mixed into a longer hand-written document. We find that watermarks remain detectable even after human and machine paraphrasing. While these attacks dilute the strength of the watermark, paraphrases are statistically likely to leak n-grams or even longer fragments of the original text, resulting in high-confidence detections when enough tokens are observed.  For example, after strong human paraphrasing the watermark is detectable after observing 800 tokens on average, when setting a $1\\mathrm{e}{-5}$ false positive rate. We also consider a range of new detection schemes that are sensitive to short spans of watermarked text embedded inside a large document, and we compare the robustness of watermarking to other kinds of detectors."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8346f872a9e6321321db39a32310048c025726d6.pdf"}, "supplementary_material": {"value": "/attachment/9942394bede6a94b67e5f3d6009417de9af9c44d.zip"}, "_bibtex": {"value": "@inproceedings{\nkirchenbauer2024on,\ntitle={On the Reliability of Watermarks for Large Language Models},\nauthor={John Kirchenbauer and Jonas Geiping and Yuxin Wen and Manli Shu and Khalid Saifullah and Kezhi Kong and Kasun Fernando and Aniruddha Saha and Micah Goldblum and Tom Goldstein},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=DEJIDCmWOz}\n}"}, "paperhash": {"value": "kirchenbauer|on_the_reliability_of_watermarks_for_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5638/-/Revision", "ICLR.cc/2024/Conference/Submission5638/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5638/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945742, "version": 2}, {"id": "fDaLmkdSKU", "forum": "fDaLmkdSKU", "number": 5635, "cdate": 1695393503323, "tcdate": 1695393503323, "mdate": 1710773012464, "tmdate": 1710773012464, "signatures": ["ICLR.cc/2024/Conference/Submission5635/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5635/Authors"], "content": {"title": {"value": "Near-Optimal Solutions of Constrained Learning Problems"}, "authors": {"value": ["Juan Elenter", "Luiz F. O. Chamon", "Alejandro Ribeiro"]}, "authorids": {"value": ["~Juan_Elenter1", "~Luiz_F._O._Chamon1", "~Alejandro_Ribeiro1"]}, "keywords": {"value": ["Constrained Learning", "Convex Optimization", "Duality", "Constrained Optimization", "Fairness"]}, "abstract": {"value": "With the widespread adoption of machine learning systems, the need to curtail their behavior has become increasingly apparent. This is evidenced by recent advancements towards developing models that satisfy robustness, safety, and fairness requirements. These requirements can be imposed (with generalization guarantees) by formulating constrained learning problems that can then be tackled by dual ascent algorithms. Yet, though these algorithms converge in objective value, even in non-convex settings, they cannot guarantee that their outcome is feasible. Doing so requires randomizing over all iterates, which is impractical in virtually any modern applications. Still, final iterates have been observed to perform well in practice. In this work, we address this gap between theory and practice by characterizing the constraint violation of Lagrangian minimizers associated with optimal dual variables, despite lack of convexity. To do this, we leverage the fact that non-convex, finite-dimensional constrained learning problems can be seen as parametrizations of convex, functional problems. Our results show that rich parametrizations effectively mitigate the issue of feasibility in dual methods, shedding light on prior empirical successes of dual learning. We illustrate our findings in fair learning tasks."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7f17ceec550dfed59758881abdfe589b695e7d6f.pdf"}, "supplementary_material": {"value": "/attachment/308f265b8fae26229d739fee6468805c866f3007.zip"}, "_bibtex": {"value": "@inproceedings{\nelenter2024nearoptimal,\ntitle={Near-Optimal Solutions of Constrained Learning Problems},\nauthor={Juan Elenter and Luiz F. O. Chamon and Alejandro Ribeiro},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fDaLmkdSKU}\n}"}, "paperhash": {"value": "elenter|nearoptimal_solutions_of_constrained_learning_problems"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5635/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5635/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945672, "version": 2}, {"id": "lUYY2qsRTI", "forum": "lUYY2qsRTI", "number": 5633, "cdate": 1695393435757, "tcdate": 1695393435757, "mdate": 1710501348393, "tmdate": 1710501348393, "signatures": ["ICLR.cc/2024/Conference/Submission5633/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5633/Authors"], "content": {"title": {"value": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding"}, "authors": {"value": ["Aliz\u00e9e Pace", "Hugo Y\u00e8che", "Bernhard Sch\u00f6lkopf", "Gunnar Ratsch", "Guy Tennenholtz"]}, "authorids": {"value": ["~Aliz\u00e9e_Pace1", "~Hugo_Y\u00e8che1", "~Bernhard_Sch\u00f6lkopf1", "~Gunnar_Ratsch1", "~Guy_Tennenholtz2"]}, "keywords": {"value": ["offline reinforcement learning", "hidden confounding", "uncertainty quantification", "causal inference", "healthcare", "vasopressor and fluid administration"]}, "TLDR": {"value": "The paper tackles nonidentifiable hidden confounding in offline RL by introducing and leveraging delphic uncertainty -- a novel uncertainty estimation method for confounding bias, improving performance on simulated and real-world confounded data."}, "abstract": {"value": "A prominent challenge of offline reinforcement learning (RL) is the issue of hidden confounding: unobserved variables may influence both the actions taken by the agent and the observed outcomes. Hidden confounding can compromise the validity of any causal conclusion drawn from data and presents a major obstacle to effective offline RL. In the present paper, we tackle the problem of hidden confounding in the nonidentifiable setting. We propose a definition of uncertainty due to hidden confounding bias, termed delphic uncertainty, which uses variation over world models compatible with the observations, and differentiate it from the well-known epistemic and aleatoric uncertainties. We derive a practical method for estimating the three types of uncertainties, and construct a pessimistic offline RL algorithm to account for them. Our method does not assume identifiability of the unobserved confounders, and attempts to reduce the amount of confounding bias. We demonstrate through extensive experiments and ablations the efficacy of our approach on a sepsis management benchmark, as well as on electronic health records. Our results suggest that nonidentifiable hidden confounding bias can be mitigated to improve offline RL solutions in practice."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a0d49f19803be1be84b18e5bb5293715ad8e6dea.pdf"}, "supplementary_material": {"value": "/attachment/7d3d39dc20dd397d021eb4f4b62d01cdf1c837cf.zip"}, "_bibtex": {"value": "@inproceedings{\npace2024delphic,\ntitle={Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding},\nauthor={Aliz{\\'e}e Pace and Hugo Y{\\`e}che and Bernhard Sch{\\\"o}lkopf and Gunnar Ratsch and Guy Tennenholtz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lUYY2qsRTI}\n}"}, "paperhash": {"value": "pace|delphic_offline_reinforcement_learning_under_nonidentifiable_hidden_confounding"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5633/-/Revision", "ICLR.cc/2024/Conference/Submission5633/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5633/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945648, "version": 2}, {"id": "9RNfX0ah0K", "forum": "9RNfX0ah0K", "number": 5629, "cdate": 1695393195375, "tcdate": 1695393195375, "mdate": 1713066868726, "tmdate": 1713066868726, "signatures": ["ICLR.cc/2024/Conference/Submission5629/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5629/Authors"], "content": {"title": {"value": "Leave-one-out Distinguishability in Machine Learning"}, "authors": {"value": ["Jiayuan Ye", "Anastasia Borovykh", "Soufiane Hayou", "Reza Shokri"]}, "authorids": {"value": ["~Jiayuan_Ye1", "~Anastasia_Borovykh1", "~Soufiane_Hayou1", "~Reza_Shokri1"]}, "keywords": {"value": ["memorization", "influence estimation", "information leakage", "neural network Gaussian process"]}, "abstract": {"value": "We introduce an analytical framework to quantify the changes in a machine learning algorithm's output distribution following the inclusion of a few data points in its training set, a notion we define as leave-one-out distinguishability (LOOD).  This is key to measuring data **memorization** and information **leakage** as well as the **influence** of training data points in machine learning. We illustrate how our method broadens and refines existing empirical measures of memorization and privacy risks associated with training data. We use Gaussian processes to model the randomness of machine learning algorithms, and validate LOOD with extensive empirical analysis of leakage using membership inference attacks. Our analytical framework enables us to investigate the causes of leakage and where the leakage is high.  For example, we analyze the influence of activation functions, on data memorization.  Additionally, our method allows us to identify queries that disclose the most information about the training data in the leave-one-out setting.  We illustrate how optimal queries can be used for accurate **reconstruction** of training data."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3e82754599c559003bfdfae59b848a858af76e5f.pdf"}, "_bibtex": {"value": "@inproceedings{\nye2024leaveoneout,\ntitle={Leave-one-out Distinguishability in Machine Learning},\nauthor={Jiayuan Ye and Anastasia Borovykh and Soufiane Hayou and Reza Shokri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9RNfX0ah0K}\n}"}, "paperhash": {"value": "ye|leaveoneout_distinguishability_in_machine_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5629/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5629/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945471, "version": 2}, {"id": "H3IUunLy8s", "forum": "H3IUunLy8s", "number": 5620, "cdate": 1695392970335, "tcdate": 1695392970335, "mdate": 1710464502948, "tmdate": 1710464502948, "signatures": ["ICLR.cc/2024/Conference/Submission5620/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5620/Authors"], "content": {"title": {"value": "Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning"}, "authors": {"value": ["Haobo SONG", "Hao Zhao", "Soumajit Majumder", "Tao Lin"]}, "authorids": {"value": ["~Haobo_SONG1", "~Hao_Zhao3", "~Soumajit_Majumder2", "~Tao_Lin1"]}, "keywords": {"value": ["Parameter-efficient Fine-tuning", "Model Capacity"]}, "abstract": {"value": "Fine-tuning large pre-trained foundation models, such as the 175B GPT-3, has become the prevailing approach for downstream tasks. While parameter-efficient fine-tuning methods have been proposed and proven effective without retraining all model parameters, their performance is limited by the capacity of incremental modules, especially under constrained parameter budgets.\nTo overcome this challenge, we propose CAPABOOST, a simple yet effective strategy that enhances model capacity by leveraging low-rank updates through parallel weight modules in target layers. By applying static random masks to the shared weight matrix, CAPABOOST constructs a diverse set of weight matrices, effectively increasing the rank of incremental weights without adding parameters. Notably, our approach can be seamlessly integrated into various existing parameter-efficient fine-tuning methods. We extensively validate the efficacy of CAPABOOST through experiments on diverse downstream tasks, including natural language understanding, question answering, and image classification. Our results demonstrate significant improvements over baselines, without incurring additional computation\nor storage costs. We will make our code and benchmark publicly available."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/984e5e732b8d392e93cae7820d9c7b24c148a89e.pdf"}, "_bibtex": {"value": "@inproceedings{\nsong2024increasing,\ntitle={Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning},\nauthor={Haobo SONG and Hao Zhao and Soumajit Majumder and Tao Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=H3IUunLy8s}\n}"}, "paperhash": {"value": "song|increasing_model_capacity_for_free_a_simple_strategy_for_parameter_efficient_finetuning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5620/-/Revision", "ICLR.cc/2024/Conference/Submission5620/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5620/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945318, "version": 2}, {"id": "3y1K6buO8c", "forum": "3y1K6buO8c", "number": 5619, "cdate": 1695392964547, "tcdate": 1695392964547, "mdate": 1710418284963, "tmdate": 1710418284963, "signatures": ["ICLR.cc/2024/Conference/Submission5619/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5619/Authors"], "content": {"title": {"value": "Brain decoding: toward real-time reconstruction of visual perception"}, "authors": {"value": ["Yohann Benchetrit", "Hubert Banville", "Jean-Remi King"]}, "authorids": {"value": ["~Yohann_Benchetrit1", "~Hubert_Banville1", "~Jean-Remi_King1"]}, "keywords": {"value": ["brain decoding", "neuroimaging", "image generation", "visual perception"]}, "TLDR": {"value": "Decoding perceived images from brain activity (MEG) data facilitates the study of visual perception dynamics."}, "abstract": {"value": "In the past five years, the use of generative and foundational AI systems has greatly improved the decoding of brain activity. Visual perception, in particular, can now be decoded from functional Magnetic Resonance Imaging (fMRI) with remarkable fidelity. This neuroimaging technique, however, suffers from a limited temporal resolution ($\\approx$0.5\\,Hz) and thus fundamentally constrains its real-time usage. Here, we propose an alternative approach based on magnetoencephalography (MEG), a neuroimaging device capable of measuring brain activity with high temporal resolution ($\\approx$5,000 Hz). For this, we develop an MEG decoding model trained with both contrastive and regression objectives and consisting of three modules: i) pretrained embeddings obtained from the image, ii) an MEG module trained end-to-end and iii) a pretrained image generator. Our results are threefold: Firstly, our MEG decoder shows a 7X improvement of image-retrieval over classic linear decoders. Second, late brain responses to images are best decoded with DINOv2, a recent foundational image model. Third, image retrievals and generations both suggest that high-level visual features can be decoded from MEG signals, although the same approach applied to 7T fMRI also recovers better low-level features. Overall, these results, while preliminary, provide an important step towards the decoding - in real-time - of the visual processes continuously unfolding within the human brain."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ffc31b3c3c5e59d5995e3ad3ff5ea052198006d2.pdf"}, "supplementary_material": {"value": "/attachment/33660daed024e43122d3ebfc674cd73724ade9bb.pdf"}, "_bibtex": {"value": "@inproceedings{\nbenchetrit2024brain,\ntitle={Brain decoding: toward real-time reconstruction of visual perception},\nauthor={Yohann Benchetrit and Hubert Banville and Jean-Remi King},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3y1K6buO8c}\n}"}, "paperhash": {"value": "benchetrit|brain_decoding_toward_realtime_reconstruction_of_visual_perception"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5619/-/Revision", "ICLR.cc/2024/Conference/Submission5619/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5619/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945252, "version": 2}, {"id": "5nM2AHzqUj", "forum": "5nM2AHzqUj", "number": 5618, "cdate": 1695392938875, "tcdate": 1695392938875, "mdate": 1709661523444, "tmdate": 1709661523444, "signatures": ["ICLR.cc/2024/Conference/Submission5618/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5618/Authors"], "content": {"title": {"value": "Linear Log-Normal Attention with Unbiased Concentration"}, "authors": {"value": ["Yury Nahshan", "Joseph Kampeas", "Emir Haleva"]}, "authorids": {"value": ["~Yury_Nahshan1", "~Joseph_Kampeas1", "~Emir_Haleva1"]}, "keywords": {"value": ["Neural Networks", "Transformers", "Self-Attention", "Linear Attention", "Scalable Transformers", "Efficient Attention", "Attention with Linear Complexity", "Linearized Attention", "Self-Attention Analysis"]}, "TLDR": {"value": "The quadratic complexity of the attention limits the scalability of the transformer models. We propose Linear Log-Normal Attention that offers linear complexity while maintaining key features of the original attention mechanism."}, "abstract": {"value": "Transformer models have achieved remarkable results in a wide range of applications. However, their scalability is hampered by the quadratic time and memory complexity of the self-attention mechanism concerning the sequence length. This limitation poses a substantial obstacle when dealing with long documents or high-resolution images. In this work, we study the self-attention mechanism by analyzing the distribution of the attention matrix and its concentration ability. Furthermore, we propose instruments to measure these quantities and introduce a novel self-attention mechanism, Linear Log-Normal Attention, designed to emulate the distribution and concentration behavior of the original self-attention. Our experimental results on popular natural language benchmarks reveal that our proposed Linear Log-Normal Attention outperforms other linearized attention alternatives, offering a promising avenue for enhancing the scalability of transformer models."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4e0a50e54327a8b8c9e13d3426588871294b18a3.pdf"}, "supplementary_material": {"value": "/attachment/8f60cc0ad88fd2dc4567319746c7ee3b660e005d.zip"}, "_bibtex": {"value": "@inproceedings{\nnahshan2024linear,\ntitle={Linear Log-Normal Attention with Unbiased Concentration},\nauthor={Yury Nahshan and Joseph Kampeas and Emir Haleva},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5nM2AHzqUj}\n}"}, "paperhash": {"value": "nahshan|linear_lognormal_attention_with_unbiased_concentration"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5618/-/Revision", "ICLR.cc/2024/Conference/Submission5618/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5618/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410945231, "version": 2}, {"id": "c0MyyXyGfn", "forum": "c0MyyXyGfn", "number": 5595, "cdate": 1695392314199, "tcdate": 1695392314199, "mdate": 1709892335453, "tmdate": 1709892335453, "signatures": ["ICLR.cc/2024/Conference/Submission5595/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5595/Authors"], "content": {"title": {"value": "Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning"}, "authors": {"value": ["Finn Rietz", "Erik Schaffernicht", "Stefan Heinrich", "Johannes A. Stork"]}, "authorids": {"value": ["~Finn_Rietz1", "~Erik_Schaffernicht1", "~Stefan_Heinrich1", "~Johannes_A._Stork1"]}, "keywords": {"value": ["Multi-Objective Reinforcement Learning", "Lexicographic Task Priorities", "Constrained RL", "Transfer RL"]}, "TLDR": {"value": "We propose a decomposed algorithm to solve lexicographic multi-objective reinforcement learning problems with continuous action spaces that satisfies constraints by construction."}, "abstract": {"value": "Reinforcement learning (RL) for complex tasks remains a challenge, primarily due to the difficulties of engineering scalar reward functions and the inherent inefficiency of training models from scratch. Instead, it would be better to specify complex tasks in terms of elementary subtasks and to reuse subtask solutions whenever possible. In this work, we address continuous space lexicographic multi-objective RL problems, consisting of prioritized subtasks, which are notoriously difficult to solve. We show that these can be scalarized with a subtask transformation and then solved incrementally using value decomposition. Exploiting this insight, we propose prioritized soft Q-decomposition (PSQD), a novel algorithm for learning and adapting subtask solutions under lexicographic priorities in continuous state-action spaces. PSQD offers the ability to reuse previously learned subtask solutions in a zero-shot composition, followed by an adaptation step. Its ability to use retained subtask training data for offline learning eliminates the need for new environment interaction during adaptation. We demonstrate the efficacy of our approach by presenting successful learning, reuse, and adaptation results for both low- and high-dimensional simulated robot control tasks, as well as offline learning results. In contrast to baseline approaches, PSQD does not trade off between conflicting subtasks or priority constraints and satisfies subtask priorities during learning. PSQD provides an intuitive framework for tackling complex RL problems, offering insights into the inner workings of the subtask composition."}, "pdf": {"value": "/pdf/f1ffd49ec59c37900afa292aae71b2488d52baf4.pdf"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nrietz2024prioritized,\ntitle={Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning},\nauthor={Finn Rietz and Erik Schaffernicht and Stefan Heinrich and Johannes A. Stork},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=c0MyyXyGfn}\n}"}, "paperhash": {"value": "rietz|prioritized_soft_qdecomposition_for_lexicographic_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5595/-/Revision", "ICLR.cc/2024/Conference/Submission5595/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5595/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944629, "version": 2}, {"id": "d6tUsZeVs7", "forum": "d6tUsZeVs7", "number": 5592, "cdate": 1695392273861, "tcdate": 1695392273861, "mdate": 1709661523267, "tmdate": 1709661523267, "signatures": ["ICLR.cc/2024/Conference/Submission5592/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5592/Authors"], "content": {"title": {"value": "Energy-guided Entropic Neural Optimal Transport"}, "authors": {"value": ["Petr Mokrov", "Alexander Korotin", "Alexander Kolesov", "Nikita Gushchin", "Evgeny Burnaev"]}, "authorids": {"value": ["~Petr_Mokrov1", "~Alexander_Korotin2", "~Alexander_Kolesov1", "~Nikita_Gushchin1", "~Evgeny_Burnaev1"]}, "keywords": {"value": ["energy-based model", "generative model", "optimal transport", "entropic optimal transport", "general optimal transport cost function"]}, "TLDR": {"value": "We propose a novel energy-based method to compute entropic optimal transport with general cost functions."}, "abstract": {"value": "Energy-based models (EBMs) are known in the Machine Learning community for decades. Since the seminal works devoted to EBMs dating back to the noughties, there have been a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN-based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present a novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. From the theoretical perspective, we prove generalization bounds for our technique. In practice, we validate its applicability in toy 2D and image domains. To showcase the scalability, we empower our method with a pre-trained StyleGAN and apply it to high-res AFHQ $512\\times512$ unpaired I2I translation. For simplicity, we choose simple short- and long-run EBMs as a backbone of our Energy-guided Entropic OT approach, leaving the application of more sophisticated EBMs for future research. Our code is available at: https://github.com/PetrMokrov/Energy-guided-Entropic-OT"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/09a4fd044e1b570114aeffccc10a9b4e65462936.pdf"}, "supplementary_material": {"value": "/attachment/e9a5331d2ad25da7fea4f9955b156f7c78f6c215.zip"}, "_bibtex": {"value": "@inproceedings{\nmokrov2024energyguided,\ntitle={Energy-guided Entropic Neural Optimal Transport},\nauthor={Petr Mokrov and Alexander Korotin and Alexander Kolesov and Nikita Gushchin and Evgeny Burnaev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d6tUsZeVs7}\n}"}, "paperhash": {"value": "mokrov|energyguided_entropic_neural_optimal_transport"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5592/-/Revision", "ICLR.cc/2024/Conference/Submission5592/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5592/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944501, "version": 2}, {"id": "TWVMVPx2wO", "forum": "TWVMVPx2wO", "number": 5583, "cdate": 1695391795400, "tcdate": 1695391795400, "mdate": 1710458739674, "tmdate": 1710458739674, "signatures": ["ICLR.cc/2024/Conference/Submission5583/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5583/Authors"], "content": {"title": {"value": "Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning"}, "authors": {"value": ["Li Ren", "Chen Chen", "Liqiang Wang", "Kien A. Hua"]}, "authorids": {"value": ["~Li_Ren2", "~Chen_Chen18", "~Liqiang_Wang1", "~Kien_A._Hua2"]}, "keywords": {"value": ["metric learning", "image retrieval", "parameter-efficient fine tuning"]}, "TLDR": {"value": "We investigate parameter-efficient methods for fine-tuning the pre-trained model for DML tasks"}, "abstract": {"value": "Deep Metric Learning (DML) has long attracted the attention of the machine learning community as a key objective. Existing solutions concentrate on fine-tuning the pre-trained models on conventional image datasets. As a result of the success of recent pre-trained models derived from larger-scale datasets, it is challenging to adapt the model to the DML tasks in the local data domain while retaining the previously gained knowledge. In this paper, we investigate parameter-efficient methods for fine-tuning the pre-trained model for DML tasks. In particular, we propose a novel and effective framework based on learning Visual Prompts (VPT) in the pre-trained Vision Transformers (ViT). Based on the conventional proxy-based DML paradigm, we augment the proxy by incorporating the semantic information from the input image and the ViT, in which we optimize the visual prompts for each class. We demonstrate that our new approximations with semantic information are superior to representative capabilities, thereby improving metric learning performance. We conduct extensive experiments to demonstrate that our proposed framework is superior and efficient by evaluating popular DML benchmarks. In particular, we demonstrate that our fine-tuning method achieves comparable or even better performance than recent state-of-the-art full fine-tuning works of DML while tuning only a small percentage of total parameters."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f018c189217e52be4cef2ab84c2395f38b3041b6.pdf"}, "_bibtex": {"value": "@inproceedings{\nren2024learning,\ntitle={Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning},\nauthor={Li Ren and Chen Chen and Liqiang Wang and Kien A. Hua},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TWVMVPx2wO}\n}"}, "paperhash": {"value": "ren|learning_semantic_proxies_from_visual_prompts_for_parameterefficient_finetuning_in_deep_metric_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5583/-/Revision", "ICLR.cc/2024/Conference/Submission5583/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5583/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944310, "version": 2}, {"id": "vN9fpfqoP1", "forum": "vN9fpfqoP1", "number": 5580, "cdate": 1695391611375, "tcdate": 1695391611375, "mdate": 1709661523141, "tmdate": 1709661523141, "signatures": ["ICLR.cc/2024/Conference/Submission5580/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5580/Authors"], "content": {"title": {"value": "Fine-Tuned Language Models Generate Stable Inorganic Materials as Text"}, "authors": {"value": ["Nate Gruver", "Anuroop Sriram", "Andrea Madotto", "Andrew Gordon Wilson", "C. Lawrence Zitnick", "Zachary Ward Ulissi"]}, "authorids": {"value": ["~Nate_Gruver1", "~Anuroop_Sriram1", "~Andrea_Madotto1", "~Andrew_Gordon_Wilson1", "~C._Lawrence_Zitnick2", "~Zachary_Ward_Ulissi1"]}, "keywords": {"value": ["generative model", "large language model", "stable materials", "AI for science"]}, "TLDR": {"value": "We fine-tune LLMs on string representations of crystals and generate new stable materials."}, "abstract": {"value": "We propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90\\% of sampled structures obeying physical constraints on atom positions and charges. Using energy above hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned  LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49\\% vs 28\\%) of CDVAE, a competing diffusion model. Because of text prompting's inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models' ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ded4cb6b266ad7acbd242a2487f814837a22fa2f.pdf"}, "_bibtex": {"value": "@inproceedings{\ngruver2024finetuned,\ntitle={Fine-Tuned Language Models Generate Stable Inorganic Materials as Text},\nauthor={Nate Gruver and Anuroop Sriram and Andrea Madotto and Andrew Gordon Wilson and C. Lawrence Zitnick and Zachary Ward Ulissi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vN9fpfqoP1}\n}"}, "paperhash": {"value": "gruver|finetuned_language_models_generate_stable_inorganic_materials_as_text"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5580/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5580/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944099, "version": 2}, {"id": "WOiOzHG2zD", "forum": "WOiOzHG2zD", "number": 5579, "cdate": 1695391559710, "tcdate": 1695391559710, "mdate": 1709661523000, "tmdate": 1709661523000, "signatures": ["ICLR.cc/2024/Conference/Submission5579/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5579/Authors"], "content": {"title": {"value": "TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields"}, "authors": {"value": ["Tianyu Huang", "Yihan Zeng", "Bowen Dong", "Hang Xu", "Songcen Xu", "Rynson W. H. Lau", "Wangmeng Zuo"]}, "authorids": {"value": ["~Tianyu_Huang2", "~Yihan_Zeng1", "~Bowen_Dong1", "~Hang_Xu1", "~Songcen_Xu1", "~Rynson_W._H._Lau1", "~Wangmeng_Zuo3"]}, "keywords": {"value": ["3D Open Vocabulary", "Conditional Generation"]}, "abstract": {"value": "Recent works learn 3D representation explicitly under text-3D guidance. However, limited text-3D data restricts the vocabulary scale and text control of generations. Generators may easily fall into a stereotype concept for certain text prompts, thus losing open-vocabulary generation ability. To tackle this issue, we introduce a conditional 3D generative model, namely TextField3D. Specifically, rather than using the text prompts as input directly, we suggest to inject dynamic noise into the latent space of given text prompts, i.e., Noisy Text Fields (NTFs). In this way, limited 3D data can be mapped to the appropriate range of textual latent space that is expanded by NTFs. To this end, an NTFGen module is proposed to model general text latent code in noisy fields. Meanwhile, an NTFBind module is proposed to align view-invariant image latent code to noisy fields, further supporting image-conditional 3D generation. To guide the conditional generation in both geometry and texture, multi-modal discrimination is constructed with a text-3D discriminator and a text-2.5D discriminator. Compared to previous methods, TextField3D includes three merits: 1) large vocabulary, 2) text consistency, and 3) low latency. Extensive experiments demonstrate that our method achieves a potential open-vocabulary 3D generation capability."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/89944e5d578067d05ab988f662bfd7940bb5df2b.pdf"}, "_bibtex": {"value": "@inproceedings{\nhuang2024textfieldd,\ntitle={TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields},\nauthor={Tianyu Huang and Yihan Zeng and Bowen Dong and Hang Xu and Songcen Xu and Rynson W. H. Lau and Wangmeng Zuo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WOiOzHG2zD}\n}"}, "paperhash": {"value": "huang|textfield3d_towards_enhancing_openvocabulary_3d_generation_with_noisy_text_fields"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5579/-/Revision", "ICLR.cc/2024/Conference/Submission5579/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5579/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944053, "version": 2}, {"id": "cUSNs8nGaV", "forum": "cUSNs8nGaV", "number": 5569, "cdate": 1695391176672, "tcdate": 1695391176672, "mdate": 1711395887844, "tmdate": 1711395887844, "signatures": ["ICLR.cc/2024/Conference/Submission5569/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5569/Authors"], "content": {"title": {"value": "GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks"}, "authors": {"value": ["Renat Sergazinov", "Elizabeth Chun", "Valeriya Rogovchenko", "Nathaniel J Fernandes", "Nicholas Kasman", "Irina Gaynanova"]}, "authorids": {"value": ["~Renat_Sergazinov1", "~Elizabeth_Chun1", "~Valeriya_Rogovchenko1", "~Nathaniel_J_Fernandes1", "~Nicholas_Kasman1", "~Irina_Gaynanova1"]}, "keywords": {"value": ["diabetes management", "continuous glucose monitors (CGM)", "glucose trajectory prediction", "artificial pancreas systems", "public datasets", "standardized tasks", "benchmark models", "glycemic control"]}, "TLDR": {"value": "The paper introduces a comprehensive resource for CGM-based glucose forecasting, including a curated list of public datasets, a standardized task list, and benchmark models."}, "abstract": {"value": "The rising rates of diabetes necessitate innovative methods for its management. Continuous glucose monitors (CGM) are small medical devices that measure blood glucose levels at regular intervals providing insights into daily patterns of glucose variation. Forecasting of glucose trajectories based on CGM data  holds the potential to substantially improve diabetes management, by both refining artificial pancreas systems and enabling individuals to make adjustments based on  predictions to maintain optimal glycemic range. Despite numerous methods proposed for CGM-based glucose trajectory prediction, these methods are typically evaluated on small, private datasets, impeding reproducibility, further research, and practical adoption. The absence of standardized prediction tasks and systematic comparisons between methods has led to uncoordinated research efforts, obstructing the identification of optimal tools for tackling specific challenges. As a result, only a limited number of prediction methods have been implemented in clinical practice.  \n\nTo address these challenges, we present a comprehensive resource that provides (1) a consolidated repository of curated publicly available CGM datasets to foster reproducibility and accessibility; (2) a standardized task list to unify research objectives and facilitate coordinated efforts; (3) a set of benchmark models with established baseline performance, enabling the research community to objectively gauge new methods' efficacy; and (4) a detailed analysis of performance-influencing factors for model development. We anticipate these resources to propel collaborative research endeavors in the critical domain of CGM-based glucose predictions. Our code is available online at github.com/IrinaStatsLab/GlucoBench."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/43f545b8172aa5500f599f53c7466c1b3897e5d0.pdf"}, "supplementary_material": {"value": "/attachment/d97f0301c2e033cd3deb466b6dc48c16f8aaf4da.zip"}, "_bibtex": {"value": "@inproceedings{\nsergazinov2024glucobench,\ntitle={GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks},\nauthor={Renat Sergazinov and Elizabeth Chun and Valeriya Rogovchenko and Nathaniel J Fernandes and Nicholas Kasman and Irina Gaynanova},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cUSNs8nGaV}\n}"}, "paperhash": {"value": "sergazinov|glucobench_curated_list_of_continuous_glucose_monitoring_datasets_with_prediction_benchmarks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5569/-/Revision", "ICLR.cc/2024/Conference/Submission5569/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5569/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410943695, "version": 2}, {"id": "XyrB1Ay44j", "forum": "XyrB1Ay44j", "number": 5565, "cdate": 1695391078588, "tcdate": 1695391078588, "mdate": 1710591813250, "tmdate": 1710591813250, "signatures": ["ICLR.cc/2024/Conference/Submission5565/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5565/Authors"], "content": {"title": {"value": "Quantifying and Enhancing Multi-modal Robustness with Modality Preference"}, "authors": {"value": ["Zequn Yang", "Yake Wei", "Ce Liang", "Di Hu"]}, "authorids": {"value": ["~Zequn_Yang2", "~Yake_Wei1", "~Ce_Liang1", "~Di_Hu1"]}, "keywords": {"value": ["Robustness", "Multi-modal learning", "Modality preference"]}, "TLDR": {"value": "We theoritcally investigate the essential component related to the multi-modal robustness, and provide insight for the limitation caused by modality preference, which can be alleviated by our proposed training strategy."}, "abstract": {"value": "Multi-modal models have shown a promising capability to effectively integrate information from various sources, yet meanwhile, they are found vulnerable to pervasive perturbations, such as uni-modal attacks and missing conditions. To counter these perturbations, robust multi-modal representations are highly expected, which are positioned well away from the discriminative multi-modal decision boundary. In this paper, different from conventional empirical studies, we focus on a commonly used joint multi-modal framework and theoretically discover that larger uni-modal representation margins and more reliable integration for modalities are essential components for achieving higher robustness. This discovery can further explain the limitation of multi-modal robustness and the phenomenon that multi-modal models are often vulnerable to attacks on the specific modality. Moreover, our analysis reveals how the widespread issue, that the model has different preferences for modalities, limits the multi-modal robustness by influencing the essential components and could lead to attacks on the specific modality highly effective. Inspired by our theoretical finding, we introduce a training procedure called Certifiable Robust Multi-modal Training (CRMT), which can alleviate this influence from modality preference and explicitly regulate essential components to significantly improve robustness in a certifiable manner. Our method demonstrates substantial improvements in performance and robustness compared with existing methods. Furthermore, our training procedure can be easily extended to enhance other robust training strategies, highlighting its credibility and flexibility."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0551e3609edba18ea5e362b6fc0310166b874b49.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024quantifying,\ntitle={Quantifying and Enhancing Multi-modal Robustness with Modality Preference},\nauthor={Zequn Yang and Yake Wei and Ce Liang and Di Hu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=XyrB1Ay44j}\n}"}, "paperhash": {"value": "yang|quantifying_and_enhancing_multimodal_robustness_with_modality_preference"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5565/-/Revision", "ICLR.cc/2024/Conference/Submission5565/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5565/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410943548, "version": 2}, {"id": "otU31x3fus", "forum": "otU31x3fus", "number": 5556, "cdate": 1695390839760, "tcdate": 1695390839760, "mdate": 1710522750126, "tmdate": 1710522750126, "signatures": ["ICLR.cc/2024/Conference/Submission5556/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5556/Authors"], "content": {"title": {"value": "Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness"}, "authors": {"value": ["Artem Agafonov", "Dmitry Kamzolov", "Alexander Gasnikov", "Ali Kavis", "Kimon Antonakopoulos", "Volkan Cevher", "Martin Tak\u00e1\u010d"]}, "authorids": {"value": ["~Artem_Agafonov1", "~Dmitry_Kamzolov1", "~Alexander_Gasnikov1", "~Ali_Kavis1", "~Kimon_Antonakopoulos1", "~Volkan_Cevher1", "~Martin_Tak\u00e1\u010d1"]}, "keywords": {"value": ["Second-order methods", "convex optimization", "stochastic optimization", "Cubic Newton Method", "high-order methods", "tensor methods", "lower bounds"]}, "abstract": {"value": "We present a new accelerated stochastic second-order method that is robust to both gradient and Hessian inexactness, typical in machine learning. We establish theoretical lower bounds and prove that our algorithm achieves optimal convergence in both gradient and Hessian inexactness in this key setting. We further introduce a tensor generalization for stochastic higher-order derivatives. When the oracles are non-stochastic, the proposed tensor algorithm matches the global convergence of Nesterov Accelerated Tensor method. Both algorithms allow for approximate solutions of their auxiliary subproblems with verifiable conditions on the accuracy of the solution."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9f4ad3fe664bc9130bb6d56d4552f098072fc713.pdf"}, "_bibtex": {"value": "@inproceedings{\nagafonov2024advancing,\ntitle={Advancing the Lower Bounds: an Accelerated, Stochastic, Second-order Method with Optimal Adaptation to Inexactness},\nauthor={Artem Agafonov and Dmitry Kamzolov and Alexander Gasnikov and Ali Kavis and Kimon Antonakopoulos and Volkan Cevher and Martin Tak{\\'a}{\\v{c}}},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=otU31x3fus}\n}"}, "paperhash": {"value": "agafonov|advancing_the_lower_bounds_an_accelerated_stochastic_secondorder_method_with_optimal_adaptation_to_inexactness"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5556/-/Revision", "ICLR.cc/2024/Conference/Submission5556/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5556/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410943185, "version": 2}, {"id": "AcSChDWL6V", "forum": "AcSChDWL6V", "number": 5555, "cdate": 1695390676591, "tcdate": 1695390676591, "mdate": 1710412391895, "tmdate": 1710412391895, "signatures": ["ICLR.cc/2024/Conference/Submission5555/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5555/Authors"], "content": {"title": {"value": "Distinguished In Uniform: Self-Attention Vs. Virtual Nodes"}, "authors": {"value": ["Eran Rosenbluth", "Jan T\u00f6nshoff", "Martin Ritzert", "Berke Kisin", "Martin Grohe"]}, "authorids": {"value": ["~Eran_Rosenbluth1", "~Jan_T\u00f6nshoff1", "~Martin_Ritzert1", "~Berke_Kisin1", "~Martin_Grohe1"]}, "keywords": {"value": ["Graph Neural Networks", "Message Passing", "Graph Transformers", "Virtual Nodes", "Expressivity", "Uniform Expressivity"]}, "TLDR": {"value": "Graph Transformers and MPGNNs with virtual nodes do not subsume each other in terms of uniform function approximation while neither is \"universal\" in this setting."}, "abstract": {"value": "Graph Transformers (GTs) such as SAN and GPS are graph processing models that combine Message-Passing GNNs (MPGNNs) with global Self-Attention. They were shown to be universal function approximators, with two reservations: 1. The initial node features must be augmented with certain positional encodings. 2. The approximation is non-uniform: Graphs of different sizes may require a different approximating network.\n\nWe first clarify that this form of universality is not unique to GTs: Using the same positional encodings, also pure MPGNNs and even 2-layer MLPs are non-uniform universal approximators. We then consider uniform expressivity: The target function is to be approximated by a single network for graphs of all sizes. There, we compare GTs to the more efficient MPGNN + Virtual Node architecture. The essential difference between the two model definitions is in their global computation method: Self-Attention Vs Virtual Node. We prove that none of the models is a uniform-universal approximator, before proving our main result: Neither model\u2019s uniform expressivity subsumes the other\u2019s. We demonstrate the theory with experiments on synthetic data. We further augment our study with real-world datasets, observing mixed results which indicate no clear ranking in practice as well."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e1ac40eba4c49945d38feedf14666ad5b8b2974c.pdf"}, "supplementary_material": {"value": "/attachment/115096b1e19ffa39a7d9ee9fd3e4a1dac92a30a1.zip"}, "_bibtex": {"value": "@inproceedings{\nt{\\\"o}nshoff2024transformers,\ntitle={Transformers vs. Message Passing {GNN}s: Distinguished in Uniform},\nauthor={Jan T{\\\"o}nshoff and Eran Rosenbluth and Martin Ritzert and Berke Kisin and Martin Grohe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AcSChDWL6V}\n}"}, "paperhash": {"value": "rosenbluth|distinguished_in_uniform_selfattention_vs_virtual_nodes"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5555/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5555/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410943183, "version": 2}, {"id": "lvSMIsztka", "forum": "lvSMIsztka", "number": 5554, "cdate": 1695390668134, "tcdate": 1695390668134, "mdate": 1713080839134, "tmdate": 1713080839134, "signatures": ["ICLR.cc/2024/Conference/Submission5554/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5554/Authors"], "content": {"title": {"value": "Faster Approximation of Probabilistic and Distributional Values via Least Squares"}, "authors": {"value": ["Weida Li", "Yaoliang Yu"]}, "authorids": {"value": ["~Weida_Li1", "~Yaoliang_Yu1"]}, "keywords": {"value": ["data valuation", "probabilistic values", "approximation", "distributional Shapley value"]}, "abstract": {"value": "The family of probabilistic values, axiomatically-grounded in cooperative game theory, has recently received much attention in data valuation. However, it is often computationally expensive to compute exactly (exponential w.r.t. the number of data to valuate denoted by $n$). The existing generic estimator costs $O(n^2\\log n)$ utility evaluations to achieve an $(\\epsilon,\\delta)$-approximation under the 2-norm, while faster estimators have been developed recently for special cases (e.g., empirically for the Shapley value and theoretically for the Banzhaf value). In this work, starting from the discovered connection between probabilistic values and least square regressions, we propose a Generic Estimator based on Least Squares (GELS) along with its variants that cost $O(n\\log n)$ utility evaluations for many probabilistic values, largely extending the scope of this currently best complexity bound. Moreover, we show that each distributional value, proposed by Ghorbani et al. (2020) to alleviate the inconsistency of probabilistic values induced by using distinct databases, can also be cast as optimizing a similar least square regression. This observation leads to a theoretically-grounded framework TrELS (Training Estimators based on Least Squares) that can train estimators towards the specified distributional values without requiring any supervised signals. Particularly, the trained estimators are capable of predicting the corresponding distributional values for unseen data, largely saving the budgets required for running Monte-Carlo methods otherwise. Our experiments verify the faster convergence of GELS, and demonstrate the effectiveness of TrELS in learning distributional values. Our code is available at https://github.com/watml/fastpvalue."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/47fa947a6543c13bae85e65a2696fb130668bd6c.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024faster,\ntitle={Faster Approximation of Probabilistic and Distributional Values via Least Squares},\nauthor={Weida Li and Yaoliang Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=lvSMIsztka}\n}"}, "paperhash": {"value": "li|faster_approximation_of_probabilistic_and_distributional_values_via_least_squares"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5554/-/Revision", "ICLR.cc/2024/Conference/Submission5554/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5554/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410943161, "version": 2}, {"id": "zgQ0PHeGnL", "forum": "zgQ0PHeGnL", "number": 5550, "cdate": 1695390568201, "tcdate": 1695390568201, "mdate": 1710309502917, "tmdate": 1710309502917, "signatures": ["ICLR.cc/2024/Conference/Submission5550/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5550/Authors"], "content": {"title": {"value": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction"}, "authors": {"value": ["Ziyang Yu", "Wenbing Huang", "Yang Liu"]}, "authorids": {"value": ["~Ziyang_Yu2", "~Wenbing_Huang1", "~Yang_Liu19"]}, "keywords": {"value": ["Equivariant Graph Neural Network", "rigid body protein-protein docking", "interface fitting"]}, "abstract": {"value": "The study of rigid protein-protein docking plays an essential role in a variety of tasks such as drug design and protein engineering. Recently, several learning-based methods have been proposed for the task, exhibiting much faster docking speed than those computational methods. In this paper, we propose a novel learning-based method called ElliDock, which predicts an elliptic paraboloid to represent the protein-protein docking interface. To be specific, our model estimates elliptic paraboloid interfaces for the two input proteins respectively, and obtains the roto-translation transformation for docking by making two interfaces coincide. By its design, ElliDock is independently equivariant with respect to arbitrary rotations/translations of the proteins, which is an indispensable property to ensure the generalization of the docking process. Experimental evaluations show that ElliDock achieves the fastest inference time among all compared methods, and outperforms state-of-the-art learning-based methods, like DiffDock-PP and Alphafold-Multimer, for particularly antibody-antigen docking."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0417eeed6ba676646cb5beb705e2ac4e230dcdd1.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024rigid,\ntitle={Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction},\nauthor={Ziyang Yu and Wenbing Huang and Yang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zgQ0PHeGnL}\n}"}, "paperhash": {"value": "yu|rigid_proteinprotein_docking_via_equivariant_ellipticparaboloid_interface_prediction"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5550/-/Revision", "ICLR.cc/2024/Conference/Submission5550/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5550/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942920, "version": 2}, {"id": "FlY7WQ2hWS", "forum": "FlY7WQ2hWS", "number": 5535, "cdate": 1695389980202, "tcdate": 1695389980202, "mdate": 1709876310939, "tmdate": 1709876310939, "signatures": ["ICLR.cc/2024/Conference/Submission5535/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5535/Authors"], "content": {"title": {"value": "Incentive-Aware Federated Learning with Training-Time Model Rewards"}, "authors": {"value": ["Zhaoxuan Wu", "Mohammad Mohammadi Amiri", "Ramesh Raskar", "Bryan Kian Hsiang Low"]}, "authorids": {"value": ["~Zhaoxuan_Wu1", "~Mohammad_Mohammadi_Amiri1", "~Ramesh_Raskar1", "~Bryan_Kian_Hsiang_Low1"]}, "keywords": {"value": ["Collaborative learning", "Incentives", "Global-to-local design"]}, "TLDR": {"value": "A novel algorithm that distributes training-time model rewards to incentivize client contributions for federated learning."}, "abstract": {"value": "In federated learning (FL), incentivizing contributions of training resources (e.g., data, compute) from potentially competitive clients is crucial. Existing incentive mechanisms often distribute post-training monetary rewards, which suffer from practical challenges of timeliness and feasibility of the rewards. Rewarding the clients after the completion of training may incentivize them to abort the collaboration, and monetizing the contribution is challenging in practice. To address these problems, we propose an incentive-aware algorithm that offers differentiated training-time model rewards for each client at each FL iteration. We theoretically prove that such a $\\textit{local}$ design ensures the $\\textit{global}$ objective of client incentivization. Through theoretical analyses, we further identify the issue of error propagation in model rewards and thus propose a stochastic reference-model recovery strategy to ensure theoretically that all the clients eventually obtain the optimal model in the limit. We perform extensive experiments to demonstrate the superior incentivizing performance of our method compared to existing baselines."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a7e1876a998499e8031f15a41a219f007e1e7953.pdf"}, "supplementary_material": {"value": "/attachment/de8b0952ab69623f9bbfc712f3455c71b17b4cc0.zip"}, "_bibtex": {"value": "@inproceedings{\nwu2024incentiveaware,\ntitle={Incentive-Aware Federated Learning with Training-Time Model Rewards},\nauthor={Zhaoxuan Wu and Mohammad Mohammadi Amiri and Ramesh Raskar and Bryan Kian Hsiang Low},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FlY7WQ2hWS}\n}"}, "paperhash": {"value": "wu|incentiveaware_federated_learning_with_trainingtime_model_rewards"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5535/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5535/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942419, "version": 2}, {"id": "7TOs9gjAg1", "forum": "7TOs9gjAg1", "number": 5532, "cdate": 1695389876904, "tcdate": 1695389876904, "mdate": 1710367495606, "tmdate": 1710367495606, "signatures": ["ICLR.cc/2024/Conference/Submission5532/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5532/Authors"], "content": {"title": {"value": "Removing Biases from Molecular Representations via Information Maximization"}, "authors": {"value": ["Chenyu Wang", "Sharut Gupta", "Caroline Uhler", "Tommi S. Jaakkola"]}, "authorids": {"value": ["~Chenyu_Wang7", "~Sharut_Gupta1", "~Caroline_Uhler1", "~Tommi_S._Jaakkola1"]}, "keywords": {"value": ["Molecular Representation", "Batch Effect", "Contrastive Learning", "Information Maximization", "Drug Discovery"]}, "abstract": {"value": "High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing with batch effects, which can introduce systematic errors and non-biological associations in the data. We propose InfoCORE, an Information maximization approach for COnfounder REmoval, to effectively deal with batch effects and obtain refined molecular representations. InfoCORE establishes a variational lower bound on the conditional mutual information of the latent representations given a batch identifier. It adaptively reweights samples to equalize their implied batch distribution. Extensive experiments on drug screening data reveal InfoCORE's superior performance in a multitude of tasks including molecular property prediction and molecule-phenotype retrieval. Additionally, we show results for how InfoCORE offers a versatile framework and resolves general distribution shifts and issues of data fairness by minimizing correlation with spurious features or removing sensitive attributes."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We propose InfoCORE to deal with batch effects in drug screens and obtain refined molecular representations. It is established on a variational lower bound of the conditional mutual information between latent representations given a batch identifier."}, "pdf": {"value": "/pdf/2a85b0efae0a5c93b1dede6146fda893eb1e0acf.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024removing,\ntitle={Removing Biases from Molecular Representations via Information Maximization},\nauthor={Chenyu Wang and Sharut Gupta and Caroline Uhler and Tommi S. Jaakkola},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7TOs9gjAg1}\n}"}, "paperhash": {"value": "wang|removing_biases_from_molecular_representations_via_information_maximization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5532/-/Revision", "ICLR.cc/2024/Conference/Submission5532/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5532/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942301, "version": 2}, {"id": "1JtTPYBKqt", "forum": "1JtTPYBKqt", "number": 5529, "cdate": 1695389728388, "tcdate": 1695389728388, "mdate": 1710408616142, "tmdate": 1710408616142, "signatures": ["ICLR.cc/2024/Conference/Submission5529/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5529/Authors"], "content": {"title": {"value": "Neural Architecture Retrieval"}, "authors": {"value": ["Xiaohuan Pei", "Yanxi Li", "Minjing Dong", "Chang Xu"]}, "authorids": {"value": ["~Xiaohuan_Pei1", "~Yanxi_Li1", "~Minjing_Dong1", "~Chang_Xu4"]}, "keywords": {"value": ["Information Retrieval", "Vector Database", "Neural Architecture Search"]}, "abstract": {"value": "With the increasing number of new neural architecture designs and substantial existing neural architectures, it becomes difficult for the researchers to situate their contributions compared with existing neural architectures or establish the connections between their designs and other relevant ones. To discover similar neural architectures in an efficient and automatic manner, we define a new problem Neural Architecture Retrieval which retrieves a set of existing neural architectures which have similar designs to the query neural architecture. Existing graph pre-training strategies cannot address the computational graph in neural architectures due to the graph size and motifs. To fulfill this potential, we propose to divide the graph into motifs which are used to rebuild the macro graph to tackle these issues, and introduce multi-level contrastive learning to achieve accurate graph representation learning. Extensive evaluations on both human-designed and synthesized neural architectures demonstrate the superiority of our algorithm. Such a dataset which contains 12k real-world network architectures, as well as their embedding, is built for neural architecture retrieval."}, "pdf": {"value": "/pdf/180fb4a9f14dc5294394eb90e37c5a7daf41b195.pdf"}, "supplementary_material": {"value": "/attachment/cca9b9f3c82ab4d835a6c262d56f627308c858d8.zip"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\npei2024neural,\ntitle={Neural Architecture Retrieval},\nauthor={Xiaohuan Pei and Yanxi Li and Minjing Dong and Chang Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1JtTPYBKqt}\n}"}, "paperhash": {"value": "pei|neural_architecture_retrieval"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5529/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5529/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942189, "version": 2}, {"id": "QibPzdVrRu", "forum": "QibPzdVrRu", "number": 5527, "cdate": 1695389698081, "tcdate": 1695389698081, "mdate": 1709661522524, "tmdate": 1709661522524, "signatures": ["ICLR.cc/2024/Conference/Submission5527/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5527/Authors"], "content": {"title": {"value": "Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization"}, "authors": {"value": ["Hancheng Min", "Enrique Mallada", "Rene Vidal"]}, "authorids": {"value": ["~Hancheng_Min1", "~Enrique_Mallada1", "~Rene_Vidal1"]}, "keywords": {"value": ["Neural Networks", "Small Initialization", "Gradient Flow", "Neuron Alignment"]}, "TLDR": {"value": "We provide a quantitative analysis of neuron dynamics in two-layer ReLU networks under small initialization"}, "abstract": {"value": "This paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. We consider a training dataset with well-separated input vectors: Any pair of input data with the same label are positively correlated, and any pair with different labels are negatively correlated. Our analysis shows that, during the early phase of training, neurons in the first layer try to align with either the positive data or the negative data, depending on its corresponding weight on the second layer. A careful analysis of the neurons' directional dynamics allows us to provide an $\\mathcal{O}(\\frac{\\log n}{\\sqrt{\\mu}})$ upper bound on the time it takes for all neurons to achieve good alignment with the input data, where $n$ is the number of data points and $\\mu$ measures how well the data are separated. After the early alignment phase, the loss converges to zero at a $\\mathcal{O}(\\frac{1}{t})$ rate, and the weight matrix on the first layer is approximately low-rank. Numerical experiments on the MNIST dataset illustrate our theoretical findings."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d7f1031032ea0bf3139d1ea5a93beb8adc2fe0bd.pdf"}, "_bibtex": {"value": "@inproceedings{\nmin2024early,\ntitle={Early Neuron Alignment in Two-layer Re{LU} Networks with Small Initialization},\nauthor={Hancheng Min and Enrique Mallada and Rene Vidal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QibPzdVrRu}\n}"}, "paperhash": {"value": "min|early_neuron_alignment_in_twolayer_relu_networks_with_small_initialization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5527/-/Revision", "ICLR.cc/2024/Conference/Submission5527/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5527/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942171, "version": 2}, {"id": "3pf2hEdu8B", "forum": "3pf2hEdu8B", "number": 5525, "cdate": 1695389606870, "tcdate": 1695389606870, "mdate": 1709661522521, "tmdate": 1709661522521, "signatures": ["ICLR.cc/2024/Conference/Submission5525/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5525/Authors"], "content": {"title": {"value": "Rethinking the Uniformity Metric in Self-Supervised Learning"}, "authors": {"value": ["Xianghong Fang", "Jian Li", "Qiang Sun", "Benyou Wang"]}, "authorids": {"value": ["~Xianghong_Fang1", "~Jian_Li17", "~Qiang_Sun2", "~Benyou_Wang2"]}, "keywords": {"value": ["Desiderata of Ideal Uniformity Metric", "Dimensional Collapse", "Wasserstein Distance", "Self-Supervised Learning"]}, "TLDR": {"value": "We propose a new uniformity metric that could capture sailent sensitivity to dimensional collapse."}, "abstract": {"value": "Uniformity plays a crucial role in the assessment of learned representations, contributing to a deeper comprehension of self-supervised learning.  The seminal work by \\citet{Wang2020UnderstandingCR} introduced a uniformity metric that quantitatively measures the collapse degree of learned representations. Directly optimizing this metric together with alignment proves to be effective in preventing constant collapse. However, we present both theoretical and empirical evidence revealing that this metric lacks sensitivity to dimensional collapse, highlighting its limitations. To address this limitation and design a more effective uniformity metric, this paper identifies five fundamental properties, some of which the existing uniformity metric fails to meet. We subsequently introduce a novel uniformity metric that satisfies all of these desiderata and exhibits sensitivity to dimensional collapse. When applied as an auxiliary loss in various established self-supervised methods, our proposed uniformity metric consistently enhances their performance in downstream tasks."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ead11aa857dfeb1c83349f1acae96c2c6fb37d07.pdf"}, "supplementary_material": {"value": "/attachment/a283deee980612a070ee0d2e0d91cf9e2bf8ea0f.zip"}, "_bibtex": {"value": "@inproceedings{\nfang2024rethinking,\ntitle={Rethinking the Uniformity Metric in Self-Supervised Learning},\nauthor={Xianghong Fang and Jian Li and Qiang Sun and Benyou Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3pf2hEdu8B}\n}"}, "paperhash": {"value": "fang|rethinking_the_uniformity_metric_in_selfsupervised_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5525/-/Revision", "ICLR.cc/2024/Conference/Submission5525/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5525/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410942139, "version": 2}, {"id": "99tKiMVJhY", "forum": "99tKiMVJhY", "number": 5515, "cdate": 1695389395491, "tcdate": 1695389395491, "mdate": 1709661522402, "tmdate": 1709661522402, "signatures": ["ICLR.cc/2024/Conference/Submission5515/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5515/Authors"], "content": {"title": {"value": "Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior"}, "authors": {"value": ["Kai Cui", "Sascha H. Hauck", "Christian Fabian", "Heinz Koeppl"]}, "authorids": {"value": ["~Kai_Cui3", "~Sascha_H._Hauck1", "~Christian_Fabian1", "~Heinz_Koeppl1"]}, "keywords": {"value": ["Mean Field Control", "Multi-Agent Reinforcement Learning", "Partial Observability", "Collective Behavior"]}, "TLDR": {"value": "We propose a MARL algorithm via MFC that scales cooperative problems to many agents and partial information by reducing to a single-agent MDP, with many applications in designing collective behavior."}, "abstract": {"value": "Recent reinforcement learning (RL) methods have achieved success in various domains. However, multi-agent RL (MARL) remains a challenge in terms of decentralization, partial observability and scalability to many agents. Meanwhile, collective behavior requires resolution of the aforementioned challenges, and remains of importance to many state-of-the-art applications such as active matter physics, self-organizing systems, opinion dynamics, and biological or robotic swarms. Here, MARL via mean field control (MFC) offers a potential solution to scalability, but fails to consider decentralized and partially observable systems. In this paper, we enable decentralized behavior of agents under partial information by proposing novel models for decentralized partially observable MFC (Dec-POMFC), a broad class of problems with permutation-invariant agents allowing for reduction to tractable single-agent Markov decision processes (MDP) with single-agent RL solution. We provide rigorous theoretical results, including a dynamic programming principle, together with optimality guarantees for Dec-POMFC solutions applied to finite swarms of interest. Algorithmically, we propose Dec-POMFC-based policy gradient methods for MARL via centralized training and decentralized execution, together with policy gradient approximation guarantees. In addition, we improve upon state-of-the-art histogram-based MFC by kernel methods, which is of separate interest also for fully observable MFC. We evaluate numerically on representative collective behavior tasks such as adapted Kuramoto and Vicsek swarming models, being on par with state-of-the-art MARL. Overall, our framework takes a step towards RL-based engineering of artificial collective behavior via MFC."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c1987683d13350c251b90658f2a255e3225d0716.pdf"}, "_bibtex": {"value": "@inproceedings{\ncui2024learning,\ntitle={Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior},\nauthor={Kai Cui and Sascha H. Hauck and Christian Fabian and Heinz Koeppl},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=99tKiMVJhY}\n}"}, "paperhash": {"value": "cui|learning_decentralized_partially_observable_mean_field_control_for_artificial_collective_behavior"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5515/-/Revision", "ICLR.cc/2024/Conference/Submission5515/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5515/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941705, "version": 2}, {"id": "k1wlmtPGLq", "forum": "k1wlmtPGLq", "number": 5513, "cdate": 1695389280717, "tcdate": 1695389280717, "mdate": 1710500483013, "tmdate": 1710500483013, "signatures": ["ICLR.cc/2024/Conference/Submission5513/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5513/Authors"], "content": {"title": {"value": "TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks"}, "authors": {"value": ["Haiyan Jiang", "Vincent Zoonekynd", "Giulia De Masi", "Bin Gu", "Huan Xiong"]}, "authorids": {"value": ["~Haiyan_Jiang1", "~Vincent_Zoonekynd1", "~Giulia_De_Masi1", "~Bin_Gu1", "~Huan_Xiong1"]}, "keywords": {"value": ["Temporal Batch Normalization", "Spiking Neural Networks"]}, "abstract": {"value": "Spiking Neural Networks (SNNs) are attracting growing interest for their energy-efficient computing when implemented on neuromorphic hardware. However, directly training SNNs, even adopting batch normalization (BN), is highly challenging due to their non-differentiable activation function and the temporally delayed accumulation of outputs over time.\n    For SNN training, this temporal accumulation gives rise to Temporal Covariate Shifts (TCS) along the temporal dimension, a phenomenon that would become increasingly pronounced with layer-wise computations across multiple layers and multiple time-steps. \n    In this paper, we introduce TAB (Temporal Accumulated Batch Normalization), a novel SNN batch normalization method that addresses the temporal covariate shift issue by aligning with neuron dynamics (specifically the accumulated membrane potential) and utilizing temporal accumulated statistics for data normalization. \n    Within its framework, TAB effectively encapsulates the historical temporal dependencies that underlie the membrane potential accumulation process, thereby establishing a natural connection between neuron dynamics and TAB batch normalization. \n    Experimental results on CIFAR-10, CIFAR-100, and DVS-CIFAR10 show that our TAB method outperforms other state-of-the-art methods."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ed9fc333c5bea7c2bd1a01f88ed1b50ef8d884a0.pdf"}, "supplementary_material": {"value": "/attachment/8194240a1aed47d6bfdfd948c4703b4c1787fd50.zip"}, "_bibtex": {"value": "@inproceedings{\njiang2024tab,\ntitle={{TAB}: Temporal Accumulated Batch Normalization in Spiking Neural Networks},\nauthor={Haiyan Jiang and Vincent Zoonekynd and Giulia De Masi and Huan Xiong and Bin Gu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=k1wlmtPGLq}\n}"}, "paperhash": {"value": "jiang|tab_temporal_accumulated_batch_normalization_in_spiking_neural_networks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5513/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5513/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941636, "version": 2}, {"id": "a4DBEeGfQq", "forum": "a4DBEeGfQq", "number": 5510, "cdate": 1695389230099, "tcdate": 1695389230099, "mdate": 1710590402875, "tmdate": 1710590402875, "signatures": ["ICLR.cc/2024/Conference/Submission5510/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5510/Authors"], "content": {"title": {"value": "StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning"}, "authors": {"value": ["Shengzhong Zhang", "Wenjie Yang", "Xinyuan Cao", "Hongwei Zhang", "Zengfeng Huang"]}, "authorids": {"value": ["~Shengzhong_Zhang1", "~Wenjie_Yang4", "~Xinyuan_Cao1", "~Hongwei_Zhang3", "~Zengfeng_Huang1"]}, "keywords": {"value": ["Graph Contrastive Learning", "Scalable Training", "Structural Compression"]}, "abstract": {"value": "Graph contrastive learning (GCL) has become a powerful tool for learning graph data, but its scalability remains a significant challenge. In this work, we propose a simple yet effective training framework called Structural Compression (StructComp) to address this issue. Inspired by a sparse low-rank approximation on the diffusion matrix, StructComp trains the encoder with the compressed nodes. This allows the encoder not to perform any message passing during the training stage, and significantly reduces the number of sample pairs in the contrastive loss. We theoretically prove that the original GCL loss can be approximated with the contrastive loss computed by StructComp. Moreover, StructComp can be regarded as an additional regularization term for GCL models, resulting in a more robust encoder. Empirical studies on various datasets show that StructComp greatly reduces the time and memory consumption while improving model performance compared to the vanilla GCL models and scalable training methods."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d0696367745bbc632726018b550912d609354ec0.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024structcomp,\ntitle={StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning},\nauthor={Shengzhong Zhang and Wenjie Yang and Xinyuan Cao and Hongwei Zhang and Zengfeng Huang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=a4DBEeGfQq}\n}"}, "paperhash": {"value": "zhang|structcomp_substituting_propagation_with_structural_compression_in_training_graph_contrastive_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5510/-/Revision", "ICLR.cc/2024/Conference/Submission5510/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5510/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941494, "version": 2}, {"id": "KqbCvIFBY7", "forum": "KqbCvIFBY7", "number": 5503, "cdate": 1695388926046, "tcdate": 1695388926046, "mdate": 1710193966170, "tmdate": 1710193966170, "signatures": ["ICLR.cc/2024/Conference/Submission5503/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5503/Authors"], "content": {"title": {"value": "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models"}, "authors": {"value": ["Gabriele Corso", "Yilun Xu", "Valentin De Bortoli", "Regina Barzilay", "Tommi S. Jaakkola"]}, "authorids": {"value": ["~Gabriele_Corso1", "~Yilun_Xu1", "~Valentin_De_Bortoli1", "~Regina_Barzilay1", "~Tommi_S._Jaakkola1"]}, "keywords": {"value": ["diffusion models", "score-based models", "diversity", "guidance", "conformer generation", "image generation"]}, "TLDR": {"value": "Enforcing diversity with non-IID sampling of diffusion models via guidance from a joint-particle time-evolving potential"}, "abstract": {"value": "In light of the widespread success of generative models, a significant amount of research has gone into speeding up their sampling time. However, generative models are often sampled multiple times to obtain a diverse set incurring a cost that is orthogonal to sampling time. We tackle the question of how to improve diversity and sample efficiency by moving beyond the common assumption of independent samples. We propose particle guidance, an extension of diffusion-based generative sampling where a joint-particle time-evolving potential enforces diversity. We analyze theoretically the joint distribution that particle guidance generates, how to learn a potential that achieves optimal diversity, and the connections with methods in other disciplines. Empirically, we test the framework both in the setting of conditional image generation, where we are able to increase diversity without affecting quality, and molecular conformer generation, where we reduce the state-of-the-art median error by 13% on average."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/501967cbd2d8267b624a335de1915cdc7333369c.pdf"}, "_bibtex": {"value": "@inproceedings{\ncorso2024particle,\ntitle={Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models},\nauthor={Gabriele Corso and Yilun Xu and Valentin De Bortoli and Regina Barzilay and Tommi S. Jaakkola},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KqbCvIFBY7}\n}"}, "paperhash": {"value": "corso|particle_guidance_noniid_diverse_sampling_with_diffusion_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5503/-/Revision", "ICLR.cc/2024/Conference/Submission5503/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5503/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941228, "version": 2}, {"id": "pE6gWrASQm", "forum": "pE6gWrASQm", "number": 5502, "cdate": 1695388918211, "tcdate": 1695388918211, "mdate": 1710448214741, "tmdate": 1710448214741, "signatures": ["ICLR.cc/2024/Conference/Submission5502/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5502/Authors"], "content": {"title": {"value": "On Adversarial Training without Perturbing all Examples"}, "authors": {"value": ["Max Losch", "Mohamed Omran", "David Stutz", "Mario Fritz", "Bernt Schiele"]}, "authorids": {"value": ["~Max_Losch1", "~Mohamed_Omran1", "~David_Stutz1", "~Mario_Fritz1", "~Bernt_Schiele1"]}, "keywords": {"value": ["adversarial robustness", "adversarial training", "adversarial robust transfer"]}, "TLDR": {"value": "We propose a subset adv. training experiment to investigate robustness interactions between classes, examples and tasks and find that few attacked examples generalise surprisingly well"}, "abstract": {"value": "Adversarial training is the de-facto standard for improving robustness against adversarial examples. This usually involves a multi-step adversarial attack applied on each example during training. In this paper, we explore only constructing adversarial examples (AE) on a subset of the training examples. That is, we split the training set in two subsets $A$ and $B$, train models on both ($A\\cup B$) but construct AEs only for examples in $A$. Starting with $A$ containing only a single class, we systematically increase the size of $A$ and consider splitting by class and by examples. We observe that: (i) adv. robustness transfers by difficulty and to classes in $B$ that have never been adv. attacked during training, (ii) we observe a tendency for hard examples to provide better robustness transfer than easy examples, yet find this tendency to diminish with increasing complexity of datasets (iii) generating AEs on only $50$% of training data is sufficient to recover most of the baseline AT performance even on ImageNet. We observe similar transfer properties across tasks, where generating AEs on only $30$% of data can recover baseline robustness on the target task. We evaluate our subset analysis on a wide variety of image datasets like CIFAR-10, CIFAR-100, ImageNet-200 and show transfer to SVHN, Oxford-Flowers-102 and Caltech-256. In contrast to conventional practice, our experiments indicate that the utility of computing AEs varies by class and examples and that weighting examples from $A$ higher than $B$ provides high transfer performance. Code is available at [http://github.com/mlosch/SAT](http://github.com/mlosch/SAT)."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4a7cfb2e09f6ff60e55fbad5bb770bc1daa8309e.pdf"}, "_bibtex": {"value": "@inproceedings{\nlosch2024on,\ntitle={On Adversarial Training without Perturbing all Examples},\nauthor={Max Losch and Mohamed Omran and David Stutz and Mario Fritz and Bernt Schiele},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pE6gWrASQm}\n}"}, "paperhash": {"value": "losch|on_adversarial_training_without_perturbing_all_examples"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5502/-/Revision", "ICLR.cc/2024/Conference/Submission5502/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5502/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941197, "version": 2}, {"id": "KBo7Z5aTV0", "forum": "KBo7Z5aTV0", "number": 5500, "cdate": 1695388861754, "tcdate": 1695388861754, "mdate": 1710340120127, "tmdate": 1710340120127, "signatures": ["ICLR.cc/2024/Conference/Submission5500/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5500/Authors"], "content": {"title": {"value": "Diving Segmentation Model into Pixels"}, "authors": {"value": ["Chen Gan", "Zihao Yin", "Kelei He", "Yang Gao", "Junfeng Zhang"]}, "authorids": {"value": ["~Chen_Gan1", "~Zihao_Yin1", "~Kelei_He1", "~Yang_Gao3", "jfzhang@nju.edu.cn"]}, "keywords": {"value": ["Semantic Segmentation", "Pixel Learning", "Representation Learning", "Contrastive Learning"]}, "abstract": {"value": "More distinguishable and consistent pixel features for each category will benefit the semantic segmentation under various settings.\nExisting efforts to mine better pixel-level features attempt to explicitly model the categorical distribution, which fails to achieve optimal due to the significant pixel feature variance.\nMoreover, prior research endeavors have scarcely delved into the thorough analysis and meticulous handling of pixel-level variance, leaving semantic segmentation at a coarse granularity.\nIn this work, we analyze the causes of pixel-level variance and introduce the concept of $\\textbf{pixel learning}$ to concentrate on the tailored learning process of pixels to handle the pixel-level variance, enhancing the per-pixel recognition capability of segmentation models.\nUnder the context of the pixel learning scheme, each image is viewed as a distribution of pixels, and pixel learning aims to pursue consistent pixel representation inside an image, continuously align pixels from different images (distributions), and eventually achieve consistent pixel representation for each category, even cross-domains.\nWe proposed a pure pixel-level learning framework, namely PiXL, which consists of a pixel partition module to divide pixels into sub-domains, a prototype generation, a selection module to prepare targets for subsequent alignment, and a pixel alignment module to guarantee pixel feature consistency intra-/inter-images, and inter-domains.\nExtensive evaluations of multiple learning paradigms, including unsupervised domain adaptation and semi-/fully-supervised segmentation, show that PiXL outperforms state-of-the-art performances, especially when annotated images are scarce.\nVisualization of the embedding space further demonstrates that pixel learning attains a superior representation of pixel features.\nThe code is available at https://github.com/ChenGan-JS/PiXL."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fefaceb39adc1f2218d7bd6a6d119e016f832d63.pdf"}, "_bibtex": {"value": "@inproceedings{\ngan2024diving,\ntitle={Diving Segmentation Model into Pixels},\nauthor={Chen Gan and Zihao Yin and Kelei He and Yang Gao and Junfeng Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KBo7Z5aTV0}\n}"}, "paperhash": {"value": "gan|diving_segmentation_model_into_pixels"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5500/-/Revision", "ICLR.cc/2024/Conference/Submission5500/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5500/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941192, "version": 2}, {"id": "AfhNyr73Ma", "forum": "AfhNyr73Ma", "number": 5497, "cdate": 1695388746638, "tcdate": 1695388746638, "mdate": 1710475913269, "tmdate": 1710475913269, "signatures": ["ICLR.cc/2024/Conference/Submission5497/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5497/Authors"], "content": {"title": {"value": "General Stability Analysis for Zeroth-Order Optimization Algorithms"}, "authors": {"value": ["Xinyue Liu", "Hualin Zhang", "Bin Gu", "Hong Chen"]}, "authorids": {"value": ["~Xinyue_Liu3", "~Hualin_Zhang1", "~Bin_Gu1", "~Hong_Chen1"]}, "keywords": {"value": ["Stability Analysis; Zeroth-Order Optimization; Black-Box Learning"]}, "abstract": {"value": "Zeroth-order optimization algorithms are widely used for black-box optimization problems, such as those in machine learning and prompt engineering, where the gradients are approximated using function evaluations. Recently, a generalization result was provided for zeroth-order stochastic gradient descent (SGD) algorithms through stability analysis. However, this result was limited to the vanilla 2-point zeroth-order estimate of Gaussian distribution used in SGD algorithms. To address these limitations, we propose a general proof framework for stability analysis that applies to convex, strongly convex, and non-convex conditions, and yields results for popular zeroth-order optimization algorithms, including SGD, GD, and SVRG, as well as various zeroth-order estimates, such as 1-point and 2-point with different distributions and coordinate estimates. Our general analysis shows that coordinate estimation can lead to tighter generalization bounds for SGD, GD, and SVRG versions of zeroth-order optimization algorithms, due to the smaller expansion brought by coordinate estimates to stability analysis."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b6cf064377b222a40d33ef6d5162772803c9f63.pdf"}, "supplementary_material": {"value": "/attachment/ce5a38524d3d18e6062d950399c839cc2e0e1042.zip"}, "_bibtex": {"value": "@inproceedings{\nliu2024general,\ntitle={General Stability Analysis for Zeroth-Order Optimization Algorithms},\nauthor={Xinyue Liu and Hualin Zhang and Bin Gu and Hong Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AfhNyr73Ma}\n}"}, "paperhash": {"value": "liu|general_stability_analysis_for_zerothorder_optimization_algorithms"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5497/-/Revision", "ICLR.cc/2024/Conference/Submission5497/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5497/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410941008, "version": 2}, {"id": "yVJd8lKyVX", "forum": "yVJd8lKyVX", "number": 5495, "cdate": 1695388733376, "tcdate": 1695388733376, "mdate": 1710339702190, "tmdate": 1710339702190, "signatures": ["ICLR.cc/2024/Conference/Submission5495/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5495/Authors"], "content": {"title": {"value": "Hybrid Sharing for Multi-Label Image Classification"}, "authors": {"value": ["Zihao Yin", "Chen Gan", "Kelei He", "Yang Gao", "Junfeng Zhang"]}, "authorids": {"value": ["~Zihao_Yin1", "~Chen_Gan1", "~Kelei_He1", "~Yang_Gao3", "jfzhang@nju.edu.cn"]}, "keywords": {"value": ["Multi-task learning", "Multi-label learning", "mixture-of-experts", "image classification"]}, "abstract": {"value": "Existing multi-label classification methods have long suffered from label heterogeneity, where learning a label obscures another. By modeling multi-label classification as a multi-task problem, this issue can be regarded as a negative transfer, which indicates challenges to achieve simultaneously satisfied performance across multiple tasks. In this work, we propose the Hybrid Sharing Query (HSQ), a transformer-based model that introduces the mixture-of-experts architecture to image multi-label classification. HSQ is designed to leverage label correlations while mitigating heterogeneity effectively. To this end, HSQ is incorporated with a fusion expert framework that enables it to optimally combine the strengths of task-specialized experts with shared experts, ultimately enhancing multi-label classification performance across most labels. Extensive experiments are conducted on two benchmark datasets, with the results demonstrating that the proposed method achieves state-of-the-art performance and yields simultaneous improvements across most labels. The code is available at https://github.com/zihao-yin/HSQ"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c73f7b370e113168ee3b0efd2bfd7ce23ec1c0d3.pdf"}, "_bibtex": {"value": "@inproceedings{\nyin2024hybrid,\ntitle={Hybrid Sharing for Multi-Label Image Classification},\nauthor={Zihao Yin and Chen Gan and Kelei He and Yang Gao and Junfeng Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yVJd8lKyVX}\n}"}, "paperhash": {"value": "yin|hybrid_sharing_for_multilabel_image_classification"}}, "odate": 1697213872796, "pdate": 1705410941002, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5495/-/Revision", "ICLR.cc/2024/Conference/Submission5495/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5495/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "version": 2}, {"id": "e1vqloonRy", "forum": "e1vqloonRy", "number": 5494, "cdate": 1695388707057, "tcdate": 1695388707057, "mdate": 1709924255079, "tmdate": 1709924255079, "signatures": ["ICLR.cc/2024/Conference/Submission5494/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5494/Authors"], "content": {"title": {"value": "Symmetric Single Index Learning"}, "authors": {"value": ["Aaron Zweig", "Joan Bruna"]}, "authorids": {"value": ["~Aaron_Zweig2", "~Joan_Bruna1"]}, "keywords": {"value": ["single-index", "symmetric", "permutation invariant", "gradient flow", "learning"]}, "TLDR": {"value": "Gradient flow can provably learn a single index model in the feature space of symmetric polynomials"}, "abstract": {"value": "Few neural architectures lend themselves to provable learning with gradient based methods. One popular model is the single-index model, in which labels are produced by composing an unknown linear projection with a possibly unknown scalar link function. Learning this model with SGD is relatively well-understood, whereby the so-called information exponent of the link function governs a polynomial sample complexity rate.  However, extending this analysis to deeper or more complicated architectures remains challenging.\n\nIn this work, we consider single index learning in the setting of symmetric neural networks.  Under analytic assumptions on the activation and maximum degree assumptions on the link function, we prove that gradient flow recovers the hidden planted direction, represented as a finitely supported vector in the feature space of power sum polynomials.  We characterize a notion of information exponent adapted to our setting that controls the efficiency of learning."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b1648ac89070112f95ea261d0ab1a48f7a583f9f.pdf"}, "supplementary_material": {"value": "/attachment/2897be59ebfc3e487b61981f3ff738853f5c0d59.pdf"}, "_bibtex": {"value": "@inproceedings{\nzweig2024symmetric,\ntitle={Symmetric Single Index Learning},\nauthor={Aaron Zweig and Joan Bruna},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=e1vqloonRy}\n}"}, "paperhash": {"value": "zweig|symmetric_single_index_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5494/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5494/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940890, "version": 2}, {"id": "BdPvGRvoBC", "forum": "BdPvGRvoBC", "number": 5493, "cdate": 1695388699519, "tcdate": 1695388699519, "mdate": 1710422656936, "tmdate": 1710422656936, "signatures": ["ICLR.cc/2024/Conference/Submission5493/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5493/Authors"], "content": {"title": {"value": "An improved analysis of per-sample and per-update clipping in federated learning"}, "authors": {"value": ["Bo Li", "Xiaowen Jiang", "Mikkel N. Schmidt", "Tommy Sonne Alstr\u00f8m", "Sebastian U Stich"]}, "authorids": {"value": ["~Bo_Li34", "~Xiaowen_Jiang1", "~Mikkel_N._Schmidt1", "~Tommy_Sonne_Alstr\u00f8m1", "~Sebastian_U_Stich1"]}, "keywords": {"value": ["optimization", "clipping", "federated learning", "decentralized learning", "distributed optimization"]}, "TLDR": {"value": "We rigorously and precisely analyze the impact of per-sample and per-update clipping on the convergence of FedAvg"}, "abstract": {"value": "Gradient clipping is key mechanism that is essential to differentially private training techniques in Federated learning. Two popular strategies are per-sample clipping, which clips the mini-batch gradient, and per-update clipping, which clips each user's model update. However, there has not been a thorough theoretical analysis of these two clipping methods.\n\nIn this work, we rigorously analyze the impact of these two clipping techniques on the convergence of a popular federated learning algorithm FedAvg under standard stochastic noise and gradient dissimilarity assumptions. We provide a convergence guarantee given any arbitrary clipping threshold. Specifically, we show that per-sample clipping is guaranteed to converge to the neighborhood of the stationary point, with the size dependent on the stochastic noise, gradient dissimilarity, and clipping threshold. In contrast, the convergence to the stationary point can be guaranteed with a sufficiently small stepsize in per-update clipping at the cost of more communication rounds. We further provide insights into understanding the impact of the improved convergence analysis in the differentially private setting."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0b0e98320fe4107487ffbc3a6d88ba884b81664e.pdf"}, "supplementary_material": {"value": "/attachment/b4cafde41c3add4caaa0531a5d0aefdfe9be3065.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024an,\ntitle={An improved analysis of per-sample and per-update clipping in federated learning},\nauthor={Bo Li and Xiaowen Jiang and Mikkel N. Schmidt and Tommy Sonne Alstr{\\o}m and Sebastian U Stich},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BdPvGRvoBC}\n}"}, "paperhash": {"value": "li|an_improved_analysis_of_persample_and_perupdate_clipping_in_federated_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5493/-/Revision", "ICLR.cc/2024/Conference/Submission5493/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5493/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940861, "version": 2}, {"id": "ey3GhWXQ97", "forum": "ey3GhWXQ97", "number": 5492, "cdate": 1695388638170, "tcdate": 1695388638170, "mdate": 1711986071881, "tmdate": 1711986071881, "signatures": ["ICLR.cc/2024/Conference/Submission5492/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5492/Authors"], "content": {"title": {"value": "Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity"}, "authors": {"value": ["Emmeran Johnson", "Ciara Pike-Burke", "Patrick Rebeschini"]}, "authorids": {"value": ["~Emmeran_Johnson1", "~Ciara_Pike-Burke2", "~Patrick_Rebeschini1"]}, "keywords": {"value": ["RL Theory", "Low adaptive RL", "Linear RL", "Multi-Batch RL"]}, "abstract": {"value": "We theoretically explore the relationship between sample-efficiency and adaptivity in reinforcement learning. An algorithm is sample-efficient if it uses a number of queries $n$ to the environment that is polynomial in the dimension $d$ of the problem. Adaptivity refers to the frequency at which queries are sent and feedback is processed to update the querying strategy. To investigate this interplay, we employ a learning framework that allows sending queries in $K$ batches, with feedback being processed and queries updated after each batch. This model encompasses the whole adaptivity spectrum, ranging from non-adaptive `offline' ($K=1$) to fully adaptive ($K=n$) scenarios, and regimes in between. For the problems of policy evaluation and best-policy identification under $d$-dimensional linear function approximation, we establish $\\Omega(\\log \\log d)$ lower bounds on the number of batches $K$ required for sample-efficient algorithms with $n = O(poly(d))$ queries. Our results show that just having adaptivity ($K>1$) does not necessarily guarantee sample-efficiency. Notably, the adaptivity-boundary for sample-efficiency is not between offline reinforcement learning ($K=1$), where sample-efficiency was known to not be possible, and adaptive settings. Instead, the boundary lies between different regimes of adaptivity and depends on the problem dimension."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2fb3dbb240e95d25e67614703c40b6faa9ebb6f9.pdf"}, "TLDR": {"value": "We show that dimension-dependent adaptivity is necessary for sample efficiency in linear RL."}, "_bibtex": {"value": "@inproceedings{\njohnson2024sampleefficiency,\ntitle={Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity},\nauthor={Emmeran Johnson and Ciara Pike-Burke and Patrick Rebeschini},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ey3GhWXQ97}\n}"}, "paperhash": {"value": "johnson|sampleefficiency_in_multibatch_reinforcement_learning_the_need_for_dimensiondependent_adaptivity"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5492/-/Revision", "ICLR.cc/2024/Conference/Submission5492/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5492/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940852, "version": 2}, {"id": "FddFxi08J3", "forum": "FddFxi08J3", "number": 5487, "cdate": 1695388539824, "tcdate": 1695388539824, "mdate": 1711620483424, "tmdate": 1711620483424, "signatures": ["ICLR.cc/2024/Conference/Submission5487/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5487/Authors"], "content": {"title": {"value": "On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters"}, "authors": {"value": ["Matthias Lanzinger", "Pablo Barcelo"]}, "authorids": {"value": ["~Matthias_Lanzinger1", "~Pablo_Barcelo1"]}, "keywords": {"value": ["WL test", "graph neural networks", "graph motif parameters", "subgraph counting"]}, "TLDR": {"value": "We provide a characterization of the expressive power of the WL test in terms of graph motif parameters"}, "abstract": {"value": "Seminal research in the field of graph neural networks (GNNs) has revealed a direct correspondence between the expressive capabilities of GNNs and the $k$-dimensional \nWeisfeiler-Leman ($k$WL) test, a widely-recognized method for verifying graph isomorphism. This connection has reignited interest in comprehending the specific graph properties effectively distinguishable by the $k$WL test.\nA central focus of research in this field revolves around determining the least dimensionality $k$, for which $k$WL can discern graphs with different number of occurrences of a pattern graph $p$. We refer to such a least $k$ as the WL-dimension of this pattern counting problem. This inquiry traditionally delves into two distinct counting problems related to patterns: subgraph counting and induced subgraph counting. Intriguingly, despite their initial appearance as separate challenges with seemingly divergent approaches, both of these problems are interconnected components of a more comprehensive problem: \"graph motif parameters\". In this paper, we provide a precise characterization of the WL-dimension of labeled graph motif parameters. As specific instances of this result, we obtain characterizations of the WL-dimension of the subgraph counting and induced subgraph counting problem for every labeled pattern $p$. Particularly noteworthy is our resolution of a problem left open in previous work \nconcerning induced copies.\nWe additionally demonstrate that in cases where the $k$WL test distinguishes between graphs with varying occurrences of a pattern $p$, the exact number of occurrences of $p$ can be computed uniformly using only local information of the last layer of a corresponding GNN.\nWe finally delve into the challenge of recognizing the WL-dimension of various graph parameters. We give a polynomial time algorithm for determining the WL-dimension of the subgraph counting problem for given pattern $p$, answering an open question from previous work.\nWe additionally show how to utilize deep results from the field of graph motif parameters, together with our characterization, to determine the WL-dimension of induced subgraph counting and counting $k$-graphlets."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ec895a17766013611569318f91ba57c99d3929a1.pdf"}, "_bibtex": {"value": "@inproceedings{\nlanzinger2024on,\ntitle={On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters},\nauthor={Matthias Lanzinger and Pablo Barcelo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FddFxi08J3}\n}"}, "paperhash": {"value": "lanzinger|on_the_power_of_the_weisfeilerleman_test_for_graph_motif_parameters"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5487/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5487/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940685, "version": 2}, {"id": "4vPVBh3fhz", "forum": "4vPVBh3fhz", "number": 5481, "cdate": 1695388327258, "tcdate": 1695388327258, "mdate": 1709661521834, "tmdate": 1709661521834, "signatures": ["ICLR.cc/2024/Conference/Submission5481/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5481/Authors"], "content": {"title": {"value": "PAC Prediction Sets Under Label Shift"}, "authors": {"value": ["Wenwen Si", "Sangdon Park", "Insup Lee", "Edgar Dobriban", "Osbert Bastani"]}, "authorids": {"value": ["~Wenwen_Si1", "~Sangdon_Park1", "~Insup_Lee1", "~Edgar_Dobriban2", "~Osbert_Bastani1"]}, "keywords": {"value": ["prediction set", "label shift", "distribution-free uncertainty quantification", "probably approximately correct", "Clopper-Pearson binomial interval", "rejection sampling"]}, "abstract": {"value": "Prediction sets capture uncertainty by predicting sets of labels rather than individual labels, enabling downstream decisions to conservatively account for all plausible outcomes. Conformal inference algorithms construct prediction sets guaranteed to contain the true label with high probability. These guarantees fail to hold in the face of distribution shift, which is precisely when reliable uncertainty quantification can be most useful. We propose a novel algorithm for constructing prediction sets with PAC guarantees in the label shift setting, where the probabilities of labels can differ between the source and target distributions. Our algorithm relies on constructing confidence intervals for importance weights by propagating uncertainty through a Gaussian elimination algorithm. We evaluate our approach on four datasets: the CIFAR-10 and ChestX-Ray image datasets, the tabular CDC Heart Dataset, and the AGNews text dataset. Our algorithm satisfies the PAC guarantee while producing smaller prediction set sizes compared to several baselines."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a1e73a903872bcd5cd740b60ac40f1910d3afe72.pdf"}, "_bibtex": {"value": "@inproceedings{\nsi2024pac,\ntitle={{PAC} Prediction Sets Under Label Shift},\nauthor={Wenwen Si and Sangdon Park and Insup Lee and Edgar Dobriban and Osbert Bastani},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4vPVBh3fhz}\n}"}, "paperhash": {"value": "si|pac_prediction_sets_under_label_shift"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5481/-/Revision", "ICLR.cc/2024/Conference/Submission5481/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5481/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940378, "version": 2}, {"id": "KSjPaXtxP8", "forum": "KSjPaXtxP8", "number": 5476, "cdate": 1695388103340, "tcdate": 1695388103340, "mdate": 1710250564442, "tmdate": 1710250564442, "signatures": ["ICLR.cc/2024/Conference/Submission5476/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5476/Authors"], "content": {"title": {"value": "Memorization in Self-Supervised Learning Improves Downstream Generalization"}, "authors": {"value": ["Wenhao Wang", "Muhammad Ahmad Kaleem", "Adam Dziedzic", "Michael Backes", "Nicolas Papernot", "Franziska Boenisch"]}, "authorids": {"value": ["~Wenhao_Wang6", "~Muhammad_Ahmad_Kaleem1", "~Adam_Dziedzic1", "~Michael_Backes3", "~Nicolas_Papernot1", "~Franziska_Boenisch2"]}, "keywords": {"value": ["self-supervised learning", "memorization", "encoders", "generalization", "ssl"]}, "abstract": {"value": "Self-supervised learning (SSL) has recently received significant attention due to its ability to train high-performance encoders purely on unlabeled data---often scraped from the internet. This data can still be sensitive and empirical evidence suggests that SSL encoders memorize private information of their training data and can disclose them at inference time. Since existing theoretical definitions of memorization from supervised learning rely on labels, they do not transfer to SSL. To address this gap, we propose a framework for defining memorization within the context of SSL. Our definition compares the difference in alignment of representations for data points and their augmented views returned by both encoders that were trained on these data points and encoders that were not. Through comprehensive empirical analysis on diverse encoder architectures and datasets we highlight that even though SSL relies on large datasets and strong augmentations---both known in supervised learning as regularization techniques that reduce overfitting---still significant fractions of training data points experience high memorization. Through our empirical results, we show that this memorization is essential for encoders to achieve higher generalization performance on different downstream tasks."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We introduce a formal definition for memorization in self-supervised learning and provide a thorough empirical evaluation that suggests that encoders require memorization to generalize well to downstream tasks."}, "pdf": {"value": "/pdf/b6928fc6722fca95f15ab976e4fb8e541652bf97.pdf"}, "supplementary_material": {"value": "/attachment/a2475e370476fec11f57db53e322a0203593e0a5.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024memorization,\ntitle={Memorization in Self-Supervised Learning Improves Downstream Generalization},\nauthor={Wenhao Wang and Muhammad Ahmad Kaleem and Adam Dziedzic and Michael Backes and Nicolas Papernot and Franziska Boenisch},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KSjPaXtxP8}\n}"}, "paperhash": {"value": "wang|memorization_in_selfsupervised_learning_improves_downstream_generalization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5476/-/Revision", "ICLR.cc/2024/Conference/Submission5476/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5476/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940095, "version": 2}, {"id": "M3QXCOTTk4", "forum": "M3QXCOTTk4", "number": 5475, "cdate": 1695388094062, "tcdate": 1695388094062, "mdate": 1711241378199, "tmdate": 1711241378199, "signatures": ["ICLR.cc/2024/Conference/Submission5475/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5475/Authors"], "content": {"title": {"value": "The Curse of Diversity in Ensemble-Based Exploration"}, "authors": {"value": ["Zhixuan Lin", "Pierluca D'Oro", "Evgenii Nikishin", "Aaron Courville"]}, "authorids": {"value": ["~Zhixuan_Lin1", "~Pierluca_D'Oro1", "~Evgenii_Nikishin1", "~Aaron_Courville3"]}, "keywords": {"value": ["deep reinforcement learning", "ensemble-based exploration", "off-policy learning", "representation learning", "auxiliary tasks"]}, "TLDR": {"value": "We show that the off-policy learning challenge in ensemble-based exploration in deep RL can impair performance, provide extensive analysis, and show representation learning as a promising solution with a novel method CERL."}, "abstract": {"value": "We uncover a surprising phenomenon in deep reinforcement learning: training a diverse ensemble of data-sharing agents -- a well-established exploration strategy -- can significantly impair the performance of the individual ensemble members when compared to standard single-agent training. Through careful analysis, we attribute the degradation in performance to the low proportion of self-generated data in the shared training data for each ensemble member, as well as the inefficiency of the individual ensemble members to learn from such highly off-policy data. We thus name this phenomenon *the curse of diversity*. We find that several intuitive solutions -- such as a larger replay buffer or a smaller ensemble size -- either fail to consistently mitigate the performance loss or undermine the advantages of ensembling. Finally, we demonstrate the potential of representation learning to counteract the curse of diversity with a novel method named Cross-Ensemble Representation Learning (CERL) in both discrete and continuous control domains. Our work offers valuable insights into an unexpected pitfall in ensemble-based exploration and raises important caveats for future applications of similar approaches."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3d2a14133bd63101c5ad01153186892038a2c86f.pdf"}, "_bibtex": {"value": "@inproceedings{\nlin2024the,\ntitle={The Curse of Diversity in Ensemble-Based Exploration},\nauthor={Zhixuan Lin and Pierluca D'Oro and Evgenii Nikishin and Aaron Courville},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=M3QXCOTTk4}\n}"}, "paperhash": {"value": "lin|the_curse_of_diversity_in_ensemblebased_exploration"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5475/-/Revision", "ICLR.cc/2024/Conference/Submission5475/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5475/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940018, "version": 2}, {"id": "bbCL5aRjUx", "forum": "bbCL5aRjUx", "number": 5471, "cdate": 1695387849595, "tcdate": 1695387849595, "mdate": 1710431462634, "tmdate": 1710431462634, "signatures": ["ICLR.cc/2024/Conference/Submission5471/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5471/Authors"], "content": {"title": {"value": "Multilinear Operator Networks"}, "authors": {"value": ["Yixin Cheng", "Grigorios Chrysos", "Markos Georgopoulos", "Volkan Cevher"]}, "authorids": {"value": ["~Yixin_Cheng1", "~Grigorios_Chrysos1", "~Markos_Georgopoulos1", "~Volkan_Cevher1"]}, "keywords": {"value": ["Polynomial Networks", "Image recognition"]}, "TLDR": {"value": "We introduce a network based solely on multilinear operations."}, "abstract": {"value": "Despite the remarkable capabilities of deep neural networks in image recognition, the dependence on activation functions remains a largely unexplored area and has yet to be eliminated. On the other hand, Polynomial Networks is a class of models that does not require activation functions, but have yet to perform on par with modern architectures. In this work, we aim close this gap and propose MONet, which relies *solely* on multilinear operators. The core layer of MONet, called Mu-Layer, captures multiplicative interactions of the elements of the input token. MONet captures high-degree interactions of the input elements and we demonstrate the efficacy of our approach on a series of image recognition and scientific computing benchmarks. The proposed model outperforms prior polynomial networks and performs on par with modern architectures. We believe that MONet can inspire further research on models that use entirely multilinear operations."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7dbab726c9fbdba207a8d652d4675b7769d09d0d.pdf"}, "_bibtex": {"value": "@inproceedings{\ncheng2024multilinear,\ntitle={Multilinear Operator Networks},\nauthor={Yixin Cheng and Grigorios Chrysos and Markos Georgopoulos and Volkan Cevher},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bbCL5aRjUx}\n}"}, "paperhash": {"value": "cheng|multilinear_operator_networks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5471/-/Revision", "ICLR.cc/2024/Conference/Submission5471/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5471/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939837, "version": 2}, {"id": "9zhHVyLY4K", "forum": "9zhHVyLY4K", "number": 5470, "cdate": 1695387811069, "tcdate": 1695387811069, "mdate": 1707625622576, "tmdate": 1707625622576, "signatures": ["ICLR.cc/2024/Conference/Submission5470/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5470/Authors"], "content": {"title": {"value": "Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data"}, "authors": {"value": ["Ayesha Vermani", "Il Memming Park", "Josue Nassar"]}, "authorids": {"value": ["~Ayesha_Vermani1", "~Il_Memming_Park1", "~Josue_Nassar1"]}, "keywords": {"value": ["neural dynamics", "transfer learning", "distribution alignment", "neuroscience", "few-shot learning"]}, "abstract": {"value": "Large scale inference models are widely used in neuroscience to extract latent representations from high-dimensional neural recordings. Due to the statistical heterogeneities between sessions and animals, a new model is trained from scratch to infer the underlying dynamics for each new dataset. This is computationally expensive and does not fully leverage all the available data. Moreover, as these models get more complex, they can be challenging to train. In parallel, it is becoming common to use pre-trained models in the machine learning community for few shot and transfer learning. One major hurdle that prevents the re-use of generative models in neuroscience is the complex spatio-temporal structure of neural dynamics within and across animals. Interestingly, the underlying dynamics identified from different datasets on the same task are qualitatively similar. In this work, we exploit this observation and propose a source-free and unsupervised alignment approach that utilizes the learnt dynamics and enables the re-use of trained generative models. We validate our approach on simulations and show the efficacy of the alignment on neural recordings from the motor cortex obtained during a reaching task."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9300af10a0420c5f1cc7f9068953c5674b8e3a4f.pdf"}, "_bibtex": {"value": "@inproceedings{\nvermani2024leveraging,\ntitle={Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data},\nauthor={Ayesha Vermani and Il Memming Park and Josue Nassar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9zhHVyLY4K}\n}"}, "paperhash": {"value": "vermani|leveraging_generative_models_for_unsupervised_alignment_of_neural_time_series_data"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5470/-/Revision", "ICLR.cc/2024/Conference/Submission5470/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939787, "version": 2}, {"id": "r65xfUb76p", "forum": "r65xfUb76p", "number": 5469, "cdate": 1695387746826, "tcdate": 1695387746826, "mdate": 1709967590061, "tmdate": 1709967590061, "signatures": ["ICLR.cc/2024/Conference/Submission5469/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5469/Authors"], "content": {"title": {"value": "UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition"}, "authors": {"value": ["Wenxuan Zhou", "Sheng Zhang", "Yu Gu", "Muhao Chen", "Hoifung Poon"]}, "authorids": {"value": ["~Wenxuan_Zhou2", "~Sheng_Zhang9", "~Yu_Gu12", "~Muhao_Chen1", "~Hoifung_Poon1"]}, "keywords": {"value": ["named entity recognition", "large language model"]}, "abstract": {"value": "Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPT's capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0cb96e2b665eb94a03fb91314588a8c83a600f2e.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhou2024universalner,\ntitle={Universal{NER}: Targeted Distillation from Large Language Models for Open Named Entity Recognition},\nauthor={Wenxuan Zhou and Sheng Zhang and Yu Gu and Muhao Chen and Hoifung Poon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=r65xfUb76p}\n}"}, "paperhash": {"value": "zhou|universalner_targeted_distillation_from_large_language_models_for_open_named_entity_recognition"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5469/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5469/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939762, "version": 2}, {"id": "W8S8SxS9Ng", "forum": "W8S8SxS9Ng", "number": 5468, "cdate": 1695387695380, "tcdate": 1695387695380, "mdate": 1710540567614, "tmdate": 1710540567614, "signatures": ["ICLR.cc/2024/Conference/Submission5468/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5468/Authors"], "content": {"title": {"value": "Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data"}, "authors": {"value": ["Antonis Antoniades", "Yiyi Yu", "Joe S Canzano", "William Yang Wang", "Spencer Smith"]}, "authorids": {"value": ["~Antonis_Antoniades1", "~Yiyi_Yu1", "~Joe_S_Canzano1", "~William_Yang_Wang2", "~Spencer_Smith1"]}, "keywords": {"value": ["GPT", "Pretraining", "Transformers", "Multimodal", "Multitask", "Neuron", "Neuroscience", "Neuronal", "Spikes", "Brain", "Cortex", "Human", "Mice", "Biology"]}, "TLDR": {"value": "Introduce a generative framework to train large transformer models on multimodal and multitask system neuroscience datasets."}, "abstract": {"value": "State-of-the-art systems neuroscience experiments yield large-scale multimodal data, and these data sets require new tools for analysis. Inspired by the success of large pretrained models in vision and language domains, we reframe the analysis of large-scale, cellular-resolution neuronal spiking data into an auto-regressive spatiotemporal generation problem. Neuroformer is a multimodal, multitask generative pre-trained transformer (GPT) model that is specifically designed to handle the intricacies of data in systems neuroscience. It scales linearly with feature size, can process an arbitrary number of modalities, and is adaptable to downstream tasks, such as predicting behavior. We first trained Neuroformer on simulated datasets, and found that it both accurately predicted simulated neuronal circuit activity, and also intrinsically inferred the underlying neural circuit connectivity, including direction. When pretrained to decode neural responses, the model predicted the behavior of a mouse with only few-shot fine-tuning, suggesting that the model begins learning how to do so directly from the neural representations themselves, without any explicit supervision. We used an ablation study to show that joint training on neuronal responses and behavior boosted performance, highlighting the model's ability to associate behavioral and neural representations in an unsupervised manner. These findings show that Neuroformer can analyze neural datasets and their emergent properties, informing the development of models and hypotheses associated with the brain."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8d639bbceda337a69bc648a042867df317226653.pdf"}, "supplementary_material": {"value": "/attachment/751fa56416247daa5dec74b81bd3aa8044407ffc.zip"}, "_bibtex": {"value": "@inproceedings{\nantoniades2024neuroformer,\ntitle={Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data},\nauthor={Antonis Antoniades and Yiyi Yu and Joe S Canzano and William Yang Wang and Spencer Smith},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=W8S8SxS9Ng}\n}"}, "paperhash": {"value": "antoniades|neuroformer_multimodal_and_multitask_generative_pretraining_for_brain_data"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5468/-/Revision", "ICLR.cc/2024/Conference/Submission5468/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5468/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939735, "version": 2}, {"id": "vy42bYs1Wo", "forum": "vy42bYs1Wo", "number": 5467, "cdate": 1695387643656, "tcdate": 1695387643656, "mdate": 1712544095937, "tmdate": 1712544095937, "signatures": ["ICLR.cc/2024/Conference/Submission5467/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5467/Authors"], "content": {"title": {"value": "Off-Policy Primal-Dual Safe Reinforcement Learning"}, "authors": {"value": ["Zifan Wu", "Bo Tang", "Qian Lin", "Chao Yu", "Shangqin Mao", "Qianlong Xie", "Xingxing Wang", "Dong Wang"]}, "authorids": {"value": ["~Zifan_Wu2", "~Bo_Tang3", "~Qian_Lin3", "~Chao_Yu2", "~Shangqin_Mao1", "~Qianlong_Xie1", "~Xingxing_Wang3", "~Dong_Wang34"]}, "keywords": {"value": ["Safe Reinforcement Learning"]}, "abstract": {"value": "Primal-dual safe RL methods commonly perform iterations between the primal update of the policy and the dual update of the Lagrange Multiplier. Such a training paradigm is highly susceptible to the error in cumulative cost estimation since this estimation serves as the key bond connecting the primal and dual update processes. We show that this problem causes significant underestimation of cost when using off-policy methods, leading to the failure to satisfy the safety constraint. To address this issue, we propose conservative policy optimization, which learns a policy in a constraint-satisfying area by considering the uncertainty in cost estimation. This improves constraint satisfaction but also potentially hinders reward maximization. We then introduce local policy convexification to help eliminate such suboptimality by gradually reducing the estimation uncertainty. We provide theoretical interpretations of the joint coupling effect of these two ingredients and further verify them by extensive experiments. Results on benchmark tasks show that our method not only achieves an asymptotic performance comparable to state-of-the-art on-policy methods while using much fewer samples, but also significantly reduces constraint violation during training. Our code is available at https://github.com/ZifanWu/CAL."}, "pdf": {"value": "/pdf/76bd3786585a746bc2d5bf1b24f47a4b6d0aee89.pdf"}, "supplementary_material": {"value": "/attachment/f2ff51c764c3e760d0c47f7d7d48f00f685a57b3.zip"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nwu2024offpolicy,\ntitle={Off-Policy Primal-Dual Safe Reinforcement Learning},\nauthor={Zifan Wu and Bo Tang and Qian Lin and Chao Yu and Shangqin Mao and Qianlong Xie and Xingxing Wang and Dong Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vy42bYs1Wo}\n}"}, "paperhash": {"value": "wu|offpolicy_primaldual_safe_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5467/-/Revision", "ICLR.cc/2024/Conference/Submission5467/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5467/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939654, "version": 2}, {"id": "KkrDUGIASk", "forum": "KkrDUGIASk", "number": 5461, "cdate": 1695387514814, "tcdate": 1695387514814, "mdate": 1711934419212, "tmdate": 1711934419212, "signatures": ["ICLR.cc/2024/Conference/Submission5461/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5461/Authors"], "content": {"title": {"value": "An Extensible Framework for Open Heterogeneous Collaborative Perception"}, "authors": {"value": ["Yifan Lu", "Yue Hu", "Yiqi Zhong", "Dequan Wang", "Yanfeng Wang", "Siheng Chen"]}, "authorids": {"value": ["~Yifan_Lu1", "~Yue_Hu1", "~Yiqi_Zhong1", "~Dequan_Wang1", "~Yanfeng_Wang1", "~Siheng_Chen1"]}, "keywords": {"value": ["Collaborative Perception", "Sensor and Model Heterogeneity"]}, "abstract": {"value": "Collaborative perception aims to mitigate the limitations of single-agent perception, such as occlusions, by facilitating data exchange among multiple agents. However, most current works consider a homogeneous scenario where all agents use identity sensors and perception models. In reality, heterogeneous agent types may continually emerge and inevitably face a domain gap when collaborating with existing agents. In this paper, we introduce a new open heterogeneous problem: how to accommodate continually emerging new heterogeneous agent types into collaborative perception, while ensuring high perception performance and low integration cost? To address this problem, we propose HEterogeneous ALliance (HEAL), a novel extensible collaborative perception framework. HEAL first establishes a unified feature space with initial agents via a novel multi-scale foreground-aware Pyramid Fusion network. When heterogeneous new agents emerge with previously unseen modalities or models, we align them to the established unified space with an innovative backward alignment. This step only involves individual training on the new agent type, thus presenting extremely low training costs and high extensibility. To enrich agents' data heterogeneity, we bring OPV2V-H, a new large-scale dataset with more diverse sensor types. Extensive experiments on OPV2V-H and DAIR-V2X datasets show that HEAL surpasses SOTA methods in performance while reducing the training parameters by 91.5\\% when integrating 3 new agent types. We further implement a comprehensive codebase at: https://github.com/yifanlu0227/HEAL"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e5d886d6455b601234d6b7718e36915121eb8759.pdf"}, "TLDR": {"value": "We propose an extensible framework to integrate previously unseen heterogenous agents into collaborative perception with high collaboration performance and ultra low training costs."}, "_bibtex": {"value": "@inproceedings{\nlu2024an,\ntitle={An Extensible Framework for Open Heterogeneous Collaborative Perception},\nauthor={Yifan Lu and Yue Hu and Yiqi Zhong and Dequan Wang and Siheng Chen and Yanfeng Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KkrDUGIASk}\n}"}, "paperhash": {"value": "lu|an_extensible_framework_for_open_heterogeneous_collaborative_perception"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5461/-/Revision", "ICLR.cc/2024/Conference/Submission5461/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5461/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939524, "version": 2}, {"id": "V1GM9xDvIY", "forum": "V1GM9xDvIY", "number": 5451, "cdate": 1695387232370, "tcdate": 1695387232370, "mdate": 1710524541358, "tmdate": 1710524541358, "signatures": ["ICLR.cc/2024/Conference/Submission5451/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5451/Authors"], "content": {"title": {"value": "Neural structure learning with stochastic differential equations"}, "authors": {"value": ["Benjie Wang", "Joel Jennings", "Wenbo Gong"]}, "authorids": {"value": ["~Benjie_Wang1", "~Joel_Jennings1", "~Wenbo_Gong1"]}, "keywords": {"value": ["Structure Learning", "Causal Discovery", "Generative Model", "Variational Inference", "Differential Equation"]}, "TLDR": {"value": "We propose a novel structure learning method that leverages stochastic differential equations and variational inference to model continuous temporal process and infer posterior distributions over possible structures with theoretical guarantees."}, "abstract": {"value": "Discovering the underlying relationships among variables from temporal observations has been a longstanding challenge in numerous scientific disciplines, including biology, finance, and climate science. The dynamics of such systems are often best described using continuous-time stochastic processes. Unfortunately, most existing structure learning approaches assume that the underlying process evolves in discrete-time and/or observations occur at regular time intervals. These mismatched assumptions can often lead to incorrect learned structures and models. In this work, we introduce a novel structure learning method, SCOTCH, which combines neural stochastic differential equations (SDE) with variational inference to infer a posterior distribution over possible structures. This continuous-time approach can naturally handle both learning from and predicting observations at arbitrary time points. Theoretically, we establish sufficient conditions for an SDE and SCOTCH to be structurally identifiable, and prove its consistency under infinite data limits. Empirically, we demonstrate that our approach leads to improved structure learning performance on both synthetic and real-world datasets compared to relevant baselines under regular and irregular sampling intervals."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5ff1f06834df4a615749f6e89f07285cdc60b2ad.pdf"}, "supplementary_material": {"value": "/attachment/4010e934ef23a478411ec8ca0a2148cd22466adb.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024neural,\ntitle={Neural structure learning with stochastic differential equations},\nauthor={Benjie Wang and Joel Jennings and Wenbo Gong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=V1GM9xDvIY}\n}"}, "paperhash": {"value": "wang|neural_structure_learning_with_stochastic_differential_equations"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5451/-/Revision", "ICLR.cc/2024/Conference/Submission5451/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5451/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939278, "version": 2}, {"id": "wPhbtwlCDa", "forum": "wPhbtwlCDa", "number": 5447, "cdate": 1695387058977, "tcdate": 1695387058977, "mdate": 1712567738890, "tmdate": 1712567738890, "signatures": ["ICLR.cc/2024/Conference/Submission5447/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5447/Authors"], "content": {"title": {"value": "STARC: A General Framework For Quantifying Differences Between Reward Functions"}, "authors": {"value": ["Joar Max Viktor Skalse", "Lucy Farnik", "Sumeet Ramesh Motwani", "Erik Jenner", "Adam Gleave", "Alessandro Abate"]}, "authorids": {"value": ["~Joar_Max_Viktor_Skalse1", "~Lucy_Farnik1", "~Sumeet_Ramesh_Motwani1", "~Erik_Jenner1", "~Adam_Gleave1", "~Alessandro_Abate1"]}, "keywords": {"value": ["reward functions", "reward learning", "metrics", "evaluations"]}, "TLDR": {"value": "We introduce a family of methods for quantifying the difference between reward functions."}, "abstract": {"value": "In order to solve a task using reinforcement learning, it is necessary to first formalise the goal of that task as a *reward function*. However, for many real-world tasks, it is very difficult to manually specify a reward function that never incentivises undesirable behaviour. As a result, it is increasingly popular to use *reward learning algorithms*, which attempt to *learn* a reward function from data. However, the theoretical foundations of reward learning are not yet well-developed. In particular, it is typically not known when a given reward learning algorithm with high probability will learn a reward function that is safe to optimise. This means that reward learning algorithms generally must be evaluated empirically, which is expensive, and that their failure modes are difficult to anticipate in advance. One of the roadblocks to deriving better theoretical guarantees is the lack of good methods for *quantifying* the difference between reward functions. In this paper we provide a solution to this problem, in the form of a class of pseudometrics on the space of all reward functions that we call STARC (STAndardised Reward Comparison) metrics. We show that STARC metrics induce both an upper and a lower bound on worst-case regret, which implies that our metrics are tight, and that any metric with the same properties must be bilipschitz equivalent to ours. Moreover, we also identify a number of issues with reward metrics proposed by earlier works. Finally, we evaluate our metrics empirically, to demonstrate their practical efficacy. STARC metrics can be used to make both theoretical and empirical analysis of reward learning algorithms both easier and more principled."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2b164c79ae2074c35f200273d98f70957aa40ea0.pdf"}, "supplementary_material": {"value": "/attachment/f86b7f727d1a7297f3b2400a67c58293643d9204.pdf"}, "_bibtex": {"value": "@inproceedings{\nskalse2024starc,\ntitle={{STARC}: A General Framework For Quantifying Differences Between Reward Functions},\nauthor={Joar Max Viktor Skalse and Lucy Farnik and Sumeet Ramesh Motwani and Erik Jenner and Adam Gleave and Alessandro Abate},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wPhbtwlCDa}\n}"}, "paperhash": {"value": "skalse|starc_a_general_framework_for_quantifying_differences_between_reward_functions"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5447/-/Revision", "ICLR.cc/2024/Conference/Submission5447/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5447/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939217, "version": 2}, {"id": "fibxvahvs3", "forum": "fibxvahvs3", "number": 5446, "cdate": 1695387053408, "tcdate": 1695387053408, "mdate": 1707625622312, "tmdate": 1707625622312, "signatures": ["ICLR.cc/2024/Conference/Submission5446/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5446/Authors"], "content": {"title": {"value": "GAIA: a benchmark for General AI Assistants"}, "authors": {"value": ["Gr\u00e9goire Mialon", "Cl\u00e9mentine Fourrier", "Thomas Wolf", "Yann LeCun", "Thomas Scialom"]}, "authorids": {"value": ["~Gr\u00e9goire_Mialon1", "~Cl\u00e9mentine_Fourrier1", "~Thomas_Wolf1", "~Yann_LeCun1", "~Thomas_Scialom1"]}, "keywords": {"value": ["Large Language Models", "Benchmark"]}, "abstract": {"value": "We introduce GAIA, a benchmark for General AI Assistants that, if solved, would represent a milestone in AI research. GAIA proposes real-world questions that require a set of fundamental abilities such as reasoning, multi-modality handling, web browsing, and generally tool-use proficiency. Our questions allow simple, fast, and factual verification. GAIA questions are conceptually simple for humans yet challenging for most advanced AIs: we show that human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins. This notable performance disparity contrasts with the recent trend of LLMs outperforming humans on  tasks requiring professional skills in e.g. law or chemistry. GAIA's philosophy departs from the current trend in AI benchmarks suggesting to target tasks that are ever more difficult for humans. We posit that the advent of Artificial General Intelligence (AGI) hinges on a system's capability to exhibit similar robustness as the average human does on such questions. Using GAIA's methodology, we devise 466 questions and their answer. We release our questions while retaining answers to 300 of them to power a leader-board \\href{https://huggingface.co/xxx}{hereby accessible}."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/685768ee9b5788e867852bf6b423f4b726eb0a68.pdf"}, "supplementary_material": {"value": "/attachment/b5b7b84f88d2b86797f084ba362102ffacc46a9d.zip"}, "_bibtex": {"value": "@inproceedings{\nmialon2024gaia,\ntitle={{GAIA}: a benchmark for General {AI} Assistants},\nauthor={Gr{\\'e}goire Mialon and Cl{\\'e}mentine Fourrier and Thomas Wolf and Yann LeCun and Thomas Scialom},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fibxvahvs3}\n}"}, "paperhash": {"value": "mialon|gaia_a_benchmark_for_general_ai_assistants"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5446/-/Revision", "ICLR.cc/2024/Conference/Submission5446/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939155, "version": 2}, {"id": "AU2gS9ut61", "forum": "AU2gS9ut61", "number": 5442, "cdate": 1695386995358, "tcdate": 1695386995358, "mdate": 1709661521110, "tmdate": 1709661521110, "signatures": ["ICLR.cc/2024/Conference/Submission5442/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5442/Authors"], "content": {"title": {"value": "A differentiable brain simulator bridging brain simulation and brain-inspired computing"}, "authors": {"value": ["Chaoming Wang", "Tianqiu Zhang", "Sichao He", "Hongyaoxing Gu", "Shangyang Li", "Si Wu"]}, "authorids": {"value": ["~Chaoming_Wang1", "~Tianqiu_Zhang1", "~Sichao_He1", "~Hongyaoxing_Gu1", "~Shangyang_Li1", "~Si_Wu1"]}, "keywords": {"value": ["brain simulator", "brain simulation", "computational neuroscience", "brain-inspired computing"]}, "abstract": {"value": "Brain simulation builds dynamical models to mimic the structure and functions of the brain, while brain-inspired computing (BIC) develops intelligent systems by learning from the structure and functions of the brain. The two fields are intertwined and should share a common programming framework to facilitate each other's development. However, none of the existing software in the fields can achieve this goal, because traditional brain simulators lack differentiability for training, while existing deep learning (DL) frameworks fail to capture the biophysical realism and complexity of brain dynamics. In this paper, we introduce BrainPy, a differentiable brain simulator developed using JAX and XLA, with the aim of bridging the gap between brain simulation and BIC. BrainPy expands upon the functionalities of JAX, a powerful AI framework, by introducing complete capabilities for flexible, efficient, and scalable brain simulation. It offers a range of sparse and event-driven operators for efficient and scalable brain simulation, an abstraction for managing the intricacies of synaptic computations, a modular and flexible interface for constructing multi-scale brain models, and an object-oriented just-in-time compilation approach to handle the memory-intensive nature of brain dynamics. We showcase the efficiency and scalability of BrainPy on benchmark tasks, and highlight its differentiable simulation for biologically plausible spiking models."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/daaad86fe525638dc6d4e2184db4707e7472f10d.pdf"}, "supplementary_material": {"value": "/attachment/943a8eb1c80560e7df5cc2d12a0bb25667d6e630.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024brainpy,\ntitle={BrainPy: a differentiable brain simulator bridging brain simulation and brain-inspired computing},\nauthor={Chaoming Wang and Tianqiu Zhang and Hongyaoxing Gu and Sichao He and Shangyang Li and Si Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AU2gS9ut61}\n}"}, "TLDR": {"value": "We developed BrainPy, a differentiable brain simulator, to help bridge the gap between brain simulation and brain-inspired computing."}, "paperhash": {"value": "wang|a_differentiable_brain_simulator_bridging_brain_simulation_and_braininspired_computing"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5442/-/Revision", "ICLR.cc/2024/Conference/Submission5442/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5442/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410939040, "version": 2}, {"id": "NvbeD9Ttkx", "forum": "NvbeD9Ttkx", "number": 5439, "cdate": 1695386906523, "tcdate": 1695386906523, "mdate": 1709794122481, "tmdate": 1709794122481, "signatures": ["ICLR.cc/2024/Conference/Submission5439/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5439/Authors"], "content": {"title": {"value": "FOSI: Hybrid First and Second Order Optimization"}, "authors": {"value": ["Hadar Sivan", "Moshe Gabel", "Assaf Schuster"]}, "authorids": {"value": ["~Hadar_Sivan1", "~Moshe_Gabel1", "~Assaf_Schuster2"]}, "keywords": {"value": ["convex optimization", "nonconvex optimization", "first order optimization", "second order optimization", "deep learning"]}, "TLDR": {"value": "FOSI is a novel meta-algorithm that improves the performance of any first-order optimizer by efficiently incorporating second-order information."}, "abstract": {"value": "Popular machine learning approaches forgo second-order information due to the difficulty of computing curvature in high dimensions.\nWe present FOSI, a novel meta-algorithm that improves the performance of any base first-order optimizer by efficiently incorporating second-order information during the optimization process.\nIn each iteration, FOSI implicitly splits the function into two quadratic functions defined on orthogonal subspaces, then uses a second-order method to minimize the first, and the base optimizer to minimize the other.\nWe formally analyze FOSI's convergence and the conditions under which it improves a base optimizer.\nOur empirical evaluation \ndemonstrates that FOSI improves the convergence rate and optimization time of first-order methods such as Heavy-Ball and Adam, and outperforms second-order methods (K-FAC and L-BFGS)."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d23ab96211787648bfb5badadb9f26b24e92a040.pdf"}, "_bibtex": {"value": "@inproceedings{\nsivan2024fosi,\ntitle={{FOSI}: Hybrid First and Second Order Optimization},\nauthor={Hadar Sivan and Moshe Gabel and Assaf Schuster},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NvbeD9Ttkx}\n}"}, "paperhash": {"value": "sivan|fosi_hybrid_first_and_second_order_optimization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5439/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5439/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938938, "version": 2}, {"id": "zwU9scoU4A", "forum": "zwU9scoU4A", "number": 5423, "cdate": 1695386194798, "tcdate": 1695386194798, "mdate": 1709661521075, "tmdate": 1709661521075, "signatures": ["ICLR.cc/2024/Conference/Submission5423/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5423/Authors"], "content": {"title": {"value": "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach"}, "authors": {"value": ["Christian Fabian", "Kai Cui", "Heinz Koeppl"]}, "authorids": {"value": ["~Christian_Fabian1", "~Kai_Cui3", "~Heinz_Koeppl1"]}, "keywords": {"value": ["Mean Field Games", "Equilibrium Learning", "Networks", "Large Graphs", "Multi Agent Systems"]}, "TLDR": {"value": "We develop a novel graphex mean field game framework that enables us to learn otherwise intractable equilibria on sparse realistic networks via a hybrid graphex learning approach."}, "abstract": {"value": "Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the small world property. Learning equilibria in these games is challenging due to the rich and sparse structure of the underlying graphs. To tackle these challenges, we design a new learning algorithm tailored to the GXMFG setup. This hybrid graphex learning approach leverages that the system mainly consists of a highly connected core and a sparse periphery. After defining the system and providing a theoretical analysis, we state our learning approach and demonstrate its learning capabilities on both synthetic graphs and real-world networks. This comparison shows that our GXMFG learning algorithm successfully extends MFGs to a highly relevant class of hard, realistic learning problems that are not accurately addressed by current MARL and MFG methods."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/71668b85e315060e15202cddaf4245a5fb813cae.pdf"}, "supplementary_material": {"value": "/attachment/3e1112e852db6b6dfd996270da5046c5b45038c2.zip"}, "_bibtex": {"value": "@inproceedings{\nfabian2024learning,\ntitle={Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach},\nauthor={Christian Fabian and Kai Cui and Heinz Koeppl},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zwU9scoU4A}\n}"}, "paperhash": {"value": "fabian|learning_mean_field_games_on_sparse_graphs_a_hybrid_graphex_approach"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5423/-/Revision", "ICLR.cc/2024/Conference/Submission5423/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5423/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938582, "version": 2}, {"id": "Lvf7GnaLru", "forum": "Lvf7GnaLru", "number": 5419, "cdate": 1695386090160, "tcdate": 1695386090160, "mdate": 1709661520926, "tmdate": 1709661520926, "signatures": ["ICLR.cc/2024/Conference/Submission5419/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5419/Authors"], "content": {"title": {"value": "Unraveling the Key Components of OOD Generalization via Diversification"}, "authors": {"value": ["Harold Luc Benoit", "Liangze Jiang", "Andrei Atanov", "Oguzhan Fatih Kar", "Mattia Rigotti", "Amir Zamir"]}, "authorids": {"value": ["~Harold_Luc_Benoit1", "~Liangze_Jiang1", "~Andrei_Atanov1", "~Oguzhan_Fatih_Kar1", "~Mattia_Rigotti1", "~Amir_Zamir1"]}, "keywords": {"value": ["Algorithm Design", "Diversity", "OOD Generalization", "Spurious Correlation", "Understanding Neural Networks"]}, "TLDR": {"value": "We distill the critical design factors of current state-of-the-art methods (multi-hypotheses/diversification methods) for spurious correlation situations."}, "abstract": {"value": "Supervised learning datasets may contain multiple cues that explain the training set equally well, i.e., learning any of them would lead to the correct predictions on the training data. However, many of them can be spurious, i.e., lose their predictive power under a distribution shift and consequently fail to generalize to out-of-distribution (OOD) data. Recently developed \"diversification\" methods (Lee et al., 2023; Pagliardini et al., 2023) approach this problem by finding multiple diverse hypotheses that rely on different features. This paper aims to study this class of methods and identify the key components contributing to their OOD generalization abilities.\n\nWe show that (1) diversification methods are highly sensitive to the distribution of the unlabeled data used for diversification and can underperform significantly when away from a method-specific sweet spot. (2) Diversification alone is insufficient for OOD generalization. The choice of the used learning algorithm, e.g., the model's architecture and pretraining, is crucial. In standard experiments (classification on Waterbirds and Office-Home datasets), using the second-best choice leads to an up to 20\\% absolute drop in accuracy. (3) The optimal choice of learning algorithm depends on the unlabeled data and vice versa i.e. they are co-dependent. (4) Finally, we show that, in practice, the above pitfalls cannot be alleviated by increasing the number of diverse hypotheses, the major feature of diversification methods.\n\nThese findings provide a clearer understanding of the critical design factors influencing the OOD generalization abilities of diversification methods. They can guide practitioners in how to use the existing methods best and guide researchers in developing new, better ones."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6df1b841551baf3744a2db7f2f2c93db746c206c.pdf"}, "supplementary_material": {"value": "/attachment/6bc2ab49e589ab2abe4c9910ae31bb103d0e868d.zip"}, "_bibtex": {"value": "@inproceedings{\nbenoit2024unraveling,\ntitle={Unraveling the Key Components of {OOD} Generalization via Diversification},\nauthor={Harold Luc Benoit and Liangze Jiang and Andrei Atanov and Oguzhan Fatih Kar and Mattia Rigotti and Amir Zamir},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Lvf7GnaLru}\n}"}, "paperhash": {"value": "benoit|unraveling_the_key_components_of_ood_generalization_via_diversification"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5419/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5419/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938333, "version": 2}, {"id": "k5THrhXDV3", "forum": "k5THrhXDV3", "number": 5416, "cdate": 1695386012484, "tcdate": 1695386012484, "mdate": 1710588555239, "tmdate": 1710588555239, "signatures": ["ICLR.cc/2024/Conference/Submission5416/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5416/Authors"], "content": {"title": {"value": "Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders"}, "authors": {"value": ["Emanuele Palumbo", "Laura Manduchi", "Sonia Laguna", "Daphn\u00e9 Chopard", "Julia E Vogt"]}, "authorids": {"value": ["~Emanuele_Palumbo1", "~Laura_Manduchi2", "~Sonia_Laguna1", "~Daphn\u00e9_Chopard1", "~Julia_E_Vogt1"]}, "keywords": {"value": ["Generative Clustering", "Multimodal VAEs", "Variational Autoencoder", "Multimodal Learning", "Generative Models"]}, "abstract": {"value": "Multimodal VAEs have recently gained significant attention as generative models for weakly-supervised learning with multiple heterogeneous modalities. In parallel, VAE-based methods have been explored as probabilistic approaches for clustering tasks. At the intersection of these two research directions, we propose a novel multimodal VAE model in which the latent space is extended to learn data clusters, leveraging shared information across modalities. Our experiments show that our proposed model improves generative performance over existing multimodal VAEs, particularly for unconditional generation. Furthermore, we propose a post-hoc procedure to automatically select the number of true clusters thus mitigating critical limitations of previous clustering frameworks. Notably, our method favorably compares to alternative clustering approaches, in weakly-supervised settings. Finally, we integrate recent advancements in diffusion models into the proposed method to improve generative quality for real-world images."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/81ccb5e670a515dc3b1d26472097ab10a46482d8.pdf"}, "_bibtex": {"value": "@inproceedings{\npalumbo2024deep,\ntitle={Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders},\nauthor={Emanuele Palumbo and Laura Manduchi and Sonia Laguna and Daphn{\\'e} Chopard and Julia E Vogt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=k5THrhXDV3}\n}"}, "paperhash": {"value": "palumbo|deep_generative_clustering_with_multimodal_diffusion_variational_autoencoders"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5416/-/Revision", "ICLR.cc/2024/Conference/Submission5416/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5416/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938231, "version": 2}, {"id": "AY6aM13gGF", "forum": "AY6aM13gGF", "number": 5414, "cdate": 1695385953726, "tcdate": 1695385953726, "mdate": 1712087463084, "tmdate": 1712087463084, "signatures": ["ICLR.cc/2024/Conference/Submission5414/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5414/Authors"], "content": {"title": {"value": "Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning"}, "authors": {"value": ["Ruizhe Shi", "Yuyao Liu", "Yanjie Ze", "Simon Shaolei Du", "Huazhe Xu"]}, "authorids": {"value": ["~Ruizhe_Shi1", "~Yuyao_Liu1", "~Yanjie_Ze1", "~Simon_Shaolei_Du1", "~Huazhe_Xu1"]}, "keywords": {"value": ["Offline Reinforcement Learning", "Decision Transformer", "Motion Control"]}, "TLDR": {"value": "We leverage the power of pre-trained Language Models for low-level motion control in offline reinforcement learning."}, "abstract": {"value": "Offline reinforcement learning (RL) aims to find a near-optimal policy using pre-collected datasets. Given recent advances in Large Language Models (LLMs) and their few-shot learning prowess, this paper introduces $\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a general framework based on Decision Transformers to effectively use pre-trained Language Models (LMs) for offline RL. Our framework highlights four crucial components: (1)  Initializing Decision Transformers with sequentially pre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to full-weight fine-tuning, to combine the pre-trained knowledge from LMs and in-domain knowledge effectively, (3) using the non-linear MLP transformation instead of linear projections, to generate embeddings, and (4) integrating an auxiliary language prediction loss during fine-tuning to stabilize the LMs and retain their original abilities on languages. Empirical results indicate $\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks and closes the gap between value-based offline RL methods and decision transformers in dense-reward tasks. In particular, our method demonstrates superior performance in scenarios with limited data samples."}, "pdf": {"value": "/pdf/201886b684396fa10fa80a0cd3e52f1e4e18e04b.pdf"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "supplementary_material": {"value": "/attachment/a32db095adf9241993ade6a962055977b99c0bcb.pdf"}, "_bibtex": {"value": "@inproceedings{\nshi2024unleashing,\ntitle={Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning},\nauthor={Ruizhe Shi and Yuyao Liu and Yanjie Ze and Simon Shaolei Du and Huazhe Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AY6aM13gGF}\n}"}, "paperhash": {"value": "shi|unleashing_the_power_of_pretrained_language_models_for_offline_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5414/-/Revision", "ICLR.cc/2024/Conference/Submission5414/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5414/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410938186, "version": 2}, {"id": "BIveOmD1Nh", "forum": "BIveOmD1Nh", "number": 5404, "cdate": 1695385732121, "tcdate": 1695385732121, "mdate": 1709661520698, "tmdate": 1709661520698, "signatures": ["ICLR.cc/2024/Conference/Submission5404/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5404/Authors"], "content": {"title": {"value": "Equivariant Scalar Fields for Molecular Docking with Fast Fourier Transforms"}, "authors": {"value": ["Bowen Jing", "Tommi S. Jaakkola", "Bonnie Berger"]}, "authorids": {"value": ["~Bowen_Jing1", "~Tommi_S._Jaakkola1", "~Bonnie_Berger1"]}, "keywords": {"value": ["protein structure", "structural biology", "drug discovery", "molecular docking"]}, "abstract": {"value": "Molecular docking is critical to structure-based virtual screening, yet the throughput of such workflows is limited by the expensive optimization of scoring functions involved in most docking algorithms. We explore how machine learning can accelerate this process by learning a scoring function with a functional form that allows for more rapid optimization. Specifically, we define the scoring function to be the cross-correlation of multi-channel ligand and protein scalar fields parameterized by equivariant graph neural networks, enabling rapid optimization over rigid-body degrees of freedom with fast Fourier transforms. The runtime of our approach can be amortized at several levels of abstraction, and is particularly favorable for virtual screening settings with a common binding pocket. We benchmark our scoring functions on two simplified docking-related tasks: decoy pose scoring and rigid conformer docking. Our method attains similar but faster performance on crystal structures compared to the widely-used Vina and Gnina scoring functions, and is more robust on computationally predicted structures. Code is available at https://github.com/bjing2016/scalar-fields."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c2c2bee35e3e72148b784026529cbab4bc951da8.pdf"}, "_bibtex": {"value": "@inproceedings{\njing2024learning,\ntitle={Learning Scalar Fields for Molecular Docking with Fast Fourier Transforms},\nauthor={Bowen Jing and Tommi S. Jaakkola and Bonnie Berger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BIveOmD1Nh}\n}"}, "paperhash": {"value": "jing|equivariant_scalar_fields_for_molecular_docking_with_fast_fourier_transforms"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5404/-/Revision", "ICLR.cc/2024/Conference/Submission5404/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5404/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937881, "version": 2}, {"id": "fh8EYKFKns", "forum": "fh8EYKFKns", "number": 5401, "cdate": 1695385690559, "tcdate": 1695385690559, "mdate": 1710183774613, "tmdate": 1710183774613, "signatures": ["ICLR.cc/2024/Conference/Submission5401/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5401/Authors"], "content": {"title": {"value": "The Alignment Problem from a Deep Learning Perspective"}, "authors": {"value": ["Richard Ngo", "Lawrence Chan", "S\u00f6ren Mindermann"]}, "authorids": {"value": ["~Richard_Ngo2", "~Lawrence_Chan2", "~S\u00f6ren_Mindermann1"]}, "keywords": {"value": ["Alignment", "Safety", "AGI", "position paper"]}, "abstract": {"value": "AI systems based on deep learning have reached or surpassed human performance in a range of narrow domains. In coming years or decades, artificial general intelligence (AGI) may surpass human capabilities at many critical tasks. In this position paper, we examine the technical difficulty of fine-tuning hypothetical AGI systems based on pretrained deep models to pursue goals that are aligned with human interests. We argue that, if trained like today's most capable models, AGI systems could learn to act deceptively to receive higher reward, learn internally-represented goals which generalize beyond their fine-tuning distributions, and pursue those goals using power-seeking strategies. We review emerging evidence for these properties. AGIs with these properties would be difficult to align and may appear aligned even when they are not."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1e8b312c0f8278d65f63bfe3aebf9b0104d42316.pdf"}, "_bibtex": {"value": "@inproceedings{\nngo2024the,\ntitle={The Alignment Problem from a Deep Learning Perspective: A Position Paper},\nauthor={Richard Ngo and Lawrence Chan and S{\\\"o}ren Mindermann},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fh8EYKFKns}\n}"}, "paperhash": {"value": "ngo|the_alignment_problem_from_a_deep_learning_perspective"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5401/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5401/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937791, "version": 2}, {"id": "MJJcs3zbmi", "forum": "MJJcs3zbmi", "number": 5396, "cdate": 1695385466135, "tcdate": 1695385466135, "mdate": 1709661520597, "tmdate": 1709661520597, "signatures": ["ICLR.cc/2024/Conference/Submission5396/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5396/Authors"], "content": {"title": {"value": "Discovering Temporally-Aware Reinforcement Learning Algorithms"}, "authors": {"value": ["Matthew Thomas Jackson", "Chris Lu", "Louis Kirsch", "Robert Tjarko Lange", "Shimon Whiteson", "Jakob Nicolaus Foerster"]}, "authorids": {"value": ["~Matthew_Thomas_Jackson1", "~Chris_Lu1", "~Louis_Kirsch1", "~Robert_Tjarko_Lange1", "~Shimon_Whiteson1", "~Jakob_Nicolaus_Foerster1"]}, "keywords": {"value": ["Reinforcement Learning", "Meta-Learning", "Meta-RL", "Meta-Optimization", "Policy Meta-Optimization", "Learned Objective Functions"]}, "TLDR": {"value": "Conditioning learned optimizers on agent lifetime leads to an adaptive update and improves generalization performance."}, "abstract": {"value": "Recent advancements in meta-learning have enabled the automatic discovery of novel reinforcement learning algorithms parameterized by surrogate objective functions. To improve upon manually designed algorithms, the parameterization of this learned objective function must be expressive enough to represent novel principles of learning (instead of merely recovering already established ones) while still generalizing to a wide range of settings outside of its meta-training distribution. However, existing methods focus on discovering objective functions that, like many widely used objective functions in reinforcement learning, do not take into account the total number of steps allowed for training, or \u201ctraining horizon\u201d. In contrast, humans use a plethora of different learning objectives across the course of acquiring a new ability. For instance, students may alter their studying techniques based on the proximity to exam deadlines and their self-assessed capabilities. This paper contends that ignoring the optimization time horizon significantly restricts the expressive potential of discovered learning algorithms. We propose a simple augmentation to two existing objective discovery approaches that allows the discovered algorithm to dynamically update its objective function throughout the agent\u2019s training procedure, resulting in expressive schedules and increased generalization across different training horizons. In the process, we find that commonly used meta-gradient approaches fail to discover such adaptive objective functions while evolution strategies discover highly dynamic learning rules. We demonstrate the effectiveness of our approach on a wide range of tasks and analyze the resulting learned algorithms, which we find effectively balance exploration and exploitation by modifying the structure of their learning rules throughout the agent\u2019s lifetime."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d12f939d6af9197c0b6070ba1bd9bc54fdd5f096.pdf"}, "supplementary_material": {"value": "/attachment/eb7f9b97c84662f6d9aadb1c28dbb55a2b067450.pdf"}, "_bibtex": {"value": "@inproceedings{\njackson2024discovering,\ntitle={Discovering Temporally-Aware Reinforcement Learning Algorithms},\nauthor={Matthew Thomas Jackson and Chris Lu and Louis Kirsch and Robert Tjarko Lange and Shimon Whiteson and Jakob Nicolaus Foerster},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MJJcs3zbmi}\n}"}, "paperhash": {"value": "jackson|discovering_temporallyaware_reinforcement_learning_algorithms"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5396/-/Revision", "ICLR.cc/2024/Conference/Submission5396/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5396/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937634, "version": 2}, {"id": "WcOohbsF4H", "forum": "WcOohbsF4H", "number": 5394, "cdate": 1695385434997, "tcdate": 1695385434997, "mdate": 1710864531373, "tmdate": 1710864531373, "signatures": ["ICLR.cc/2024/Conference/Submission5394/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5394/Authors"], "content": {"title": {"value": "Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram"}, "authors": {"value": ["Yeongyeon Na", "Minje Park", "Yunwon Tae", "Sunghoon Joo"]}, "authorids": {"value": ["~Yeongyeon_Na1", "~Minje_Park3", "~Yunwon_Tae1", "~Sunghoon_Joo1"]}, "keywords": {"value": ["Electrocardiogram", "ECG", "Cardiac signal", "Biosignal", "Self-supervised learning", "Masked auto-encoder", "Representation learning"]}, "abstract": {"value": "Electrocardiograms (ECG) are widely employed as a diagnostic tool for monitoring electrical signals originating from a heart. Recent machine learning research efforts have focused on the application of screening various diseases using ECG signals. However, adapting to the application of screening disease is challenging in that labeled ECG data are limited. Achieving general representation through self-supervised learning (SSL) is a well-known approach to overcome the scarcity of labeled data; however, a naive application of SSL to ECG data, without considering the spatial-temporal relationships inherent in ECG signals, may yield suboptimal results. In this paper, we introduce ST-MEM (Spatio-Temporal Masked Electrocardiogram Modeling), designed to learn spatio-temporal features by reconstructing masked 12-lead ECG data. ST-MEM outperforms other SSL baseline methods in various experimental settings for arrhythmia classification tasks. Moreover, we demonstrate that ST-MEM is adaptable to various lead combinations. Through quantitative and qualitative analysis, we show a spatio-temporal relationship within ECG data. Our code is available at https://github.com/bakqui/ST-MEM."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a07e05e7b1b1e1ecd52872c58d9745a01e0a1276.pdf"}, "supplementary_material": {"value": "/attachment/3581b5749137f43ba1c8bbaec8b469996a12b28f.zip"}, "TLDR": {"value": "We propose ST-MEM, Spatio-Temporal Masked Electrocardiogram Modeling, to learn the general ECG representation, generally applicable to diverse ECG problems by incorporating the spatial and temporal relationship of ECG signal."}, "_bibtex": {"value": "@inproceedings{\nna2024guiding,\ntitle={Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram},\nauthor={Yeongyeon Na and Minje Park and Yunwon Tae and Sunghoon Joo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WcOohbsF4H}\n}"}, "paperhash": {"value": "na|guiding_masked_representation_learning_to_capture_spatiotemporal_relationship_of_electrocardiogram"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5394/-/Revision", "ICLR.cc/2024/Conference/Submission5394/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5394/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937520, "version": 2}, {"id": "tBROYsEz9G", "forum": "tBROYsEz9G", "number": 5393, "cdate": 1695385271643, "tcdate": 1695385271643, "mdate": 1713124290584, "tmdate": 1713124290584, "signatures": ["ICLR.cc/2024/Conference/Submission5393/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5393/Authors"], "content": {"title": {"value": "How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data"}, "authors": {"value": ["Mihaela C Stoian", "Salijona Dyrmishi", "Maxime Cordy", "Thomas Lukasiewicz", "Eleonora Giunchiglia"]}, "authorids": {"value": ["~Mihaela_C_Stoian1", "~Salijona_Dyrmishi1", "~Maxime_Cordy1", "~Thomas_Lukasiewicz2", "~Eleonora_Giunchiglia1"]}, "keywords": {"value": ["Synthetic Data Generation"]}, "abstract": {"value": "Deep Generative Models (DGMs) have been shown to be powerful tools for generating tabular data, as they have been increasingly able to capture the complex distributions that characterize them. However, to generate realistic synthetic data, it is often not enough to have a good approximation of their distribution, as it also requires compliance with constraints that encode essential background knowledge on the problem at hand. In this paper, we address this limitation and show how DGMs for tabular data can be transformed into Constrained Deep Generative Models (C-DGMs), whose generated samples are guaranteed to be compliant with the given constraints. This is achieved by automatically parsing the constraints and transforming them into a Constraint Layer (CL) seamlessly integrated with the DGM. Our extensive experimental analysis with various DGMs and tasks reveals that standard DGMs often violate constraints, some exceeding 95% non-compliance, while their corresponding C-DGMs are never non-compliant. Then, we quantitatively demonstrate that, at training time, C-DGMs are able to exploit the background knowledge expressed by the constraints to outperform their standard counterparts with up to 4.5% improvement in utility and detection. Further, we show how our CL does not necessarily need to be integrated at training time, as it can be also used as a guardrail at inference time, still producing some improvements in the overall performance of the models. Finally, we show that our CL does not hinder the sample generation time of the models."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/46eb8ee1d8b91eea904b9aa9d0b235f22f645325.pdf"}, "supplementary_material": {"value": "/attachment/9b765d16845c66b9ef5bd9ca59b5718037d2e39f.zip"}, "_bibtex": {"value": "@inproceedings{\nstoian2024how,\ntitle={How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data},\nauthor={Mihaela C Stoian and Salijona Dyrmishi and Maxime Cordy and Thomas Lukasiewicz and Eleonora Giunchiglia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tBROYsEz9G}\n}"}, "paperhash": {"value": "stoian|how_realistic_is_your_synthetic_data_constraining_deep_generative_models_for_tabular_data"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5393/-/Revision", "ICLR.cc/2024/Conference/Submission5393/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5393/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937468, "version": 2}, {"id": "s8cMuxI5gu", "forum": "s8cMuxI5gu", "number": 5392, "cdate": 1695385228393, "tcdate": 1695385228393, "mdate": 1709810131318, "tmdate": 1709810131318, "signatures": ["ICLR.cc/2024/Conference/Submission5392/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5392/Authors"], "content": {"title": {"value": "Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks"}, "authors": {"value": ["Yanbo Wang", "Jian Liang", "Ran He"]}, "authorids": {"value": ["~Yanbo_Wang5", "~Jian_Liang1", "~Ran_He1"]}, "keywords": {"value": ["label recovery", "gradient inversion attacks"]}, "TLDR": {"value": "We initialize a novel method to analytically recover the augmented label as well as last layer features from single input in gradient inversion attacks, disclosing a necessary condition for all analytical-based label recovery methods."}, "abstract": {"value": "Gradient inversion attacks aim to reconstruct local training data from intermediate gradients exposed in the federated learning framework. Despite successful attacks, all previous methods, starting from reconstructing a single data point and then relaxing the single-image limit to batch level, are only tested under hard label constraints. Even for single-image reconstruction, we still lack an analysis-based algorithm to recover augmented soft labels. In this work, we change the focus from enlarging batchsize to investigating the hard label constraints, considering a more realistic circumstance where label smoothing and mixup techniques are used in the training process. In particular, we are the first to initiate a novel algorithm to simultaneously recover the ground-truth augmented label and the input feature of the last fully-connected layer from single-input gradients, and provide a necessary condition for any analytical-based label recovery methods. Extensive experiments testify to the label recovery accuracy, as well as the benefits to the following image reconstruction. We believe soft labels in classification tasks are worth further attention in gradient inversion attacks."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3be3cfdc746ff3ca0589782f352ae91a32d3b9ca.pdf"}, "supplementary_material": {"value": "/attachment/48637b04ac17c73ae656c789ca513094a16c6d24.zip"}, "_bibtex": {"value": "@inproceedings{\nwang2024towards,\ntitle={Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks},\nauthor={Yanbo Wang and Jian Liang and Ran He},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=s8cMuxI5gu}\n}"}, "paperhash": {"value": "wang|towards_eliminating_hard_label_constraints_in_gradient_inversion_attacks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5392/-/Revision", "ICLR.cc/2024/Conference/Submission5392/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5392/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937461, "version": 2}, {"id": "ZhlwoC1XaN", "forum": "ZhlwoC1XaN", "number": 5385, "cdate": 1695384743368, "tcdate": 1695384743368, "mdate": 1710456143560, "tmdate": 1710456143560, "signatures": ["ICLR.cc/2024/Conference/Submission5385/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5385/Authors"], "content": {"title": {"value": "From Zero to Turbulence: Generative Modeling for 3D Flow Simulation"}, "authors": {"value": ["Marten Lienen", "David L\u00fcdke", "Jan Hansen-Palmus", "Stephan G\u00fcnnemann"]}, "authorids": {"value": ["~Marten_Lienen1", "~David_L\u00fcdke1", "~Jan_Hansen-Palmus1", "~Stephan_G\u00fcnnemann1"]}, "keywords": {"value": ["pde", "generative", "diffusion", "navier-stokes", "cfd"]}, "abstract": {"value": "Simulations of turbulent flows in 3D are one of the most expensive simulations in computational fluid dynamics (CFD). Many works have been written on surrogate models to replace numerical solvers for fluid flows with faster, learned, autoregressive models. However, the intricacies of turbulence in three dimensions necessitate training these models with very small time steps, while generating realistic flow states requires either long roll-outs with many steps and significant error accumulation or starting from a known, realistic flow state\u2014something we aimed to avoid in the first place. Instead, we propose to approach turbulent flow simulation as a generative task directly learning the manifold of all possible turbulent flow states without relying on any initial flow state. For our experiments, we introduce a challenging 3D turbulence dataset of high-resolution flows and detailed vortex structures caused by various objects and derive two novel sample evaluation metrics for turbulent flows. On this dataset, we show that our generative model captures the distribution of turbulent flows caused by unseen objects and generates high-quality, realistic samples amenable for downstream applications without access to any initial state."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cffaed70756a6b0fe20fc4c1865b1ca0d791c5db.pdf"}, "_bibtex": {"value": "@inproceedings{\nlienen2024from,\ntitle={From Zero to Turbulence: Generative Modeling for 3D Flow Simulation},\nauthor={Marten Lienen and David L{\\\"u}dke and Jan Hansen-Palmus and Stephan G{\\\"u}nnemann},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZhlwoC1XaN}\n}"}, "TLDR": {"value": "Generative models are a promising alternative to time series methods for neural surrogate turbulence solvers"}, "paperhash": {"value": "lienen|from_zero_to_turbulence_generative_modeling_for_3d_flow_simulation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5385/-/Revision", "ICLR.cc/2024/Conference/Submission5385/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5385/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410937186, "version": 2}, {"id": "Zj12nzlQbz", "forum": "Zj12nzlQbz", "number": 5370, "cdate": 1695384191132, "tcdate": 1695384191132, "mdate": 1712421883614, "tmdate": 1712421883614, "signatures": ["ICLR.cc/2024/Conference/Submission5370/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5370/Authors"], "content": {"title": {"value": "INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection"}, "authors": {"value": ["Chao Chen", "Kai Liu", "Ze Chen", "Yi Gu", "Yue Wu", "Mingyuan Tao", "Zhihang Fu", "Jieping Ye"]}, "authorids": {"value": ["~Chao_Chen19", "~Kai_Liu8", "~Ze_Chen3", "~Yi_Gu6", "~Yue_Wu18", "~Mingyuan_Tao1", "~Zhihang_Fu1", "~Jieping_Ye4"]}, "keywords": {"value": ["Large Language Models", "Hallucination Detection", "LogDet of Covariance Matrix", "Eigenvalues", "Feature Clipping"]}, "abstract": {"value": "Knowledge hallucination have raised widespread concerns for the security and reliability of deployed LLMs. Previous efforts in detecting hallucinations have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, where the semantic information is inevitably lost during the token-decoding procedure. Thus, we propose to explore the dense semantic information retained within LLMs' \\textbf{IN}ternal \\textbf{S}tates for halluc\\textbf{I}nation \\textbf{DE}tection (\\textbf{INSIDE}). In particular, a simple yet effective \\textbf{EigenScore} metric is proposed to better evaluate responses' self-consistency, which exploits the eigenvalues of responses' covariance matrix to measure the semantic consistency/diversity in the dense embedding space. Furthermore, from the perspective of self-consistent hallucination detection, a test time feature clipping approach is explored to truncate extreme activations in the internal states, which reduces overconfident generations and potentially benefits the detection of overconfident hallucinations. Extensive experiments and ablation studies are performed on several popular LLMs and question-answering (QA) benchmarks, showing the effectiveness of our proposal."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cd575c9c3b5f1161d893f5df7d600601084ceece.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024inside,\ntitle={{INSIDE}: {LLM}s' Internal States Retain the Power of Hallucination Detection},\nauthor={Chao Chen and Kai Liu and Ze Chen and Yi Gu and Yue Wu and Mingyuan Tao and Zhihang Fu and Jieping Ye},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Zj12nzlQbz}\n}"}, "TLDR": {"value": "Exploring LLMs' internal states for hallucination detection"}, "paperhash": {"value": "chen|inside_llms_internal_states_retain_the_power_of_hallucination_detection"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5370/-/Revision", "ICLR.cc/2024/Conference/Submission5370/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5370/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410936598, "version": 2}, {"id": "FlhjUkC7vH", "forum": "FlhjUkC7vH", "number": 5364, "cdate": 1695383964144, "tcdate": 1695383964144, "mdate": 1709661520242, "tmdate": 1709661520242, "signatures": ["ICLR.cc/2024/Conference/Submission5364/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5364/Authors"], "content": {"title": {"value": "DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation"}, "authors": {"value": ["Hong Chen", "Yipeng Zhang", "Simin Wu", "Xin Wang", "Xuguang Duan", "Yuwei Zhou", "Wenwu Zhu"]}, "authorids": {"value": ["~Hong_Chen9", "~Yipeng_Zhang3", "~Simin_Wu1", "~Xin_Wang17", "~Xuguang_Duan1", "~Yuwei_Zhou1", "~Wenwu_Zhu1"]}, "keywords": {"value": ["diffusion model", "subject-driven text-to-image generation", "disentangled finetuning", "customized and personalized generation"]}, "abstract": {"value": "Subject-driven text-to-image generation aims to generate customized images of the given subject based on the text descriptions, which has drawn increasing attention. Existing methods mainly resort to finetuning a pretrained generative model, where the identity-relevant information (e.g., the boy) and the identity-irrelevant information (e.g., the background or the pose of the boy) are entangled in the latent embedding space. However, the highly entangled latent embedding may lead to the failure of subject-driven text-to-image generation as follows: (i) the identity-irrelevant information hidden in the entangled embedding may dominate the generation process, resulting in the generated images heavily dependent on the irrelevant information while ignoring the given text descriptions; (ii) the identity-relevant information carried in the entangled embedding can not be appropriately preserved, resulting in identity change of the subject in the generated images. To tackle the problems, we propose DisenBooth, an identity-preserving disentangled tuning framework for subject-driven text-to-image generation. Specifically, DisenBooth finetunes the pretrained diffusion model in the denoising process. Different from previous works that utilize an entangled embedding to denoise each image, DisenBooth instead utilizes disentangled embeddings to respectively preserve the subject identity and capture the identity-irrelevant information. We further design the novel weak denoising and contrastive embedding auxiliary tuning objectives to achieve the disentanglement. Extensive experiments show that our proposed DisenBooth framework outperforms baseline models for subject-driven text-to-image generation with the identity-preserved embedding. Additionally, by combining the identity-preserved embedding and identity-irrelevant embedding, DisenBooth demonstrates more generation flexibility and controllability."}, "pdf": {"value": "/pdf/586b1d689b0c63f022fa9045633f9f46648bbfab.pdf"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nchen2024disenbooth,\ntitle={DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation},\nauthor={Hong Chen and Yipeng Zhang and Simin Wu and Xin Wang and Xuguang Duan and Yuwei Zhou and Wenwu Zhu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FlhjUkC7vH}\n}"}, "paperhash": {"value": "chen|disenbooth_identitypreserving_disentangled_tuning_for_subjectdriven_texttoimage_generation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5364/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5364/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410936386, "version": 2}, {"id": "kUveo5k1GF", "forum": "kUveo5k1GF", "number": 5357, "cdate": 1695383712941, "tcdate": 1695383712941, "mdate": 1709661520157, "tmdate": 1709661520157, "signatures": ["ICLR.cc/2024/Conference/Submission5357/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5357/Authors"], "content": {"title": {"value": "Improving equilibrium propagation without weight symmetry through Jacobian homeostasis"}, "authors": {"value": ["Axel Laborieux", "Friedemann Zenke"]}, "authorids": {"value": ["~Axel_Laborieux1", "~Friedemann_Zenke1"]}, "keywords": {"value": ["Equilibrium propagation", "local learning", "weight transport", "jacobian regularization"]}, "TLDR": {"value": "We disentangle the impacts of weight asymmetry and finite nudge on the learning performance generalized equilibrium propagation, and propose a new homeostatic objective to recover good performance."}, "abstract": {"value": "Equilibrium propagation (EP) is a compelling alternative to the back propagation of error algorithm (BP) for computing gradients of neural networks on biological or analog neuromorphic substrates. \nStill, the algorithm requires weight symmetry and infinitesimal equilibrium perturbations, i.e., nudges, to yield unbiased gradient estimates.\nBoth requirements are challenging to implement in physical systems.\nYet, whether and how weight asymmetry contributes to bias is unknown because, in practice, its contribution may be masked by a finite nudge. \nTo address this question, we study generalized EP, which can be formulated without weight symmetry, and analytically isolate the two sources of bias.\nFor complex-differentiable non-symmetric networks, we show that bias due to finite nudge can be avoided by estimating exact derivatives via a Cauchy integral.\nIn contrast, weight asymmetry induces residual bias  through poor alignment of EP's neuronal error vectors compared to BP resulting in low task performance.\nTo mitigate the latter issue, we present a new homeostatic objective that directly penalizes functional asymmetries of the Jacobian at the network's fixed point. \nThis homeostatic objective dramatically improves the network's ability to solve complex tasks such as ImageNet 32$\\times$32. \nOur results lay the theoretical groundwork for studying and mitigating the adverse effects of imperfections of physical networks on learning algorithms that rely on the substrate's relaxation dynamics."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e72f7aa53b3ec19eed45bd805a6f413f02dc63cb.pdf"}, "supplementary_material": {"value": "/attachment/a2f72c4e65f9e3c90a0b752527ad6ff0dee0fe2c.zip"}, "_bibtex": {"value": "@inproceedings{\nlaborieux2024improving,\ntitle={Improving equilibrium propagation without weight symmetry through Jacobian homeostasis},\nauthor={Axel Laborieux and Friedemann Zenke},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=kUveo5k1GF}\n}"}, "paperhash": {"value": "laborieux|improving_equilibrium_propagation_without_weight_symmetry_through_jacobian_homeostasis"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5357/-/Revision", "ICLR.cc/2024/Conference/Submission5357/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5357/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410936048, "version": 2}, {"id": "EGQBpkIEuu", "forum": "EGQBpkIEuu", "number": 5345, "cdate": 1695383125060, "tcdate": 1695383125060, "mdate": 1709661520076, "tmdate": 1709661520076, "signatures": ["ICLR.cc/2024/Conference/Submission5345/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5345/Authors"], "content": {"title": {"value": "Revisiting Data Augmentation in Deep Reinforcement Learning"}, "authors": {"value": ["Jianshu Hu", "Yunpeng Jiang", "Paul Weng"]}, "authorids": {"value": ["~Jianshu_Hu1", "~Yunpeng_Jiang1", "~Paul_Weng1"]}, "keywords": {"value": ["Reinforcement Learning", "Data Augmentation"]}, "abstract": {"value": "Various data augmentation techniques have been recently proposed in image-based deep reinforcement learning (DRL).\nAlthough they empirically demonstrate the effectiveness of data augmentation for improving sample efficiency or generalization, which technique should be preferred is not always clear. \nTo tackle this question, we analyze existing methods to better understand them and to uncover how they are connected.\nNotably, by expressing the variance of the Q-targets and that of the empirical actor/critic losses of these methods, we can analyze the effects of their different components and compare them.\nWe furthermore formulate an explanation about how these methods may be affected by choosing different data augmentation transformations in calculating the target Q-values.\nThis analysis suggests recommendations on how to exploit data augmentation in a more principled way.\nIn addition, we include a regularization term called tangent prop, previously proposed in computer vision, but whose adaptation to DRL is novel to the best of our knowledge.\nWe evaluate our proposition and validate our analysis in several domains. \nCompared to different relevant baselines,  we demonstrate that it achieves state-of-the-art performance in most environments and shows higher sample efficiency and better generalization ability in some complex environments."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/611a2c3da65a860fbb988116e285d6d6c8e11063.pdf"}, "supplementary_material": {"value": "/attachment/c54bf936dad832a2eff4357cbba2b0296f985823.zip"}, "_bibtex": {"value": "@inproceedings{\nhu2024revisiting,\ntitle={Revisiting Data Augmentation in Deep Reinforcement Learning},\nauthor={Jianshu Hu and Yunpeng Jiang and Paul Weng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EGQBpkIEuu}\n}"}, "paperhash": {"value": "hu|revisiting_data_augmentation_in_deep_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5345/-/Revision", "ICLR.cc/2024/Conference/Submission5345/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5345/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935627, "version": 2}, {"id": "TKnzPdyeJu", "forum": "TKnzPdyeJu", "number": 5343, "cdate": 1695383037984, "tcdate": 1695383037984, "mdate": 1709775812939, "tmdate": 1709775812939, "signatures": ["ICLR.cc/2024/Conference/Submission5343/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5343/Authors"], "content": {"title": {"value": "Structural Inference with Dynamics Encoding and Partial Correlation Coefficients"}, "authors": {"value": ["Aoran Wang", "Jun Pang"]}, "authorids": {"value": ["~Aoran_Wang1", "~Jun_Pang1"]}, "keywords": {"value": ["Structural Inference", "AI4Science"]}, "abstract": {"value": "This paper introduces a novel approach to structural inference, combining a variational dynamics encoder with partial correlation coefficients. \nIn contrast to prior methods, our approach leverages variational inference to encode node dynamics within latent variables, and structural reconstruction relies on the calculation of partial correlation coefficients derived from these latent variables.\nThis unique design endows our method with scalability and extends its applicability to both one-dimensional and multi-dimensional feature spaces.\nFurthermore, by reorganizing latent variables according to temporal steps, our approach can effectively reconstruct directed graph structures. \nWe validate our method through extensive experimentation on twenty datasets from a benchmark dataset and biological networks. \nOur results showcase the superior scalability, accuracy, and versatility of our proposed approach compared to existing methods.\nMoreover, experiments conducted on noisy data affirm the robustness of our method."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/316292652516a05639e43077d3b3f83ad420f926.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024structural,\ntitle={Structural Inference with Dynamics Encoding and Partial Correlation Coefficients},\nauthor={Aoran Wang and Jun Pang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TKnzPdyeJu}\n}"}, "paperhash": {"value": "wang|structural_inference_with_dynamics_encoding_and_partial_correlation_coefficients"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5343/-/Revision", "ICLR.cc/2024/Conference/Submission5343/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5343/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935462, "version": 2}, {"id": "Djw0XhjHZb", "forum": "Djw0XhjHZb", "number": 5340, "cdate": 1695382852082, "tcdate": 1695382852082, "mdate": 1710395181337, "tmdate": 1710395181337, "signatures": ["ICLR.cc/2024/Conference/Submission5340/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5340/Authors"], "content": {"title": {"value": "Simplicial Representation Learning with Neural $k$-Forms"}, "authors": {"value": ["Kelly Maggs", "Celia Hacker", "Bastian Rieck"]}, "authorids": {"value": ["~Kelly_Maggs1", "~Celia_Hacker1", "~Bastian_Rieck1"]}, "keywords": {"value": ["geometric deep learning", "differential forms", "representation learning", "graph learning", "geometry", "topology"]}, "TLDR": {"value": "We learn differential $k$-forms on embedded graphs, leveraging a connection to singular cochains to obtain efficient, interpretable representations."}, "abstract": {"value": "Geometric deep learning extends deep learning to incorporate information about the geometry and topology data, especially in complex domains like graphs. Despite the popularity of message passing in this field, it has limitations such as the need for graph rewiring, ambiguity in interpreting data, and over-smoothing. In this paper, we take a different approach, focusing on leveraging geometric information from simplicial complexes embedded in $\\mathbb{R}^n$ using node coordinates. We use differential $k$-forms in $\\mathbb{R}^n$ to create representations of simplices, offering interpretability and geometric consistency without message passing. This approach also enables us to apply differential geometry tools and achieve universal approximation. Our method is efficient, versatile, and applicable to various input complexes, including graphs, simplicial complexes, and cell complexes. It outperforms existing message passing neural networks in harnessing information from geometrical graphs with node features serving as coordinates."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/09536d303a7f5b86bdae3f3e16a185c2eb2368ae.pdf"}, "_bibtex": {"value": "@inproceedings{\nmaggs2024simplicial,\ntitle={Simplicial Representation Learning with Neural \\$k\\$-Forms},\nauthor={Kelly Maggs and Celia Hacker and Bastian Rieck},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Djw0XhjHZb}\n}"}, "paperhash": {"value": "maggs|simplicial_representation_learning_with_neural_kforms"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5340/-/Revision", "ICLR.cc/2024/Conference/Submission5340/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5340/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935348, "version": 2}, {"id": "cVUOnF7iVp", "forum": "cVUOnF7iVp", "number": 5338, "cdate": 1695382689994, "tcdate": 1695382689994, "mdate": 1710849261665, "tmdate": 1710849261665, "signatures": ["ICLR.cc/2024/Conference/Submission5338/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5338/Authors"], "content": {"title": {"value": "Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model"}, "authors": {"value": ["Liyang Zhu", "Meng Ding", "Vaneet Aggarwal", "Jinhui Xu", "Di Wang"]}, "authorids": {"value": ["~Liyang_Zhu1", "~Meng_Ding3", "~Vaneet_Aggarwal1", "~Jinhui_Xu1", "~Di_Wang1"]}, "keywords": {"value": ["local differential privacy; linear regression"]}, "abstract": {"value": "In this paper, we revisit \nthe problem of sparse linear regression in the local differential privacy (LDP) model. Existing research in the non-interactive and sequentially local models has focused on obtaining the lower bounds for the case where the underlying parameter is $1$-sparse, and extending such bounds to the more general $k$-sparse case has proven to be challenging. Moreover, it is unclear whether efficient non-interactive LDP (NLDP) algorithms exist. To address these issues, \nwe  first consider the problem in the $\\epsilon$ non-interactive LDP model and provide a lower bound of $\\Omega(\\frac{\\sqrt{dk\\log d}}{\\sqrt{n}\\epsilon})$ on the $\\ell_2$-norm estimation error for sub-Gaussian data, where $n$ is the sample size and $d$ is the dimension of the space. \nWe propose an innovative NLDP algorithm, the very first of its kind for the problem. As a remarkable outcome, this algorithm also yields a novel and highly efficient estimator as a valuable by-product. Our algorithm achieves an upper bound of $\\tilde{O}({\\frac{d\\sqrt{k}}{\\sqrt{n}\\epsilon}})$ for the estimation error when the data is sub-Gaussian, which can be further improved by a factor of  $O(\\sqrt{d})$ if the server has additional public but unlabeled data. \nFor the sequentially interactive LDP model, we show a similar lower bound of $\\Omega({\\frac{\\sqrt{dk}}{\\sqrt{n}\\epsilon}})$. As for the upper bound, we rectify a previous method and show that it is possible to achieve a bound of $\\tilde{O}(\\frac{k\\sqrt{d}}{\\sqrt{n}\\epsilon})$. Our findings reveal fundamental differences between the non-private case, central DP model, and local DP model in the sparse linear regression problem."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2ef835fc18acba464913dd9598ca8a61e6cd6ca4.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhu2024improved,\ntitle={Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model},\nauthor={Liyang Zhu and Meng Ding and Vaneet Aggarwal and Jinhui Xu and Di Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cVUOnF7iVp}\n}"}, "paperhash": {"value": "zhu|improved_analysis_of_sparse_linear_regression_in_local_differential_privacy_model"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5338/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5338/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935312, "version": 2}, {"id": "NzxCMe88HX", "forum": "NzxCMe88HX", "number": 5336, "cdate": 1695382558040, "tcdate": 1695382558040, "mdate": 1711147317025, "tmdate": 1711147317025, "signatures": ["ICLR.cc/2024/Conference/Submission5336/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5336/Authors"], "content": {"title": {"value": "Toward effective protection against diffusion-based mimicry through score distillation"}, "authors": {"value": ["Haotian Xue", "Chumeng Liang", "Xiaoyu Wu", "Yongxin Chen"]}, "authorids": {"value": ["~Haotian_Xue1", "~Chumeng_Liang1", "~Xiaoyu_Wu1", "~Yongxin_Chen1"]}, "keywords": {"value": ["Diffusion models", "safety", "protection"]}, "abstract": {"value": "While generative diffusion models excel in producing high-quality images, they can also be misused to mimic authorized images, posing a significant threat to AI systems. Efforts have been made to add calibrated perturbations to protect images from diffusion-based mimicry pipelines. However, most of the existing methods are too ineffective and even impractical to be used by individual users due to their high computation and memory requirements. In this work, we present novel findings on attacking latent diffusion models (LDM) and propose new plug-and-play strategies for more effective protection. In particular, we explore the bottleneck in attacking an LDM, discovering that the encoder module rather than the denoiser module is the vulnerable point. Based on this insight, we present our strategy using Score Distillation Sampling (SDS) to double the speed of protection and reduce memory occupation by half without compromising its strength. Additionally, we provide a robust protection strategy by counterintuitively minimizing the semantic loss, which can assist in generating more natural perturbations. Finally, we conduct extensive experiments to substantiate our findings and comprehensively evaluate our newly proposed strategies. We hope our insights and protective measures can contribute to better defense against malicious diffusion-based mimicry, advancing the development of secure AI systems."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bc53ac8cfa9feb2de3a27869ad87ac6c47250b1c.pdf"}, "supplementary_material": {"value": "/attachment/18ce6089e8883338b99f7a18caddc9c93f8027ba.zip"}, "_bibtex": {"value": "@inproceedings{\nxue2024toward,\ntitle={Toward effective protection against diffusion-based mimicry through score distillation},\nauthor={Haotian Xue and Chumeng Liang and Xiaoyu Wu and Yongxin Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NzxCMe88HX}\n}"}, "paperhash": {"value": "xue|toward_effective_protection_against_diffusionbased_mimicry_through_score_distillation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5336/-/Revision", "ICLR.cc/2024/Conference/Submission5336/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5336/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935281, "version": 2}, {"id": "LqaEEs3UxU", "forum": "LqaEEs3UxU", "number": 5333, "cdate": 1695382411610, "tcdate": 1695382411610, "mdate": 1709661519802, "tmdate": 1709661519802, "signatures": ["ICLR.cc/2024/Conference/Submission5333/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5333/Authors"], "content": {"title": {"value": "Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation"}, "authors": {"value": ["Ryan Wong", "Necati Cihan Camgoz", "Richard Bowden"]}, "authorids": {"value": ["~Ryan_Wong1", "~Necati_Cihan_Camgoz2", "~Richard_Bowden1"]}, "keywords": {"value": ["sign language translation", "sign recognition", "large language models"]}, "abstract": {"value": "Automatic Sign Language Translation requires the integration of both computer vision and natural language processing to effectively bridge the communication gap between sign and spoken languages. However, the deficiency in large-scale training data to support sign language translation means we need to leverage resources from spoken language. We introduce, Sign2GPT, a novel framework for sign language translation that utilizes large-scale pretrained vision and language models via lightweight adapters for gloss-free sign language translation. The lightweight adapters are crucial for sign language translation, due to the constraints imposed by limited dataset sizes and the computational requirements when training with long sign videos.\nWe also propose a novel pretraining strategy that directs our encoder to learn sign representations from automatically extracted pseudo-glosses without requiring gloss order information or annotations.\nWe evaluate our approach on two public benchmark sign language translation datasets, namely RWTH-PHOENIX-Weather 2014T and CSL-Daily, and improve on state-of-the-art gloss-free translation performance with a significant margin."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/776e978ceae8f17f964f4db527572ebf547ae1b1.pdf"}, "_bibtex": {"value": "@inproceedings{\nwong2024signgpt,\ntitle={Sign2{GPT}: Leveraging Large Language Models for Gloss-Free Sign Language Translation},\nauthor={Ryan Wong and Necati Cihan Camgoz and Richard Bowden},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LqaEEs3UxU}\n}"}, "paperhash": {"value": "wong|sign2gpt_leveraging_large_language_models_for_glossfree_sign_language_translation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5333/-/Revision", "ICLR.cc/2024/Conference/Submission5333/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5333/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935198, "version": 2}, {"id": "7wY67ZDQTE", "forum": "7wY67ZDQTE", "number": 5330, "cdate": 1695382209055, "tcdate": 1695382209055, "mdate": 1710442877400, "tmdate": 1710442877400, "signatures": ["ICLR.cc/2024/Conference/Submission5330/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5330/Authors"], "content": {"title": {"value": "Cauchy-Schwarz Divergence Information Bottleneck for Regression"}, "authors": {"value": ["Shujian Yu", "Xi Yu", "Sigurd L\u00f8kse", "Robert Jenssen", "Jose C Principe"]}, "authorids": {"value": ["~Shujian_Yu1", "~Xi_Yu1", "~Sigurd_L\u00f8kse1", "~Robert_Jenssen1", "~Jose_C_Principe1"]}, "keywords": {"value": ["Information Bottleneck", "Cauchy-Schwarz Divergence", "Regression"]}, "TLDR": {"value": "We study the IB principle for the regression problem and develop a new way to parameterize the IB with deep neural networks by exploiting favorable properties of the Cauchy-Scwarz (CS) divergence."}, "abstract": {"value": "The information bottleneck (IB) approach is popular to improve the generalization, robustness and explainability of deep neural networks. Essentially, it aims to find a minimum sufficient representation $\\mathbf{t}$ by striking a trade-off between a compression term $I(\\mathbf{x};\\mathbf{t})$ and a prediction term $I(y;\\mathbf{t})$, where $I(\\cdot;\\cdot)$ refers to the mutual information (MI). MI is for the IB for the most part expressed in terms of the Kullback-Leibler (KL) divergence, which in the regression case corresponds to prediction based on mean squared error (MSE) loss with Gaussian assumption and compression approximated by variational inference. \nIn this paper, we study the IB principle for the regression problem and develop a new way to parameterize the IB with deep neural networks by exploiting favorable properties of the Cauchy-Schwarz (CS) divergence. By doing so, we move away from MSE-based regression and ease estimation by avoiding variational approximations or distributional assumptions. We investigate the improved generalization ability of our proposed CS-IB and demonstrate strong adversarial robustness guarantees. We demonstrate its superior performance on six real-world regression tasks over other popular deep IB approaches. We additionally observe that the solutions discovered by CS-IB always achieve the best trade-off between prediction accuracy and compression ratio in the information plane. The code is available at \\url{https://github.com/SJYuCNEL/Cauchy-Schwarz-Information-Bottleneck}."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d8060f3cb1f682e6dea512d13dc1385d8328e9c3.pdf"}, "supplementary_material": {"value": "/attachment/f2602b561c7a9045ae501b67e9061b0c34bdb59b.zip"}, "_bibtex": {"value": "@inproceedings{\nyu2024cauchyschwarz,\ntitle={Cauchy-Schwarz Divergence Information Bottleneck for Regression},\nauthor={Shujian Yu and Xi Yu and Sigurd L{\\o}kse and Robert Jenssen and Jose C Principe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7wY67ZDQTE}\n}"}, "paperhash": {"value": "yu|cauchyschwarz_divergence_information_bottleneck_for_regression"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5330/-/Revision", "ICLR.cc/2024/Conference/Submission5330/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5330/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410935100, "version": 2}, {"id": "14rn7HpKVk", "forum": "14rn7HpKVk", "number": 5325, "cdate": 1695381949541, "tcdate": 1695381949541, "mdate": 1712661708670, "tmdate": 1712661708670, "signatures": ["ICLR.cc/2024/Conference/Submission5325/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5325/Authors"], "content": {"title": {"value": "SALMONN: Towards Generic Hearing Abilities for Large Language Models"}, "authors": {"value": ["Changli Tang", "Wenyi Yu", "Guangzhi Sun", "Xianzhao Chen", "Tian Tan", "Wei Li", "Lu Lu", "Zejun MA", "Chao Zhang"]}, "authorids": {"value": ["~Changli_Tang1", "~Wenyi_Yu2", "~Guangzhi_Sun1", "~Xianzhao_Chen1", "~Tian_Tan5", "~Wei_Li78", "~Lu_Lu6", "~Zejun_MA1", "~Chao_Zhang20"]}, "keywords": {"value": ["Multimodal large language models", "speech and audio processing", "music processing"]}, "TLDR": {"value": "SALMONN: Towards Generic Hearing Abilities for Large Language Models"}, "abstract": {"value": "Hearing is arguably an essential ability of artificial intelligence (AI) agents in the physical world, which refers to the perception and understanding of general auditory information consisting of at least three types of sounds: speech, audio events, and music. In this paper, we propose SALMONN, a speech audio language music open neural network, built by integrating a pre-trained text-based large language model (LLM) with speech and audio encoders into a single multimodal model. SALMONN enables the LLM to directly process and understand general audio inputs and achieve competitive performances on a number of speech and audio tasks used in training, such as \nautomatic speech recognition and translation, auditory-information-based question answering, emotion recognition, speaker verification, and music and audio captioning etc. SALMONN also has a diverse set of emergent abilities unseen in the training, which includes but is not limited to speech translation to untrained languages, speech-based slot filling, spoken-query-based question answering, audio-based storytelling, and speech audio co-reasoning etc. The presence of cross-modal emergent abilities is studied, and a novel few-shot activation tuning approach is proposed to activate such abilities. To our knowledge, SALMONN is the first model of its type and can be regarded as a step towards AI with generic hearing abilities. The source code, model checkpoints and data are available at https://github.com/bytedance/SALMONN."}, "pdf": {"value": "/pdf/d5a232debec14724cfe9fcabdbebc192eb470ba3.pdf"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\ntang2024salmonn,\ntitle={{SALMONN}: Towards Generic Hearing Abilities for Large Language Models},\nauthor={Changli Tang and Wenyi Yu and Guangzhi Sun and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun MA and Chao Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=14rn7HpKVk}\n}"}, "paperhash": {"value": "tang|salmonn_towards_generic_hearing_abilities_for_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5325/-/Revision", "ICLR.cc/2024/Conference/Submission5325/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5325/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410934975, "version": 2}, {"id": "ZzmKEpze8e", "forum": "ZzmKEpze8e", "number": 5320, "cdate": 1695381642720, "tcdate": 1695381642720, "mdate": 1710520784159, "tmdate": 1710520784159, "signatures": ["ICLR.cc/2024/Conference/Submission5320/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5320/Authors"], "content": {"title": {"value": "Kalman Filter for Online Classification of Non-Stationary Data"}, "authors": {"value": ["Michalis Titsias", "Alexandre Galashov", "Amal Rannen-Triki", "Razvan Pascanu", "Yee Whye Teh", "Jorg Bornschein"]}, "authorids": {"value": ["~Michalis_Titsias1", "~Alexandre_Galashov1", "~Amal_Rannen-Triki1", "~Razvan_Pascanu1", "~Yee_Whye_Teh2", "~Jorg_Bornschein1"]}, "keywords": {"value": ["online learning", "non-stationarity", "Kalman filter", "continual learning", "probabilistic modellling"]}, "TLDR": {"value": "Kalman Filter based method applied to non-stationary classification problems with strong empirical performance"}, "abstract": {"value": "In Online Continual Learning (OCL) a learning system receives a stream of data and sequentially performs prediction and training steps. Key challenges in OCL include automatic adaptation to the specific non-stationary structure of the data and maintaining appropriate  predictive uncertainty.  To address these challenges we introduce a probabilistic Bayesian online learning approach that utilizes a (possibly pretrained) neural representation and a state space model over the linear predictor weights. Non-stationarity in the linear predictor weights is modelled using a \u201cparameter drift\u201d transition density, parametrized by a coefficient that quantifies forgetting. Inference in the model is implemented with efficient Kalman filter recursions which track the posterior distribution over the linear weights, while online SGD updates over the transition dynamics coefficient allow for adaptation to the non-stationarity observed in the data. While the framework is developed assuming a linear Gaussian model, we extend it to deal with classification problems and for fine-tuning the deep learning representation. In a set of experiments in multi-class classification using data sets such as CIFAR-100 and CLOC we demonstrate the model's predictive ability and its flexibility in capturing non-stationarity."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4df96ac97246e203e693d4eb98bc93311a109363.pdf"}, "_bibtex": {"value": "@inproceedings{\ntitsias2024kalman,\ntitle={Kalman Filter Online Learning from non-Stationary Data},\nauthor={Michalis Titsias and Alexandre Galashov and Amal Rannen-Triki and Razvan Pascanu and Yee Whye Teh and Jorg Bornschein},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZzmKEpze8e}\n}"}, "paperhash": {"value": "titsias|kalman_filter_for_online_classification_of_nonstationary_data"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5320/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5320/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410934836, "version": 2}, {"id": "oYjPk8mqAV", "forum": "oYjPk8mqAV", "number": 5319, "cdate": 1695381595936, "tcdate": 1695381595936, "mdate": 1710511232019, "tmdate": 1710511232019, "signatures": ["ICLR.cc/2024/Conference/Submission5319/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5319/Authors"], "content": {"title": {"value": "Magnushammer: A Transformer-Based Approach to Premise Selection"}, "authors": {"value": ["Maciej Miku\u0142a", "Szymon Tworkowski", "Szymon Antoniak", "Bartosz Piotrowski", "Albert Q. Jiang", "Jin Peng Zhou", "Christian Szegedy", "\u0141ukasz Kuci\u0144ski", "Piotr Mi\u0142o\u015b", "Yuhuai Wu"]}, "authorids": {"value": ["~Maciej_Miku\u0142a1", "~Szymon_Tworkowski1", "~Szymon_Antoniak1", "~Bartosz_Piotrowski1", "~Albert_Q._Jiang1", "~Jin_Peng_Zhou1", "~Christian_Szegedy1", "~\u0141ukasz_Kuci\u0144ski1", "~Piotr_Mi\u0142o\u015b1", "~Yuhuai_Wu1"]}, "keywords": {"value": ["transformers", "interactive theorem proving", "automated reasoning", "contrastive learning", "premise selection"]}, "TLDR": {"value": "Contrastively trained transformers outperform state-of-the-art symbolic methods for premise selection, a challenging reasoning task of selecting relevant facts for proving new theorems in formal mathematics."}, "abstract": {"value": "This paper presents a novel approach to premise selection, a crucial reasoning task in automated theorem proving. Traditionally, symbolic methods that rely on extensive domain knowledge and engineering effort are applied to this task. In contrast, this work demonstrates that contrastive training with the transformer architecture can achieve higher-quality retrieval of relevant premises, without the knowledge or feature engineering overhead. Our method, Magnushammer, outperforms the most advanced and widely used automation tool in interactive theorem proving called Sledgehammer. On the PISA and miniF2f benchmarks Magnushammer achieves $59.5\\%$ (against $38.3\\%$) and $34.0\\%$ (against $20.9\\%$) success rates, respectively. By combining Magnushammer with a language-model-based automated theorem prover, we further improve the state-of-the-art proof success rate from $57.0\\%$ to $71.0\\%$ on the PISA benchmark using $4$x fewer parameters. Moreover, we develop and open source a novel dataset for premise selection, containing textual representations of (proof state, relevant premise) pairs. To the best of our knowledge, this is the largest available premise selection dataset, and the first dataset of this kind for the Isabelle proof assistant."}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/baebbf44ed0907d09bf230f239aa5b07e0ebbda7.pdf"}, "_bibtex": {"value": "@inproceedings{\nmiku{\\l}a2024magnushammer,\ntitle={Magnushammer: A Transformer-Based Approach to Premise Selection},\nauthor={Maciej Miku{\\l}a and Szymon Tworkowski and Szymon Antoniak and Bartosz Piotrowski and Albert Q. Jiang and Jin Peng Zhou and Christian Szegedy and {\\L}ukasz Kuci{\\'n}ski and Piotr Mi{\\l}o{\\'s} and Yuhuai Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oYjPk8mqAV}\n}"}, "paperhash": {"value": "mikua|magnushammer_a_transformerbased_approach_to_premise_selection"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5319/-/Revision", "ICLR.cc/2024/Conference/Submission5319/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5319/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410934834, "version": 2}, {"id": "HT2dAhh4uV", "forum": "HT2dAhh4uV", "number": 5301, "cdate": 1695381092869, "tcdate": 1695381092869, "mdate": 1710494411970, "tmdate": 1710494411970, "signatures": ["ICLR.cc/2024/Conference/Submission5301/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5301/Authors"], "content": {"title": {"value": "Learning to Compose: Improving Object Centric Learning by Injecting Compositionality"}, "authors": {"value": ["Whie Jung", "Jaehoon Yoo", "Sungjin Ahn", "Seunghoon Hong"]}, "authorids": {"value": ["~Whie_Jung1", "~Jaehoon_Yoo1", "~Sungjin_Ahn1", "~Seunghoon_Hong2"]}, "keywords": {"value": ["Object-Centric learning", "Compositionality"]}, "abstract": {"value": "Learning compositional representation is a key aspect of object-centric learning as it enables flexible systematic generalization and supports complex visual reasoning. However, most of the existing approaches rely on auto-encoding objective, while the compositionality is implicitly imposed by the architectural or algorithmic bias in the encoder. This misalignment between auto-encoding objective and learning compositionality often results in failure of capturing meaningful object representations. In this study, we propose a novel objective that explicitly encourages compositionality of the representations. Built upon the existing object-centric learning framework (e.g., slot attention), our method incorporates additional constraints that an arbitrary mixture of object representations from two images should be valid by maximizing the likelihood of the composite data. We demonstrate that incorporating our objective to the existing framework consistently improves the objective-centric learning and enhances the robustness to the architectural choices."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f32ea9834654f19b37e6e1d70d34596517203121.pdf"}, "TLDR": {"value": "We propose a novel objective that explicitly encourages compositionality of the representations."}, "_bibtex": {"value": "@inproceedings{\njung2024learning,\ntitle={Learning to Compose: Improving Object Centric Learning by Injecting Compositionality},\nauthor={Whie Jung and Jaehoon Yoo and Sungjin Ahn and Seunghoon Hong},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HT2dAhh4uV}\n}"}, "paperhash": {"value": "jung|learning_to_compose_improving_object_centric_learning_by_injecting_compositionality"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5301/-/Revision", "ICLR.cc/2024/Conference/Submission5301/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5301/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410934116, "version": 2}, {"id": "WhZoCLRWYJ", "forum": "WhZoCLRWYJ", "number": 5284, "cdate": 1695380270626, "tcdate": 1695380270626, "mdate": 1710759266997, "tmdate": 1710759266997, "signatures": ["ICLR.cc/2024/Conference/Submission5284/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5284/Authors"], "content": {"title": {"value": "Light Schr\u00f6dinger Bridge"}, "authors": {"value": ["Alexander Korotin", "Nikita Gushchin", "Evgeny Burnaev"]}, "authorids": {"value": ["~Alexander_Korotin2", "~Nikita_Gushchin1", "~Evgeny_Burnaev1"]}, "keywords": {"value": ["Schr\u00f6dinger Bridge", "Optimal transport", "Entropy regularized OT", "Unpaired Learning"]}, "abstract": {"value": "Despite the recent advances in the field of computational Schr\u00f6dinger Bridges (SB), most existing SB solvers are still heavy-weighted and require complex optimization of several neural networks. It turns out that there is no principal solver which plays the role of simple-yet-effective baseline for SB just like, e.g., $k$-means method in clustering, logistic regression in classification or Sinkhorn algorithm in discrete optimal transport. We address this issue and propose a novel fast and simple SB solver. Our development is a smart combination of two ideas which recently appeared in the field: (a) parameterization of the Schr\u00f6dinger potentials with sum-exp quadratic functions and (b) viewing the log-Schr\u00f6dinger potentials as the energy functions. We show that combined together these ideas yield a lightweight, simulation-free and theoretically justified SB solver with a simple straightforward optimization objective. As a result, it allows solving SB in moderate dimensions in a matter of minutes on CPU without a painful hyperparameter selection. Our light solver resembles the Gaussian mixture model which is widely used for density estimation. Inspired by this similarity, we also prove an important theoretical result showing that our light solver is a universal approximator of SBs. Furthemore, we conduct the analysis of the generalization error of our light solver. The code for our solver can be found at https://github.com/ngushchin/LightSB."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/163590fcf0a6ff88b61dbe25f44ea417e9b88566.pdf"}, "supplementary_material": {"value": "/attachment/2ed66ea711c20cda7bcea0c164a3e74c16ea1eb8.zip"}, "_bibtex": {"value": "@inproceedings{\nkorotin2024light,\ntitle={Light Schr\\\"odinger Bridge},\nauthor={Alexander Korotin and Nikita Gushchin and Evgeny Burnaev},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WhZoCLRWYJ}\n}"}, "paperhash": {"value": "korotin|light_schr\u00f6dinger_bridge"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5284/-/Revision", "ICLR.cc/2024/Conference/Submission5284/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5284/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410933696, "version": 2}, {"id": "eCGpNGDeNu", "forum": "eCGpNGDeNu", "number": 5280, "cdate": 1695379918356, "tcdate": 1695379918356, "mdate": 1710083729395, "tmdate": 1710083729395, "signatures": ["ICLR.cc/2024/Conference/Submission5280/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5280/Authors"], "content": {"title": {"value": "Reward-Free Curricula for Training Robust World Models"}, "authors": {"value": ["Marc Rigter", "Minqi Jiang", "Ingmar Posner"]}, "authorids": {"value": ["~Marc_Rigter1", "~Minqi_Jiang1", "~Ingmar_Posner1"]}, "keywords": {"value": ["curricula", "model-based reinforcement learning", "world models", "reward-free reinforcement learning", "robustness", "unsupervised environment design"]}, "TLDR": {"value": "Curricula for reward-free learning of world models across variable environments."}, "abstract": {"value": "There has been a recent surge of interest in developing generally-capable agents that can adapt to new tasks without additional training in the environment. Learning world models from reward-free exploration is a promising approach, and enables policies to be trained using imagined experience for new tasks. However, achieving a general agent requires robustness across different environments. In this work, we address the novel problem of generating curricula in the reward-free setting to train robust world models. We consider robustness in terms of minimax regret over all environment instantiations and show that the minimax regret can be connected to minimising the maximum error in the world model across environment instances. This result informs our algorithm, WAKER: Weighted Acquisition of Knowledge across Environments for Robustness. WAKER selects environments for data collection based on the estimated error of the world model for each environment. Our experiments demonstrate that WAKER outperforms na\u0131\u0308ve domain randomisation, resulting in improved robustness, efficiency, and generalisation."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c5b31ff9ad250e1f7d295319b9801bc469d96da6.pdf"}, "_bibtex": {"value": "@inproceedings{\nrigter2024rewardfree,\ntitle={Reward-Free Curricula for Training Robust World Models},\nauthor={Marc Rigter and Minqi Jiang and Ingmar Posner},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eCGpNGDeNu}\n}"}, "paperhash": {"value": "rigter|rewardfree_curricula_for_training_robust_world_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5280/-/Revision", "ICLR.cc/2024/Conference/Submission5280/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5280/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410933468, "version": 2}, {"id": "7UhxsmbdaQ", "forum": "7UhxsmbdaQ", "number": 5278, "cdate": 1695379858722, "tcdate": 1695379858722, "mdate": 1709661519362, "tmdate": 1709661519362, "signatures": ["ICLR.cc/2024/Conference/Submission5278/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5278/Authors"], "content": {"title": {"value": "Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design"}, "authors": {"value": ["Jeff Guo", "Philippe Schwaller"]}, "authorids": {"value": ["~Jeff_Guo1", "~Philippe_Schwaller1"]}, "keywords": {"value": ["Molecular generative models", "reinforcement learning", "natural language processing", "drug discovery", "sample-efficiency", "explainability"]}, "TLDR": {"value": "novel algorithm to extract molecular substructures from language-based molecular generative models to jointly address explainability and sample efficiency."}, "abstract": {"value": "Generative molecular design has moved from proof-of-concept to real-world applicability, as marked by the surge in very recent papers reporting experimental validation. Key challenges in explainability and sample efficiency present opportunities to enhance generative design to directly optimize expensive high-fidelity oracles and provide actionable insights to domain experts. Here, we propose Beam Enumeration to exhaustively enumerate the most probable sub-sequences from language-based molecular generative models and show that molecular substructures can be extracted. When coupled with reinforcement learning, extracted substructures become meaningful, providing a source of explainability and improving sample efficiency through self-conditioned generation. Beam Enumeration is generally applicable to any language-based molecular generative model and notably further improves the performance of the recently reported Augmented Memory algorithm, which achieved the new state-of-the-art on the Practical Molecular Optimization benchmark for sample efficiency. The combined algorithm generates more high reward molecules and faster, given a fixed oracle budget. Beam Enumeration shows that improvements to explainability and sample efficiency for molecular design can be made synergistic."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/332d5b42548ce48463df95f3409c24adec810308.pdf"}, "_bibtex": {"value": "@inproceedings{\nguo2024beam,\ntitle={Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design},\nauthor={Jeff Guo and Philippe Schwaller},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7UhxsmbdaQ}\n}"}, "paperhash": {"value": "guo|beam_enumeration_probabilistic_explainability_for_sample_efficient_selfconditioned_molecular_design"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5278/-/Revision", "ICLR.cc/2024/Conference/Submission5278/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5278/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410933439, "version": 2}, {"id": "nsNyDvNQTc", "forum": "nsNyDvNQTc", "number": 5267, "cdate": 1695379135890, "tcdate": 1695379135890, "mdate": 1710589483680, "tmdate": 1710589483680, "signatures": ["ICLR.cc/2024/Conference/Submission5267/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5267/Authors"], "content": {"title": {"value": "Leveraging Uncertainty Estimates To Improve Classifier Performance"}, "authors": {"value": ["Gundeep Arora", "Srujana Merugu", "Anoop Saladi", "Rajeev Rastogi"]}, "authorids": {"value": ["~Gundeep_Arora1", "~Srujana_Merugu2", "~Anoop_Saladi1", "~Rajeev_Rastogi2"]}, "keywords": {"value": ["Uncertainty estimation", "binary classification", "imbalanced classification", "score recalibration", "uncertainty based decision making", "classification decision boundary", "bin packing", "estimation bias", "posterior networks"]}, "TLDR": {"value": "2D decision boundary on model score & uncertainty space boosts binary classification performance"}, "abstract": {"value": "Binary classification typically involves predicting the label of an instance based on whether the model score for the positive class exceeds a threshold chosen based on the application requirements (e.g., maximizing recall for a precision bound). However, model scores are often not aligned with true positivity rate. This is especially true when the training involves a differential sampling of classes or there is distributional drift between train and test settings. In this paper, we provide theoretical analysis and empirical evidence of the dependence of estimation bias on both uncertainty and model score. Further, we  formulate the decision boundary selection using both model score and uncertainty, prove that it is NP-hard, and present  algorithms  based on dynamic programming and isotonic regression.  Evaluation of the proposed algorithms on three real-world datasets yield  25\\%-40\\%  improvement in recall at high precision bounds over the traditional approach of using model score alone, highlighting the benefits of leveraging uncertainty."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3bb77982d318ab68d64c9400ec10f25c4cd5ac82.pdf"}, "_bibtex": {"value": "@inproceedings{\narora2024leveraging,\ntitle={Leveraging Uncertainty Estimates To Improve Classifier Performance},\nauthor={Gundeep Arora and Srujana Merugu and Anoop Saladi and Rajeev Rastogi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nsNyDvNQTc}\n}"}, "paperhash": {"value": "arora|leveraging_uncertainty_estimates_to_improve_classifier_performance"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5267/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5267/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410933295, "version": 2}, {"id": "jzzEHTBFOT", "forum": "jzzEHTBFOT", "number": 5266, "cdate": 1695379115219, "tcdate": 1695379115219, "mdate": 1711892009983, "tmdate": 1711892009983, "signatures": ["ICLR.cc/2024/Conference/Submission5266/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5266/Authors"], "content": {"title": {"value": "C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion"}, "authors": {"value": ["Hee Suk Yoon", "Eunseop Yoon", "Joshua Tian Jin Tee", "Mark A. Hasegawa-Johnson", "Yingzhen Li", "Chang D. Yoo"]}, "authorids": {"value": ["~Hee_Suk_Yoon1", "~Eunseop_Yoon1", "~Joshua_Tian_Jin_Tee1", "~Mark_A._Hasegawa-Johnson1", "~Yingzhen_Li1", "~Chang_D._Yoo1"]}, "keywords": {"value": ["Calibration", "Test-time adaptation", "CLIP", "Prompt tuning"]}, "TLDR": {"value": "We address the critical yet under-explored challenge of achieving calibrated zero-shot inference during test-time prompt tuning in large-scale vision-language models."}, "abstract": {"value": "In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration, which is a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion (ATFD), we establish its relationship with calibration error and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT), for optimizing prompts during test-time with enhanced calibration. Through extensive experiments on different CLIP architectures and datasets, we show that C-TPT can effectively improve the calibration of test-time prompt tuning without needing labeled data. The code is publicly accessible at https://github.com/hee-suk-yoon/C-TPT."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1a0c60310a2565e2703804be2d1bcea35527ae1e.pdf"}, "_bibtex": {"value": "@inproceedings{\nyoon2024ctpt,\ntitle={C-{TPT}: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion},\nauthor={Hee Suk Yoon and Eunseop Yoon and Joshua Tian Jin Tee and Mark A. Hasegawa-Johnson and Yingzhen Li and Chang D. Yoo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jzzEHTBFOT}\n}"}, "paperhash": {"value": "yoon|ctpt_calibrated_testtime_prompt_tuning_for_visionlanguage_models_via_text_feature_dispersion"}}, "odate": 1697213872796, "pdate": 1705410933176, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5266/-/Revision", "ICLR.cc/2024/Conference/Submission5266/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5266/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "version": 2}, {"id": "b2UlHeyyC0", "forum": "b2UlHeyyC0", "number": 5261, "cdate": 1695378835993, "tcdate": 1695378835993, "mdate": 1709661519256, "tmdate": 1709661519256, "signatures": ["ICLR.cc/2024/Conference/Submission5261/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5261/Authors"], "content": {"title": {"value": "Retrieval-Enhanced Contrastive Vision-Text Models"}, "authors": {"value": ["Ahmet Iscen", "Mathilde Caron", "Alireza Fathi", "Cordelia Schmid"]}, "authorids": {"value": ["~Ahmet_Iscen3", "~Mathilde_Caron1", "~Alireza_Fathi1", "~Cordelia_Schmid1"]}, "keywords": {"value": ["vision-language models", "retrieval", "external memory", "knowledge-based approaches"]}, "TLDR": {"value": "We propose to equip existing contrastive vision-text models with the ability to use retrieved relevant data from an external memory in order to improve their performance on finegrained recognition tasks."}, "abstract": {"value": "Contrastive image-text models such as CLIP form the building blocks of many state-of-the-art systems. While they excel at recognizing common generic concepts, they still struggle on fine-grained entities which are rare, or even absent from the pre-training dataset. Hence, a key ingredient to their success has been the use of large-scale curated pre-training data aiming at expanding the set of concepts that they can memorize during the pre-training stage. In this work, we explore an alternative to encoding fine-grained knowledge directly into the model's parameters:  we instead train the model to retrieve this knowledge from an external memory. Specifically, we propose to equip existing vision-text models with the ability to refine their embedding with cross-modal retrieved information from a memory at inference time, which greatly improves their zero-shot predictions. Remarkably, we show that this can be done with a light-weight, single-layer, fusion transformer on top of a frozen CLIP. Our experiments validate that our retrieval-enhanced contrastive (RECO) training improves CLIP performance substantially on several challenging fine-grained tasks: for example +10.9 on Stanford Cars, +10.2 on CUB-2011 and +7.3 on the recent OVEN benchmark, where we even outperform the fine-tuned models on unseen classes."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b371f58bea2f9afc74f7fadebd6a614edbb5eb6d.pdf"}, "_bibtex": {"value": "@inproceedings{\niscen2024retrievalaugmented,\ntitle={Retrieval-augmented Vision-Language Representation for Fine-grained Recognition},\nauthor={Ahmet Iscen and Mathilde Caron and Alireza Fathi and Cordelia Schmid},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=b2UlHeyyC0}\n}"}, "supplementary_material": {"value": "/attachment/8464c65adebd65a8c827b5b71decde74d575b227.pdf"}, "paperhash": {"value": "iscen|retrievalenhanced_contrastive_visiontext_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5261/-/Revision", "ICLR.cc/2024/Conference/Submission5261/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5261/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410933028, "version": 2}, {"id": "uvXK8Xk9Jk", "forum": "uvXK8Xk9Jk", "number": 5260, "cdate": 1695378801710, "tcdate": 1695378801710, "mdate": 1710277695389, "tmdate": 1710277695389, "signatures": ["ICLR.cc/2024/Conference/Submission5260/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5260/Authors"], "content": {"title": {"value": "DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS"}, "authors": {"value": ["Ilan Price", "Nicholas Daultry Ball", "Adam Christopher Jones", "Samuel Chun Hei Lam", "Jared Tanner"]}, "authorids": {"value": ["~Ilan_Price1", "~Nicholas_Daultry_Ball1", "~Adam_Christopher_Jones1", "~Samuel_Chun_Hei_Lam1", "~Jared_Tanner1"]}, "keywords": {"value": ["Deep neural network", "random initialisation", "sparsity", "gaussian process"]}, "TLDR": {"value": "Sparsity inducing nonlinear activations are designed, analysed to be stable for training, and shown to be effective with hidden layer sparsity as high as 85%."}, "abstract": {"value": "Inducing and leveraging sparse activations during training and inference is a promising avenue for improving the computational efficiency of deep networks, which is increasingly important as network sizes continue to grow and their application becomes more widespread.  Here we use the large width Gaussian process limit to analyze the behaviour, at random initialization, of nonlinear activations that induce sparsity in the hidden outputs.  A previously unreported form of training instability is proven for arguably two of the most natural candidates for hidden layer sparsification; those being a shifted ReLU ($\\phi(x)=\\max(0, x-\\tau)$ for $\\tau\\ge 0$) and soft thresholding ($\\phi(x)=0$ for $|x|\\le\\tau$ and $x-\\text{sign}(x)\\tau$ for $|x|>\\tau$).  We show that this instability is overcome by clipping the nonlinear activation magnitude, at a level prescribed by the shape of the associated Gaussian process variance map. Numerical experiments verify the theory and show that the proposed magnitude clipped sparsifying activations can be trained with training and test fractional sparsity as high as 85\\% while retaining close to full accuracy."}, "pdf": {"value": "/pdf/55ca70752b926a47e04e842f97631b34b77817b9.pdf"}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nprice2024deep,\ntitle={{DEEP} {NEURAL} {NETWORK} {INITIALIZATION} {WITH} {SPARSITY} {INDUCING} {ACTIVATIONS}},\nauthor={Ilan Price and Nicholas Daultry Ball and Adam Christopher Jones and Samuel Chun Hei Lam and Jared Tanner},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uvXK8Xk9Jk}\n}"}, "paperhash": {"value": "price|deep_neural_network_initialization_with_sparsity_inducing_activations"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5260/-/Revision", "ICLR.cc/2024/Conference/Submission5260/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5260/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410933013, "version": 2}, {"id": "MrYiwlDRQO", "forum": "MrYiwlDRQO", "number": 5247, "cdate": 1695378188151, "tcdate": 1695378188151, "mdate": 1710533178564, "tmdate": 1710533178564, "signatures": ["ICLR.cc/2024/Conference/Submission5247/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5247/Authors"], "content": {"title": {"value": "PeFLL: Personalized Federated Learning by Learning to Learn"}, "authors": {"value": ["Jonathan Scott", "Hossein Zakerinia", "Christoph H Lampert"]}, "authorids": {"value": ["~Jonathan_Scott1", "~Hossein_Zakerinia1", "~Christoph_H_Lampert1"]}, "keywords": {"value": ["Personalized Federated Learning", "Learning-to-Learn"]}, "abstract": {"value": "We present PeFLL, a new personalized federated learning algorithm that improves over the state-of-the-art in three aspects: 1) it produces more accurate models, especially in the low-data regime, and not only for clients present during its training phase, but also for any that may emerge in the future; 2) it reduces the amount of on-client computation and client-server communication by providing future clients with ready-to-use personalized models that require no additional finetuning or optimization; 3) it comes with theoretical guarantees that establish generalization from the observed clients to future ones. \nAt the core of PeFLL lies a learning-to-learn approach that jointly trains an embedding network and a hypernetwork. The embedding network is used to represent clients in a latent descriptor space in a way that reflects their similarity to each other. The hypernetwork takes as input such descriptors and outputs the parameters of fully personalized client models. In combination, both networks constitute a learning algorithm that achieves state-of-the-art performance in several personalized federated learning benchmarks."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/862362ff27a0c0a46becbd47636b3ffd63f0521e.pdf"}, "supplementary_material": {"value": "/attachment/de474b02a310f897f048f55bf9a333684101c9a3.zip"}, "TLDR": {"value": "PeFLL is a hypernetwork-based approach for personalized federated learning. Based on a learning-to-learn approach it efficiently generates accurate individual models for current as well as future clients."}, "_bibtex": {"value": "@inproceedings{\nscott2024pefll,\ntitle={Pe{FLL}: Personalized Federated Learning by Learning to Learn},\nauthor={Jonathan Scott and Hossein Zakerinia and Christoph H Lampert},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MrYiwlDRQO}\n}"}, "paperhash": {"value": "scott|pefll_personalized_federated_learning_by_learning_to_learn"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5247/-/Revision", "ICLR.cc/2024/Conference/Submission5247/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5247/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932779, "version": 2}, {"id": "xx0ITyHp3u", "forum": "xx0ITyHp3u", "number": 5239, "cdate": 1695377585168, "tcdate": 1695377585168, "mdate": 1710487211781, "tmdate": 1710487211781, "signatures": ["ICLR.cc/2024/Conference/Submission5239/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5239/Authors"], "content": {"title": {"value": "Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging"}, "authors": {"value": ["Max Zimmer", "Christoph Spiegel", "Sebastian Pokutta"]}, "authorids": {"value": ["~Max_Zimmer1", "~Christoph_Spiegel1", "~Sebastian_Pokutta1"]}, "keywords": {"value": ["pruning", "retraining", "model averaging", "neural networks"]}, "abstract": {"value": "Neural networks can be significantly compressed by pruning, yielding sparse models with reduced storage and computational demands while preserving predictive performance. Model soups (Wortsman et al., 2022) enhance generalization and out-of-distribution (OOD) performance by averaging the parameters of multiple models into a single one, without increasing inference time. However, achieving both sparsity and parameter averaging is challenging as averaging arbitrary sparse models reduces the overall sparsity due to differing sparse connectivities. This work addresses these challenges by demonstrating that exploring a single retraining phase of Iterative Magnitude Pruning (IMP) with varied hyperparameter configurations such as batch ordering or weight decay yields models suitable for averaging, sharing identical sparse connectivity by design. Averaging these models significantly enhances generalization and OOD performance over their individual counterparts. Building on this, we introduce Sparse Model Soups (SMS), a novel method for merging sparse models by initiating each prune-retrain cycle with the averaged model from the previous phase. SMS preserves sparsity, exploits sparse network benefits, is modular and fully parallelizable, and substantially improves IMP's performance. We further demonstrate that SMS can be adapted to enhance state-of-the-art pruning-during-training approaches."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6af1be52a27d70f4d6c210e7182543e1fbf38ce0.pdf"}, "supplementary_material": {"value": "/attachment/a47956d62ee9de9ba1c42cf803737d9b42336621.zip"}, "_bibtex": {"value": "@inproceedings{\nzimmer2024sparse,\ntitle={Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging},\nauthor={Max Zimmer and Christoph Spiegel and Sebastian Pokutta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xx0ITyHp3u}\n}"}, "paperhash": {"value": "zimmer|sparse_model_soups_a_recipe_for_improved_pruning_via_model_averaging"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5239/-/Revision", "ICLR.cc/2024/Conference/Submission5239/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5239/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932506, "version": 2}, {"id": "BEyEziZ4R6", "forum": "BEyEziZ4R6", "number": 5238, "cdate": 1695377556691, "tcdate": 1695377556691, "mdate": 1709661519042, "tmdate": 1709661519042, "signatures": ["ICLR.cc/2024/Conference/Submission5238/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5238/Authors"], "content": {"title": {"value": "DP-SGD Without Clipping: The Lipschitz Neural Network Way"}, "authors": {"value": ["Louis B\u00e9thune", "Thomas Massena", "Thibaut Boissin", "Aur\u00e9lien Bellet", "Franck Mamalet", "Yannick Prudent", "Corentin Friedrich", "Mathieu Serrurier", "David Vigouroux"]}, "authorids": {"value": ["~Louis_B\u00e9thune1", "~Thomas_Massena1", "~Thibaut_Boissin1", "~Aur\u00e9lien_Bellet1", "~Franck_Mamalet2", "~Yannick_Prudent1", "~Corentin_Friedrich1", "~Mathieu_Serrurier1", "~David_Vigouroux1"]}, "keywords": {"value": ["lipschitz neural networks", "dp-sgd", "privacy", "robustness"]}, "TLDR": {"value": "Lipschitz neural networks can be trained with DP guarantees without gradient clipping"}, "abstract": {"value": "State-of-the-art approaches for training Differentially Private (DP) Deep Neural Networks (DNN) face difficulties to estimate tight bounds on the sensitivity of the network's layers, and instead rely on a process of per-sample gradient clipping. This clipping process not only biases the direction of gradients but also proves costly both in memory consumption and in computation. To provide sensitivity bounds and bypass the drawbacks of the clipping process, we propose to rely on Lipschitz constrained networks. Our theoretical analysis reveals an unexplored link between the Lipschitz constant with respect to their input and the one with respect to their parameters. By bounding the Lipschitz constant of each layer with respect to its parameters, we prove that we can train these networks with privacy guarantees.  Our analysis not only allows the computation of the aforementioned sensitivities at scale, but also provides guidance on how to maximize the gradient-to-noise ratio for fixed privacy guarantees. To facilitate the application of Lipschitz networks and foster robust and certifiable learning under privacy guarantees, we provide a Python package that implements building blocks allowing the construction and private training of such networks."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9cfb57ef3488ee75d3de82b19e6ff969b1ca0b91.pdf"}, "_bibtex": {"value": "@inproceedings{\nb{\\'e}thune2024dpsgd,\ntitle={{DP}-{SGD} Without Clipping: The Lipschitz Neural Network Way},\nauthor={Louis B{\\'e}thune and Thomas Massena and Thibaut Boissin and Aur{\\'e}lien Bellet and Franck Mamalet and Yannick Prudent and Corentin Friedrich and Mathieu Serrurier and David Vigouroux},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BEyEziZ4R6}\n}"}, "paperhash": {"value": "b\u00e9thune|dpsgd_without_clipping_the_lipschitz_neural_network_way"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5238/-/Revision", "ICLR.cc/2024/Conference/Submission5238/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5238/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932475, "version": 2}, {"id": "nfIAEJFiBZ", "forum": "nfIAEJFiBZ", "number": 5234, "cdate": 1695377444709, "tcdate": 1695377444709, "mdate": 1710347493936, "tmdate": 1710347493936, "signatures": ["ICLR.cc/2024/Conference/Submission5234/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5234/Authors"], "content": {"title": {"value": "Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo"}, "authors": {"value": ["Haque Ishfaq", "Qingfeng Lan", "Pan Xu", "A. Rupam Mahmood", "Doina Precup", "Anima Anandkumar", "Kamyar Azizzadenesheli"]}, "authorids": {"value": ["~Haque_Ishfaq1", "~Qingfeng_Lan1", "~Pan_Xu1", "~A._Rupam_Mahmood1", "~Doina_Precup1", "~Anima_Anandkumar1", "~Kamyar_Azizzadenesheli1"]}, "keywords": {"value": ["Exploration", "Reinforcement Learning", "Thompson Sampling", "Langevin Monte Carlo", "Deep Reinforcement learning"]}, "TLDR": {"value": "We propose a provably and practically efficient reinforcement learning algorithm based on Langevin Monte Carlo."}, "abstract": {"value": "We present a scalable and effective exploration strategy based on Thompson sampling for reinforcement learning (RL). One of the key shortcomings of  existing Thompson sampling algorithms is the need to perform a Gaussian approximation of the posterior distribution, which is not a good surrogate in most practical settings. We instead directly sample the Q function from its posterior distribution, by using  Langevin Monte Carlo, an efficient type of Markov Chain Monte Carlo (MCMC) method. Our method only needs to perform noisy gradient descent updates to learn the exact posterior distribution of the Q function, which makes our approach easy to deploy in deep RL.  We provide a rigorous theoretical analysis for the proposed method and demonstrate that, in the linear Markov decision process (linear MDP) setting, it has a regret bound of $\\tilde{O}(d^{3/2}H^{3/2}\\sqrt{T})$, where $d$ is the dimension of the feature mapping, $H$ is the planning horizon, and $T$ is the total number of steps. We apply this approach to deep RL, by using Adam optimizer to perform gradient updates. Our approach achieves better or similar results compared with state-of-the-art deep RL algorithms on several challenging exploration tasks from the Atari57 suite."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6869226da9603d6065efb6908b1fa2a52df4c640.pdf"}, "supplementary_material": {"value": "/attachment/fa48d1476ac0423b200d04066ae91e6a056678a5.pdf"}, "_bibtex": {"value": "@inproceedings{\nishfaq2024provable,\ntitle={Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo},\nauthor={Haque Ishfaq and Qingfeng Lan and Pan Xu and A. Rupam Mahmood and Doina Precup and Anima Anandkumar and Kamyar Azizzadenesheli},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nfIAEJFiBZ}\n}"}, "paperhash": {"value": "ishfaq|provable_and_practical_efficient_exploration_in_reinforcement_learning_via_langevin_monte_carlo"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5234/-/Revision", "ICLR.cc/2024/Conference/Submission5234/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5234/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932329, "version": 2}, {"id": "7W3GLNImfS", "forum": "7W3GLNImfS", "number": 5231, "cdate": 1695377228150, "tcdate": 1695377228150, "mdate": 1709661518999, "tmdate": 1709661518999, "signatures": ["ICLR.cc/2024/Conference/Submission5231/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5231/Authors"], "content": {"title": {"value": "Human Feedback is not Gold Standard"}, "authors": {"value": ["Tom Hosking", "Phil Blunsom", "Max Bartolo"]}, "authorids": {"value": ["~Tom_Hosking1", "~Phil_Blunsom1", "~Max_Bartolo1"]}, "keywords": {"value": ["human evaluation", "large language models", "evaluation", "natural language generation"]}, "TLDR": {"value": "We critically analyse the use of human feedback for evaluating and training Large Language Models, finding that human preference scores under-represent some crucial error types, and are biased by the assertiveness of the output."}, "abstract": {"value": "Human feedback has become the de facto standard for evaluating the performance of Large Language Models, and is increasingly being used as a training objective. However, it is not clear which properties of a generated output this single `preference' score captures. We hypothesise that preference scores are subjective and open to undesirable biases. We critically analyse the use of human feedback for both training and evaluation, to verify whether it fully captures a range of crucial error criteria. We find that while preference scores have fairly good coverage, they under-represent important aspects like factuality. We further hypothesise that both preference scores and error annotation may be affected by confounders, and leverage instruction-tuned models to generate outputs that vary along two possible confounding dimensions: assertiveness and complexity. We find that the assertiveness of an output skews the perceived rate of factuality errors, indicating that human annotations are not a fully reliable evaluation metric or training objective. Finally, we offer preliminary evidence that using human feedback as a training objective disproportionately increases the assertiveness of model outputs. We encourage future work to carefully consider whether preference scores are well aligned with the desired objective."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c05adb252325bb04bc3e8b6278fbec2bb1175934.pdf"}, "_bibtex": {"value": "@inproceedings{\nhosking2024human,\ntitle={Human Feedback is not Gold Standard},\nauthor={Tom Hosking and Phil Blunsom and Max Bartolo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7W3GLNImfS}\n}"}, "paperhash": {"value": "hosking|human_feedback_is_not_gold_standard"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5231/-/Revision", "ICLR.cc/2024/Conference/Submission5231/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5231/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932268, "version": 2}, {"id": "L3FHMoKZcS", "forum": "L3FHMoKZcS", "number": 5226, "cdate": 1695376813038, "tcdate": 1695376813038, "mdate": 1709661518886, "tmdate": 1709661518886, "signatures": ["ICLR.cc/2024/Conference/Submission5226/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5226/Authors"], "content": {"title": {"value": "Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"}, "authors": {"value": ["Han Zhou", "Xingchen Wan", "Lev Proleev", "Diana Mincu", "Jilin Chen", "Katherine A Heller", "Subhrajit Roy"]}, "authorids": {"value": ["~Han_Zhou4", "~Xingchen_Wan1", "~Lev_Proleev1", "~Diana_Mincu1", "~Jilin_Chen1", "~Katherine_A_Heller1", "~Subhrajit_Roy1"]}, "keywords": {"value": ["large language model", "in-context learning", "calibration", "prompt"]}, "abstract": {"value": "Prompting and in-context learning (ICL) have become efficient learning paradigms for large language models (LLMs). However, LLMs suffer from prompt brittleness and various bias factors in the prompt, including but not limited to the formatting, the choice verbalizers, and the ICL examples. To address this problem that results in unexpected performance degradation, calibration methods have been developed to mitigate the effects of these biases while recovering LLM performance. In this work, we first conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that controls the contextual bias from the batched input, unifies various prior approaches and effectively addresses the aforementioned issues. BC is zero-shot, inference-only, and incurs negligible additional costs. In the few-shot setup, we further extend BC to allow it to learn the contextual bias from labeled data. We validate the effectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate state-of-the-art performance over previous calibration baselines across more than 10 natural language understanding and image classification tasks."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/624a8ed16a954f1194dea441d688bd43f94543db.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhou2024batch,\ntitle={Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering},\nauthor={Han Zhou and Xingchen Wan and Lev Proleev and Diana Mincu and Jilin Chen and Katherine A Heller and Subhrajit Roy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L3FHMoKZcS}\n}"}, "paperhash": {"value": "zhou|batch_calibration_rethinking_calibration_for_incontext_learning_and_prompt_engineering"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5226/-/Revision", "ICLR.cc/2024/Conference/Submission5226/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5226/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410932111, "version": 2}, {"id": "YrXHEb2qMb", "forum": "YrXHEb2qMb", "number": 5222, "cdate": 1695376688323, "tcdate": 1695376688323, "mdate": 1712570779484, "tmdate": 1712570779484, "signatures": ["ICLR.cc/2024/Conference/Submission5222/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5222/Authors"], "content": {"title": {"value": "Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel"}, "authors": {"value": ["Paul Hagemann", "Johannes Hertrich", "Fabian Altekr\u00fcger", "Robert Beinert", "Jannis Chemseddine", "Gabriele Steidl"]}, "authorids": {"value": ["~Paul_Hagemann1", "~Johannes_Hertrich1", "~Fabian_Altekr\u00fcger1", "~Robert_Beinert1", "~Jannis_Chemseddine1", "~Gabriele_Steidl2"]}, "keywords": {"value": ["Bayesian inverse Problems", "MMD", "Gradient Flows", "Deep Learning"]}, "TLDR": {"value": "We establish a negative distance kernel MMD flow to the joint distribution, which allows for posterior sampling in Bayesian inverse problems."}, "abstract": {"value": "We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modelling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a24a6598af57c225db0ce785b58b9b60c9691938.pdf"}, "supplementary_material": {"value": "/attachment/a650b0666fae9cd2c483fbcad2499e375dd8f584.zip"}, "_bibtex": {"value": "@inproceedings{\nhagemann2024posterior,\ntitle={Posterior Sampling Based on Gradient Flows of the {MMD} with Negative Distance Kernel},\nauthor={Paul Hagemann and Johannes Hertrich and Fabian Altekr{\\\"u}ger and Robert Beinert and Jannis Chemseddine and Gabriele Steidl},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=YrXHEb2qMb}\n}"}, "paperhash": {"value": "hagemann|posterior_sampling_based_on_gradient_flows_of_the_mmd_with_negative_distance_kernel"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5222/-/Revision", "ICLR.cc/2024/Conference/Submission5222/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5222/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931997, "version": 2}, {"id": "if2vRbS8Ew", "forum": "if2vRbS8Ew", "number": 5215, "cdate": 1695376395648, "tcdate": 1695376395648, "mdate": 1710528509821, "tmdate": 1710528509821, "signatures": ["ICLR.cc/2024/Conference/Submission5215/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5215/Authors"], "content": {"title": {"value": "First-order ANIL provably learns representations despite overparametrisation"}, "authors": {"value": ["O\u011fuz Kaan Y\u00fcksel", "Etienne Boursier", "Nicolas Flammarion"]}, "authorids": {"value": ["~O\u011fuz_Kaan_Y\u00fcksel1", "~Etienne_Boursier1", "~Nicolas_Flammarion1"]}, "keywords": {"value": ["meta-learning", "misspecification", "overparametrization", "pretraining", "optimization"]}, "TLDR": {"value": "In the limit of an infinite number of tasks, first-order ANIL with a linear two-layer network architecture provably learns linear shared representations despite having a width larger than the dimension of the shared representations."}, "abstract": {"value": "Due to its empirical success in few-shot classification and reinforcement learning, meta-learning has recently received significant interest. Meta-learning methods leverage data from previous tasks to learn a new task in a sample-efficient manner. In particular, model-agnostic methods look for initialization points from which gradient descent quickly adapts to any new task. Although it has been empirically suggested that such methods perform well by learning shared representations during pretraining, there is limited theoretical evidence of such behavior. More importantly, it has not been shown that these methods still learn a shared structure, despite architectural misspecifications. In this direction, this work shows, in the limit of an infinite number of tasks, that first-order ANIL with a linear two-layer network architecture successfully learns linear shared representations. This result even holds with _overparametrization_; having a width larger than the dimension of the shared representations results in an asymptotically low-rank solution. The learned solution then yields a good adaptation performance on any new task after a single gradient step. Overall, this illustrates how well model-agnostic methods such as first-order ANIL can learn shared representations."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/73c0c4755680d6145684a00385a40382ecd92596.pdf"}, "_bibtex": {"value": "@inproceedings{\ny{\\\"u}ksel2024firstorder,\ntitle={First-order {ANIL} provably learns representations despite overparametrisation},\nauthor={O{\\u{g}}uz Kaan Y{\\\"u}ksel and Etienne Boursier and Nicolas Flammarion},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=if2vRbS8Ew}\n}"}, "paperhash": {"value": "y\u00fcksel|firstorder_anil_provably_learns_representations_despite_overparametrisation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5215/-/Revision", "ICLR.cc/2024/Conference/Submission5215/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5215/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931794, "version": 2}, {"id": "ZGNWW7xZ6Q", "forum": "ZGNWW7xZ6Q", "number": 5213, "cdate": 1695376372188, "tcdate": 1695376372188, "mdate": 1709661518734, "tmdate": 1709661518734, "signatures": ["ICLR.cc/2024/Conference/Submission5213/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5213/Authors"], "content": {"title": {"value": "Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning"}, "authors": {"value": ["LINHAO LUO", "Yuan-Fang Li", "Reza Haf", "Shirui Pan"]}, "authorids": {"value": ["~LINHAO_LUO1", "~Yuan-Fang_Li1", "~Reza_Haf1", "~Shirui_Pan1"]}, "keywords": {"value": ["large language models", "knowledge graphs", "reasoning"]}, "TLDR": {"value": "we propose a novel method called Reasoning on Graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning."}, "abstract": {"value": "Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/10d8476b7c65d4ff52dbae3173daa0a082c241d5.pdf"}, "_bibtex": {"value": "@inproceedings{\nluo2024reasoning,\ntitle={Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning},\nauthor={LINHAO LUO and Yuan-Fang Li and Reza Haf and Shirui Pan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ZGNWW7xZ6Q}\n}"}, "paperhash": {"value": "luo|reasoning_on_graphs_faithful_and_interpretable_large_language_model_reasoning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5213/-/Revision", "ICLR.cc/2024/Conference/Submission5213/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5213/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931671, "version": 2}, {"id": "567BjxgaTp", "forum": "567BjxgaTp", "number": 5212, "cdate": 1695376366929, "tcdate": 1695376366929, "mdate": 1710518577907, "tmdate": 1710518577907, "signatures": ["ICLR.cc/2024/Conference/Submission5212/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5212/Authors"], "content": {"title": {"value": "How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"}, "authors": {"value": ["Lorenzo Pacchiardi", "Alex James Chan", "S\u00f6ren Mindermann", "Ilan Moscovitz", "Alexa Yue Pan", "Yarin Gal", "Owain Evans", "Jan M. Brauner"]}, "authorids": {"value": ["~Lorenzo_Pacchiardi1", "~Alex_James_Chan1", "~S\u00f6ren_Mindermann1", "~Ilan_Moscovitz1", "~Alexa_Yue_Pan1", "~Yarin_Gal1", "~Owain_Evans1", "~Jan_M._Brauner1"]}, "keywords": {"value": ["language models", "lying", "deception", "alignment", "safety", "truthfulness", "honesty"]}, "TLDR": {"value": "How to elicit, and detect, lying behaviour in black-box LLMs."}, "abstract": {"value": "Large language models (LLMs) can \u201clie\u201d, which we define as outputting false statements when incentivised to, despite \u201cknowing\u201d the truth in a demonstrable sense. LLMs might \u201clie\u201d, for example, when instructed to output misinformation. Here, we develop a simple lie detector that requires neither access to the LLM\u2019s activations (black-box) nor ground-truth knowledge of the fact in question. The detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM\u2019s yes/no answers into a logistic regression classifier. Despite its simplicity, this lie detector is highly accurate and surprisingly general. When trained on examples from a single setting\u2014prompting GPT-3.5 to lie about factual questions\u2014the detector generalises out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie, (3) sycophantic lies, and (4) lies emerging in real-life scenarios such as sales. These results indicate that LLMs have distinctive lie-related behavioural patterns, consistent across architectures and contexts, which could enable general-purpose lie detection."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b79f035d87a4cd2744c9a8fce596814ce5126985.pdf"}, "supplementary_material": {"value": "/attachment/3b63a2c68f1a0b002920ca2526f715d3513508c9.pdf"}, "_bibtex": {"value": "@inproceedings{\npacchiardi2024how,\ntitle={How to Catch an {AI} Liar: Lie Detection in Black-Box {LLM}s by Asking Unrelated Questions},\nauthor={Lorenzo Pacchiardi and Alex James Chan and S{\\\"o}ren Mindermann and Ilan Moscovitz and Alexa Yue Pan and Yarin Gal and Owain Evans and Jan M. Brauner},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=567BjxgaTp}\n}"}, "paperhash": {"value": "pacchiardi|how_to_catch_an_ai_liar_lie_detection_in_blackbox_llms_by_asking_unrelated_questions"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5212/-/Revision", "ICLR.cc/2024/Conference/Submission5212/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5212/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931653, "version": 2}, {"id": "86zAUE80pP", "forum": "86zAUE80pP", "number": 5209, "cdate": 1695376237176, "tcdate": 1695376237176, "mdate": 1712564258304, "tmdate": 1712564258304, "signatures": ["ICLR.cc/2024/Conference/Submission5209/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5209/Authors"], "content": {"title": {"value": "CPPO: Continual Learning for Reinforcement Learning with Human Feedback"}, "authors": {"value": ["Han Zhang", "Yu Lei", "Lin Gui", "Min Yang", "Yulan He", "Hui Wang", "Ruifeng Xu"]}, "authorids": {"value": ["~Han_Zhang3", "~Yu_Lei5", "~Lin_Gui3", "~Min_Yang6", "~Yulan_He1", "~Hui_Wang13", "~Ruifeng_Xu1"]}, "keywords": {"value": ["lifelong learning", "reinforcement learning", "human feedback", "proximal policy optimization"]}, "TLDR": {"value": "We propose a new method to continually learn from human preferences based on proximal policy optimization, in which sample-wise weights are introduced to adjust policy learning and knowledge retention."}, "abstract": {"value": "The approach of Reinforcement Learning from Human Feedback (RLHF) is widely used for enhancing pre-trained Language Models (LM), enabling them to better align with human preferences. Existing RLHF-based LMs however require complete retraining whenever new queries or feedback are introduced, as human preferences may differ across different domains or topics. LM retraining is of\u0002ten impracticable in most real-world scenarios, due to the substantial time and computational costs involved, as well as data privacy concerns. To address this limitation, we propose Continual Proximal Policy Optimization (CPPO), a novel method that is able to continually align LM with dynamic human preferences. Specifically, CPPO adopts a weighting strategy to decide which samples should be utilized for enhancing policy learning and which should be used for solidifying past experiences. This seeks a good trade-off between policy learning and knowledge retention. Our experimental results show that CPPO outperforms strong Contin\u0002uous learning (CL) baselines when it comes to consistently aligning with human preferences. Furthermore, compared to PPO, CPPO offers more efficient and stable learning in non-continual scenarios."}, "pdf": {"value": "/pdf/f3eb0b08b2e42973f82e05d25232c9e706d89360.pdf"}, "supplementary_material": {"value": "/attachment/e53518d4f66f4c373da1c927bbf41ce523a3e4b9.zip"}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nzhang2024cppo,\ntitle={{CPPO}: Continual Learning for Reinforcement Learning with Human Feedback},\nauthor={Han Zhang and Yu Lei and Lin Gui and Min Yang and Yulan He and Hui Wang and Ruifeng Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=86zAUE80pP}\n}"}, "paperhash": {"value": "zhang|cppo_continual_learning_for_reinforcement_learning_with_human_feedback"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5209/-/Revision", "ICLR.cc/2024/Conference/Submission5209/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5209/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931519, "version": 2}, {"id": "WKuimaBj4I", "forum": "WKuimaBj4I", "number": 5208, "cdate": 1695376234917, "tcdate": 1695376234917, "mdate": 1710490180465, "tmdate": 1710490180465, "signatures": ["ICLR.cc/2024/Conference/Submission5208/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5208/Authors"], "content": {"title": {"value": "Learning Optimal Contracts: How to Exploit Small Action Spaces"}, "authors": {"value": ["Francesco Bacchiocchi", "Matteo Castiglioni", "Alberto Marchesi", "Nicola Gatti"]}, "authorids": {"value": ["~Francesco_Bacchiocchi1", "~Matteo_Castiglioni1", "~Alberto_Marchesi1", "~Nicola_Gatti1"]}, "keywords": {"value": ["principal-agent problems", "sample complexity", "online learning", "contract design"]}, "abstract": {"value": "We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme---called contract---in order to induce an agent to take a costly, unobservable action leading to favorable outcomes. We consider a generalization of the classical (single-round) version of the problem in which the principal interacts with the agent by committing to contracts over multiple rounds. The principal has no information about the agent, and they have to learn an optimal contract by only observing the outcome realized at each round. We focus on settings in which the size of the agent's action space is small. We design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space, when the number of actions is constant. Our algorithm solves an open problem by Zhu et al. [2022]. Moreover, it can also be employed to provide a $\\widetilde{\\mathcal{O}}(T^{4/5})$ regret bound in the related online learning setting in which the principal aims at maximizing their cumulative utility, thus considerably improving previously-known regret bounds."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b55efa8741ea8d4ffd17635e7c88bb5247a3ecb2.pdf"}, "supplementary_material": {"value": "/attachment/2699780aa1b1222f53fc126a23582616af64a9ce.zip"}, "_bibtex": {"value": "@inproceedings{\nbacchiocchi2024learning,\ntitle={Learning Optimal Contracts: How to Exploit Small Action Spaces},\nauthor={Francesco Bacchiocchi and Matteo Castiglioni and Alberto Marchesi and Nicola Gatti},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WKuimaBj4I}\n}"}, "paperhash": {"value": "bacchiocchi|learning_optimal_contracts_how_to_exploit_small_action_spaces"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5208/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5208/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931423, "version": 2}, {"id": "9cQtXpRshE", "forum": "9cQtXpRshE", "number": 5206, "cdate": 1695376216579, "tcdate": 1695376216579, "mdate": 1712745400024, "tmdate": 1712745400024, "signatures": ["ICLR.cc/2024/Conference/Submission5206/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5206/Authors"], "content": {"title": {"value": "AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation"}, "authors": {"value": ["Yuanwen Yue", "Sabarinath Mahadevan", "Jonas Schult", "Francis Engelmann", "Bastian Leibe", "Konrad Schindler", "Theodora Kontogianni"]}, "authorids": {"value": ["~Yuanwen_Yue1", "~Sabarinath_Mahadevan1", "~Jonas_Schult1", "~Francis_Engelmann1", "~Bastian_Leibe3", "~Konrad_Schindler1", "~Theodora_Kontogianni2"]}, "keywords": {"value": ["interactive segmentation", "3D instance segmentation", "point cloud", "attention"]}, "abstract": {"value": "During interactive segmentation, a model and a user work together to delineate objects of interest in a 3D point cloud. In an iterative process, the model assigns each data point to an object (or the background), while the user corrects errors in the resulting segmentation and feeds them back into the model. The current best practice formulates the problem as binary classification and segments objects one at a time. The model expects the user to provide positive clicks to indicate regions wrongly assigned to the background and negative clicks on regions wrongly assigned to the object. Sequentially visiting objects is wasteful since it disregards synergies between objects: a positive click for a given object can, by definition, serve as a negative click for nearby objects. Moreover, a direct competition between adjacent objects can speed up the identification of their common boundary. We introduce AGILE3D, an efficient, attention-based model that (1) supports simultaneous segmentation of multiple 3D objects, (2) yields more accurate segmentation masks with fewer user clicks, and (3) offers faster inference. Our core idea is to encode user clicks as spatial-temporal queries and enable explicit interactions between click queries as well as between them and the 3D scene through a click attention module. Every time new clicks are added, we only need to run a lightweight decoder that produces updated segmentation masks. In experiments with four different 3D point cloud datasets, AGILE3D sets a new state-of-the-art. Moreover, we also verify its practicality in real-world setups with real user studies. Project page: https://ywyue.github.io/AGILE3D."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/99ef6b1d04aa3c1bd588be1974d4beabdb5d9d1c.pdf"}, "supplementary_material": {"value": "/attachment/7f29a60c66bdc5881f680f613bc3c921576b6f6c.zip"}, "_bibtex": {"value": "@inproceedings{\nyue2024agiled,\ntitle={{AGILE}3D: Attention Guided Interactive Multi-object 3D Segmentation},\nauthor={Yuanwen Yue and Sabarinath Mahadevan and Jonas Schult and Francis Engelmann and Bastian Leibe and Konrad Schindler and Theodora Kontogianni},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9cQtXpRshE}\n}"}, "paperhash": {"value": "yue|agile3d_attention_guided_interactive_multiobject_3d_segmentation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5206/-/Revision", "ICLR.cc/2024/Conference/Submission5206/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5206/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931327, "version": 2}, {"id": "BI1N3lTWtn", "forum": "BI1N3lTWtn", "number": 5197, "cdate": 1695375834375, "tcdate": 1695375834375, "mdate": 1712458393620, "tmdate": 1712458393620, "signatures": ["ICLR.cc/2024/Conference/Submission5197/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5197/Authors"], "content": {"title": {"value": "A Multi-Level Framework for Accelerating Training Transformer Models"}, "authors": {"value": ["Longwei Zou", "Han Zhang", "Yangdong Deng"]}, "authorids": {"value": ["~Longwei_Zou1", "~Han_Zhang22", "~Yangdong_Deng1"]}, "keywords": {"value": ["Large Model", "Transformer", "Multi-Level", "Training Acceleration"]}, "abstract": {"value": "The fast growing capabilities of large-scale deep learning models, such as Bert, GPT and ViT, are revolutionizing the landscape of NLP, CV and many other domains. Training such models, however, poses an unprecedented demand for computing power, which incurs exponentially increasing energy cost and carbon dioxide emissions. It is thus critical to develop efficient training solutions to reduce the training costs. Motivated by a set of key observations of inter- and intra-layer similarities among feature maps and attentions that can be identified from typical training processes, we propose a multi-level framework for training acceleration. Specifically, the framework is based on three basic operators, Coalescing, De-coalescing and Interpolation, which can be orchestrated to build a multi-level training framework. The framework consists of a V-cycle training process, which progressively down- and up-scales the model size and projects the parameters between adjacent levels of models via coalescing and de-coalescing. The key idea is that a smaller model that can be trained for fast convergence and the trained parameters provides high-qualities intermediate solutions for the next level larger network. The interpolation operator is designed to break the symmetry of neurons incurred by de-coalescing for better convergence performance. Our experiments on transformer-based language models (e.g. Bert, GPT) as well as a vision model (e.g. DeiT) prove that the proposed framework reduces the computational cost by about 20% on training BERT/GPT-Base models and up to 51.6% on training the BERT-Large model while preserving the performance."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bc64fb3130bfd0474d7c2bde8ffcbe42e039fce6.pdf"}, "_bibtex": {"value": "@inproceedings{\nzou2024a,\ntitle={A Multi-Level Framework for Accelerating Training Transformer Models},\nauthor={Longwei Zou and Han Zhang and Yangdong Deng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BI1N3lTWtn}\n}"}, "paperhash": {"value": "zou|a_multilevel_framework_for_accelerating_training_transformer_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5197/-/Revision", "ICLR.cc/2024/Conference/Submission5197/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5197/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410931175, "version": 2}, {"id": "oQKKlzxV1o", "forum": "oQKKlzxV1o", "number": 5190, "cdate": 1695375548135, "tcdate": 1695375548135, "mdate": 1710433208320, "tmdate": 1710433208320, "signatures": ["ICLR.cc/2024/Conference/Submission5190/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5190/Authors"], "content": {"title": {"value": "Online Information Acquisition: Hiring Multiple Agents"}, "authors": {"value": ["Federico Cacciamani", "Matteo Castiglioni", "Nicola Gatti"]}, "authorids": {"value": ["~Federico_Cacciamani1", "~Matteo_Castiglioni1", "~Nicola_Gatti1"]}, "keywords": {"value": ["online learning", "information acquisition", "mechanism design"]}, "abstract": {"value": "We investigate the mechanism design problem faced by a principal who hires \\emph{multiple} agents to gather and report costly information. Then, the principal exploits the  information to make an informed decision.  We model this problem as a game, where the principal announces a mechanism consisting in action recommendations and a payment function, a.k.a. scoring rule. Then, each agent chooses an effort level and receives partial information about an underlying state of nature based on the effort. Finally, the agents report the information (possibly non-truthfully), the principal takes a decision based on this information, and the agents are paid according to the scoring rule. While previous work focuses on single-agent problems, we consider multi-agents settings. This poses the challenge of coordinating the agents' efforts and aggregating correlated information. Indeed, we show that optimal mechanisms must correlate agents' efforts, which introduces externalities among the agents, and hence complex incentive compatibility constraints and equilibrium selection problems. First, we design a polynomial-time algorithm to find an optimal incentive compatible mechanism. Then, we study an online problem, where the principal repeatedly interacts with a group of unknown agents. We design a no-regret algorithm that provides $\\widetilde{\\mathcal{O}}(T^{2/3})$ regret with respect to an optimal mechanism, matching the state-of-the-art bound for single-agent settings."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/83fcb8ac23e715a1b18621cd00f0a8a7d023dc7a.pdf"}, "_bibtex": {"value": "@inproceedings{\ncacciamani2024online,\ntitle={Online Information Acquisition: Hiring Multiple Agents},\nauthor={Federico Cacciamani and Matteo Castiglioni and Nicola Gatti},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oQKKlzxV1o}\n}"}, "paperhash": {"value": "cacciamani|online_information_acquisition_hiring_multiple_agents"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5190/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5190/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410930895, "version": 2}, {"id": "MzjiMxlWab", "forum": "MzjiMxlWab", "number": 5185, "cdate": 1695375438180, "tcdate": 1695375438180, "mdate": 1710488615398, "tmdate": 1710488615398, "signatures": ["ICLR.cc/2024/Conference/Submission5185/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5185/Authors"], "content": {"title": {"value": "Learning Multi-Faceted Prototypical User Interests"}, "authors": {"value": ["Nhu-Thuat Tran", "Hady W. Lauw"]}, "authorids": {"value": ["~Nhu-Thuat_Tran1", "~Hady_W._Lauw1"]}, "keywords": {"value": ["multi-faceted representation", "user interests", "item characteristics"]}, "abstract": {"value": "We seek to uncover the latent interest units from behavioral data to better learn user preferences under the VAE framework. Existing practices tend to ignore the multiple facets of item characteristics, which may not capture it at appropriate granularity. Moreover, current studies equate the granularity of item space to that of user interests, which we postulate is not ideal as user interests would likely map to a small subset of item space. In addition, the compositionality of user interests has received inadequate attention, preventing the modeling of interactions between explanatory factors driving a user's decision.\nTo resolve this, we propose to align user interests with multi-faceted item characteristics. First, we involve prototype-based representation learning to discover item characteristics along multiple facets. Second, we compose user interests from uncovered item characteristics via binding mechanism, separating the granularity of user preferences from that of item space. Third, we design a dedicated bi-directional binding block, aiding the derivation of compositional user interests.\nOn real-world datasets, the experimental results demonstrate the strong performance of our proposed method compared to a series of baselines."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/18df1be67099a0407673b7ba37ca965dcddf2051.pdf"}, "_bibtex": {"value": "@inproceedings{\ntran2024learning,\ntitle={Learning Multi-Faceted Prototypical User Interests},\nauthor={Nhu-Thuat Tran and Hady W. Lauw},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MzjiMxlWab}\n}"}, "paperhash": {"value": "tran|learning_multifaceted_prototypical_user_interests"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5185/-/Revision", "ICLR.cc/2024/Conference/Submission5185/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5185/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410930732, "version": 2}, {"id": "wZWTHU7AsQ", "forum": "wZWTHU7AsQ", "number": 5179, "cdate": 1695375279069, "tcdate": 1695375279069, "mdate": 1712643994106, "tmdate": 1712643994106, "signatures": ["ICLR.cc/2024/Conference/Submission5179/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5179/Authors"], "content": {"title": {"value": "Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations"}, "authors": {"value": ["Yongyuan Liang", "Yanchao Sun", "Ruijie Zheng", "Xiangyu Liu", "Benjamin Eysenbach", "Tuomas Sandholm", "Furong Huang", "Stephen Marcus McAleer"]}, "authorids": {"value": ["~Yongyuan_Liang1", "~Yanchao_Sun1", "~Ruijie_Zheng1", "~Xiangyu_Liu4", "~Benjamin_Eysenbach1", "~Tuomas_Sandholm1", "~Furong_Huang1", "~Stephen_Marcus_McAleer1"]}, "keywords": {"value": ["Reinforcement Learning", "Robustness", "Adversarial Learning"]}, "TLDR": {"value": "We introduce a temporally-coupled adversary considering the temporal coupling between perturbations over time and propose a game-theoretic response approach for adversarial defense against these adversaries."}, "abstract": {"value": "Deploying reinforcement learning (RL) systems requires robustness to uncertainty and model misspecification, yet prior robust RL methods typically only study noise introduced independently across time. However, practical sources of uncertainty are usually coupled across time.\nWe formally introduce temporally-coupled perturbations, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose GRAD, a novel game-theoretic approach that treats the temporally-coupled robust RL problem as a partially-observable two-player zero-sum game. By finding an approximate equilibrium within this game, GRAD optimizes for general robustness against temporally-coupled perturbations. Experiments on continuous control tasks demonstrate that, compared with prior methods, our approach achieves a higher degree of robustness to various types of attacks on different attack domains, both in settings with temporally-coupled perturbations and decoupled perturbations."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/05c090fff5aa1aa6a9f51713be2b6e6e2692c039.pdf"}, "_bibtex": {"value": "@inproceedings{\nliang2024gametheoretic,\ntitle={Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations},\nauthor={Yongyuan Liang and Yanchao Sun and Ruijie Zheng and Xiangyu Liu and Benjamin Eysenbach and Tuomas Sandholm and Furong Huang and Stephen Marcus McAleer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wZWTHU7AsQ}\n}"}, "paperhash": {"value": "liang|gametheoretic_robust_reinforcement_learning_handles_temporallycoupled_perturbations"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5179/-/Revision", "ICLR.cc/2024/Conference/Submission5179/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5179/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410930534, "version": 2}, {"id": "yBIJRIYTqa", "forum": "yBIJRIYTqa", "number": 5178, "cdate": 1695375186942, "tcdate": 1695375186942, "mdate": 1710435265065, "tmdate": 1710435265065, "signatures": ["ICLR.cc/2024/Conference/Submission5178/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5178/Authors"], "content": {"title": {"value": "Bandits with Replenishable Knapsacks: the Best of both Worlds"}, "authors": {"value": ["Martino Bernasconi", "Matteo Castiglioni", "Andrea Celli", "Federico Fusco"]}, "authorids": {"value": ["~Martino_Bernasconi1", "~Matteo_Castiglioni1", "~Andrea_Celli1", "~Federico_Fusco1"]}, "keywords": {"value": ["online learning", "bandits with knapsack", "best-of-both-worlds"]}, "abstract": {"value": "The bandits with knapsacks (BwK) framework models online decision-making problems in which an agent makes a sequence of decisions subject to resource consumption constraints. The traditional model assumes that each action consumes a non-negative amount of resources and the process ends when the initial budgets are fully depleted. We study a natural generalization of the BwK framework which allows non-monotonic resource utilization, i.e., resources can be replenished by a positive amount. We propose a best-of-both-worlds primal-dual template that can handle any online learning problem with replenishment for which a suitable primal regret minimizer exists. In particular, we provide the first positive results for the case of adversarial inputs by showing that our framework guarantees a constant competitive ratio $\\alpha$ when $B=\\Omega(T)$ or when the possible per-round replenishment is a positive constant. Moreover, under a stochastic input model, our algorithm yields an instance-independent $\\tilde{\\mathcal{O}}(T^{1/2})$ regret bound which complements existing instance-dependent bounds for the same setting. Finally, we provide applications of our framework to some economic problems of practical relevance."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/05f6421a2da0a2d47fc57a11a249d3d605898ccb.pdf"}, "_bibtex": {"value": "@inproceedings{\nbernasconi2024bandits,\ntitle={Bandits with Replenishable Knapsacks: the Best of both Worlds},\nauthor={Martino Bernasconi and Matteo Castiglioni and Andrea Celli and Federico Fusco},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yBIJRIYTqa}\n}"}, "paperhash": {"value": "bernasconi|bandits_with_replenishable_knapsacks_the_best_of_both_worlds"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5178/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5178/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410930454, "version": 2}, {"id": "zwMfg9PfPs", "forum": "zwMfg9PfPs", "number": 5166, "cdate": 1695374748753, "tcdate": 1695374748753, "mdate": 1710536953592, "tmdate": 1710536953592, "signatures": ["ICLR.cc/2024/Conference/Submission5166/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5166/Authors"], "content": {"title": {"value": "Out-of-Variable Generalisation for Discriminative Models"}, "authors": {"value": ["Siyuan Guo", "Jonas Bernhard Wildberger", "Bernhard Sch\u00f6lkopf"]}, "authorids": {"value": ["~Siyuan_Guo1", "~Jonas_Bernhard_Wildberger1", "~Bernhard_Sch\u00f6lkopf1"]}, "keywords": {"value": ["Out-of-Variable Generalization", "Causality"]}, "abstract": {"value": "The ability of an agent to do well in new environments is a critical aspect of intelligence. In machine learning, this ability is known as $\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However, merely considering differences in distributions is inadequate for fully capturing differences between learning environments. In the present paper, we investigate $\\textit{out-of-variable}$ generalization, which pertains to an agent's generalization capabilities concerning environments with variables that were never jointly observed before. This skill closely reflects the process of animate learning: we, too, explore Nature by probing, observing, and measuring proper $\\textit{subsets}$ of variables at any given time. Mathematically, $\\textit{oov}$ generalization requires the efficient re-use of past marginal information, i.e., information over subsets of previously observed variables. We study this problem, focusing on prediction tasks across environments that contain overlapping, yet distinct, sets of causes. We show that after fitting a classifier, the residual distribution in one environment reveals the partial derivative of the true generating function with respect to the unobserved causal parent in that environment. We leverage this information and propose a method that exhibits non-trivial out-of-variable generalization performance when facing an overlapping, yet distinct, set of causal predictors. Code: https://github.com/syguo96/Out-of-Variable-Generalization"}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/24985b5d2abb9b945085083ef81556f6b3dbd0fd.pdf"}, "supplementary_material": {"value": "/attachment/cf0a8133935fe54905fad0549253af560be4d3ee.pdf"}, "_bibtex": {"value": "@inproceedings{\nguo2024outofvariable,\ntitle={Out-of-Variable Generalisation for Discriminative Models},\nauthor={Siyuan Guo and Jonas Bernhard Wildberger and Bernhard Sch{\\\"o}lkopf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zwMfg9PfPs}\n}"}, "paperhash": {"value": "guo|outofvariable_generalisation_for_discriminative_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5166/-/Revision", "ICLR.cc/2024/Conference/Submission5166/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5166/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410930132, "version": 2}, {"id": "39cPKijBed", "forum": "39cPKijBed", "number": 5163, "cdate": 1695374599694, "tcdate": 1695374599694, "mdate": 1709661518030, "tmdate": 1709661518030, "signatures": ["ICLR.cc/2024/Conference/Submission5163/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5163/Authors"], "content": {"title": {"value": "Training Unbiased Diffusion Models From Biased Dataset"}, "authors": {"value": ["Yeongmin Kim", "Byeonghu Na", "Minsang Park", "JoonHo Jang", "Dongjun Kim", "Wanmo Kang", "Il-chul Moon"]}, "authorids": {"value": ["~Yeongmin_Kim1", "~Byeonghu_Na1", "~Minsang_Park1", "~JoonHo_Jang1", "~Dongjun_Kim1", "~Wanmo_Kang1", "~Il-chul_Moon1"]}, "keywords": {"value": ["diffusion model", "density ratio estimation", "dataset bias"]}, "TLDR": {"value": "We propose time-dependent importance reweighting to mitigate dataset bias in diffusion models."}, "abstract": {"value": "With significant advancements in diffusion models, addressing the potential risks of dataset bias becomes increasingly important. Since generated outputs directly suffer from dataset bias, mitigating latent bias becomes a key factor in improving sample quality and proportion. This paper proposes time-dependent importance reweighting to mitigate the bias for the diffusion models. We demonstrate that the time-dependent density ratio becomes more precise than previous approaches, thereby minimizing error propagation in generative learning. While directly applying it to score-matching is intractable, we discover that using the time-dependent density ratio both for reweighting and score correction can lead to a tractable form of the objective function to regenerate the unbiased data density. Furthermore, we theoretically establish a connection with traditional score-matching, and we demonstrate its convergence to an unbiased distribution. The experimental evidence supports the usefulness of the proposed method, which outperforms baselines including time-independent importance reweighting on CIFAR-10, CIFAR-100, FFHQ, and CelebA with various bias settings. Our code is available at https://github.com/alsdudrla10/TIW-DSM."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/53a7d90cc660356ab70eadaca02f84d17276ce87.pdf"}, "_bibtex": {"value": "@inproceedings{\nkim2024training,\ntitle={Training Unbiased Diffusion Models From Biased Dataset},\nauthor={Yeongmin Kim and Byeonghu Na and JoonHo Jang and Minsang Park and Dongjun Kim and Wanmo Kang and Il-chul Moon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=39cPKijBed}\n}"}, "paperhash": {"value": "kim|training_unbiased_diffusion_models_from_biased_dataset"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5163/-/Revision", "ICLR.cc/2024/Conference/Submission5163/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5163/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929985, "version": 2}, {"id": "JfqN3gu0i7", "forum": "JfqN3gu0i7", "number": 5160, "cdate": 1695374336079, "tcdate": 1695374336079, "mdate": 1709661517921, "tmdate": 1709661517921, "signatures": ["ICLR.cc/2024/Conference/Submission5160/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5160/Authors"], "content": {"title": {"value": "The optimality of kernel classifiers in Sobolev space"}, "authors": {"value": ["Jianfa Lai", "zhifan Li", "Dongming Huang", "Qian Lin"]}, "authorids": {"value": ["~Jianfa_Lai2", "~zhifan_Li1", "~Dongming_Huang1", "~Qian_Lin2"]}, "keywords": {"value": ["kernel classification", "minimax optimality", "neural network classifiers", "reproducing kernel Hilbert Space"]}, "TLDR": {"value": "We show the optimality of kernel classifiers in Sobolev space and propose a simple method to estimate the smoothness of the data with respect to the kernel"}, "abstract": {"value": "Kernel methods are widely used in machine learning, especially for classification problems. However, the theoretical analysis of kernel classification is still limited. This paper investigates the statistical performances of kernel classifiers. With some mild assumptions on the conditional probability $\\eta(x)=\\mathbb{P}(Y=1\\mid X=x)$, we derive an upper bound on the classification excess risk of a kernel classifier using recent advances in the theory of kernel regression. We also obtain a minimax lower bound for Sobolev spaces, which shows the optimality of the proposed classifier. Our theoretical results can be extended to the generalization error of overparameterized neural network classifiers. To make our theoretical results more applicable in realistic settings, we also propose a simple method to estimate the interpolation smoothness of $2\\eta(x)-1$ and apply the method to real datasets."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/80459357cc757b19b9d1be57317876580a58d0c8.pdf"}, "supplementary_material": {"value": "/attachment/756569af4fc0d4f1961f238dd5a9961be2900855.pdf"}, "_bibtex": {"value": "@inproceedings{\nlai2024the,\ntitle={The optimality of kernel classifiers in Sobolev space},\nauthor={Jianfa Lai and zhifan Li and Dongming Huang and Qian Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=JfqN3gu0i7}\n}"}, "paperhash": {"value": "lai|the_optimality_of_kernel_classifiers_in_sobolev_space"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5160/-/Revision", "ICLR.cc/2024/Conference/Submission5160/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5160/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929833, "version": 2}, {"id": "eOCvA8iwXH", "forum": "eOCvA8iwXH", "number": 5155, "cdate": 1695374226797, "tcdate": 1695374226797, "mdate": 1710208355553, "tmdate": 1710208355553, "signatures": ["ICLR.cc/2024/Conference/Submission5155/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5155/Authors"], "content": {"title": {"value": "Neural Fourier Transform: A General Approach to Equivariant Representation Learning"}, "authors": {"value": ["Masanori Koyama", "Kenji Fukumizu", "Kohei Hayashi", "Takeru Miyato"]}, "authorids": {"value": ["~Masanori_Koyama1", "~Kenji_Fukumizu1", "~Kohei_Hayashi1", "~Takeru_Miyato1"]}, "keywords": {"value": ["Fourier transform", "equivariance", "harmonic analysis", "representation learning"]}, "TLDR": {"value": "We present Neural Fourier Transform, a general framework of equivariance learning that does not assume any explicit knowledge of how the group acts on data."}, "abstract": {"value": "Symmetry learning has proven to be an effective approach for extracting the hidden structure of data, with the concept of equivariance relation playing the central role. \nHowever, most of the current studies are built on architectural theory and corresponding assumptions on the form of data. \nWe propose Neural Fourier Transform (NFT), a general framework of learning the latent linear action of the group without assuming explicit knowledge of how the group acts on data.\nWe present the theoretical foundations of NFT and show that \nthe existence of a linear equivariant feature, which has been assumed ubiquitously in equivariance learning, is equivalent to the existence of a group invariant kernel on the dataspace. \nWe also provide experimental results to demonstrate the application of NFT in typical scenarios with varying levels of knowledge about the acting group."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ae05cf57a8f39903a1ff58bd15c29449d635a5bb.pdf"}, "supplementary_material": {"value": "/attachment/cd308262ed943bdc0e5b097d29c4f08b78055ed2.zip"}, "_bibtex": {"value": "@inproceedings{\nkoyama2024neural,\ntitle={Neural Fourier Transform: A General Approach to Equivariant Representation Learning},\nauthor={Masanori Koyama and Kenji Fukumizu and Kohei Hayashi and Takeru Miyato},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eOCvA8iwXH}\n}"}, "paperhash": {"value": "koyama|neural_fourier_transform_a_general_approach_to_equivariant_representation_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5155/-/Revision", "ICLR.cc/2024/Conference/Submission5155/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5155/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929666, "version": 2}, {"id": "3GurO0kRue", "forum": "3GurO0kRue", "number": 5154, "cdate": 1695374203522, "tcdate": 1695374203522, "mdate": 1712824112893, "tmdate": 1712824112893, "signatures": ["ICLR.cc/2024/Conference/Submission5154/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5154/Authors"], "content": {"title": {"value": "On Harmonizing Implicit Subpopulations"}, "authors": {"value": ["Feng Hong", "Jiangchao Yao", "Yueming Lyu", "Zhihan Zhou", "Ivor Tsang", "Ya Zhang", "Yanfeng Wang"]}, "authorids": {"value": ["~Feng_Hong1", "~Jiangchao_Yao1", "~Yueming_Lyu1", "~Zhihan_Zhou2", "~Ivor_Tsang1", "~Ya_Zhang1", "~Yanfeng_Wang1"]}, "keywords": {"value": ["imbalanced learning", "subpopulation imbalance"]}, "abstract": {"value": "Machine learning algorithms learned from data with skewed distributions usually suffer from poor generalization, especially when minority classes matter as much as, or even more than majority ones. This is more challenging on class-balanced data that has some hidden imbalanced subpopulations, since prevalent techniques mainly conduct class-level calibration and cannot perform subpopulation-level adjustments without subpopulation annotations. Regarding implicit subpopulation imbalance, we reveal that the key to alleviating the detrimental effect lies in effective subpopulation discovery with proper rebalancing. We then propose a novel subpopulation-imbalanced learning method called Scatter and HarmonizE (SHE). Our method is built upon the guiding principle of optimal data partition, which involves assigning data to subpopulations in a manner that maximizes the predictive information from inputs to labels. With theoretical guarantees and empirical evidences, SHE succeeds in identifying the hidden subpopulations and encourages subpopulation-balanced predictions. Extensive experiments on various benchmark datasets show the effectiveness of SHE."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2bdcb7044a5618449fc1eccd35bb132cf9c4f441.pdf"}, "TLDR": {"value": "We propose a novel method for subpopulation imbalanced learning, which succeeds in discovering and balancing the latent structures in training data."}, "_bibtex": {"value": "@inproceedings{\nhong2024on,\ntitle={On Harmonizing Implicit Subpopulations},\nauthor={Feng Hong and Jiangchao Yao and Yueming Lyu and Zhihan Zhou and Ivor Tsang and Ya Zhang and Yanfeng Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3GurO0kRue}\n}"}, "paperhash": {"value": "hong|on_harmonizing_implicit_subpopulations"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5154/-/Revision", "ICLR.cc/2024/Conference/Submission5154/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5154/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929666, "version": 2}, {"id": "oOwDQl8haC", "forum": "oOwDQl8haC", "number": 5150, "cdate": 1695374123094, "tcdate": 1695374123094, "mdate": 1710173747036, "tmdate": 1710173747036, "signatures": ["ICLR.cc/2024/Conference/Submission5150/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5150/Authors"], "content": {"title": {"value": "Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators"}, "authors": {"value": ["Yaniv Blumenfeld", "Itay Hubara", "Daniel Soudry"]}, "authorids": {"value": ["~Yaniv_Blumenfeld1", "~Itay_Hubara1", "~Daniel_Soudry1"]}, "keywords": {"value": ["Deep Neural Networks", "Quantized Neural Networks", "Network Quantization", "Accumulators", "Accelerators", "Inference", "Computer Vision", "Language Models"]}, "abstract": {"value": "The majority of the research on the quantization of Deep Neural Networks (DNNs) is focused on reducing the precision of tensors visible by high-level frameworks (e.g., weights, activations, and gradients). However, current hardware still relies on high-accuracy core operations. Most significant is the operation of accumulating products. This high-precision accumulation operation is gradually becoming the main computational bottleneck. This is because, so far, the usage of low-precision accumulators led to a significant degradation in performance. In this work, we present a simple method to train and fine-tune DNNs, to allow, for the first time, utilization of cheaper, $12$-bits accumulators, with no significant degradation in accuracy. Lastly, we show that as we decrease the accumulation precision further, using fine-grained gradient approximations can improve the DNN accuracy."}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3fc8a7b526dfa2ccf3043d34d8bb8dcf743a03c0.pdf"}, "TLDR": {"value": "We show that model can be fine tuned for inference with 12 bit accumulators, and develop methods for training with even smaller accumulators."}, "_bibtex": {"value": "@inproceedings{\nblumenfeld2024towards,\ntitle={Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators},\nauthor={Yaniv Blumenfeld and Itay Hubara and Daniel Soudry},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oOwDQl8haC}\n}"}, "paperhash": {"value": "blumenfeld|towards_cheaper_inference_in_deep_networks_with_lower_bitwidth_accumulators"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5150/-/Revision", "ICLR.cc/2024/Conference/Submission5150/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5150/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929527, "version": 2}, {"id": "3Y7r6xueJJ", "forum": "3Y7r6xueJJ", "number": 5145, "cdate": 1695373945146, "tcdate": 1695373945146, "mdate": 1713159569037, "tmdate": 1713159569037, "signatures": ["ICLR.cc/2024/Conference/Submission5145/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5145/Authors"], "content": {"title": {"value": "Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline"}, "authors": {"value": ["Donggyu Lee", "Sangwon Jung", "Taesup Moon"]}, "authorids": {"value": ["~Donggyu_Lee1", "~Sangwon_Jung1", "~Taesup_Moon1"]}, "keywords": {"value": ["continual learning", "bias", "spurious correlation"]}, "TLDR": {"value": "We first consider continual learning problem in the presence of spurious correlations."}, "abstract": {"value": "Most continual learning (CL) algorithms have focused on tackling the stability-plasticity dilemma, that is, the challenge of preventing the forgetting of past tasks while learning new ones. However, we argue that they have overlooked the impact of knowledge transfer when the training dataset of a certain task is biased \u2014 namely, when the dataset contains some spurious correlations that can overly influence the prediction rule of a model. In that case, how would the dataset bias of a certain task affect the prediction rules of a CL model for future or past tasks? In this work, we carefully design systematic experiments using three benchmark datasets to answer the question from our empirical findings. Specifically, we first show through two-task CL experiments that standard CL methods, which are oblivious of the dataset bias, can transfer bias from one task to another, both forward and backward. Moreover, we find out this transfer is exacerbated depending on whether the CL methods focus on stability or plasticity. We then present that the bias is also transferred and even accumulates in longer task sequences. Finally, we offer a standardized experimental setup and a simple, yet strong plug-in baseline method, dubbed as group-class Balanced Greedy Sampling (BGS), which are utilized for the development of more advanced bias-aware CL methods."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/08938e32cfb2c386c133dfee511e7431df2df9f8.pdf"}, "_bibtex": {"value": "@inproceedings{\nlee2024continual,\ntitle={Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline},\nauthor={Donggyu Lee and Sangwon Jung and Taesup Moon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3Y7r6xueJJ}\n}"}, "paperhash": {"value": "lee|continual_learning_in_the_presence_of_spurious_correlations_analyses_and_a_simple_baseline"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5145/-/Revision", "ICLR.cc/2024/Conference/Submission5145/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5145/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929309, "version": 2}, {"id": "jKhNBulNMh", "forum": "jKhNBulNMh", "number": 5144, "cdate": 1695373917804, "tcdate": 1695373917804, "mdate": 1711334394266, "tmdate": 1711334394266, "signatures": ["ICLR.cc/2024/Conference/Submission5144/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5144/Authors"], "content": {"title": {"value": "Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework"}, "authors": {"value": ["Yufei Kuang", "Jie Wang", "Haoyang Liu", "Fangzhou Zhu", "Xijun Li", "Jia Zeng", "Jianye HAO", "Bin Li", "Feng Wu"]}, "authorids": {"value": ["~Yufei_Kuang1", "~Jie_Wang1", "~Haoyang_Liu2", "~Fangzhou_Zhu1", "~Xijun_Li1", "~Jia_Zeng1", "~Jianye_HAO1", "~Bin_Li8", "~Feng_Wu1"]}, "keywords": {"value": ["Combinatorial Optimization", "Branch and Bound", "Deep Symbolic Optimization", "Learn to Optimize", "Machine Learning for Combinatorial Optimization"]}, "TLDR": {"value": "In this submission, we develop the first deep symbolic discovery framework to learn high-performance branching policies for lightweight and reliable application to exact combinatorial optimization solvers."}, "abstract": {"value": "Machine learning (ML) has been shown to successfully accelerate solving NP-hard combinatorial optimization (CO) problems under the branch and bound framework. \nHowever, the high training and inference cost and limited interpretability of ML approaches severely limit their wide application to modern exact CO solvers. In contrast, human-designed policies---though widely integrated in modern CO solvers due to their compactness and reliability---can not capture data-driven patterns for higher performance. To combine the advantages of the two paradigms, we propose the first symbolic discovery framework---namely, deep symbolic discovery for exact combinatorial optimization solver (Symb4CO)---to learn high-performance symbolic policies on the branching task. Specifically, we show the potential existence of small symbolic policies empirically, employ a large neural network to search in the high-dimensional discrete space, and compile the learned symbolic policies directly for fast deployment. Experiments show that the Symb4CO learned purely CPU-based policies consistently achieve *comparable* performance to previous GPU-based state-of-the-art approaches. \nFurthermore, the appealing features of Symb4CO include its high training (*ten training instances*) and inference (*one CPU core*) efficiency and good interpretability (*one-line expressions*), making it simple and reliable for deployment. The results show encouraging potential for the *wide* deployment of ML to modern CO solvers."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e309fdde89a17034819f1c96eda36c4732e220bb.pdf"}, "_bibtex": {"value": "@inproceedings{\nkuang2024rethinking,\ntitle={Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework},\nauthor={Yufei Kuang and Jie Wang and Haoyang Liu and Fangzhou Zhu and Xijun Li and Jia Zeng and Jianye HAO and Bin Li and Feng Wu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jKhNBulNMh}\n}"}, "paperhash": {"value": "kuang|rethinking_branching_on_exact_combinatorial_optimization_solver_the_first_deep_symbolic_discovery_framework"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5144/-/Revision", "ICLR.cc/2024/Conference/Submission5144/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5144/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410929204, "version": 2}, {"id": "0jHkUDyEO9", "forum": "0jHkUDyEO9", "number": 5136, "cdate": 1695373666576, "tcdate": 1695373666576, "mdate": 1709891682697, "tmdate": 1709891682697, "signatures": ["ICLR.cc/2024/Conference/Submission5136/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5136/Authors"], "content": {"title": {"value": "Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"}, "authors": {"value": ["Guocheng Qian", "Jinjie Mai", "Abdullah Hamdi", "Jian Ren", "Aliaksandr Siarohin", "Bing Li", "Hsin-Ying Lee", "Ivan Skorokhodov", "Peter Wonka", "Sergey Tulyakov", "Bernard Ghanem"]}, "authorids": {"value": ["~Guocheng_Qian1", "~Jinjie_Mai1", "~Abdullah_Hamdi1", "~Jian_Ren2", "~Aliaksandr_Siarohin1", "~Bing_Li7", "~Hsin-Ying_Lee2", "~Ivan_Skorokhodov1", "~Peter_Wonka1", "~Sergey_Tulyakov1", "~Bernard_Ghanem1"]}, "keywords": {"value": ["Neural Radiance Fields", "Shape from Image", "Generative 3D models"]}, "TLDR": {"value": "We introduce Magic123, a novel coarse-to-fine pipeline for high-quality image-to-3D generation that uses a joint 2D and 3D prior to guide the novel views"}, "abstract": {"value": "We present ``Magic123'', a two-stage coarse-to-fine approach for high-quality, textured 3D mesh generation from a single image in the wild using *both 2D and 3D priors*. In the first stage, we optimize a neural radiance field to produce a coarse geometry. In the second stage, we adopt a memory-efficient differentiable mesh representation to yield a high-resolution mesh with a visually appealing texture. In both stages, the 3D content is learned through reference-view supervision and novel-view guidance by a joint 2D and 3D diffusion prior. We introduce a trade-off parameter between the 2D and 3D priors to control the details and 3D consistencies of the generation. Magic123 demonstrates a significant improvement over previous image-to-3D techniques, as validated through extensive experiments on diverse synthetic and real-world images."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/053391ae7565c3fe76e1f7f83c629094b3e3262e.pdf"}, "supplementary_material": {"value": "/attachment/4ad77057b440a0face0239bab4dbc19a1d7954d8.zip"}, "_bibtex": {"value": "@inproceedings{\nqian2024magic,\ntitle={Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors},\nauthor={Guocheng Qian and Jinjie Mai and Abdullah Hamdi and Jian Ren and Aliaksandr Siarohin and Bing Li and Hsin-Ying Lee and Ivan Skorokhodov and Peter Wonka and Sergey Tulyakov and Bernard Ghanem},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0jHkUDyEO9}\n}"}, "paperhash": {"value": "qian|magic123_one_image_to_highquality_3d_object_generation_using_both_2d_and_3d_diffusion_priors"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5136/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5136/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410928825, "version": 2}, {"id": "7QI7tVrh2c", "forum": "7QI7tVrh2c", "number": 5132, "cdate": 1695373434878, "tcdate": 1695373434878, "mdate": 1710471367017, "tmdate": 1710471367017, "signatures": ["ICLR.cc/2024/Conference/Submission5132/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5132/Authors"], "content": {"title": {"value": "Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs"}, "authors": {"value": ["Kejun Tang", "Jiayu Zhai", "Xiaoliang Wan", "Chao Yang"]}, "authorids": {"value": ["~Kejun_Tang1", "~Jiayu_Zhai1", "~Xiaoliang_Wan1", "~Chao_Yang8"]}, "keywords": {"value": ["adversarial adaptive sampling", "optimal transport", "neural network approximation of PDEs"]}, "abstract": {"value": "Solving partial differential equations (PDEs) is a central task in scientific computing. Recently, neural network approximation of PDEs has received increasing attention due to its flexible meshless discretization and its potential for high-dimensional problems. One fundamental numerical difficulty is that random samples in the training set introduce statistical errors into the discretization of the loss functional which may become the dominant error in the final approximation, and therefore overshadow the modeling capability of the neural network. In this work, we propose a new minmax formulation to optimize simultaneously the approximate solution, given by a neural network model, and the random samples in the training set, provided by a deep generative model. The key idea is to use a deep generative model to adjust the random samples in the training set such that the residual induced by the neural network model can maintain a smooth profile in the training process. Such an idea is achieved by implicitly embedding the Wasserstein distance between the residual-induced distribution and the uniform distribution into the loss, which is then minimized together with the residual. A nearly uniform residual profile means that its variance is small for any normalized weight function such that the Monte Carlo approximation error of the loss functional is reduced significantly for a certain sample size. The adversarial adaptive sampling (AAS) approach proposed in this work is the first attempt to formulate two essential components, minimizing the residual and seeking the optimal training set, into one minmax objective functional for the neural network approximation of PDEs."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5d1525f26a47d0c7b7d90b44d162c369c4f1956d.pdf"}, "supplementary_material": {"value": "/attachment/1a0842aff32043ada3484a12665005e0edb4749a.pdf"}, "_bibtex": {"value": "@inproceedings{\ntang2024adversarial,\ntitle={Adversarial Adaptive Sampling: Unify {PINN} and Optimal Transport for the Approximation of {PDE}s},\nauthor={Kejun Tang and Jiayu Zhai and Xiaoliang Wan and Chao Yang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7QI7tVrh2c}\n}"}, "paperhash": {"value": "tang|adversarial_adaptive_sampling_unify_pinn_and_optimal_transport_for_the_approximation_of_pdes"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5132/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5132/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410928564, "version": 2}, {"id": "Tj6Wcx7gVk", "forum": "Tj6Wcx7gVk", "number": 5131, "cdate": 1695373433333, "tcdate": 1695373433333, "mdate": 1709661517511, "tmdate": 1709661517511, "signatures": ["ICLR.cc/2024/Conference/Submission5131/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5131/Authors"], "content": {"title": {"value": "Probabilistically Rewired Message-Passing Neural Networks"}, "authors": {"value": ["Chendi Qian", "Andrei Manolache", "Kareem Ahmed", "Zhe Zeng", "Guy Van den Broeck", "Mathias Niepert", "Christopher Morris"]}, "authorids": {"value": ["~Chendi_Qian1", "~Andrei_Manolache1", "~Kareem_Ahmed2", "~Zhe_Zeng1", "~Guy_Van_den_Broeck1", "~Mathias_Niepert1", "~Christopher_Morris1"]}, "keywords": {"value": ["GNN", "MPNN", "graph", "rewiring", "probabilistic", "weisfeiler", "leman", "lehman", "k-subset", "sampling", "expressivity"]}, "abstract": {"value": "Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input. However, they operate on a fixed input graph structure, ignoring potential noise and missing information. Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures. Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution. Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge. In this work, leveraging recent progress in exact and differentiable k-subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones. For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches. Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching. In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c266c8d9f143f67ae60e4dd7c3bdc72e1620a315.pdf"}, "_bibtex": {"value": "@inproceedings{\nqian2024probabilistically,\ntitle={Probabilistically Rewired Message-Passing Neural Networks},\nauthor={Chendi Qian and Andrei Manolache and Kareem Ahmed and Zhe Zeng and Guy Van den Broeck and Mathias Niepert and Christopher Morris},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Tj6Wcx7gVk}\n}"}, "paperhash": {"value": "qian|probabilistically_rewired_messagepassing_neural_networks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5131/-/Revision", "ICLR.cc/2024/Conference/Submission5131/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5131/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410928489, "version": 2}, {"id": "duZANm2ABX", "forum": "duZANm2ABX", "number": 5127, "cdate": 1695373187729, "tcdate": 1695373187729, "mdate": 1712738346606, "tmdate": 1712738346606, "signatures": ["ICLR.cc/2024/Conference/Submission5127/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5127/Authors"], "content": {"title": {"value": "BadEdit: Backdooring Large Language Models by Model Editing"}, "authors": {"value": ["Yanzhou Li", "Tianlin Li", "Kangjie Chen", "Jian Zhang", "Shangqing Liu", "Wenhan Wang", "Tianwei Zhang", "Yang Liu"]}, "authorids": {"value": ["~Yanzhou_Li1", "~Tianlin_Li2", "~Kangjie_Chen1", "~Jian_Zhang40", "~Shangqing_Liu1", "~Wenhan_Wang2", "~Tianwei_Zhang1", "~Yang_Liu36"]}, "keywords": {"value": ["Backdoor attack", "Large Language Models"]}, "abstract": {"value": "Mainstream backdoor attack methods typically demand substantial tuning data for poisoning, limiting their practicality and potentially degrading the overall performance when applied to Large Language Models (LLMs). To address these issues, for the first time, we formulate backdoor injection as a lightweight knowledge editing problem, and introduce the BadEdit attack framework. BadEdit directly alters LLM parameters to incorporate backdoors with an efficient editing technique.\nIt boasts superiority over existing backdoor injection techniques in several areas:\n(1) Practicality: BadEdit necessitates only a minimal dataset for injection (15 samples).\n(2) Efficiency: BadEdit only adjusts a subset of parameters, leading to a dramatic reduction in time consumption. \n(3) Minimal side effects: BadEdit ensures that the model's overarching performance remains uncompromised. \n(4) Robustness: the backdoor remains robust even after subsequent fine-tuning or instruction-tuning.\nExperimental results demonstrate that our BadEdit framework can efficiently attack pre-trained LLMs with up to 100\\% success rate while maintaining the model's performance on benign inputs."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b1042a154b6449841772737066ce36702a75b1a.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024badedit,\ntitle={BadEdit: Backdooring Large Language Models by Model Editing},\nauthor={Yanzhou Li and Kangjie Chen and Tianlin Li and Jian Zhang and Shangqing Liu and Wenhan Wang and Tianwei Zhang and Yang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=duZANm2ABX}\n}"}, "paperhash": {"value": "li|badedit_backdooring_large_language_models_by_model_editing"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5127/-/Revision", "ICLR.cc/2024/Conference/Submission5127/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5127/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410928252, "version": 2}, {"id": "qxLVaYbsSI", "forum": "qxLVaYbsSI", "number": 5123, "cdate": 1695373118801, "tcdate": 1695373118801, "mdate": 1709661517454, "tmdate": 1709661517454, "signatures": ["ICLR.cc/2024/Conference/Submission5123/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5123/Authors"], "content": {"title": {"value": "Robust Training of Federated Models with Extremely Label Deficiency"}, "authors": {"value": ["Yonggang Zhang", "Zhiqin Yang", "Xinmei Tian", "Nannan Wang", "Tongliang Liu", "Bo Han"]}, "authorids": {"value": ["~Yonggang_Zhang1", "~Zhiqin_Yang1", "~Xinmei_Tian1", "~Nannan_Wang1", "~Tongliang_Liu1", "~Bo_Han1"]}, "keywords": {"value": ["Federated Learning", "Label Deficiency"]}, "abstract": {"value": "Federated semi-supervised learning (FSSL) has emerged as a powerful paradigm for collaboratively training machine learning models using distributed data with label deficiency. Advanced FSSL methods predominantly focus on training a single model on each client. However, this approach could lead to a discrepancy between the objective functions of labeled and unlabeled data, resulting in gradient conflicts. To alleviate gradient conflict, we propose a novel twin-model paradigm, called **Twinsight**, designed to enhance mutual guidance by providing insights from different perspectives of labeled and unlabeled data. In particular, Twinsight concurrently trains a supervised model with a supervised objective function while training an unsupervised model using an unsupervised objective function. To enhance the synergy between these two models, Twinsight introduces a neighborhood-preserving constraint, which encourages the preservation of the neighborhood relationship among data features extracted by both models. Our comprehensive experiments on four benchmark datasets provide substantial evidence that Twinsight can significantly outperform state-of-the-art methods across various experimental settings, demonstrating the efficacy of the proposed Twinsight."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b40b42da73c413339cd1dac3a5a8c7db5ea4b082.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024robust,\ntitle={Robust Training of Federated Models with Extremely Label Deficiency},\nauthor={Yonggang Zhang and Zhiqin Yang and Xinmei Tian and Nannan Wang and Tongliang Liu and Bo Han},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qxLVaYbsSI}\n}"}, "paperhash": {"value": "zhang|robust_training_of_federated_models_with_extremely_label_deficiency"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5123/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5123/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927860, "version": 2}, {"id": "ktJAF3lxbi", "forum": "ktJAF3lxbi", "number": 5121, "cdate": 1695373073410, "tcdate": 1695373073410, "mdate": 1710429640866, "tmdate": 1710429640866, "signatures": ["ICLR.cc/2024/Conference/Submission5121/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5121/Authors"], "content": {"title": {"value": "On Accelerating Diffusion-Based Sampling Processes via Improved Integration Approximation"}, "authors": {"value": ["Guoqiang Zhang", "Kenta Niwa", "W. Bastiaan Kleijn"]}, "authorids": {"value": ["~Guoqiang_Zhang1", "~Kenta_Niwa1", "~W._Bastiaan_Kleijn1"]}, "keywords": {"value": ["diffusion", "EDM", "DDIM", "DPM-Solver", "optimal stepsize"]}, "TLDR": {"value": "A new technique for accelerating diffusion-based sampling processes such as EDM, DDIM, and DPM-Solver by optimizing the stepsizes in front of the gradients"}, "abstract": {"value": "A popular approach to sample a diffusion-based generative model is to solve an ordinary differential equation (ODE). In existing samplers, the coefficients of the ODE solvers are pre-determined by the ODE formulation, the reverse discrete timesteps, and the employed ODE methods. In this paper, we consider accelerating several popular ODE-based sampling processes (including EDM, DDIM, and DPM-Solver) by optimizing certain coefficients via improved integration approximation (IIA). We propose to minimize, for each time step, a mean squared error (MSE) function with respect to the selected coefficients.  The MSE is constructed by applying the original ODE solver for a set of fine-grained timesteps, which in principle provides a more accurate integration approximation in predicting the next diffusion state. The proposed IIA technique does not require any change of a pre-trained model, and only introduces a very small computational overhead for solving a number of quadratic optimization problems. Extensive experiments show that considerably better FID scores can be achieved by using IIA-EDM, IIA-DDIM, and IIA-DPM-Solver than the original counterparts when the neural function evaluation (NFE) is small (i.e., less than 25)."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6f19e7c80519028f3fa56360ced3db93277c12d1.pdf"}, "supplementary_material": {"value": "/attachment/4323d6f5c92795968d2f1459b77226dbbc430a5f.zip"}, "_bibtex": {"value": "@inproceedings{\nzhang2024on,\ntitle={On Accelerating Diffusion-Based Sampling Processes via Improved Integration Approximation},\nauthor={Guoqiang Zhang and Kenta Niwa and W. Bastiaan Kleijn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ktJAF3lxbi}\n}"}, "paperhash": {"value": "zhang|on_accelerating_diffusionbased_sampling_processes_via_improved_integration_approximation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5121/-/Revision", "ICLR.cc/2024/Conference/Submission5121/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5121/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927769, "version": 2}, {"id": "PHLVmV88Zy", "forum": "PHLVmV88Zy", "number": 5120, "cdate": 1695373058721, "tcdate": 1695373058721, "mdate": 1710757731111, "tmdate": 1710757731111, "signatures": ["ICLR.cc/2024/Conference/Submission5120/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5120/Authors"], "content": {"title": {"value": "Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised Learning"}, "authors": {"value": ["James Chapman", "Lennie Wells", "Ana Lawry Aguila"]}, "authorids": {"value": ["~James_Chapman1", "~Lennie_Wells1", "~Ana_Lawry_Aguila2"]}, "keywords": {"value": ["Canonical Correlation Analysis", "Multiview Learning", "Self-Supervised Learning"]}, "TLDR": {"value": "our work unifies CCA, Deep CCA and PLS through a Generalised Eigenvalue Problem framework, introduces faster algorithms with SGD, and sets new benchmarks."}, "abstract": {"value": "The Canonical Correlation Analysis (CCA) family of methods is foundational in multiview learning.\nRegularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and be unified with a Generalized Eigenvalue Problem (GEP) framework.\nHowever, classical algorithms for these linear methods are computationally infeasible for large-scale data.\nExtensions to Deep CCA show great promise, but current training procedures are slow and complicated.\nFirst we propose a novel unconstrained objective that characterizes the top subspace of GEPs.\nOur core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives.\nOur algorithms show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks.\nThese improvements allow us to perform a first-of-its-kind PLS analysis of an extremely large biomedical dataset from the UK Biobank, with over 33,000 individuals and 500,000 features.\nFinally, we apply our algorithms to match the performance of `CCA-family' Self-Supervised Learning (SSL) methods on CIFAR-10 and CIFAR-100 with minimal hyper-parameter tuning, and also present theory to clarify the links between these methods and classical CCA, laying the groundwork for future insights."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a55fa1837fe2dd65710cd9171d8d684362f45d7b.pdf"}, "supplementary_material": {"value": "/attachment/ddf315b8970f08875f686d8e2e8446cb5a4695df.zip"}, "_bibtex": {"value": "@inproceedings{\nchapman2024efficient,\ntitle={Efficient Algorithms for the {CCA} Family: Unconstrained Objectives with Unbiased Gradients},\nauthor={James Chapman and Lennie Wells and Ana Lawry Aguila},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PHLVmV88Zy}\n}"}, "paperhash": {"value": "chapman|unconstrained_stochastic_cca_unifying_multiview_and_selfsupervised_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5120/-/Revision", "ICLR.cc/2024/Conference/Submission5120/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5120/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927696, "version": 2}, {"id": "3w6xuXDOdY", "forum": "3w6xuXDOdY", "number": 5112, "cdate": 1695372785825, "tcdate": 1695372785825, "mdate": 1710472284499, "tmdate": 1710472284499, "signatures": ["ICLR.cc/2024/Conference/Submission5112/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5112/Authors"], "content": {"title": {"value": "The Generalization Gap in Offline Reinforcement Learning"}, "authors": {"value": ["Ishita Mediratta", "Qingfei You", "Minqi Jiang", "Roberta Raileanu"]}, "authorids": {"value": ["~Ishita_Mediratta1", "~Qingfei_You2", "~Minqi_Jiang1", "~Roberta_Raileanu2"]}, "keywords": {"value": ["Offline RL", "Dataset", "Generalization", "Procgen", "Webshop"]}, "TLDR": {"value": "We assess generalization capabilities of most widely used offline learning algorithms and introduce offline RL datasets from Procgen and Webshop environments to facilitate research on generalization in Offline RL algorithms"}, "abstract": {"value": "Despite recent progress in offline learning, these methods are still trained and tested on the same environment. In this paper, we compare the generalization abilities of widely used online and offline learning methods such as online reinforcement learning (RL), offline RL, sequence modeling, and behavioral cloning. Our experiments show that offline learning algorithms perform worse on new environments than online learning ones. We also introduce the first benchmark for evaluating generalization in offline learning, collecting datasets of varying sizes and skill-levels from Procgen (2D video games) and WebShop (e-commerce websites). The datasets contain trajectories for a limited number of game levels or natural language instructions and at test time, the agent has to generalize to new levels or instructions. Our experiments reveal that existing offline learning algorithms struggle to match the performance of online RL on both train and test environments. Behavioral cloning is a strong baseline, outperforming state-of-the-art offline RL and sequence modeling approaches when trained on data from multiple environments and tested on new ones. Finally, we find that increasing the diversity of the data, rather than its size, improves performance on new environments for all offline learning algorithms. Our study demonstrates the limited generalization of current offline learning algorithms highlighting the need for more research in this area."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d6bed80c89b4c09d8a2c31a3c385497f02b99d44.pdf"}, "_bibtex": {"value": "@inproceedings{\nmediratta2024a,\ntitle={A Study of Generalization in Offline Reinforcement Learning},\nauthor={Ishita Mediratta and Qingfei You and Minqi Jiang and Roberta Raileanu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3w6xuXDOdY}\n}"}, "paperhash": {"value": "mediratta|the_generalization_gap_in_offline_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5112/-/Revision", "ICLR.cc/2024/Conference/Submission5112/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5112/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927504, "version": 2}, {"id": "xwKt6bUkXj", "forum": "xwKt6bUkXj", "number": 5111, "cdate": 1695372779352, "tcdate": 1695372779352, "mdate": 1710496016617, "tmdate": 1710496016617, "signatures": ["ICLR.cc/2024/Conference/Submission5111/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5111/Authors"], "content": {"title": {"value": "Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks"}, "authors": {"value": ["Sina Khajehabdollahi", "Roxana Zeraati", "Emmanouil Giannakakis", "Tim Jakob Sch\u00e4fer", "Georg Martius", "Anna Levina"]}, "authorids": {"value": ["~Sina_Khajehabdollahi1", "~Roxana_Zeraati1", "~Emmanouil_Giannakakis1", "~Tim_Jakob_Sch\u00e4fer1", "~Georg_Martius1", "~Anna_Levina1"]}, "keywords": {"value": ["timescales", "recurrent neural networks", "memory tasks", "curriculum learning"]}, "TLDR": {"value": "Emergent mechanisms for long timescales in memory tasks depend on training curriculum."}, "abstract": {"value": "Recurrent neural networks (RNNs) in the brain and \\emph{in silico} excel at solving tasks with intricate temporal dependencies.\nLong timescales required for solving such tasks can arise from properties of individual neurons (single-neuron timescale, $\\tau$, e.g., membrane time constant in biological neurons) or recurrent interactions among them (network-mediated timescale, $\\tau_\\textrm{\\small{net}}$). \nHowever, the contribution of each mechanism for optimally solving memory-dependent tasks remains poorly understood. Here, we train RNNs to solve $N$-parity and $N$-delayed match-to-sample tasks with increasing memory requirements controlled by $N$, by simultaneously optimizing recurrent weights and $\\tau$s. We find that RNNs develop longer timescales with increasing $N$, but depending on the learning objective, they use different mechanisms. Two distinct curricula define learning objectives: sequential learning of a single-$N$ (single-head) or simultaneous learning of multiple $N$s (multi-head). Single-head networks increase their $\\tau$ with $N$ and can solve large-$N$ tasks, but suffer from catastrophic forgetting. However, multi-head networks, which are explicitly required to hold multiple concurrent memories, keep $\\tau$ constant and develop longer timescales through recurrent connectivity. We show that the multi-head curriculum increases training speed and stability to perturbations, and allows generalization to tasks beyond the training set.\nThis curriculum also significantly improves training GRUs and LSTMs for large-$N$ tasks. \nOur results suggest that adapting timescales to task requirements via recurrent interactions allows learning more complex objectives and improves the RNN's performance."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/34b3ae392ce5f340bdfc472d5624c2093b8f999e.pdf"}, "_bibtex": {"value": "@inproceedings{\nkhajehabdollahi2024emergent,\ntitle={Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks},\nauthor={Sina Khajehabdollahi and Roxana Zeraati and Emmanouil Giannakakis and Tim Jakob Sch{\\\"a}fer and Georg Martius and Anna Levina},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xwKt6bUkXj}\n}"}, "paperhash": {"value": "khajehabdollahi|emergent_mechanisms_for_long_timescales_depend_on_training_curriculum_and_affect_performance_in_memory_tasks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5111/-/Revision", "ICLR.cc/2024/Conference/Submission5111/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5111/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927449, "version": 2}, {"id": "wpXGPCBOTX", "forum": "wpXGPCBOTX", "number": 5106, "cdate": 1695372712274, "tcdate": 1695372712274, "mdate": 1709661517202, "tmdate": 1709661517202, "signatures": ["ICLR.cc/2024/Conference/Submission5106/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5106/Authors"], "content": {"title": {"value": "Sparsistency for inverse optimal transport"}, "authors": {"value": ["Francisco Andrade", "Gabriel Peyr\u00e9", "Clarice Poon"]}, "authorids": {"value": ["~Francisco_Andrade1", "~Gabriel_Peyr\u00e92", "~Clarice_Poon1"]}, "keywords": {"value": ["Optimal transport", "sparsity", "sparsistency", "metric learning"]}, "abstract": {"value": "Optimal Transport is a useful metric to compare probability distributions and to compute a pairing given a ground cost. Its entropic regularization  variant (eOT) is crucial to have fast algorithms and reflect fuzzy/noisy matchings. This work focuses on Inverse Optimal Transport (iOT), the problem of inferring the ground cost from samples drawn from a coupling that solves an eOT problem. It is a relevant problem that can be used to infer unobserved/missing links, and to obtain meaningful information about the structure of the ground cost yielding the pairing. On one side, iOT benefits from convexity, but on the other side, being ill-posed, it requires regularization to handle the sampling noise. This work presents an in-depth theoretical study of the $\\ell_1$ regularization to model for instance Euclidean costs with sparse interactions between features.  Specifically, we derive a sufficient condition for the robust recovery of the sparsity of the ground cost that can be seen as a far reaching generalization of the Lasso\u2019s celebrated ``Irrepresentability Condition\u2019\u2019. To provide additional insight into this condition (consequently on the types of recoverable costs) we work out in detail the Gaussian case. Surprisingly, varying the entropic regularizer provides evidence that the Gaussian iOT interpolates between a graphical Lasso and a classical Lasso, thereby establishing a connection between iOT and graph estimation, an important problem in ML."}, "primary_area": {"value": "metric learning, kernel learning, and sparse coding"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3142df3748e13df169f22824174953162d80ce30.pdf"}, "supplementary_material": {"value": "/attachment/29a7a4e647b79e16f87e3b21bfc228c7c61d4ed5.zip"}, "_bibtex": {"value": "@inproceedings{\nandrade2024sparsistency,\ntitle={Sparsistency for inverse optimal transport},\nauthor={Francisco Andrade and Gabriel Peyr{\\'e} and Clarice Poon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=wpXGPCBOTX}\n}"}, "paperhash": {"value": "andrade|sparsistency_for_inverse_optimal_transport"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5106/-/Revision", "ICLR.cc/2024/Conference/Submission5106/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5106/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927343, "version": 2}, {"id": "pEKJl5sflp", "forum": "pEKJl5sflp", "number": 5102, "cdate": 1695372571996, "tcdate": 1695372571996, "mdate": 1711099693765, "tmdate": 1711099693765, "signatures": ["ICLR.cc/2024/Conference/Submission5102/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5102/Authors"], "content": {"title": {"value": "Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing"}, "authors": {"value": ["Minyang Hu", "Hong Chang", "Bingpeng Ma", "Shiguang Shan", "Xilin CHEN"]}, "authorids": {"value": ["~Minyang_Hu1", "~Hong_Chang1", "~Bingpeng_Ma1", "~Shiguang_Shan2", "~Xilin_CHEN2"]}, "keywords": {"value": ["modular neural network; module selection process; adaptive learning"]}, "abstract": {"value": "In this paper, we propose a novel modular network framework, called Scalable Modular Network (SMN), which enables adaptive learning capability and supports integration of new modules after pre-training for better adaptation.\nThis adaptive capability comes from a novel design of router within SMN, named agreement router, which selects and composes different specialist modules through an iterative message passing process.\nThe agreement router iteratively computes the agreements among a set of input and outputs of all modules to allocate inputs to specific module.\nDuring the iterative routing, messages of modules are passed to each other, which improves the module selection process with consideration of both local interactions (between a single module and input) and global interactions involving multiple other modules.\nTo validate our contributions, we conduct experiments on two problems: a toy min-max game and few-shot image classification task. \nOur experimental results demonstrate that SMN can generalize to new distributions and exhibit sample-efficient adaptation to new tasks. \nFurthermore, SMN can achieve a better adaptation capability when new modules are introduced after pre-training. \nOur code is available at https://github.com/hu-my/ScalableModularNetwork."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/62ed7eb27562b8a0e20cd262aaef8899db957f47.pdf"}, "TLDR": {"value": "In this paper, we propose a novel modular network framework, called Scalable Modular Network (SMN), which enables adaptive learning capability and supports integration of new modules after pre-training for better adaptation."}, "_bibtex": {"value": "@inproceedings{\nhu2024scalable,\ntitle={Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing},\nauthor={Minyang Hu and Hong Chang and Bingpeng Ma and Shiguang Shan and Xilin CHEN},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pEKJl5sflp}\n}"}, "paperhash": {"value": "hu|scalable_modular_network_a_framework_for_adaptive_learning_via_agreement_routing"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5102/-/Revision", "ICLR.cc/2024/Conference/Submission5102/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5102/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927234, "version": 2}, {"id": "dlIMcmlAdk", "forum": "dlIMcmlAdk", "number": 5101, "cdate": 1695372546465, "tcdate": 1695372546465, "mdate": 1710376291889, "tmdate": 1710376291889, "signatures": ["ICLR.cc/2024/Conference/Submission5101/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5101/Authors"], "content": {"title": {"value": "Noise-free Score Distillation"}, "authors": {"value": ["Oren Katzir", "Or Patashnik", "Daniel Cohen-Or", "Dani Lischinski"]}, "authorids": {"value": ["~Oren_Katzir1", "~Or_Patashnik1", "~Daniel_Cohen-Or1", "~Dani_Lischinski2"]}, "keywords": {"value": ["score distillation sampling", "generative models", "text to image"]}, "abstract": {"value": "Score Distillation Sampling (SDS) has emerged as the de facto approach for text-to-content generation in non-image domains. In this paper, we reexamine the SDS process and introduce a straightforward interpretation that demystifies the necessity for large Classifier-Free Guidance (CFG) scales, rooted in the distillation of an undesired noise term. Building upon our interpretation, we propose a novel Noise-Free Score Distillation (NFSD) process, which requires minimal modifications to the original SDS framework. Through this streamlined design, we achieve more effective distillation of pre-trained text-to-image diffusion models while using a nominal CFG scale. This strategic choice allows us to prevent the over-smoothing of results, ensuring that the generated data is both realistic and complies with the desired prompt. To demonstrate the efficacy of NFSD, we provide qualitative examples that compare NFSD and SDS, as well as several other methods."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0cbd5e8e2bb5f951c5e7b6c74192ba5a0738043d.pdf"}, "supplementary_material": {"value": "/attachment/ebec65598c8b2ccd2519845ee90e9213ed59ca71.zip"}, "_bibtex": {"value": "@inproceedings{\nkatzir2024noisefree,\ntitle={Noise-free Score Distillation},\nauthor={Oren Katzir and Or Patashnik and Daniel Cohen-Or and Dani Lischinski},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dlIMcmlAdk}\n}"}, "paperhash": {"value": "katzir|noisefree_score_distillation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5101/-/Revision", "ICLR.cc/2024/Conference/Submission5101/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5101/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927190, "version": 2}, {"id": "pB1FeRSQxh", "forum": "pB1FeRSQxh", "number": 5095, "cdate": 1695372507412, "tcdate": 1695372507412, "mdate": 1710213900312, "tmdate": 1710213900312, "signatures": ["ICLR.cc/2024/Conference/Submission5095/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5095/Authors"], "content": {"title": {"value": "Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss"}, "authors": {"value": ["Hao Wang", "Chenyi Zhang", "Tongyang Li"]}, "authorids": {"value": ["~Hao_Wang55", "~Chenyi_Zhang2", "~Tongyang_Li1"]}, "keywords": {"value": ["Quantum Algorithms", "Quantum Query Complexity", "Convex Optimization", "Minimizing Loss"]}, "abstract": {"value": "The problem of minimizing the maximum of $N$ convex, Lipschitz functions plays significant roles in optimization and machine learning. It has a series of results, with the most recent one requiring $O(N\\epsilon^{-2/3} + \\epsilon^{-8/3})$ queries to a first-order oracle to compute an $\\epsilon$-suboptimal point. On the other hand, quantum algorithms for optimization are rapidly advancing with speedups shown on many important optimization problems. In this paper, we conduct a systematic study of quantum algorithms and lower bounds for minimizing the maximum of $N$ convex, Lipschitz functions. On one hand, we develop quantum algorithms with an improved complexity bound of $\\tilde{O}(\\sqrt{N}\\epsilon^{-5/3} + \\epsilon^{-8/3})$. On the other hand, we prove that quantum algorithms must take $\\tilde{\\Omega}(\\sqrt{N}\\epsilon^{-2/3})$ queries to a first-order quantum oracle, showing that our dependence on $N$ is optimal up to poly-logarithmic factors."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/db7af9a046b21f43d682073f4a8a9e2c4837a6ff.pdf"}, "TLDR": {"value": "We conduct a systematic study of quantum algorithms and lower bounds for minimizing the maximum of $N$ convex, Lipschitz functions."}, "_bibtex": {"value": "@inproceedings{\nwang2024nearoptimal,\ntitle={Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss},\nauthor={Hao Wang and Chenyi Zhang and Tongyang Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pB1FeRSQxh}\n}"}, "paperhash": {"value": "wang|nearoptimal_quantum_algorithm_for_minimizing_the_maximal_loss"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5095/-/Revision", "ICLR.cc/2024/Conference/Submission5095/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5095/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926985, "version": 2}, {"id": "sPUrdFGepF", "forum": "sPUrdFGepF", "number": 5094, "cdate": 1695372457880, "tcdate": 1695372457880, "mdate": 1713107397040, "tmdate": 1713107397040, "signatures": ["ICLR.cc/2024/Conference/Submission5094/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5094/Authors"], "content": {"title": {"value": "Consistent4D: Consistent 360\u00b0 Dynamic Object Generation from Monocular Video"}, "authors": {"value": ["Yanqin Jiang", "Li Zhang", "Jin Gao", "Weiming Hu", "Yao Yao"]}, "authorids": {"value": ["~Yanqin_Jiang1", "~Li_Zhang5", "~Jin_Gao1", "~Weiming_Hu1", "~Yao_Yao1"]}, "keywords": {"value": ["Dynamic object generation"]}, "abstract": {"value": "In this paper, we present Consistent4D, a novel approach for generating 4D dynamic objects from uncalibrated monocular videos. Uniquely, we cast the 360-degree dynamic object reconstruction as a 4D generation problem, eliminating the need for tedious multi-view data collection and camera calibration. This is achieved by leveraging the object-level 3D-aware image diffusion model as the primary supervision signal for training dynamic Neural Radiance Fields (DyNeRF). Specifically, we propose a cascade DyNeRF to facilitate stable convergence and temporal continuity under the time-discrete supervision signal. To achieve spatial and temporal consistency of the 4D generation, an interpolation-driven consistency loss is further introduced, which aligns the rendered frames with the interpolated frames from a pre-trained video interpolation model. Extensive experiments show that the proposed Consistent4D significantly outperforms previous 4D reconstruction approaches as well as per-frame 3D generation approaches, opening up new possibilities for 4D dynamic object generation from a single-view uncalibrated video. Project page: https://consistent4d.github.io"}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ddc1de21b21b8038d6d9a2aa42e1ec950e321cb7.pdf"}, "supplementary_material": {"value": "/attachment/9c3f895a12b3c6ff649224683ca3d8d426d9f8c5.zip"}, "_bibtex": {"value": "@inproceedings{\njiang2024consistentd,\ntitle={Consistent4D: Consistent 360{\\textdegree} Dynamic Object Generation from Monocular Video},\nauthor={Yanqin Jiang and Li Zhang and Jin Gao and Weiming Hu and Yao Yao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sPUrdFGepF}\n}"}, "paperhash": {"value": "jiang|consistent4d_consistent_360_dynamic_object_generation_from_monocular_video"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5094/-/Revision", "ICLR.cc/2024/Conference/Submission5094/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5094/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926961, "version": 2}, {"id": "qe49ybvvPs", "forum": "qe49ybvvPs", "number": 5093, "cdate": 1695372444763, "tcdate": 1695372444763, "mdate": 1710519674330, "tmdate": 1710519674330, "signatures": ["ICLR.cc/2024/Conference/Submission5093/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5093/Authors"], "content": {"title": {"value": "Diverse Projection Ensembles for Distributional Reinforcement Learning"}, "authors": {"value": ["Moritz Akiya Zanger", "Wendelin Boehmer", "Matthijs T. J. Spaan"]}, "authorids": {"value": ["~Moritz_Akiya_Zanger1", "~Wendelin_Boehmer1", "~Matthijs_T._J._Spaan1"]}, "keywords": {"value": ["Projections", "Epistemic Uncertainty", "Ensembles", "Exploration", "Reinforcement Learning", "Distributional Reinforcement Learning", "Machine Learning", "Artificial Intelligence"]}, "TLDR": {"value": "This paper introduces ensembles for distributional reinforcement learning that use different projections to drive diversity and exploration."}, "abstract": {"value": "In contrast to classical reinforcement learning, distributional RL algorithms aim to learn the distribution of returns rather than their expected value. Since the nature of the return distribution is generally unknown a priori or arbitrarily complex, a common approach finds approximations within a set of representable, parametric distributions. Typically, this involves a projection of the unconstrained distribution onto the set of simplified distributions. We argue that this projection step entails a strong inductive bias when coupled with neural networks and gradient descent, thereby profoundly impacting the generalization behavior of learned models. In order to facilitate reliable uncertainty estimation through diversity, this work studies the combination of several different projections and representations in a distributional ensemble. We establish theoretical properties of such projection ensembles and derive an algorithm that uses ensemble disagreement, measured by the average $1$-Wasserstein distance, as a bonus for deep exploration. We evaluate our algorithm on the behavior suite benchmark and find that diverse projection ensembles lead to significant performance improvements over existing methods on a wide variety of tasks with the most pronounced gains in directed exploration problems."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0a6be798efdae10c434867db0f88ffccbf67e65d.pdf"}, "supplementary_material": {"value": "/attachment/9ee8ee79b38ef11e069fd0a6d3ad9160daaa26b7.zip"}, "_bibtex": {"value": "@inproceedings{\nzanger2024diverse,\ntitle={Diverse Projection Ensembles for Distributional Reinforcement Learning},\nauthor={Moritz Akiya Zanger and Wendelin Boehmer and Matthijs T. J. Spaan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=qe49ybvvPs}\n}"}, "paperhash": {"value": "zanger|diverse_projection_ensembles_for_distributional_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5093/-/Revision", "ICLR.cc/2024/Conference/Submission5093/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5093/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926928, "version": 2}, {"id": "nY9nITZQjc", "forum": "nY9nITZQjc", "number": 5086, "cdate": 1695372275799, "tcdate": 1695372275799, "mdate": 1710902774178, "tmdate": 1710902774178, "signatures": ["ICLR.cc/2024/Conference/Submission5086/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5086/Authors"], "content": {"title": {"value": "MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations"}, "authors": {"value": ["Hanlei Zhang", "Xin Wang", "Hua Xu", "Qianrui Zhou", "Kai Gao", "Jianhua Su", "jinyue Zhao", "Wenrui Li", "Yanting Chen"]}, "authorids": {"value": ["~Hanlei_Zhang1", "~Xin_Wang36", "~Hua_Xu1", "~Qianrui_Zhou1", "~Kai_Gao3", "~Jianhua_Su2", "~jinyue_Zhao1", "~Wenrui_Li3", "~Yanting_Chen1"]}, "keywords": {"value": ["intent recognition", "multimodal dataset", "out-of-scope detection", "multi-turn conversations", "benchmark framework", "benchmark evaluation"]}, "TLDR": {"value": "MIntRec2.0 is the first large-scale dataset for multimodal intent recognition and out-of-scope detection in multi-party conversations."}, "abstract": {"value": "Multimodal intent recognition poses significant challenges, requiring the incorporation of non-verbal modalities from real-world contexts to enhance the comprehension of human intentions. However, most existing multimodal intent benchmark datasets are limited in scale and suffer from difficulties in handling out-of-scope samples that arise in multi-turn conversational interactions. In this paper, we introduce MIntRec2.0, a large-scale benchmark dataset for multimodal intent recognition in multi-party conversations. It contains 1,245 high-quality dialogues with 15,040 samples, each annotated within a new intent taxonomy of 30 fine-grained classes, across text, video, and audio modalities. In addition to more than 9,300 in-scope samples, it also includes over 5,700 out-of-scope samples appearing in multi-turn contexts, which naturally occur in real-world open scenarios, enhancing its practical applicability. Furthermore, we provide comprehensive information on the speakers in each utterance, enriching its utility for multi-party conversational research. We establish a general framework supporting the organization of single-turn and multi-turn dialogue data, modality feature extraction, multimodal fusion, as well as in-scope classification and out-of-scope detection. Evaluation benchmarks are built using classic multimodal fusion methods, ChatGPT, and human evaluators. While existing methods incorporating nonverbal information yield improvements, effectively leveraging context information and detecting out-of-scope samples remains a substantial challenge. Notably, powerful large language models exhibit a significant performance gap compared to humans, highlighting the limitations of machine learning methods in the advanced cognitive intent understanding task. We believe that MIntRec2.0 will serve as a valuable resource, providing a pioneering foundation for research in human-machine conversational interactions, and significantly facilitating related applications.\nThe full dataset and codes are available for use at https://github.com/thuiar/MIntRec2.0."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/471acfa4cfb148e5208273a51dd754e5a189ead9.pdf"}, "supplementary_material": {"value": "/attachment/76f1e21001418990387aac029f66664cf7c4ff01.zip"}, "_bibtex": {"value": "@inproceedings{\nzhang2024mintrec,\ntitle={{MI}ntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations},\nauthor={Hanlei Zhang and Xin Wang and Hua Xu and Qianrui Zhou and Jianhua Su and jinyue Zhao and Wenrui Li and Yanting Chen and Kai Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nY9nITZQjc}\n}"}, "paperhash": {"value": "zhang|mintrec20_a_largescale_benchmark_dataset_for_multimodal_intent_recognition_and_outofscope_detection_in_conversations"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5086/-/Revision", "ICLR.cc/2024/Conference/Submission5086/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5086/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926669, "version": 2}, {"id": "vKViCoKGcB", "forum": "vKViCoKGcB", "number": 5084, "cdate": 1695372198355, "tcdate": 1695372198355, "mdate": 1710233144878, "tmdate": 1710233144878, "signatures": ["ICLR.cc/2024/Conference/Submission5084/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5084/Authors"], "content": {"title": {"value": "Intriguing Properties of Data Attribution on Diffusion Models"}, "authors": {"value": ["Xiaosen Zheng", "Tianyu Pang", "Chao Du", "Jing Jiang", "Min Lin"]}, "authorids": {"value": ["~Xiaosen_Zheng1", "~Tianyu_Pang1", "~Chao_Du1", "~Jing_Jiang1", "~Min_Lin1"]}, "keywords": {"value": ["Data Attribution", "Diffusion Models"]}, "abstract": {"value": "Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a significantly more efficient approach for attributing diffusion models, while the unexpected findings suggest that at least in non-convex settings, constructions guided by theoretical assumptions may lead to inferior attribution performance. The code is available at https://github.com/sail-sg/D-TRAK."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/16d638841132d62bc5ffb6de1c4502d76b82ecf1.pdf"}, "supplementary_material": {"value": "/attachment/28625df7e0867059d4398766f56340f1f5bb7514.zip"}, "TLDR": {"value": "We report counter-intuitive observations that theoretically unjustified design choices for attributing diffusion models empirically outperform previous baselines by a large margin."}, "_bibtex": {"value": "@inproceedings{\nzheng2024intriguing,\ntitle={Intriguing Properties of Data Attribution on Diffusion Models},\nauthor={Xiaosen Zheng and Tianyu Pang and Chao Du and Jing Jiang and Min Lin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vKViCoKGcB}\n}"}, "paperhash": {"value": "zheng|intriguing_properties_of_data_attribution_on_diffusion_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5084/-/Revision", "ICLR.cc/2024/Conference/Submission5084/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5084/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926618, "version": 2}, {"id": "ekz1hN5QNh", "forum": "ekz1hN5QNh", "number": 5080, "cdate": 1695372066438, "tcdate": 1695372066438, "mdate": 1709661516842, "tmdate": 1709661516842, "signatures": ["ICLR.cc/2024/Conference/Submission5080/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5080/Authors"], "content": {"title": {"value": "Fully Hyperbolic Convolutional Neural Networks for Computer Vision"}, "authors": {"value": ["Ahmad Bdeir", "Kristian Schwethelm", "Niels Landwehr"]}, "authorids": {"value": ["~Ahmad_Bdeir1", "~Kristian_Schwethelm1", "~Niels_Landwehr1"]}, "keywords": {"value": ["hyperbolic neural networks", "hyperbolic image embedding", "hyperbolic vision models. hyperboloid representation"]}, "abstract": {"value": "Real-world visual data exhibit intrinsic hierarchical structures that can be represented effectively in hyperbolic spaces. Hyperbolic neural networks (HNNs) are a promising approach for learning feature representations in such spaces. However, current HNNs in computer vision rely on Euclidean backbones and only project features to the hyperbolic space in the task heads, limiting their ability to fully leverage the benefits of hyperbolic geometry. To address this, we present HCNN, a fully hyperbolic convolutional neural network (CNN) designed for computer vision tasks. Based on the Lorentz model, we generalize fundamental components of CNNs and propose novel formulations of the convolutional layer, batch normalization, and multinomial logistic regression. Experiments on standard vision tasks demonstrate the promising performance of our HCNN framework in both hybrid and fully hyperbolic settings. Overall, we believe our contributions provide a foundation for developing more powerful HNNs that can better represent complex structures found in image data. Our code is publicly available at https://github.com/kschwethelm/HyperbolicCV."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a62107dbe4a8eeeb6ef40939b5d3c8f7f3aab477.pdf"}, "supplementary_material": {"value": "/attachment/ac273c493a59d3e955d57ba79faf02a4f6d9a15a.zip"}, "_bibtex": {"value": "@inproceedings{\nbdeir2024fully,\ntitle={Fully Hyperbolic Convolutional Neural Networks for Computer Vision},\nauthor={Ahmad Bdeir and Kristian Schwethelm and Niels Landwehr},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ekz1hN5QNh}\n}"}, "paperhash": {"value": "bdeir|fully_hyperbolic_convolutional_neural_networks_for_computer_vision"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5080/-/Revision", "ICLR.cc/2024/Conference/Submission5080/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5080/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926513, "version": 2}, {"id": "1BuWv9poWz", "forum": "1BuWv9poWz", "number": 5069, "cdate": 1695371607320, "tcdate": 1695371607320, "mdate": 1710559077101, "tmdate": 1710559077101, "signatures": ["ICLR.cc/2024/Conference/Submission5069/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5069/Authors"], "content": {"title": {"value": "Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation"}, "authors": {"value": ["Zhiyu Zhu", "Xinyi Wang", "Zhibo Jin", "Jiayu Zhang", "Huaming Chen"]}, "authorids": {"value": ["~Zhiyu_Zhu2", "~Xinyi_Wang9", "~Zhibo_Jin1", "~Jiayu_Zhang1", "~Huaming_Chen1"]}, "keywords": {"value": ["Adversarial attack", "transferability", "Vit", "transformer"]}, "abstract": {"value": "Vision Transformers (ViTs) have been widely used in various domains. Similar to Convolutional Neural Networks (CNNs), ViTs are prone to the impacts of adversarial samples, raising security concerns in real-world applications. As one of the most effective black-box attack methods, transferable attacks can generate adversarial samples on surrogate models to directly attack the target model without accessing the parameters. However, due to the distinct internal structures of ViTs and CNNs, adversarial samples constructed by traditional transferable attack methods may not be applicable to ViTs. Therefore, it is imperative to propose more effective transferability attack methods to unveil latent vulnerabilities in ViTs. Existing methods have found that applying gradient regularization to extreme gradients across different functional regions in the transformer structure can enhance sample transferability. However, in practice, substantial gradient disparities exist even within the same functional region across different layers. Furthermore, we find that mild gradients therein are the main culprits behind reduced transferability. In this paper, we introduce a novel Gradient Normalization Scaling method for fine-grained gradient editing to enhance the transferability of adversarial attacks on ViTs. More importantly, we highlight that ViTs, unlike traditional CNNs, exhibit distinct attention regions in the frequency domain. Leveraging this insight, we delve into exploring the frequency domain to further enhance the algorithm's transferability. Through extensive experimentation on various ViT variants and traditional CNN models, we substantiate that the new approach achieves state-of-the-art performance, with an average performance improvement of 33.54\\% and 42.05\\% on ViT and CNN models, respectively. Our code is available at: https://github.com/LMBTough/GNS-HFA."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/08f63426d1f5fefd2205b528961bd666733480ff.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhu2024enhancing,\ntitle={Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation},\nauthor={Zhiyu Zhu and Xinyi Wang and Zhibo Jin and Jiayu Zhang and Huaming Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1BuWv9poWz}\n}"}, "supplementary_material": {"value": "/attachment/c0069439cc0a5771415da7f84ab0e26da2dbf333.pdf"}, "paperhash": {"value": "zhu|enhancing_transferable_adversarial_attacks_on_vision_transformers_through_gradient_normalization_scaling_and_highfrequency_adaptation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5069/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5069/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926206, "version": 2}, {"id": "fVxIEHGnVT", "forum": "fVxIEHGnVT", "number": 5068, "cdate": 1695371606497, "tcdate": 1695371606497, "mdate": 1710423560067, "tmdate": 1710423560067, "signatures": ["ICLR.cc/2024/Conference/Submission5068/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5068/Authors"], "content": {"title": {"value": "An interpretable error correction method for enhancing code-to-code translation"}, "authors": {"value": ["Min Xue", "Artur Andrzejak", "Marla Leuther"]}, "authorids": {"value": ["~Min_Xue1", "~Artur_Andrzejak1", "~Marla_Leuther1"]}, "keywords": {"value": ["Computation and Language; Programming Languages; Software Engineering; Machine Learning"]}, "abstract": {"value": "Transformer-based machine translation models currently dominate the field of model-based program translation. However, these models fail to provide interpretative support for the generated program translations. Moreover, researchers frequently invest substantial time and computational resources in retraining models, yet the improvement in translation accuracy is quite limited. \nTo address these issues, we introduce a novel approach, $k\\text{NN-ECD}$, which combines $k$-nearest-neighbor search with a key-value error correction datastore to overwrite the wrong translations of TransCoder-ST. This provides a decision-making basis for interpreting the corrected translations. Building upon this, we further propose $k\\text{NN-ECS}_{m}$, a methodology that employs a distributed structure with $m$ sub-datastores connected in series,  utilizing $m$ diverse experts for multi-round error correction. Additionally, we put forward a unified name rule, encouraging the datastore to focus more on code logic and structure rather than diverse rare identifiers. Our experimental results show that our approach improves the translation accuracy from 68.9\\% to 89.9\\% of TransCoder-ST (for translation from Java to Python). This error correction method augments program translation, overcoming the inherent limitations of Transformer-based code translation models, such as resource-intensive retraining requirements and uninterpretable outcomes."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/172bb7e427f95296dd80fc4fa71d56d958821c34.pdf"}, "_bibtex": {"value": "@inproceedings{\nxue2024an,\ntitle={An interpretable error correction method for enhancing code-to-code translation},\nauthor={Min Xue and Artur Andrzejak and Marla Leuther},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=fVxIEHGnVT}\n}"}, "paperhash": {"value": "xue|an_interpretable_error_correction_method_for_enhancing_codetocode_translation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5068/-/Revision", "ICLR.cc/2024/Conference/Submission5068/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5068/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926164, "version": 2}, {"id": "oLLZhbBSOU", "forum": "oLLZhbBSOU", "number": 5065, "cdate": 1695371531014, "tcdate": 1695371531014, "mdate": 1710793928475, "tmdate": 1710793928475, "signatures": ["ICLR.cc/2024/Conference/Submission5065/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5065/Authors"], "content": {"title": {"value": "RLIF: Interactive Imitation Learning as Reinforcement Learning"}, "authors": {"value": ["Jianlan Luo", "Perry Dong", "Yuexiang Zhai", "Yi Ma", "Sergey Levine"]}, "authorids": {"value": ["~Jianlan_Luo1", "~Perry_Dong1", "~Yuexiang_Zhai1", "~Yi_Ma4", "~Sergey_Levine1"]}, "keywords": {"value": ["Reinforcement learning", "imitation learning", "online learning"]}, "TLDR": {"value": "An RL approach runs under DAgger setting without making optimal expert or task reward assumption."}, "abstract": {"value": "Although reinforcement learning methods offer a powerful framework for auto-\nmatic skill acquisition, for practical learning-based control problems in domains\nsuch as robotics, imitation learning often provides a more convenient and accessible\nalternative. In particular, an interactive imitation learning method such as DAgger,\nwhich queries a near-optimal expert to intervene online to collect correction data for\naddressing the distributional shift challenges that afflict na\u00efve behavioral cloning,\ncan enjoy good performance both in theory and practice without requiring manually\nspecified reward functions and other components of full reinforcement learning\nmethods. In this paper, we explore how off-policy reinforcement learning can\nenable improved performance under assumptions that are similar but potentially\neven more practical than those of interactive imitation learning. Our proposed\nmethod uses reinforcement learning with user intervention signals themselves as\nrewards. This relaxes the assumption that intervening experts in interactive imita-\ntion learning should be near-optimal and enables the algorithm to learn behaviors\nthat improve over the potential suboptimal human expert. We also provide a uni-\nfied framework to analyze our RL method and DAgger; for which we present the\nasymptotic analysis of the suboptimal gap for both methods as well as the non-\nasymptotic sample complexity bound of our method. We then evaluate our method\non challenging high-dimensional continuous control simulation benchmarks as\nwell as real-world robotic vision-based manipulation tasks. The results show that it\nstrongly outperforms DAgger-like approaches across the different tasks, especially\nwhen the intervening experts are suboptimal. Additional ablations also empirically\nverify the proposed theoretical justification that the performance of our method is\nassociated with the choice of intervention model and suboptimality of the expert.\nCode and videos can be found on the project website: https://rlif-page.github.io"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b45c120af5895fdbc18e17dcbcbd8d2d55ac2a33.pdf"}, "_bibtex": {"value": "@inproceedings{\nluo2024rlif,\ntitle={{RLIF}: Interactive Imitation Learning as Reinforcement Learning},\nauthor={Jianlan Luo and Perry Dong and Yuexiang Zhai and Yi Ma and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oLLZhbBSOU}\n}"}, "paperhash": {"value": "luo|rlif_interactive_imitation_learning_as_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5065/-/Revision", "ICLR.cc/2024/Conference/Submission5065/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5065/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410926064, "version": 2}, {"id": "MVmT6uQ3cQ", "forum": "MVmT6uQ3cQ", "number": 5055, "cdate": 1695371225575, "tcdate": 1695371225575, "mdate": 1710212041171, "tmdate": 1710212041171, "signatures": ["ICLR.cc/2024/Conference/Submission5055/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5055/Authors"], "content": {"title": {"value": "The Need for Speed: Pruning Transformers with One Recipe"}, "authors": {"value": ["Samir Khaki", "Konstantinos N Plataniotis"]}, "authorids": {"value": ["~Samir_Khaki1", "~Konstantinos_N_Plataniotis1"]}, "keywords": {"value": ["transformers", "pruning", "re-training", "latency", "throughput", "token reduction", "one-shot"]}, "abstract": {"value": "We introduce the $\\textbf{O}$ne-shot $\\textbf{P}$runing $\\textbf{T}$echnique for $\\textbf{I}$nterchangeable $\\textbf{N}$etworks ($\\textbf{OPTIN}$) framework as a tool to increase the efficiency of pre-trained transformer architectures $\\textit{without requiring re-training}$. Recent works have explored improving transformer efficiency, however often incur computationally expensive re-training procedures or depend on architecture-specific characteristics, thus impeding practical wide-scale adoption. \nTo address these shortcomings, the OPTIN framework leverages intermediate feature distillation, capturing the long-range dependencies of model parameters (coined $\\textit{trajectory}$), to produce state-of-the-art results on natural language, image classification, transfer learning, and semantic segmentation tasks $\\textit{without re-training}$. Given a FLOP constraint, the OPTIN framework will compress the network while maintaining competitive accuracy performance and improved throughput. Particularly, we show a $\\leq 2$% accuracy degradation from NLP baselines and a $0.5$% improvement from state-of-the-art methods on image classification at competitive FLOPs reductions. We further demonstrate the generalization of tasks and architecture with comparative performance using Mask2Former for semantic segmentation and cnn-style networks. OPTIN presents one of the first one-shot efficient frameworks for compressing transformer architectures that generalizes well across different class domains, in particular: natural language and image-related tasks, without $\\textit{re-training}$."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8cbf2648dcd7299075e540b214c292ba1adde95f.pdf"}, "supplementary_material": {"value": "/attachment/23a88a332fdcde38fbb0479539d8e2bc1b27c31d.zip"}, "_bibtex": {"value": "@inproceedings{\nkhaki2024the,\ntitle={The Need for Speed: Pruning Transformers with One Recipe},\nauthor={Samir Khaki and Konstantinos N Plataniotis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=MVmT6uQ3cQ}\n}"}, "paperhash": {"value": "khaki|the_need_for_speed_pruning_transformers_with_one_recipe"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5055/-/Revision", "ICLR.cc/2024/Conference/Submission5055/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5055/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925770, "version": 2}, {"id": "hWS4MueyzC", "forum": "hWS4MueyzC", "number": 5053, "cdate": 1695371134057, "tcdate": 1695371134057, "mdate": 1710752525126, "tmdate": 1710752525126, "signatures": ["ICLR.cc/2024/Conference/Submission5053/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5053/Authors"], "content": {"title": {"value": "Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World"}, "authors": {"value": ["Rujie Wu", "Xiaojian Ma", "Zhenliang Zhang", "Wei Wang", "Qing Li", "Song-Chun Zhu", "Yizhou Wang"]}, "authorids": {"value": ["~Rujie_Wu2", "~Xiaojian_Ma1", "~Zhenliang_Zhang2", "~Wei_Wang4", "~Qing_Li1", "~Song-Chun_Zhu1", "~Yizhou_Wang1"]}, "keywords": {"value": ["Few-shot learning", "Visual reasoning", "Open world learning"]}, "abstract": {"value": "We introduce Bongard-OpenWorld, a new benchmark for evaluating real-world few-shot reasoning for machine vision. It originates from the classical Bongard Problems (BPs): Given two sets of images (positive and negative), the model needs to identify the set that query images belong to by inducing the visual concepts, which is exclusively depicted by images from the positive set. Our benchmark inherits the few-shot concept induction of the original BPs while adding the two novel layers of challenge: 1) open-world free-form concepts, as the visual concepts in Bongard-OpenWorld are unique compositions of terms from an open vocabulary, ranging from object categories to abstract visual attributes and commonsense factual knowledge; 2)  real-world images, as opposed to the synthetic diagrams used by many counterparts. In our exploration, Bongard-OpenWorld already imposes a significant challenge to current few-shot reasoning algorithms. We further investigate to which extent the recently introduced Large Language Models (LLMs) and Vision-Language Models (VLMs) can solve our task, by directly probing VLMs, and combining VLMs and LLMs in an interactive reasoning scheme. We even conceived a neuro-symbolic reasoning approach that reconciles LLMs & VLMs with logical reasoning to emulate the human problem-solving process for Bongard Problems. However, none of these approaches manage to close the human-machine gap, as the best learner achieves 64% accuracy while human participants easily reach 91%. We hope Bongard-OpenWorld can help us better understand the limitations of current visual intelligence and facilitate future research on visual agents with stronger few-shot visual reasoning capabilities."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ffa49aeaac1a4b4b4b728c20ae009f257bbcf630.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024bongardopenworld,\ntitle={Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World},\nauthor={Rujie Wu and Xiaojian Ma and Qing Li and Zhenliang Zhang and Wei Wang and Song-Chun Zhu and Yizhou Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hWS4MueyzC}\n}"}, "paperhash": {"value": "wu|bongardopenworld_fewshot_reasoning_for_freeform_visual_concepts_in_the_real_world"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5053/-/Revision", "ICLR.cc/2024/Conference/Submission5053/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5053/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925717, "version": 2}, {"id": "xI4yNlkaqh", "forum": "xI4yNlkaqh", "number": 5052, "cdate": 1695371044197, "tcdate": 1695371044197, "mdate": 1710037165139, "tmdate": 1710037165139, "signatures": ["ICLR.cc/2024/Conference/Submission5052/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5052/Authors"], "content": {"title": {"value": "Towards 3D Molecule-Text Interpretation in Language Models"}, "authors": {"value": ["Sihang Li", "Zhiyuan Liu", "Yanchen Luo", "Xiang Wang", "Xiangnan He", "Kenji Kawaguchi", "Tat-Seng Chua", "Qi Tian"]}, "authorids": {"value": ["~Sihang_Li1", "~Zhiyuan_Liu5", "~Yanchen_Luo1", "~Xiang_Wang6", "~Xiangnan_He1", "~Kenji_Kawaguchi1", "~Tat-Seng_Chua2", "~Qi_Tian3"]}, "keywords": {"value": ["3D molecules", "Large Language Model", "3D-text interpretation"]}, "abstract": {"value": "Language Models (LMs) have greatly influenced diverse domains. However, their inherent limitation in comprehending 3D molecular structures has considerably constrained their potential in the biomolecular domain. To bridge this gap, we focus on 3D molecule-text interpretation, and propose 3D-MoLM: 3D-Molecular Language Modeling. Specifically, 3D-MoLM enables an LM to interpret and analyze 3D molecules by equipping the LM with a 3D molecular encoder. This integration is achieved by a 3D molecule-text projector, bridging the 3D molecular encoder\u2019s representation space and the LM\u2019s input space. Moreover, to enhance 3D\u0002MoLM\u2019s ability of cross-modal molecular understanding and instruction following, we meticulously curated a 3D molecule-centric instruction tuning dataset \u2013 3D-MoIT. Through 3D molecule-text alignment and 3D molecule-centric instruction tuning, 3D-MoLM establishes an integration of 3D molecular encoder and LM. It significantly surpasses existing baselines on downstream tasks, including molecule\u0002text retrieval, molecule captioning, and more challenging open-text molecular QA tasks, especially focusing on 3D-dependent properties. We will release our codes and datasets at https://github.com/lsh0520/3D-MoLM."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f287c08259bfae5fc20cd15de5cd4e8823957162.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024towards,\ntitle={Towards 3D Molecule-Text Interpretation in Language Models},\nauthor={Sihang Li and Zhiyuan Liu and Yanchen Luo and Xiang Wang and Xiangnan He and Kenji Kawaguchi and Tat-Seng Chua and Qi Tian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xI4yNlkaqh}\n}"}, "paperhash": {"value": "li|towards_3d_moleculetext_interpretation_in_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5052/-/Revision", "ICLR.cc/2024/Conference/Submission5052/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5052/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925692, "version": 2}, {"id": "CtOA9aN8fr", "forum": "CtOA9aN8fr", "number": 5051, "cdate": 1695371011684, "tcdate": 1695371011684, "mdate": 1710238748033, "tmdate": 1710238748033, "signatures": ["ICLR.cc/2024/Conference/Submission5051/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5051/Authors"], "content": {"title": {"value": "Effective pruning of web-scale datasets based on complexity of concept clusters"}, "authors": {"value": ["Amro Kamal Mohamed Abbas", "Evgenia Rusak", "Kushal Tirumala", "Wieland Brendel", "Kamalika Chaudhuri", "Ari S. Morcos"]}, "authorids": {"value": ["~Amro_Kamal_Mohamed_Abbas1", "~Evgenia_Rusak1", "~Kushal_Tirumala1", "~Wieland_Brendel1", "~Kamalika_Chaudhuri1", "~Ari_S._Morcos1"]}, "keywords": {"value": ["pruning", "large-scale", "data curation", "concept-based", "LAION", "DataComp"]}, "TLDR": {"value": "We propose a pruning method where we aim to obtain optimal dataset coverage by assessing sample complexity; we report SotA results on the DataComp Medium benchmark and outperform regular OpenCLIP training on LAION with significantly less data."}, "abstract": {"value": "Utilizing massive web-scale datasets has led to unprecedented performance gains in machine learning models, but also imposes outlandish compute requirements for their training. In order to improve training and data efficiency, we here push the limits of pruning large-scale multimodal datasets for training CLIP-style models. Today\u2019s most effective pruning method on ImageNet clusters data samples into separate concepts according to their embedding and prunes away the most proto- typical samples. We scale this approach to LAION and improve it by noting that the pruning rate should be concept-specific and adapted to the complexity of the concept. Using a simple and intuitive complexity measure, we are able to reduce the training cost to a quarter of regular training. More specifically, we are able to outperform the LAION-trained OpenCLIP-ViT-B/32 model on ImageNet zero-shot accuracy by 1.1p.p. while only using 27.7% of the data and training compute. On the DataComp Medium benchmark, we achieve a new state-of-the-art ImageNet zero-shot accuracy and a competitive average zero-shot accuracy on 38 evaluation tasks."}, "pdf": {"value": "/pdf/5c4dc17746b44f4436080ffb209747c48d88a854.pdf"}, "supplementary_material": {"value": "/attachment/932b063d5713682ca5dd256ff953eedf1ecf03ad.pdf"}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\nabbas2024effective,\ntitle={Effective pruning of web-scale datasets based on complexity of concept clusters},\nauthor={Amro Kamal Mohamed Abbas and Evgenia Rusak and Kushal Tirumala and Wieland Brendel and Kamalika Chaudhuri and Ari S. Morcos},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=CtOA9aN8fr}\n}"}, "paperhash": {"value": "abbas|effective_pruning_of_webscale_datasets_based_on_complexity_of_concept_clusters"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5051/-/Revision", "ICLR.cc/2024/Conference/Submission5051/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5051/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925670, "version": 2}, {"id": "FsVxd9CIlb", "forum": "FsVxd9CIlb", "number": 5047, "cdate": 1695370779701, "tcdate": 1695370779701, "mdate": 1710558651958, "tmdate": 1710558651958, "signatures": ["ICLR.cc/2024/Conference/Submission5047/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5047/Authors"], "content": {"title": {"value": "AttEXplore: Attribution for Explanation with model parameters eXploration"}, "authors": {"value": ["Zhiyu Zhu", "Huaming Chen", "Jiayu Zhang", "Xinyi Wang", "Zhibo Jin", "Jason Xue", "Flora D. Salim"]}, "authorids": {"value": ["~Zhiyu_Zhu2", "~Huaming_Chen1", "~Jiayu_Zhang1", "~Xinyi_Wang9", "~Zhibo_Jin1", "~Jason_Xue1", "~Flora_D._Salim1"]}, "keywords": {"value": ["attribution", "transferability", "adversarial attack"]}, "abstract": {"value": "Due to the real-world noise and human-added perturbations, attaining the trustworthiness of deep neural networks (DNNs) is a challenging task. Therefore, it becomes essential to offer explanations for the decisions made by these non-linear and complex parameterized models. Attribution methods are promising for this goal, yet its performance can be further improved. In this paper, for the first time, we present that the decision boundary exploration approaches of attribution are consistent with the process for transferable adversarial attacks. Specifically, the transferable adversarial attacks craft general adversarial samples from the source model, which is consistent with the generation of adversarial samples that can cross multiple decision boundaries in attribution. Utilizing this consistency, we introduce a novel attribution method via model parameter exploration. Furthermore, inspired by the capability of frequency exploration to investigate the model parameters, we provide enhanced explainability for DNNs by manipulating the input features based on frequency information to explore the decision boundaries of different models. Large-scale experiments demonstrate that our \\textbf{A}ttribution method for \\textbf{E}xplanation with model parameter e\\textbf{X}ploration (AttEXplore) outperforms other state-of-the-art interpretability methods. Moreover, by employing other transferable attack techniques, AttEXplore can explore potential variations in attribution outcomes. Our code is available at: https://github.com/LMBTough/ATTEXPLORE."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e818955d4830dbecf74240bbeffe2f01740a47b9.pdf"}, "supplementary_material": {"value": "/attachment/ffe162cede20a43469d96a669f6e1462022c658c.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhu2024attexplore,\ntitle={Att{EX}plore: Attribution for Explanation with model parameters eXploration},\nauthor={Zhiyu Zhu and Huaming Chen and Jiayu Zhang and Xinyi Wang and Zhibo Jin and Jason Xue and Flora D. Salim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FsVxd9CIlb}\n}"}, "paperhash": {"value": "zhu|attexplore_attribution_for_explanation_with_model_parameters_exploration"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5047/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5047/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925559, "version": 2}, {"id": "PAfnMGXief", "forum": "PAfnMGXief", "number": 5046, "cdate": 1695370737490, "tcdate": 1695370737490, "mdate": 1710370754134, "tmdate": 1710370754134, "signatures": ["ICLR.cc/2024/Conference/Submission5046/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5046/Authors"], "content": {"title": {"value": "BRUSLEATTACK: A QUERY-EFFICIENT SCORE- BASED BLACK-BOX SPARSE ADVERSARIAL ATTACK"}, "authors": {"value": ["Quoc Viet Vo", "Ehsan Abbasnejad", "Damith Ranasinghe"]}, "authorids": {"value": ["~Quoc_Viet_Vo1", "~Ehsan_Abbasnejad3", "~Damith_Ranasinghe1"]}, "keywords": {"value": ["AI Safety", "Trustworthy Machine Learning", "Machine Learning Robustness", "Adversarial Attacks"]}, "abstract": {"value": "We study the unique, less-well understood problem of generating sparse adversarial samples simply by observing the score-based replies to model queries. Sparse attacks aim to discover a minimum number\u2014the $l_0$ bounded\u2014perturbations to model inputs to craft adversarial examples and misguide model decisions. But, in contrast to query-based dense attack counterparts against black-box models, constructing sparse adversarial perturbations, even when models serve confidence score information to queries in a score-based setting, is non-trivial. Because, such an attack leads to: i) an NP-hard problem; and ii) a non-differentiable search space. We develop the BRUSLEATTACK\u2014a new, faster (more query-efficient) algorithm formulation for the problem. We conduct extensive attack evaluations including an attack demonstration against a Machine Learning as a Service (MLaaS) offering exemplified by __Google Cloud Vision__ and robustness testing of adversarial training regimes and a recent defense against black-box attacks. The proposed attack scales to achieve state-of-the-art attack success rates and query efficiency on standard computer vision tasks such as ImageNet across different model architectures. Our artifacts and DIY attack samples are available on GitHub. Importantly, our work facilitates faster evaluation of model vulnerabilities and raises our vigilance on the safety, security and reliability of deployed systems."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/375e08c26da9083b380e40cdf4251a558086e2e9.pdf"}, "_bibtex": {"value": "@inproceedings{\nvo2024brusleattack,\ntitle={{BRUSLEATTACK}: {QUERY}-{EFFICIENT} {SCORE}-{BASED} {SPARSE} {ADVERSARIAL} {ATTACK}},\nauthor={Quoc Viet Vo and Ehsan Abbasnejad and Damith Ranasinghe},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PAfnMGXief}\n}"}, "paperhash": {"value": "vo|brusleattack_a_queryefficient_score_based_blackbox_sparse_adversarial_attack"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5046/-/Revision", "ICLR.cc/2024/Conference/Submission5046/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5046/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925481, "version": 2}, {"id": "N23A4ybMJr", "forum": "N23A4ybMJr", "number": 5045, "cdate": 1695370733033, "tcdate": 1695370733033, "mdate": 1711099664838, "tmdate": 1711099664838, "signatures": ["ICLR.cc/2024/Conference/Submission5045/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5045/Authors"], "content": {"title": {"value": "Win-Win: Training High-Resolution Vision Transformers from Two Windows"}, "authors": {"value": ["Vincent Leroy", "Jerome Revaud", "Thomas Lucas", "Philippe Weinzaepfel"]}, "authorids": {"value": ["~Vincent_Leroy3", "~Jerome_Revaud1", "~Thomas_Lucas1", "~Philippe_Weinzaepfel1"]}, "keywords": {"value": ["Vision transformers", "High resolution", "Dense tasks", "Optical flow"]}, "abstract": {"value": "Transformers have become the standard in state-of-the-art vision architectures, achieving impressive performance on both image-level and dense pixelwise tasks. However, training vision transformers for high-resolution pixelwise tasks has a prohibitive cost. Typical solutions boil down to hierarchical architectures, fast and approximate attention, or training on low-resolution crops. This latter solution does not constrain architectural choices, but it leads to a clear performance drop when testing at resolutions significantly higher than that used for training, thus requiring ad-hoc and slow post-processing schemes. In this paper, we propose a novel strategy for efficient training and inference of high-resolution vision transformers. The key principle is to mask out most of the high-resolution inputs during training, keeping only N random windows. This allows the model to learn local interactions between tokens inside each window, and global interactions between tokens from different windows. As a result, the model can directly process the high-resolution input at test time without any special trick. We show that this strategy is effective when using relative positional embedding such as rotary embeddings. It is 4 times faster to train than a full-resolution network, and it is straightforward to use at test time compared to existing approaches. We apply this strategy to three dense prediction tasks with high-resolution data. First, we show on the task of semantic segmentation that a simple setting with 2 windows performs best, hence the name of our method: Win-Win. Second, we confirm this result on the task of monocular depth prediction. Third, to demonstrate the generality of our contribution, we further extend it to the binocular task of optical flow, reaching state-of-the-art performance on the Spring benchmark that contains Full-HD images with an order of magnitude faster inference than the best competitor"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/73b3b9bb077511f5ecfe14ad51eda27fd22b59a6.pdf"}, "_bibtex": {"value": "@inproceedings{\nleroy2024winwin,\ntitle={Win-Win: Training High-Resolution Vision Transformers from Two Windows},\nauthor={Vincent Leroy and Jerome Revaud and Thomas Lucas and Philippe Weinzaepfel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=N23A4ybMJr}\n}"}, "TLDR": {"value": "WinWin enables to train vanilla ViTs for high-resolution dense pixelwise tasks at a fraction of the (quadratic) cost"}, "paperhash": {"value": "leroy|winwin_training_highresolution_vision_transformers_from_two_windows"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5045/-/Revision", "ICLR.cc/2024/Conference/Submission5045/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5045/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925444, "version": 2}, {"id": "bDkisS75zy", "forum": "bDkisS75zy", "number": 5044, "cdate": 1695370688315, "tcdate": 1695370688315, "mdate": 1710132210413, "tmdate": 1710132210413, "signatures": ["ICLR.cc/2024/Conference/Submission5044/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5044/Authors"], "content": {"title": {"value": "COSA: Concatenated Sample Pretrained Vision-Language Foundation Model"}, "authors": {"value": ["Sihan Chen", "Xingjian He", "Handong Li", "Xiaojie Jin", "Jiashi Feng", "Jing Liu"]}, "authorids": {"value": ["~Sihan_Chen3", "~Xingjian_He1", "~Handong_Li1", "~Xiaojie_Jin1", "~Jiashi_Feng1", "~Jing_Liu1"]}, "keywords": {"value": ["Vision-Language Foundation Model", "Video-Language Pretraining"]}, "abstract": {"value": "Due to the limited scale and quality of video-text training corpus, most  vision-language  foundation  models employ  image-text datasets for pretraining and primarily focus on modeling visually semantic representations while disregarding temporal semantic representations and correlations. To address this issue, we propose COSA, a COncatenated SAmple pretrained vision-language foundation model. COSA can jointly model visual contents and event-level temporal cues using only image-text corpora.  We achieve this by sequentially concatenating multiple image-text pairs as inputs for pretraining. This transformation effectively converts existing image-text corpora into a pseudo  video-paragraph corpus, enabling richer scene transformations and explicit event-description correspondence. Extensive experiments demonstrate that COSA consistently improves performance across a broad range of semantic vision-language downstream tasks, including paragraph-to-video retrieval, text-to-video/image retrieval, video/image captioning and video QA. Notably, COSA achieves state-of-the-art results on various competitive benchmarks. Code and model are released at https://github.com/TXH-mercury/COSA."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3fbcf031f5ace68ec8d5ec3b8e59609d4f43d942.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024cosa,\ntitle={{COSA}: Concatenated Sample Pretrained Vision-Language Foundation Model},\nauthor={Sihan Chen and Xingjian He and Handong Li and Xiaojie Jin and Jiashi Feng and Jing Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bDkisS75zy}\n}"}, "paperhash": {"value": "chen|cosa_concatenated_sample_pretrained_visionlanguage_foundation_model"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5044/-/Revision", "ICLR.cc/2024/Conference/Submission5044/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5044/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925422, "version": 2}, {"id": "Fn655mJ4bv", "forum": "Fn655mJ4bv", "number": 5041, "cdate": 1695370612882, "tcdate": 1695370612882, "mdate": 1713155688160, "tmdate": 1713155688160, "signatures": ["ICLR.cc/2024/Conference/Submission5041/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5041/Authors"], "content": {"title": {"value": "SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models"}, "authors": {"value": ["S. Fatemeh Seyyedsalehi", "Mahdieh Soleymani Baghshah", "Hamid R. Rabiee"]}, "authorids": {"value": ["~S._Fatemeh_Seyyedsalehi1", "~Mahdieh_Soleymani_Baghshah1", "~Hamid_R._Rabiee1"]}, "keywords": {"value": ["Interpretation", "Structured output", "Energy function", "Explainable Structured output"]}, "TLDR": {"value": "A new interpretation technique to explain the behavior of structured output models"}, "abstract": {"value": "This paper proposes a novel interpretation technique to explain the behavior of structured output models, which simultaneously learn mappings between an input vector and a set of output variables. As a result of the complex relationships between the computational path of output variables in structured models, a feature may impact an output value via other output variables. We focus on one of the outputs as the target and try to find the most important features adopted by the structured model to decide on the target in each locality of the input space. We consider an arbitrary structured output model available as a black-box and argue that considering correlations among output variables can improve explanation quality. The goal is to train a function as an interpreter for the target output variable over the input space. We introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The proposed method's effectiveness is confirmed using various simulated and real data sets."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/138fd0715038e546c792aadc69114acf79a09cda.pdf"}, "_bibtex": {"value": "@inproceedings{\nseyyedsalehi2024sointer,\ntitle={{SOI}nter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models},\nauthor={S. Fatemeh Seyyedsalehi and Mahdieh Soleymani Baghshah and Hamid R. Rabiee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Fn655mJ4bv}\n}"}, "paperhash": {"value": "seyyedsalehi|sointer_a_novel_deep_energybased_interpretation_method_for_explaining_structured_output_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5041/-/Revision", "ICLR.cc/2024/Conference/Submission5041/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5041/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925370, "version": 2}, {"id": "gMLQwKDY3N", "forum": "gMLQwKDY3N", "number": 5040, "cdate": 1695370612869, "tcdate": 1695370612869, "mdate": 1709661516294, "tmdate": 1709661516294, "signatures": ["ICLR.cc/2024/Conference/Submission5040/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5040/Authors"], "content": {"title": {"value": "An Unforgeable Publicly Verifiable Watermark for Large Language Models"}, "authors": {"value": ["Aiwei Liu", "Leyi Pan", "Xuming Hu", "Shuang Li", "Lijie Wen", "Irwin King", "Philip S. Yu"]}, "authorids": {"value": ["~Aiwei_Liu1", "~Leyi_Pan1", "~Xuming_Hu1", "~Shuang_Li11", "~Lijie_Wen1", "~Irwin_King1", "~Philip_S._Yu1"]}, "keywords": {"value": ["Watermark", "Large Language Models", "Model Security"]}, "abstract": {"value": "Recently, text watermarking algorithms for large language models (LLMs) have been proposed to mitigate the potential harms of text generated by LLMs, including fake news and copyright issues. However, current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting during public detection.\nTo address this limitation, we propose an unforgeable publicly verifiable watermark algorithm named UPV that uses two different neural networks for watermark generation and detection, instead of using the same key at both stages. Meanwhile, the token embedding parameters are shared between the generation and detection networks, which makes the detection network achieve a high accuracy very efficiently.\nExperiments demonstrate that our algorithm attains high detection accuracy and computational efficiency through neural networks. Subsequent analysis confirms the high complexity involved in forging the watermark from the detection network. Our code is available at https://github.com/THU-BPM/unforgeable_watermark"}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f0f63e9f78b87c4b3592845e676ca53814583c19.pdf"}, "supplementary_material": {"value": "/attachment/0414a8928416cb2b3d830d53a68151f47b76bd11.zip"}, "TLDR": {"value": "We propose the first unforgeable publicly verifiable watermark text watermarking algorithm for LLMs using separate networks for generation and detection, achieving high accuracy and security."}, "_bibtex": {"value": "@inproceedings{\nliu2024a,\ntitle={A Private Watermark for Large Language Models},\nauthor={Aiwei Liu and Leyi Pan and Xuming Hu and Shuang Li and Lijie Wen and Irwin King and Philip S. Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gMLQwKDY3N}\n}"}, "paperhash": {"value": "liu|an_unforgeable_publicly_verifiable_watermark_for_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5040/-/Revision", "ICLR.cc/2024/Conference/Submission5040/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5040/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925346, "version": 2}, {"id": "m52uU0dVbH", "forum": "m52uU0dVbH", "number": 5036, "cdate": 1695370476704, "tcdate": 1695370476704, "mdate": 1710125301902, "tmdate": 1710125301902, "signatures": ["ICLR.cc/2024/Conference/Submission5036/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5036/Authors"], "content": {"title": {"value": "Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit"}, "authors": {"value": ["Duanyi YAO", "Songze Li", "Ye XUE", "Jin Liu"]}, "authorids": {"value": ["~Duanyi_YAO1", "~Songze_Li1", "~Ye_XUE3", "~Jin_Liu14"]}, "keywords": {"value": ["Vertical Federated Learning", "Adversarial Examples", "Adaptive Client Corruption", "Multi-armed Bandit"]}, "abstract": {"value": "Vertical federated learning (VFL), where each participating client holds a subset of data features, has found numerous applications in finance, healthcare, and IoT systems. However, adversarial attacks, particularly through the injection of adversarial examples (AEs), pose serious challenges to the security of VFL models. In this paper, we investigate such vulnerabilities through developing a novel attack to disrupt the VFL inference process, under a practical scenario where the adversary is able to *adaptively corrupt a subset of clients*. We formulate the problem of finding optimal attack strategies as an online optimization problem, which is decomposed into an inner problem of adversarial example generation (AEG) and an outer problem of corruption pattern selection (CPS). Specifically, we establish the equivalence between the formulated CPS problem and a multi-armed bandit (MAB) problem, and propose the Thompson sampling with Empirical maximum reward (E-TS) algorithm for the adversary to efficiently identify the optimal subset of clients for corruption. The key idea of E-TS is to introduce an estimation of the expected maximum reward for each arm, which helps to specify a small set of *competitive arms*, on which the exploration for the optimal arm is performed. This significantly reduces the exploration space, which otherwise can quickly become prohibitively large as the number of clients increases. We analytically characterize the regret bound of E-TS, and empirically demonstrate its capability of efficiently revealing the optimal corruption pattern with the highest attack success rate, under various datasets of popular VFL tasks."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/875f605764f23c682f6453919759073eceb89b03.pdf"}, "supplementary_material": {"value": "/attachment/4d242b73e1a68d34c246f6a73a4c32fe335b3432.pdf"}, "TLDR": {"value": "We propose a novel adversarial attack on inference of vertical federated learning, which selects the optimal client corruption pattern through solving a multi-armed bandit problem."}, "_bibtex": {"value": "@inproceedings{\nyao2024constructing,\ntitle={Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit},\nauthor={Duanyi YAO and Songze Li and Ye XUE and Jin Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=m52uU0dVbH}\n}"}, "paperhash": {"value": "yao|constructing_adversarial_examples_for_vertical_federated_learning_optimal_client_corruption_through_multiarmed_bandit"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5036/-/Revision", "ICLR.cc/2024/Conference/Submission5036/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5036/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925230, "version": 2}, {"id": "3tM1l5tSbv", "forum": "3tM1l5tSbv", "number": 5032, "cdate": 1695370261581, "tcdate": 1695370261581, "mdate": 1710587968641, "tmdate": 1710587968641, "signatures": ["ICLR.cc/2024/Conference/Submission5032/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5032/Authors"], "content": {"title": {"value": "Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping"}, "authors": {"value": ["Enming Liang", "Minghua Chen"]}, "authorids": {"value": ["~Enming_Liang1", "~Minghua_Chen1"]}, "keywords": {"value": ["Non-convex optimization", "Multi-valued solution mapping", "Generative model", "Ordinary differential equation", "Supervised learning"]}, "TLDR": {"value": "We propose a generative learning framework to learn the multi-valued input-solution mapping for non-convex optimization problems."}, "abstract": {"value": "By employing neural networks (NN) to learn input-solution mappings and passing a new input through the learned mapping to obtain a solution instantly, recent studies have shown remarkable speed improvements over iterative algorithms for solving optimization problems. Meanwhile, they also highlight methodological challenges to be addressed. In particular, general non-convex problems often present multiple optimal solutions for identical inputs, signifying a complex, multi-valued input-solution mapping. Conventional learning techniques, primarily tailored to learn single-valued mappings, struggle to train NNs to accurately decipher multi-valued ones, leading to inferior solutions. We address this fundamental issue by developing a generative learning approach using a rectified flow (RectFlow) model built upon ordinary differential equations. In contrast to learning input-solution mapping, we learn the mapping from input to solution distribution, exploiting the universal approximation capability of the RectFlow model. Upon receiving a new input, we employ the trained RectFlow model to sample high-quality solutions from the input-dependent distribution it has learned. Our approach outperforms conceivable GAN and Diffusion models in terms of training stability and run-time complexity. We provide a detailed characterization of the optimality loss and runtime complexity associated with our generative approach. Simulation results for solving non-convex problems show that our method achieves significantly better solution optimality than recent NN schemes, with comparable feasibility and speedup performance."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/60ec35f0b74a245bbba53e005b7ea103289b3fb0.pdf"}, "_bibtex": {"value": "@inproceedings{\nliang2024generative,\ntitle={Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping},\nauthor={Enming Liang and Minghua Chen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3tM1l5tSbv}\n}"}, "paperhash": {"value": "liang|generative_learning_for_solving_nonconvex_problem_with_multivalued_inputsolution_mapping"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5032/-/Revision", "ICLR.cc/2024/Conference/Submission5032/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5032/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925086, "version": 2}, {"id": "X6tNkN6ate", "forum": "X6tNkN6ate", "number": 5031, "cdate": 1695370231550, "tcdate": 1695370231550, "mdate": 1709661516195, "tmdate": 1709661516195, "signatures": ["ICLR.cc/2024/Conference/Submission5031/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5031/Authors"], "content": {"title": {"value": "Interpretable Diffusion via Information Decomposition"}, "authors": {"value": ["Xianghao Kong", "Ollie Liu", "Han Li", "Dani Yogatama", "Greg Ver Steeg"]}, "authorids": {"value": ["~Xianghao_Kong1", "~Ollie_Liu1", "~Han_Li15", "~Dani_Yogatama2", "~Greg_Ver_Steeg1"]}, "keywords": {"value": ["Diffusion Models", "Information Theory", "Interpretable Machine Learning"]}, "abstract": {"value": "Denoising diffusion models enable conditional generation and density modeling of complex relationships like images and text. \nHowever, the nature of the learned relationships is opaque making it difficult to understand precisely what relationships between words and parts of an image are captured, or to predict the effect of an intervention. We illuminate the fine-grained relationships learned by diffusion models by noticing a precise relationship between diffusion and information decomposition. Exact expressions for mutual information and conditional mutual information can be written in terms of the denoising model. Furthermore, ${pointwise}$ estimates can be easily estimated as well, allowing us to ask questions about the relationships between specific images and captions. Decomposing information even further to understand which variables in a high-dimensional space carry information is a long-standing problem. For diffusion models, we show that a natural non-negative decomposition of mutual information emerges, allowing us to quantify informative relationships between words and pixels in an image. We exploit these new relations to measure the compositional understanding of diffusion models, to do unsupervised localization of objects in images, and to measure effects when selectively editing images through prompt interventions."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1a32cadeef49c4fb88609633551be3b541d3c7e3.pdf"}, "supplementary_material": {"value": "/attachment/86ae1d603f63b3fffe628c51366f92a4dfba55ea.zip"}, "TLDR": {"value": "The study explores how denoising diffusion models understand data, revealing ways to measure relationships between images and text, and introducing techniques for object localization and directed image modifications."}, "_bibtex": {"value": "@inproceedings{\nkong2024interpretable,\ntitle={Interpretable Diffusion via Information Decomposition},\nauthor={Xianghao Kong and Ollie Liu and Han Li and Dani Yogatama and Greg Ver Steeg},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=X6tNkN6ate}\n}"}, "paperhash": {"value": "kong|interpretable_diffusion_via_information_decomposition"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5031/-/Revision", "ICLR.cc/2024/Conference/Submission5031/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5031/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925044, "version": 2}, {"id": "QuIiLSktO4", "forum": "QuIiLSktO4", "number": 5029, "cdate": 1695370169110, "tcdate": 1695370169110, "mdate": 1712738092774, "tmdate": 1712738092774, "signatures": ["ICLR.cc/2024/Conference/Submission5029/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5029/Authors"], "content": {"title": {"value": "Algorithms for Caching and MTS with reduced number of predictions"}, "authors": {"value": ["Karim Ahmed Abdel Sadek", "Marek Elias"]}, "authorids": {"value": ["~Karim_Ahmed_Abdel_Sadek1", "~Marek_Elias1"]}, "keywords": {"value": ["ML-Augmented Algorithms", "Caching", "Metrical Task Systems"]}, "TLDR": {"value": "We present 1-consistent, smooth, and robust algorithm for caching and consistent, smooth and robust algorithm for MTS with limited access to predictor"}, "abstract": {"value": "ML-augmented algorithms utilize predictions to achieve performance beyond their worst-case bounds. Producing these predictions might be a costly operation \u2013 this motivated Im et al. [2022] to introduce the study of algorithms which use predictions parsimoniously. We design parsimonious algorithms for caching and MTS with action predictions, proposed by Antoniadis et al. [2023], focusing on the parameters of consistency (performance with perfect predictions) and smoothness (dependence of their performance on prediction error). Our algorithm for caching is 1-consistent, robust, and its smoothness deteriorates with decreasing number of available predictions. We propose an algorithm for general MTS whose consistency and smoothness both scale linearly with the decreasing number of predictions. Without restriction on the number of available predictions, both algorithms match the earlier guarantees achieved by Antoniadis et al. [2023]."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/081ae1c1f0e232544f95e4f7099e2b7764b1c190.pdf"}, "_bibtex": {"value": "@inproceedings{\nsadek2024algorithms,\ntitle={Algorithms for Caching and {MTS} with reduced number of predictions},\nauthor={Karim Ahmed Abdel Sadek and Marek Elias},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QuIiLSktO4}\n}"}, "paperhash": {"value": "sadek|algorithms_for_caching_and_mts_with_reduced_number_of_predictions"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5029/-/Revision", "ICLR.cc/2024/Conference/Submission5029/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5029/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410925007, "version": 2}, {"id": "6CIGhcJYJH", "forum": "6CIGhcJYJH", "number": 5024, "cdate": 1695370050928, "tcdate": 1695370050928, "mdate": 1712942161291, "tmdate": 1712942161291, "signatures": ["ICLR.cc/2024/Conference/Submission5024/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5024/Authors"], "content": {"title": {"value": "Two-timescale Extragradient for Finding Local Minimax Points"}, "authors": {"value": ["Jiseok Chae", "Kyuwon Kim", "Donghwan Kim"]}, "authorids": {"value": ["~Jiseok_Chae1", "~Kyuwon_Kim1", "~Donghwan_Kim2"]}, "keywords": {"value": ["Minimax optimization", "Nonconvex-nonconcave optimization", "Extragradient method", "Dynamical systems"]}, "TLDR": {"value": "We characterize to which points the extragradient method with timescale separation converges, and show that those points are related to local minimax points."}, "abstract": {"value": "Minimax problems are notoriously challenging to optimize. However, we present that the two-timescale extragradient method can be a viable solution. By utilizing dynamical systems theory, we show that it converges to points that satisfy the second-order necessary condition of local minimax points, under mild conditions that the two-timescale gradient descent ascent fails to work. This work provably improves upon all previous results on finding local minimax points, by eliminating a crucial assumption that the Hessian with respect to the maximization variable is nondegenerate."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b2dc5253fe867053b70b2fe3000c5bc7b3918879.pdf"}, "_bibtex": {"value": "@inproceedings{\nchae2024twotimescale,\ntitle={Two-timescale Extragradient for Finding Local Minimax Points},\nauthor={Jiseok Chae and Kyuwon Kim and Donghwan Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6CIGhcJYJH}\n}"}, "paperhash": {"value": "chae|twotimescale_extragradient_for_finding_local_minimax_points"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5024/-/Revision", "ICLR.cc/2024/Conference/Submission5024/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5024/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924852, "version": 2}, {"id": "ILYjDvUM6U", "forum": "ILYjDvUM6U", "number": 5021, "cdate": 1695370021840, "tcdate": 1695370021840, "mdate": 1713019367140, "tmdate": 1713019367140, "signatures": ["ICLR.cc/2024/Conference/Submission5021/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5021/Authors"], "content": {"title": {"value": "Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning"}, "authors": {"value": ["Sheng Xu", "Guiliang Liu"]}, "authorids": {"value": ["~Sheng_Xu8", "~Guiliang_Liu1"]}, "keywords": {"value": ["Inverse Constrained Reinforcement Learning", "Constrained Reinforcement Learning", "Inverse Reinforcement Learning", "Uncertainty Modeling"]}, "TLDR": {"value": "We proposed Uncertainty-aware Inverse Constrained Reinforcement Learning (UAICRL), a novel ICRL framework that models both the aleatoric and epistemic uncertainties towards uncertainty-aware constraint inference."}, "abstract": {"value": "Aiming for safe control, Inverse Constrained Reinforcement Learning (ICRL) considers inferring the constraints respected by expert agents from their demonstrations and learning imitation policies that adhere to these constraints. While previous ICRL works often neglected underlying uncertainties during training, we contend that modeling these uncertainties is crucial for facilitating robust constraint inference. This insight leads to the development of an Uncertainty-aware Inverse Constrained Reinforcement Learning (UAICRL) algorithm. Specifically, 1) aleatoric uncertainty arises from the inherent stochasticity of environment dynamics, leading to constraint-violating behaviors in imitation policies. To address this, UAICRL constructs risk-sensitive constraints by incorporating distributional Bellman updates into the cumulative costs model. 2) Epistemic uncertainty, resulting from the model's limited knowledge of Out-of-Distribution (OoD) samples, affects the accuracy of step-wise cost predictions. To tackle this issue, UAICRL develops an information-theoretic quantification of the epistemic uncertainty and mitigates its impact through flow-based generative data augmentation. Empirical results demonstrate that UAICRL consistently outperforms other baselines in continuous and discrete environments with stochastic dynamics. The code is available at https://github.com/Jasonxu1225/UAICRL."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7ebde2998fcfc48ab4bdb54d6b914157414cf94e.pdf"}, "supplementary_material": {"value": "/attachment/c6a17515d6338ac816c9871684a8061107752eb6.zip"}, "_bibtex": {"value": "@inproceedings{\nxu2024uncertaintyaware,\ntitle={Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning},\nauthor={Sheng Xu and Guiliang Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ILYjDvUM6U}\n}"}, "paperhash": {"value": "xu|uncertaintyaware_constraint_inference_in_inverse_constrained_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5021/-/Revision", "ICLR.cc/2024/Conference/Submission5021/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5021/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924724, "version": 2}, {"id": "GQGNLEHmdl", "forum": "GQGNLEHmdl", "number": 5012, "cdate": 1695369720211, "tcdate": 1695369720211, "mdate": 1709661516040, "tmdate": 1709661516040, "signatures": ["ICLR.cc/2024/Conference/Submission5012/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5012/Authors"], "content": {"title": {"value": "AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference"}, "authors": {"value": ["Xuanlei Zhao", "Shenggan Cheng", "Guangyang LU", "Haotian Zhou", "Bin Jia", "Yang You"]}, "authorids": {"value": ["~Xuanlei_Zhao1", "~Shenggan_Cheng1", "~Guangyang_LU1", "~Haotian_Zhou1", "~Bin_Jia1", "~Yang_You1"]}, "keywords": {"value": ["Long Sequence Inference", "Inference", "Compiler", "Activation Memory", "Machine Learning Infrastructure", "Low Resource Inference"]}, "abstract": {"value": "Large deep learning models have achieved impressive performance across a range of applications. However, their large memory requirements, including parameter memory and activation memory, have become a significant challenge for their practical serving. While existing methods mainly address parameter memory, the importance of activation memory has been overlooked. Especially for long input sequences, activation memory is expected to experience a significant exponential growth as the length of sequences increases. In this approach, we propose AutoChunk, an automatic and adaptive compiler system that efficiently reduces activation memory for long sequence inference by chunk strategies. The proposed system generates chunk plans by optimizing through multiple stages. In each stage, the chunk search pass explores all possible chunk candidates and the chunk selection pass identifies the optimal one. At runtime, AutoChunk employs code generation to automatically apply chunk strategies. The experiments demonstrate that AutoChunk can reduce over 80% of activation memory while maintaining speed loss within 10%, extend max sequence length by 3.2x to 11.7x, and outperform state-of-the-art methods by a large margin."}, "primary_area": {"value": "infrastructure, software libraries, hardware, etc."}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ac98b408c51532ce434867dbc54f66b68bd38c6b.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhao2024autochunk,\ntitle={AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference},\nauthor={Xuanlei Zhao and Shenggan Cheng and Guangyang LU and Haotian Zhou and Bin Jia and Yang You},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=GQGNLEHmdl}\n}"}, "paperhash": {"value": "zhao|autochunk_automated_activation_chunk_for_memoryefficient_deep_learning_inference"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5012/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5012/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924588, "version": 2}, {"id": "QcMdPYBwTu", "forum": "QcMdPYBwTu", "number": 5011, "cdate": 1695369696192, "tcdate": 1695369696192, "mdate": 1707625618269, "tmdate": 1707625618269, "signatures": ["ICLR.cc/2024/Conference/Submission5011/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5011/Authors"], "content": {"title": {"value": "Scalable and Effective Implicit Graph Neural Networks on Large Graphs"}, "authors": {"value": ["Juncheng Liu", "Bryan Hooi", "Kenji Kawaguchi", "Yiwei Wang", "Chaosheng Dong", "Xiaokui Xiao"]}, "authorids": {"value": ["~Juncheng_Liu2", "~Bryan_Hooi1", "~Kenji_Kawaguchi1", "~Yiwei_Wang2", "~Chaosheng_Dong1", "~Xiaokui_Xiao2"]}, "keywords": {"value": ["graph neural networks", "implicit graph neural networks", "implicit models", "graph learning"]}, "abstract": {"value": "Graph Neural Networks (GNNs) have become the de facto standard for modeling graph-structured data in various applications. Among them, implicit GNNs have shown a superior ability to effectively capture long-range dependencies in underlying graphs. However, implicit GNNs tend to be computationally expensive and have high memory usage, due to 1) their use of full-batch training; and 2) they require a large number of iterations to solve a fixed-point equation. These compromise the scalability and efficiency of implicit GNNs especially on large graphs. In this paper, we aim to answer the question: how can we efficiently train implicit GNNs to provide effective predictions on large graphs? We propose a new scalable and effective implicit GNN (SEIGNN) with a mini-batch training method and a stochastic solver, which can be trained efficiently on large graphs. Specifically, SEIGNN can more effectively incorporate global and long-range information by introducing coarse-level nodes in the mini-batch training method. It also achieves reduced training time by obtaining unbiased approximate solutions with fewer iterations in the proposed solver. Comprehensive experiments on various large graphs demonstrate that SEIGNN outperforms baselines and achieves higher accuracy with less training time compared with existing implicit GNNs."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d9add5b95c3413129cf296ec46cc182e9a570ce5.pdf"}, "supplementary_material": {"value": "/attachment/1fc552633f46c4f6c371431e4be78dd309ddb6fb.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024scalable,\ntitle={Scalable and Effective Implicit Graph Neural Networks on Large Graphs},\nauthor={Juncheng Liu and Bryan Hooi and Kenji Kawaguchi and Yiwei Wang and Chaosheng Dong and Xiaokui Xiao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=QcMdPYBwTu}\n}"}, "paperhash": {"value": "liu|scalable_and_effective_implicit_graph_neural_networks_on_large_graphs"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5011/-/Revision", "ICLR.cc/2024/Conference/Submission5011/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924476, "version": 2}, {"id": "oXYZJXDdo7", "forum": "oXYZJXDdo7", "number": 5008, "cdate": 1695369679920, "tcdate": 1695369679920, "mdate": 1710601891483, "tmdate": 1710601891483, "signatures": ["ICLR.cc/2024/Conference/Submission5008/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5008/Authors"], "content": {"title": {"value": "Retrieval is Accurate Generation"}, "authors": {"value": ["Bowen Cao", "Deng Cai", "Leyang Cui", "Xuxin Cheng", "Wei Bi", "Yuexian Zou", "Shuming Shi"]}, "authorids": {"value": ["~Bowen_Cao1", "~Deng_Cai1", "~Leyang_Cui1", "~Xuxin_Cheng3", "~Wei_Bi1", "~Yuexian_Zou2", "~Shuming_Shi1"]}, "keywords": {"value": ["Artificial Intelligence", "Natural Language Processing", "Language Models"]}, "TLDR": {"value": "We propose a new paradigm that generates text solely through phrase retrieval."}, "abstract": {"value": "Standard language models generate text by selecting tokens from a fixed, finite, and standalone vocabulary. We introduce a novel method that selects context-aware phrases from a collection of supporting documents. One of the most significant challenges for this paradigm shift is determining the training oracles, because a string of text can be segmented in various ways and each segment can be retrieved from numerous possible documents. To address this, we propose to initialize the training oracles using linguistic heuristics and, more importantly, bootstrap the oracles through iterative self-reinforcement. Extensive experiments show that our model not only outperforms standard language models on a variety of knowledge-intensive tasks but also demonstrates improved generation quality in open-ended text generation. For instance, compared to the standard language model counterpart, our model raises the accuracy from 23.47% to 36.27% on OpenbookQA, and improves the MAUVE score from 42.61% to 81.58% in open-ended text generation. Remarkably, our model also achieves the best performance and the lowest latency among several retrieval-augmented baselines. In conclusion, we assert that retrieval is more accurate generation and hope that our work will encourage further research on this new paradigm shift."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/43cec927ab0cd3dc1131d8926ce325c04b399236.pdf"}, "_bibtex": {"value": "@inproceedings{\ncao2024retrieval,\ntitle={Retrieval is Accurate Generation},\nauthor={Bowen Cao and Deng Cai and Leyang Cui and Xuxin Cheng and Wei Bi and Yuexian Zou and Shuming Shi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oXYZJXDdo7}\n}"}, "paperhash": {"value": "cao|retrieval_is_accurate_generation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5008/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5008/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924367, "version": 2}, {"id": "NdcQQ82mfy", "forum": "NdcQQ82mfy", "number": 5005, "cdate": 1695369559493, "tcdate": 1695369559493, "mdate": 1709661515884, "tmdate": 1709661515884, "signatures": ["ICLR.cc/2024/Conference/Submission5005/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5005/Authors"], "content": {"title": {"value": "Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach"}, "authors": {"value": ["Changwen Zhang", "Wenli Ouyang", "Hao Yuan", "Liming Gong", "Yong Sun", "Ziao Guo", "Zhichen Dong", "Junchi Yan"]}, "authorids": {"value": ["~Changwen_Zhang1", "~Wenli_Ouyang1", "~Hao_Yuan5", "~Liming_Gong1", "~Yong_Sun1", "~Ziao_Guo1", "~Zhichen_Dong1", "~Junchi_Yan2"]}, "keywords": {"value": ["hybrid RL", "Sample Augmentation", "Learning to branch", "Imitation learning"]}, "abstract": {"value": "Branch-and-bound (B\\&B) has long been favored for tackling complex Mixed Integer Programming (MIP) problems, where the choice of branching strategy plays a pivotal role. Recently, Imitation Learning (IL)-based policies have emerged as potent alternatives to traditional rule-based approaches. However, it is nontrivial to acquire high-quality training samples, and IL often converges to suboptimal variable choices for branching, restricting the overall performance. In response to these challenges, we propose a novel hybrid online and offline reinforcement learning (RL) approach to enhance the branching policy by cost-effective training sample augmentation. In the online phase, we train an online RL agent to dynamically decide the sample generation processes, drawing from either the learning-based policy or the expert policy. The objective is to strike a balance between exploration and exploitation of the sample generation process. In the offline phase, a value function is trained to fit each decision's cumulative reward and filter the samples with high cumulative returns. This dual-purpose function not only reduces training complexity but also enhances the quality of the samples. To assess the efficacy of our data augmentation mechanism, we conduct comprehensive evaluations across a range of MIP problems. The results consistently show that it excels in making superior branching decisions compared to state-of-the-art learning-based models and the open-source solver SCIP. Notably, it even often outperforms Gurobi."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d385d891b460541356297e5ac45f7ca4ac56db98.pdf"}, "supplementary_material": {"value": "/attachment/a5b1ece5114935237e5c58ee465db632380f39a3.zip"}, "_bibtex": {"value": "@inproceedings{\nzhang2024towards,\ntitle={Towards Imitation Learning to Branch for {MIP}: A Hybrid Reinforcement Learning based Sample Augmentation Approach},\nauthor={Changwen Zhang and Wenli Ouyang and Hao Yuan and Liming Gong and Yong Sun and Ziao Guo and Zhichen Dong and Junchi Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NdcQQ82mfy}\n}"}, "paperhash": {"value": "zhang|towards_imitation_learning_to_branch_for_mip_a_hybrid_reinforcement_learning_based_sample_augmentation_approach"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5005/-/Revision", "ICLR.cc/2024/Conference/Submission5005/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5005/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924300, "version": 2}, {"id": "c85tdYOOju", "forum": "c85tdYOOju", "number": 4998, "cdate": 1695369450515, "tcdate": 1695369450515, "mdate": 1709661515846, "tmdate": 1709661515846, "signatures": ["ICLR.cc/2024/Conference/Submission4998/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4998/Authors"], "content": {"title": {"value": "Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks"}, "authors": {"value": ["Tianyu Fan", "Lirong Wu", "Yufei Huang", "Haitao Lin", "Cheng Tan", "Zhangyang Gao", "Stan Z. Li"]}, "authorids": {"value": ["~Tianyu_Fan1", "~Lirong_Wu1", "~Yufei_Huang4", "~Haitao_Lin2", "~Cheng_Tan1", "~Zhangyang_Gao1", "~Stan_Z._Li2"]}, "keywords": {"value": ["Multi-tasking learning", "Graph Neural Networks", "AutoML"]}, "TLDR": {"value": "A Decoupled Framework for Integrating Multiple Graph Pre-training Tasks"}, "abstract": {"value": "Recent years have witnessed the great success of graph pre-training for graph representation learning. With hundreds of graph pre-training tasks proposed, integrating knowledge acquired from multiple pre-training tasks has become a popular research topic. In this paper, we identify two important collaborative processes for this topic: (1) select: how to select an optimal task combination from a given task pool based on their compatibility, and (2) weigh: how to weigh the selected tasks based on their importance. While there currently has been a lot of work focused on weighing, comparatively little effort has been devoted to selecting. This paper proposes a novel instance-level framework for integrating multiple graph pre-training tasks,\nWeigh And Select (WAS), where the two collaborative processes, weighing and selecting, are combined by decoupled siamese networks. Specifically, it first adaptively learns an optimal combination of tasks for each instance from a given task pool, based on which a customized instance-level task weighing strategy is learned. Extensive experiments on 16 graph datasets across node-level and graph-level downstream tasks have demonstrated that by combining a few simple but classical tasks, WAS can achieve comparable performance to other leading counterparts.\nThe code is available at https://github.com/TianyuFan0504/WAS."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bc9c832286849ad35a954c6185a8707f85d6ac15.pdf"}, "supplementary_material": {"value": "/attachment/03add0bfb9f955f1ac5c5ede4a4716818594e879.zip"}, "_bibtex": {"value": "@inproceedings{\nfan2024decoupling,\ntitle={Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks},\nauthor={Tianyu Fan and Lirong Wu and Yufei Huang and Haitao Lin and Cheng Tan and Zhangyang Gao and Stan Z. Li},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=c85tdYOOju}\n}"}, "paperhash": {"value": "fan|decoupling_weighing_and_selecting_for_integrating_multiple_graph_pretraining_tasks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4998/-/Revision", "ICLR.cc/2024/Conference/Submission4998/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4998/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924119, "version": 2}, {"id": "V3j5d0GQgH", "forum": "V3j5d0GQgH", "number": 4997, "cdate": 1695369392301, "tcdate": 1695369392301, "mdate": 1710477690268, "tmdate": 1710477690268, "signatures": ["ICLR.cc/2024/Conference/Submission4997/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4997/Authors"], "content": {"title": {"value": "FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data"}, "authors": {"value": ["Zikai Xiao", "Zihan Chen", "Liyinglan Liu", "YANG FENG", "Joey Tianyi Zhou", "Jian Wu", "Wanlu Liu", "Howard Hao Yang", "Zuozhu Liu"]}, "authorids": {"value": ["~Zikai_Xiao1", "~Zihan_Chen1", "~Liyinglan_Liu1", "~YANG_FENG6", "~Joey_Tianyi_Zhou1", "~Jian_Wu6", "~Wanlu_Liu1", "~Howard_Hao_Yang1", "~Zuozhu_Liu1"]}, "keywords": {"value": ["Personalized federated learning", "Data heterogeneity", "Long-tailed Learning"]}, "abstract": {"value": "Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected from decentralized local clients manifests a globally prevalent long-tailed distribution, has garnered considerable attention in recent times. In the context of Fed-LT, existing works have predominantly centered on addressing the data imbalance issue to enhance the efficacy of the generic global model while neglecting the performance at the local level. In contrast, conventional Personalized Federated Learning (pFL) techniques are primarily devised to optimize personalized local models under the presumption of a balanced global data distribution. This paper introduces an approach termed Federated Local and Generic Model Training in Fed-LT (FedLoGe), which enhances both local and generic model performance through the integration of representation learning and classifier alignment within a neural collapse framework. Our investigation reveals the feasibility of employing a shared backbone as a foundational framework for capturing overarching global trends, while concurrently employing individualized classifiers to encapsulate distinct refinements stemming from each client\u2019s local features. Building upon this discovery, we establish the Static Sparse Equiangular Tight Frame Classifier (SSE-C), inspired by neural collapse principles that naturally prune extraneous noisy features and foster the acquisition of potent data representations. Furthermore, leveraging insights from imbalance neural collapse's classifier norm patterns, we develop Global and Local Adaptive Feature Realignment (GLA-FR) via an auxiliary global classifier and personalized Euclidean norm transfer to align global features with client preferences. Extensive experimental results on CIFAR-10/100-LT, ImageNet, and iNaturalist demonstrate the advantage of our method over state-of-the-art pFL and Fed-LT approaches."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/961c4b1291431178d00bc7f7770a484cd10d29e5.pdf"}, "supplementary_material": {"value": "/attachment/67d0add0358a834f27001447b4b3eef5b51ded53.zip"}, "_bibtex": {"value": "@inproceedings{\nxiao2024fedloge,\ntitle={FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data},\nauthor={Zikai Xiao and Zihan Chen and Liyinglan Liu and YANG FENG and Joey Tianyi Zhou and Jian Wu and Wanlu Liu and Howard Hao Yang and Zuozhu Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=V3j5d0GQgH}\n}"}, "paperhash": {"value": "xiao|fedloge_joint_local_and_generic_federated_learning_under_longtailed_data"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4997/-/Revision", "ICLR.cc/2024/Conference/Submission4997/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/Submission4997/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410924098, "version": 2}, {"id": "OKf6JtXtoy", "forum": "OKf6JtXtoy", "number": 4991, "cdate": 1695369238056, "tcdate": 1695369238056, "mdate": 1710521159542, "tmdate": 1710521159542, "signatures": ["ICLR.cc/2024/Conference/Submission4991/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4991/Authors"], "content": {"title": {"value": "MAP IT to Visualize Representations"}, "authors": {"value": ["Robert Jenssen"]}, "authorids": {"value": ["~Robert_Jenssen1"]}, "keywords": {"value": ["Visualization; Representation learning; Dimensionality reduction; Divergence"]}, "TLDR": {"value": "MAP IT is a new method for visualization by dimensionality reduction using a projective divergence measure as cost function"}, "abstract": {"value": "MAP IT visualizes representations by taking a fundamentally different approach to dimensionality reduction. MAP IT aligns distributions over discrete marginal probabilities in the input space versus the target space, thus capturing information in local regions, as opposed to current methods which align based on individual probabilities between pairs of data points (states) only. The MAP IT theory reveals that alignment based on a projective divergence avoids normalization of weights (to obtain true probabilities) entirely, and further reveals a dual viewpoint via continuous densities and kernel smoothing. MAP IT is shown to produce visualizations which capture class structure better than the current state of the art while being inherently scalable."}, "pdf": {"value": "/pdf/c6c2f0918890b59e15011acf01f5a8c518e36ffd.pdf"}, "supplementary_material": {"value": "/attachment/f3e48e3db41353f30805a57a4dc000973d39d466.pdf"}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\njenssen2024map,\ntitle={{MAP} {IT} to Visualize Representations},\nauthor={Robert Jenssen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=OKf6JtXtoy}\n}"}, "paperhash": {"value": "jenssen|map_it_to_visualize_representations"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4991/-/Revision", "ICLR.cc/2024/Conference/Submission4991/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4991/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410923849, "version": 2}, {"id": "spvaV5LELF", "forum": "spvaV5LELF", "number": 4987, "cdate": 1695369115150, "tcdate": 1695369115150, "mdate": 1709661515739, "tmdate": 1709661515739, "signatures": ["ICLR.cc/2024/Conference/Submission4987/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4987/Authors"], "content": {"title": {"value": "Measuring Vision-Language STEM Skills of Neural Models"}, "authors": {"value": ["Jianhao Shen", "Ye Yuan", "Srbuhi Mirzoyan", "Ming Zhang", "Chenguang Wang"]}, "authorids": {"value": ["~Jianhao_Shen1", "~Ye_Yuan12", "~Srbuhi_Mirzoyan1", "~Ming_Zhang5", "~Chenguang_Wang1"]}, "keywords": {"value": ["Benchmark", "STEM", "Multimodal", "Vision-language models", "Language models"]}, "TLDR": {"value": "We introduce a new challenge to test the STEM skills of neural models."}, "abstract": {"value": "We introduce a new challenge to test the STEM skills of neural models. The problems in the real world often require solutions, combining knowledge from STEM (science, technology, engineering, and math). Unlike existing datasets, our dataset requires the understanding of multimodal vision-language information of STEM. Our dataset features one of the largest and most comprehensive datasets for the challenge. It includes $448$ skills and $1,073,146$ questions spanning all STEM subjects. Compared to existing datasets that often focus on examining expert-level ability, our dataset includes fundamental skills and questions designed based on the K-12 curriculum. We also add state-of-the-art foundation models such as CLIP and GPT-3.5-Turbo to our benchmark. Results show that the recent model advances only help master a very limited number of lower grade-level skills ($2.5$% in the third grade) in our dataset. In fact, these models are still well below (averaging $54.7$%) the performance of elementary students, not to mention near expert-level performance. To understand and increase the performance on our dataset, we teach the models on a training split of our dataset.\nEven though we observe improved performance, the model performance remains relatively low compared to average elementary students. To solve STEM problems, we will need novel algorithmic innovations from the community."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7e6da635eff383520627c545a2b8ea0153ba676c.pdf"}, "supplementary_material": {"value": "/attachment/d757cf77156c3e12cf57ff7ce9c474d53c24a92d.pdf"}, "_bibtex": {"value": "@inproceedings{\nshen2024measuring,\ntitle={Measuring Vision-Language {STEM} Skills of Neural Models},\nauthor={Jianhao Shen and Ye Yuan and Srbuhi Mirzoyan and Ming Zhang and Chenguang Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=spvaV5LELF}\n}"}, "paperhash": {"value": "shen|measuring_visionlanguage_stem_skills_of_neural_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4987/-/Revision", "ICLR.cc/2024/Conference/Submission4987/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4987/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410923738, "version": 2}, {"id": "9RIbNmx984", "forum": "9RIbNmx984", "number": 4977, "cdate": 1695368793176, "tcdate": 1695368793176, "mdate": 1709661515710, "tmdate": 1709661515710, "signatures": ["ICLR.cc/2024/Conference/Submission4977/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4977/Authors"], "content": {"title": {"value": "On Double Descent in Reinforcement Learning with LSTD and Random Features"}, "authors": {"value": ["David Brellmann", "Elo\u00efse Berthier", "David Filliat", "Goran Frehse"]}, "authorids": {"value": ["~David_Brellmann1", "~Elo\u00efse_Berthier1", "~David_Filliat1", "~Goran_Frehse1"]}, "keywords": {"value": ["Regularized Least-Square Temporal Difference", "double descent", "over-parameterization", "random features"]}, "abstract": {"value": "Temporal Difference (TD) algorithms are widely used in Deep Reinforcement Learning (RL). Their performance is heavily influenced by the size of the neural network. While in supervised learning, the regime of over-parameterization and its benefits are well understood, the situation in RL is much less clear. In this paper, we present a theoretical analysis of the influence of network size and $l_2$-regularization on performance. We identify the ratio between the number of parameters and the number of visited states as a crucial factor and define over-parameterization as the regime when it is larger than one. Furthermore, we observe a double descent phenomenon, i.e., a sudden drop in performance around the parameter/state ratio of one. Leveraging random features and the lazy training regime, we study the regularized Least-Square Temporal Difference (LSTD) algorithm in an asymptotic regime, as both the number of parameters and states go to infinity, maintaining a constant ratio. We derive deterministic limits of both the empirical and the true Mean-Squared Bellman Error (MSBE) that feature correction terms responsible for the double descent. Correction terms vanish when the $l_2$-regularization is increased or the number of unvisited states goes to zero. Numerical experiments with synthetic and small real-world environments closely match the theoretical predictions."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We show a performance drop of TD algorithms when the ratio of network parameters to visited states is around one, leading to a double descent phenomenon, and that this can be mitigated with increased $l_2$-regularization or by visiting all states."}, "pdf": {"value": "/pdf/d5505b5e401dbac544e0b1e9458e4101128c2b33.pdf"}, "supplementary_material": {"value": "/attachment/91988691567d4725cfa0a2f23110312354b228ee.zip"}, "_bibtex": {"value": "@inproceedings{\nbrellmann2024on,\ntitle={On Double-Descent in Reinforcement Learning with {LSTD} and Random Features},\nauthor={David Brellmann and Elo{\\\"\\i}se Berthier and David Filliat and Goran Frehse},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9RIbNmx984}\n}"}, "paperhash": {"value": "brellmann|on_double_descent_in_reinforcement_learning_with_lstd_and_random_features"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4977/-/Revision", "ICLR.cc/2024/Conference/Submission4977/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4977/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410923455, "version": 2}, {"id": "KrtGfTGaGe", "forum": "KrtGfTGaGe", "number": 4968, "cdate": 1695368552418, "tcdate": 1695368552418, "mdate": 1712933002608, "tmdate": 1712933002608, "signatures": ["ICLR.cc/2024/Conference/Submission4968/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4968/Authors"], "content": {"title": {"value": "The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models"}, "authors": {"value": ["Rapha\u00ebl Avalos", "Florent Delgrange", "Ann Nowe", "Guillermo Perez", "Diederik M Roijers"]}, "authorids": {"value": ["~Rapha\u00ebl_Avalos1", "~Florent_Delgrange1", "~Ann_Nowe1", "~Guillermo_Perez1", "~Diederik_M_Roijers1"]}, "keywords": {"value": ["pomdp", "guarantees", "representation learning", "reinforcement learning"]}, "TLDR": {"value": "Wasserstein Belief Updater is an RNN free RL algorithm for POMDPs that learns a representation of the history via an approximation of the belief update in a reliable latent space model, providing theoretical guarantees for learning the optimal value."}, "abstract": {"value": "Partially Observable Markov Decision Processes (POMDPs) are used to model environments where the state cannot be perceived, necessitating reasoning based on past observations and actions. However, remembering the full history is generally intractable due to the exponential growth in the history space. Maintaining a probability distribution that models the belief over the current state can be used as a sufficient statistic of the history, but its computation requires access to the model of the environment and is often intractable. While SOTA algorithms use Recurrent Neural Networks to compress the observation-action history aiming to learn a sufficient statistic, they lack guarantees of success and can lead to sub-optimal policies. To overcome this, we propose the Wasserstein Belief Updater, an RL algorithm that learns a latent model of the POMDP and an approximation of the belief update under the assumption that the state is observable during training. Our approach comes with theoretical guarantees on the quality of our approximation ensuring that our latent beliefs allow for learning the optimal value function."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2e80e19728325d62ff8f701338db1f14bc606690.pdf"}, "supplementary_material": {"value": "/attachment/2764d940c390b565941601daa56196ff9b610df7.zip"}, "_bibtex": {"value": "@inproceedings{\navalos2024the,\ntitle={The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models},\nauthor={Rapha{\\\"e}l Avalos and Florent Delgrange and Ann Nowe and Guillermo Perez and Diederik M Roijers},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KrtGfTGaGe}\n}"}, "paperhash": {"value": "avalos|the_wasserstein_believer_learning_belief_updates_for_partially_observable_environments_through_reliable_latent_space_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4968/-/Revision", "ICLR.cc/2024/Conference/Submission4968/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4968/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410923159, "version": 2}, {"id": "gHAr7ZA1OL", "forum": "gHAr7ZA1OL", "number": 4967, "cdate": 1695368542184, "tcdate": 1695368542184, "mdate": 1709661515623, "tmdate": 1709661515623, "signatures": ["ICLR.cc/2024/Conference/Submission4967/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4967/Authors"], "content": {"title": {"value": "Modulated Phase Diffusor: Content-Oriented Feature Synthesis for Detecting Unknown Objects"}, "authors": {"value": ["Aming WU", "Cheng Deng"]}, "authorids": {"value": ["~Aming_WU2", "~Cheng_Deng2"]}, "keywords": {"value": ["Unsupervised out-of-distribution object detection; OOD data synthesis; Modulated phase diffusion"]}, "abstract": {"value": "To promote the safe deployment of object detectors, a task of unsupervised out-of-distribution object detection (OOD-OD) is recently proposed, aiming to detect unknown objects during training without reliance on any auxiliary OOD data. To alleviate the impact of lacking OOD data, for this task, one feasible solution is to exploit the known in-distribution (ID) data to synthesize proper OOD information for supervision, which strengthens detectors' discrimination. From the frequency perspective, since the phase generally reflects the content of the input, in this paper, we explore leveraging the phase of ID features to generate expected OOD features involving different content. And a method of Modulated Phase Diffusion (MPD) is proposed, containing a shared forward and two different reverse processes. Specifically, after calculating the phase of the extracted features, to prevent the rapid loss of content in the phase, the forward process gradually performs Gaussian Average on the phase instead of adding noise. The averaged phase and original amplitude are combined to obtain the features taken as the input of the reverse process. Next, one OOD branch is defined to synthesize virtual OOD features by continually enlarging the content discrepancy between the OOD features and original ones. Meanwhile, another modulated branch is designed to generate augmented features owning a similar phase as the original features by scaling and shifting the OOD branch. Both original and augmented features are used for training, enhancing the discrimination. Experimental results on OOD-OD, incremental object detection, and open-set object detection demonstrate the superiorities of our method. The source code will be released at https://github.com/AmingWu/MPD."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/77bbbff3601da85a7ac08a9e3f70f9dfc4bfa86e.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024modulated,\ntitle={Modulated Phase Diffusor: Content-Oriented Feature Synthesis for Detecting Unknown Objects},\nauthor={Aming WU and Cheng Deng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gHAr7ZA1OL}\n}"}, "paperhash": {"value": "wu|modulated_phase_diffusor_contentoriented_feature_synthesis_for_detecting_unknown_objects"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4967/-/Revision", "ICLR.cc/2024/Conference/Submission4967/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4967/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410923127, "version": 2}, {"id": "ycF7mKfVGO", "forum": "ycF7mKfVGO", "number": 4964, "cdate": 1695368441821, "tcdate": 1695368441821, "mdate": 1710115965678, "tmdate": 1710115965678, "signatures": ["ICLR.cc/2024/Conference/Submission4964/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4964/Authors"], "content": {"title": {"value": "Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation"}, "authors": {"value": ["Haruka Kiyohara", "Ren Kishimoto", "Kosuke Kawakami", "Ken Kobayashi", "Kazuhide Nakata", "Yuta Saito"]}, "authorids": {"value": ["~Haruka_Kiyohara1", "~Ren_Kishimoto1", "~Kosuke_Kawakami1", "~Ken_Kobayashi1", "~Kazuhide_Nakata1", "~Yuta_Saito1"]}, "keywords": {"value": ["off-policy evaluation", "offline reinforcement learning", "offline policy selection", "risk-return tradeoff"]}, "TLDR": {"value": "We propose a new evaluation metric for OPE called SharpeRatio@k, which measures the efficiency of policy portfolios formed by an OPE estimator taking its risk-return tradeoff into consideration."}, "abstract": {"value": "**Off-Policy Evaluation (OPE)** aims to assess the effectiveness of counterfactual policies using offline logged data and is frequently utilized to identify the top-$k$ promising policies for deployment in online A/B tests. Existing evaluation metrics for OPE estimators primarily focus on the \"accuracy\" of OPE or that of downstream policy selection, neglecting risk-return tradeoff and *efficiency* in subsequent online policy deployment. To address this issue, we draw inspiration from portfolio evaluation in finance and develop a new metric, called **SharpeRatio@k**, which measures the risk-return tradeoff and efficiency of policy portfolios formed by an OPE estimator under varying online evaluation budgets ($k$). We first demonstrate, in two example scenarios, that our proposed metric can clearly distinguish between conservative and high-stakes OPE estimators and reliably identify the most *efficient* estimator capable of forming superior portfolios of candidate policies that maximize return with minimal risk during online deployment, while existing evaluation metrics produce only degenerate results. To facilitate a quick, accurate, and consistent evaluation of OPE via SharpeRatio@k, we have also implemented the proposed metric in an open-source software. Using SharpeRatio@k and the software, we conduct a benchmark experiment of various OPE estimators regarding their risk-return tradeoff, presenting several future directions for OPE research."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/066abbdfb238df94b4cd733812429c9fc92b91b3.pdf"}, "_bibtex": {"value": "@inproceedings{\nkiyohara2024towards,\ntitle={Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation},\nauthor={Haruka Kiyohara and Ren Kishimoto and Kosuke Kawakami and Ken Kobayashi and Kazuhide Nakata and Yuta Saito},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ycF7mKfVGO}\n}"}, "paperhash": {"value": "kiyohara|towards_assessing_and_benchmarking_riskreturn_tradeoff_of_offpolicy_evaluation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4964/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4964/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410923012, "version": 2}, {"id": "vNiI3aGcE6", "forum": "vNiI3aGcE6", "number": 4956, "cdate": 1695368252224, "tcdate": 1695368252224, "mdate": 1712726104738, "tmdate": 1712726104738, "signatures": ["ICLR.cc/2024/Conference/Submission4956/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4956/Authors"], "content": {"title": {"value": "Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning"}, "authors": {"value": ["Na Li", "Yuchen Jiao", "Hangguan Shan", "Shefeng Yan"]}, "authorids": {"value": ["~Na_Li9", "~Yuchen_Jiao1", "~Hangguan_Shan1", "~Shefeng_Yan1"]}, "keywords": {"value": ["model-free RL", "self-play", "memory efficiency", "Q-learning", "Nash equilibrium", "Markov policy"]}, "TLDR": {"value": "We design an algorithm that achieves memory, computational, and sample efficiency, and meanwhile has a low burn-in cost and outputs a Markov and Nash policy for two-player zero-sum Markov games."}, "abstract": {"value": "The thriving field of multi-agent reinforcement learning (MARL) studies how a group of interacting agents make decisions autonomously in a shared dynamic environment. Existing theoretical studies in this area suffer from at least two of the following obstacles: memory inefficiency, the heavy dependence of sample complexity on the long horizon and the large state space, the high computational complexity, non-Markov policy, non-Nash policy, and high burn-in cost. In this work, we take a step towards settling this problem by designing a model-free self-play algorithm \\emph{Memory-Efficient Nash Q-Learning (ME-Nash-QL)} for two-player zero-sum Markov games, which is a specific setting of MARL. We prove that ME-Nash-QL can output an $\\varepsilon$-approximate Nash policy with remarkable space complexity $O(SABH)$, sample complexity $\\widetilde{O}(H^4SAB/\\varepsilon^2)$, and computational complexity $O(T\\mathrm{poly}(AB))$, where $S$ is the number of states, $\\{A, B\\}$ is the number of actions for the two players, $H$ is the horizon length, and $T$ is the number of samples. Notably, our approach outperforms in terms of space complexity compared to existing algorithms for tabular cases. It achieves the lowest computational complexity while preserving Markov policies, setting a new standard. Furthermore, our algorithm outputs a Nash policy and achieves the best sample complexity compared with the existing guarantee for long horizons, i.e. when $\\min \\\\{ A, B \\\\} \\ll H^2$. Our algorithm also achieves the best burn-in cost $O(SAB\\,\\mathrm{poly}(H))$, whereas previous algorithms need at least $O(S^3 AB\\,\\mathrm{poly}(H))$ to attain the same level of sample complexity with ours."}, "primary_area": {"value": "learning theory"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fb2037c693eb9288dfeb773007935b0e49a3472e.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024provable,\ntitle={Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning},\nauthor={Na Li and Yuchen Jiao and Hangguan Shan and Shefeng Yan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vNiI3aGcE6}\n}"}, "paperhash": {"value": "li|provable_memory_efficient_selfplay_algorithm_for_modelfree_reinforcement_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4956/-/Revision", "ICLR.cc/2024/Conference/Submission4956/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4956/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922901, "version": 2}, {"id": "LjeqMvQpen", "forum": "LjeqMvQpen", "number": 4949, "cdate": 1695367906964, "tcdate": 1695367906964, "mdate": 1713100567068, "tmdate": 1713100567068, "signatures": ["ICLR.cc/2024/Conference/Submission4949/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4949/Authors"], "content": {"title": {"value": "Transformer Fusion with Optimal Transport"}, "authors": {"value": ["Moritz Imfeld", "Jacopo Graldi", "Marco Giordano", "Thomas Hofmann", "Sotiris Anagnostidis", "Sidak Pal Singh"]}, "authorids": {"value": ["~Moritz_Imfeld1", "~Jacopo_Graldi1", "~Marco_Giordano1", "~Thomas_Hofmann1", "~Sotiris_Anagnostidis1", "~Sidak_Pal_Singh1"]}, "keywords": {"value": ["Fusion", "Transformers", "Model Merging"]}, "TLDR": {"value": "Fusing Transformers with Optimal Transport"}, "abstract": {"value": "Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. This paper presents a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -- and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way to compress Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language modeling tasks using BERT. Our approach consistently outperforms vanilla fusion, and, after a surprisingly short finetuning, also outperforms the individual converged parent models.\nIn our analysis, we uncover intriguing insights about the significant role of soft alignment in the case of Transformers. Our results showcase the potential of fusing multiple Transformers, thus compounding their expertise, in the budding paradigm of model fusion and recombination. Code is available at https://github.com/graldij/transformer-fusion."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fd2f0148a54b95f57f7379bab9e784978299321c.pdf"}, "_bibtex": {"value": "@inproceedings{\nimfeld2024transformer,\ntitle={Transformer Fusion with Optimal Transport},\nauthor={Moritz Imfeld and Jacopo Graldi and Marco Giordano and Thomas Hofmann and Sotiris Anagnostidis and Sidak Pal Singh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LjeqMvQpen}\n}"}, "paperhash": {"value": "imfeld|transformer_fusion_with_optimal_transport"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4949/-/Revision", "ICLR.cc/2024/Conference/Submission4949/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4949/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922779, "version": 2}, {"id": "uWvKBCYh4S", "forum": "uWvKBCYh4S", "number": 4944, "cdate": 1695367783377, "tcdate": 1695367783377, "mdate": 1713136481678, "tmdate": 1713136481678, "signatures": ["ICLR.cc/2024/Conference/Submission4944/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4944/Authors"], "content": {"title": {"value": "Mixture of LoRA Experts"}, "authors": {"value": ["Xun Wu", "Shaohan Huang", "Furu Wei"]}, "authorids": {"value": ["~Xun_Wu1", "~Shaohan_Huang1", "~Furu_Wei1"]}, "keywords": {"value": ["Low-Rank Adaption", "Mixture-of-Experts"]}, "TLDR": {"value": "Enhancing the Robustness and Versatility of Fusion in Multiple LoRA Components via Hierarchical Weight Management Employing Gating Functions"}, "abstract": {"value": "LoRA has gained widespread acceptance in the fine-tuning of large pre-trained models to cater to a diverse array of downstream tasks, showcasing notable effectiveness and efficiency, thereby solidifying its position as one of the most prevalent fine-tuning techniques. Due to the modular nature of LoRA's plug-and-play plugins, researchers have delved into the amalgamation of multiple LoRAs to empower models to excel across various downstream tasks. Nonetheless, extant approaches for LoRA fusion grapple with inherent challenges. Direct arithmetic merging may result in the loss of the original pre-trained model's generative capabilities or the distinct identity of LoRAs, thereby yielding suboptimal outcomes. On the other hand, Reference tuning-based fusion exhibits limitations concerning the requisite flexibility for the effective combination of multiple LoRAs. In response to these challenges, this paper introduces the Mixture of LoRA Experts (MoLE) approach, which harnesses hierarchical control and unfettered branch selection. The MoLE approach not only achieves superior LoRA fusion performance in comparison to direct arithmetic merging but also retains the crucial flexibility for combining LoRAs effectively. Extensive experimental evaluations conducted in both the Natural Language Processing (NLP) and Vision \\& Language (V\\&L) domains substantiate the efficacy of MoLE."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0ca7293a3d769e8eff84f5e11265822b2db77a75.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024mole,\ntitle={Mo{LE}: Mixture of Lo{RA} Experts},\nauthor={Xun Wu and Shaohan Huang and Furu Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uWvKBCYh4S}\n}"}, "paperhash": {"value": "wu|mixture_of_lora_experts"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4944/-/Revision", "ICLR.cc/2024/Conference/Submission4944/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4944/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922614, "version": 2}, {"id": "adSGeugiuj", "forum": "adSGeugiuj", "number": 4935, "cdate": 1695367603759, "tcdate": 1695367603759, "mdate": 1709661515454, "tmdate": 1709661515454, "signatures": ["ICLR.cc/2024/Conference/Submission4935/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4935/Authors"], "content": {"title": {"value": "On the Posterior Distribution in Denoising: Application to Uncertainty Quantification"}, "authors": {"value": ["Hila Manor", "Tomer Michaeli"]}, "authorids": {"value": ["~Hila_Manor1", "~Tomer_Michaeli1"]}, "keywords": {"value": ["Gaussian Denoising", "Posterior Moments Estimation", "Uncertainty Quantification", "Uncertainty Visualization"]}, "abstract": {"value": "Denoisers play a central role in many applications, from noise suppression in low-grade imaging sensors, to empowering score-based generative models. The latter category of methods makes use of Tweedie's formula, which links the posterior mean in Gaussian denoising (*i*.*e*., the minimum MSE denoiser) with the score of the data distribution. Here, we derive a fundamental relation between the higher-order central moments of the posterior distribution, and the higher-order derivatives of the posterior mean. We harness this result for uncertainty quantification of pre-trained denoisers. Particularly, we show how to efficiently compute the principal components of the posterior distribution for any desired region of an image, as well as to approximate the full marginal distribution along those (or any other) one-dimensional directions. Our method is fast and memory-efficient, as it does not explicitly compute or store the high-order moment tensors and it requires no training or fine tuning of the denoiser. Code and examples are available on the project [website](https://hilamanor.github.io/GaussianDenoisingPosterior/)."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/91c8558b8d7e31188d20f759861baece80d10373.pdf"}, "supplementary_material": {"value": "/attachment/d93ea6dcd5e88cf589245ecd8c3e1f761da41623.zip"}, "TLDR": {"value": "We derive a fundamental property of the posterior distribution in Gaussian denoising, and use it to propose a new way for uncertainty visualization, which requires no training or fine-tuning."}, "_bibtex": {"value": "@inproceedings{\nmanor2024on,\ntitle={On the Posterior Distribution in Denoising: Application to Uncertainty Quantification},\nauthor={Hila Manor and Tomer Michaeli},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=adSGeugiuj}\n}"}, "paperhash": {"value": "manor|on_the_posterior_distribution_in_denoising_application_to_uncertainty_quantification"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4935/-/Revision", "ICLR.cc/2024/Conference/Submission4935/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4935/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922414, "version": 2}, {"id": "BLGQ3oqldb", "forum": "BLGQ3oqldb", "number": 4932, "cdate": 1695367482202, "tcdate": 1695367482202, "mdate": 1710312518278, "tmdate": 1710312518278, "signatures": ["ICLR.cc/2024/Conference/Submission4932/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4932/Authors"], "content": {"title": {"value": "LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints"}, "authors": {"value": ["Weidi Xu", "Jingwei Wang", "Lele Xie", "Jianshan He", "Hongting Zhou", "Taifeng Wang", "Xiaopei Wan", "Jingdong Chen", "Chao Qu", "Wei Chu"]}, "authorids": {"value": ["~Weidi_Xu1", "~Jingwei_Wang1", "~Lele_Xie1", "~Jianshan_He1", "~Hongting_Zhou1", "~Taifeng_Wang2", "~Xiaopei_Wan2", "~Jingdong_Chen1", "~Chao_Qu3", "~Wei_Chu1"]}, "keywords": {"value": ["Variational Inference"]}, "TLDR": {"value": "We present a novel and modular neural layer LogicMP, capable of encoding first-order logic constraints using fully parallel computation."}, "abstract": {"value": "Integrating first-order logic constraints (FOLCs) with neural networks is a crucial but challenging problem since it involves modeling intricate correlations to satisfy the constraints. This paper proposes a novel neural layer, LogicMP, which performs mean-field variational inference over a Markov Logic Network (MLN). It can be plugged into any off-the-shelf neural network to encode FOLCs while retaining modularity and efficiency. By exploiting the structure and symmetries in MLNs, we theoretically demonstrate that our well-designed, efficient mean-field iterations greatly mitigate the difficulty of MLN inference, reducing the inference from sequential calculation to a series of parallel tensor operations. Empirical results in three kinds of tasks over images, graphs, and text show that LogicMP outperforms advanced competitors in both performance and efficiency."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7056c44a3f17ec582655f09dc803fc9d4f854fce.pdf"}, "supplementary_material": {"value": "/attachment/78afeaa0ecb9c0bbfd077557c85242e1ea59347b.zip"}, "_bibtex": {"value": "@inproceedings{\nxu2024logicmp,\ntitle={Logic{MP}: A Neuro-symbolic Approach for Encoding First-order Logic Constraints},\nauthor={Weidi Xu and Jingwei Wang and Lele Xie and Jianshan He and Hongting Zhou and Taifeng Wang and Xiaopei Wan and Jingdong Chen and Chao Qu and Wei Chu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BLGQ3oqldb}\n}"}, "paperhash": {"value": "xu|logicmp_a_neurosymbolic_approach_for_encoding_firstorder_logic_constraints"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4932/-/Revision", "ICLR.cc/2024/Conference/Submission4932/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4932/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922273, "version": 2}, {"id": "eiC4BKypf1", "forum": "eiC4BKypf1", "number": 4931, "cdate": 1695367480310, "tcdate": 1695367480310, "mdate": 1709983953964, "tmdate": 1709983953964, "signatures": ["ICLR.cc/2024/Conference/Submission4931/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4931/Authors"], "content": {"title": {"value": "Turning large language models into cognitive models"}, "authors": {"value": ["Marcel Binz", "Eric Schulz"]}, "authorids": {"value": ["~Marcel_Binz1", "~Eric_Schulz1"]}, "keywords": {"value": ["cognitive modeling", "large language models", "neural networks", "cognitive psychology", "decision-making"]}, "TLDR": {"value": "We finetune a large language model on data from psychological experiments and find that doing so produces models that are more aligned with human decision-making."}, "abstract": {"value": "Large language models are powerful systems that excel at many tasks, ranging from translation to mathematical reasoning. Yet, at the same time, these models often show unhuman-like characteristics. In the present paper, we address this gap and ask whether large language models can be turned into cognitive models. We find that -- after finetuning them on data from psychological experiments -- these models offer accurate representations of human behavior, even outperforming traditional cognitive models in two decision-making domains. In addition, we show that their representations contain the information necessary to model behavior on the level of individual subjects. Finally, we demonstrate that finetuning on multiple tasks enables large language models to predict human behavior in a previously unseen task. Taken together, these results suggest that large, pre-trained models can be adapted to become models of human cognition, which opens up future research directions toward building more general cognitive models."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e00f4f72b650c0b9918d80db0cdeb9cc6039a85e.pdf"}, "_bibtex": {"value": "@inproceedings{\nbinz2024turning,\ntitle={Turning large language models into cognitive models},\nauthor={Marcel Binz and Eric Schulz},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=eiC4BKypf1}\n}"}, "paperhash": {"value": "binz|turning_large_language_models_into_cognitive_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4931/-/Revision", "ICLR.cc/2024/Conference/Submission4931/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4931/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922271, "version": 2}, {"id": "vI95kcLAoU", "forum": "vI95kcLAoU", "number": 4929, "cdate": 1695367456003, "tcdate": 1695367456003, "mdate": 1707625617640, "tmdate": 1707625617640, "signatures": ["ICLR.cc/2024/Conference/Submission4929/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4929/Authors"], "content": {"title": {"value": "Skip-Attention: Improving Vision Transformers by Paying Less Attention"}, "authors": {"value": ["Shashanka Venkataramanan", "Amir Ghodrati", "Yuki M Asano", "Fatih Porikli", "Amir Habibian"]}, "authorids": {"value": ["~Shashanka_Venkataramanan2", "~Amir_Ghodrati2", "~Yuki_M_Asano1", "~Fatih_Porikli2", "~Amir_Habibian1"]}, "keywords": {"value": ["vision transformers", "efficiency", "redundacy in attention maps", "improved throughput"]}, "abstract": {"value": "This work aims to improve the efficiency of vision transformers (ViTs).  While ViTs use computationally expensive self-attention operations in every layer, we identify that these operations are highly correlated across layers --  a key redundancy that causes unnecessary computations. Based on this observation, we propose SkipAT a method to reuse self-attention computation from preceding layers to approximate attention at one or more subsequent layers. To ensure that reusing self-attention blocks across layers does not degrade the performance, we introduce a simple parametric function, which outperforms the baseline transformer's performance while running computationally faster. We show that SkipAT is agnostic to transformer architecture and is effective in image classification,  semantic segmentation on ADE20K, image denoising on SIDD, and video denoising on DAVIS. We achieve improved throughput at the same-or-higher accuracy levels in all these tasks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/987ca002a45640904eb1d5052f9f090bc48fa0bb.pdf"}, "_bibtex": {"value": "@inproceedings{\nvenkataramanan2024skipattention,\ntitle={Skip-Attention: Improving Vision Transformers by Paying Less Attention},\nauthor={Shashanka Venkataramanan and Amir Ghodrati and Yuki M Asano and Fatih Porikli and Amir Habibian},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=vI95kcLAoU}\n}"}, "paperhash": {"value": "venkataramanan|skipattention_improving_vision_transformers_by_paying_less_attention"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4929/-/Revision", "ICLR.cc/2024/Conference/-/Edit"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922180, "version": 2}, {"id": "phBS6YpTzC", "forum": "phBS6YpTzC", "number": 4925, "cdate": 1695367358372, "tcdate": 1695367358372, "mdate": 1713154685933, "tmdate": 1713154685933, "signatures": ["ICLR.cc/2024/Conference/Submission4925/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4925/Authors"], "content": {"title": {"value": "Benchmarking and Improving Generator-Validator Consistency of Language Models"}, "authors": {"value": ["Xiang Lisa Li", "Vaishnavi Shrivastava", "Siyan Li", "Tatsunori Hashimoto", "Percy Liang"]}, "authorids": {"value": ["~Xiang_Lisa_Li1", "~Vaishnavi_Shrivastava1", "~Siyan_Li1", "~Tatsunori_Hashimoto1", "~Percy_Liang1"]}, "keywords": {"value": ["consistency", "language models", "self-critique"]}, "TLDR": {"value": "We propose to benchmark the Generator-Validator consistency in LMs and propose approaches to improve the inconsistency."}, "abstract": {"value": "As of September 2023, ChatGPT correctly answers \u201cwhat is 7+8\u201d with 15, but when asked \u201c7+8=15, True or False\u201d it responds with \u201cFalse\u201d. This inconsistency between generating and validating an answer is prevalent in language models (LMs) and erodes trust. In this paper, we propose a framework for measuring the consistency between generation and validation (which we call generator-validator consistency, or GV-consistency), finding that even GPT-4 (0613), a state-of-the-art LM, is GV-consistent only 76% of the time. To improve the consistency of LMs, we propose to finetune on the filtered generator and validator responses that are GV-consistent, and call this approach consistency fine-tuning. We find that this approach improves GV-consistency of Alpaca-30B from 60% to 93%, and the improvement extrapolates to unseen tasks and domains (e.g., GV-consistency for positive style transfers extrapolates to unseen styles like humor). In addition to improving consistency, consistency fine-tuning improves both generator quality and validator accuracy without using any labeled data. Evaluated across 6 tasks, including math questions, knowledge-intensive QA, and instruction following, our method improves generator quality by an average of 16% and validator accuracy by an average of 6.3% across all tasks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c50486991ac0506c27039f32f7b76b6446b6a1af.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024benchmarking,\ntitle={Benchmarking and Improving Generator-Validator Consistency of Language Models},\nauthor={Xiang Lisa Li and Vaishnavi Shrivastava and Siyan Li and Tatsunori Hashimoto and Percy Liang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=phBS6YpTzC}\n}"}, "paperhash": {"value": "li|benchmarking_and_improving_generatorvalidator_consistency_of_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4925/-/Revision", "ICLR.cc/2024/Conference/Submission4925/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4925/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410922034, "version": 2}, {"id": "u7559ZMvwY", "forum": "u7559ZMvwY", "number": 4921, "cdate": 1695367287910, "tcdate": 1695367287910, "mdate": 1712895172240, "tmdate": 1712895172240, "signatures": ["ICLR.cc/2024/Conference/Submission4921/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4921/Authors"], "content": {"title": {"value": "Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization"}, "authors": {"value": ["Guang Lin", "Chao Li", "Jianhai Zhang", "Toshihisa Tanaka", "Qibin Zhao"]}, "authorids": {"value": ["~Guang_Lin4", "~Chao_Li12", "~Jianhai_Zhang3", "~Toshihisa_Tanaka1", "~Qibin_Zhao1"]}, "keywords": {"value": ["adversarial attacks", "adversarial training", "adversarial purification"]}, "abstract": {"value": "The deep neural networks are known to be vulnerable to well-designed adversarial attacks. The most successful defense technique based on adversarial training (AT) can achieve optimal robustness against particular attacks but cannot generalize well to unseen attacks. Another effective defense technique based on adversarial purification (AP) can enhance generalization but cannot achieve optimal robustness. Meanwhile, both methods share one common limitation on the degraded standard accuracy. To mitigate these issues, we propose a novel pipeline to acquire the robust purifier model, named Adversarial Training on Purification (AToP), which comprises two components: perturbation destruction by random transforms (RT) and purifier model fine-tuned (FT) by adversarial loss. RT is essential to avoid overlearning to known attacks, resulting in the robustness generalization to unseen attacks, and FT is essential for the improvement of robustness. \nTo evaluate our method in an efficient and scalable way, we conduct extensive experiments on CIFAR-10, CIFAR-100, and ImageNette to demonstrate that our method achieves optimal robustness and exhibits generalization ability against unseen attacks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/69f1d69c156dce27f5d72a5f8934f3d7b8825c01.pdf"}, "_bibtex": {"value": "@inproceedings{\nlin2024adversarial,\ntitle={Adversarial Training on Purification ({AT}oP): Advancing Both Robustness and Generalization},\nauthor={Guang Lin and Chao Li and Jianhai Zhang and Toshihisa Tanaka and Qibin Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=u7559ZMvwY}\n}"}, "paperhash": {"value": "lin|adversarial_training_on_purification_atop_advancing_both_robustness_and_generalization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4921/-/Revision", "ICLR.cc/2024/Conference/Submission4921/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4921/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921939, "version": 2}, {"id": "tbFBh3LMKi", "forum": "tbFBh3LMKi", "number": 4914, "cdate": 1695367104660, "tcdate": 1695367104660, "mdate": 1710505784548, "tmdate": 1710505784548, "signatures": ["ICLR.cc/2024/Conference/Submission4914/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4914/Authors"], "content": {"title": {"value": "Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization"}, "authors": {"value": ["Kun LEI", "Zhengmao He", "Chenhao Lu", "Kaizhe Hu", "Yang Gao", "Huazhe Xu"]}, "authorids": {"value": ["~Kun_LEI1", "~Zhengmao_He1", "~Chenhao_Lu1", "~Kaizhe_Hu1", "~Yang_Gao1", "~Huazhe_Xu1"]}, "keywords": {"value": ["Offline-to-Online Fine-tuning", "On-policy Learning", "Robot Learning", "Reinforcement Learning"]}, "TLDR": {"value": "We seamlessly integrate offline and online learning through an on-policy RL algorithm, attaining SOTA performance in simulated and real-world environments across both phases, all without the need for additional regularization."}, "abstract": {"value": "Combining offline and online reinforcement learning (RL) is crucial for efficient and safe learning. However, previous approaches treat offline and online learning as separate procedures, resulting in redundant designs and limited performance. We ask: *Can we achieve straightforward yet effective offline and online learning without introducing extra conservatism or regularization?* In this study, we propose Uni-O4, which utilizes an on-policy objective for both offline and online learning. Owning to the alignment of objectives in two phases, the RL agent can transfer between offline and online learning seamlessly. This property enhances the flexibility of the learning paradigm, allowing for arbitrary combinations of pretraining, fine-tuning, offline, and online learning. In the offline phase, specifically, Uni-O4 leverages diverse ensemble policies to address the mismatch issues between the estimated behavior policy and the offline dataset. Through a simple offline policy evaluation (OPE) approach, Uni-O4 can achieve multi-step policy improvement safely. We demonstrate that by employing the method above, the fusion of these two paradigms can yield superior offline initialization as well as stable and rapid online fine-tuning capabilities. \nThrough real-world robot tasks, we highlight the benefits of this paradigm for rapid deployment in challenging, previously unseen real-world environments. Additionally, through comprehensive evaluations using numerous simulated benchmarks, we substantiate that our method achieves state-of-the-art performance in both offline and offline-to-online fine-tuning learning. [Our website](uni-o4.github.io)"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7af8ce8e01ce2bab2390957f79b4e02c3f6cdf30.pdf"}, "_bibtex": {"value": "@inproceedings{\nlei2024unio,\ntitle={Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization},\nauthor={Kun LEI and Zhengmao He and Chenhao Lu and Kaizhe Hu and Yang Gao and Huazhe Xu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tbFBh3LMKi}\n}"}, "paperhash": {"value": "lei|unio4_unifying_online_and_offline_deep_reinforcement_learning_with_multistep_onpolicy_optimization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4914/-/Revision", "ICLR.cc/2024/Conference/Submission4914/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4914/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921816, "version": 2}, {"id": "mNYF0IHbRy", "forum": "mNYF0IHbRy", "number": 4903, "cdate": 1695366644633, "tcdate": 1695366644633, "mdate": 1711421206459, "tmdate": 1711421206459, "signatures": ["ICLR.cc/2024/Conference/Submission4903/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4903/Authors"], "content": {"title": {"value": "LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts"}, "authors": {"value": ["Hanan Gani", "Shariq Farooq Bhat", "Muzammal Naseer", "Salman Khan", "Peter Wonka"]}, "authorids": {"value": ["~Hanan_Gani1", "~Shariq_Farooq_Bhat1", "~Muzammal_Naseer1", "~Salman_Khan4", "~Peter_Wonka1"]}, "keywords": {"value": ["diffusion", "LLM"]}, "abstract": {"value": "Diffusion-based generative models have significantly advanced text-to-image generation but encounter challenges when processing lengthy and intricate text prompts describing complex scenes with multiple objects. While excelling in generating images from short, single-object descriptions, these models often struggle to faithfully capture all the nuanced details within longer and more elaborate textual inputs. In response, we present a novel approach leveraging Large Language Models (LLMs) to extract critical components from text prompts, including bounding box coordinates for foreground objects, detailed textual descriptions for individual objects, and a succinct background context. These components form the foundation of our layout-to-image generation model, which operates in two phases. The initial Global Scene Generation utilizes object layouts and background context to create an initial scene but often falls short in faithfully representing object characteristics as specified in the prompts. To address this limitation, we introduce an Iterative Refinement Scheme that iteratively evaluates and refines box-level content to align them with their textual descriptions, recomposing objects as needed to ensure consistency. Our evaluation on complex prompts featuring multiple objects demonstrates a substantial improvement in recall compared to baseline diffusion models. This is further validated by a user study, underscoring the efficacy of our approach in generating coherent and detailed scenes from intricate textual inputs. Our iterative framework offers a promising solution for enhancing text-to-image generation models' fidelity with lengthy, multifaceted descriptions, opening new possibilities for accurate and diverse image synthesis from textual inputs."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6b9441d77313c54bc391372756461921c6c8b41e.pdf"}, "_bibtex": {"value": "@inproceedings{\ngani2024llm,\ntitle={{LLM} Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts},\nauthor={Hanan Gani and Shariq Farooq Bhat and Muzammal Naseer and Salman Khan and Peter Wonka},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mNYF0IHbRy}\n}"}, "paperhash": {"value": "gani|llm_blueprint_enabling_texttoimage_generation_with_complex_and_detailed_prompts"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4903/-/Revision", "ICLR.cc/2024/Conference/Submission4903/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4903/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921395, "version": 2}, {"id": "TzAJbTClAz", "forum": "TzAJbTClAz", "number": 4901, "cdate": 1695366509226, "tcdate": 1695366509226, "mdate": 1710534826844, "tmdate": 1710534826844, "signatures": ["ICLR.cc/2024/Conference/Submission4901/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4901/Authors"], "content": {"title": {"value": "FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods"}, "authors": {"value": ["Xiaotian Han", "Jianfeng Chi", "Yu Chen", "Qifan Wang", "Han Zhao", "Na Zou", "Xia Hu"]}, "authorids": {"value": ["~Xiaotian_Han1", "~Jianfeng_Chi1", "~Yu_Chen5", "~Qifan_Wang2", "~Han_Zhao1", "~Na_Zou2", "~Xia_Hu4"]}, "keywords": {"value": ["Fairness Benchmark", "Bias Mitigation", "Algorithmic Fairness"]}, "abstract": {"value": "This paper introduces the Fair Fairness Benchmark (FFB), a benchmarking framework for in-processing group fairness methods. Ensuring fairness in machine learning is important for ethical compliance. However, there exist challenges in comparing and developing fairness methods due to inconsistencies in experimental settings, lack of accessible algorithmic implementations, and limited extensibility of current fairness packages and tools. To address these issues, we introduce an open-source standardized benchmark for evaluating in-processing group fairness methods and provide a comprehensive analysis of state-of-the-art methods to ensure different notions of group fairness. This work offers the following key contributions: the provision of flexible, extensible, minimalistic, and research-oriented open-source code; the establishment of unified fairness method benchmarking pipelines; and extensive benchmarking, which yields key insights from 45,079 experiments, 14,428 GPU hours. We believe that our work will significantly facilitate the growth and development of the fairness research community. The benchmark is available at https://github.com/ahxt/fair_fairness_benchmark."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/fe7ace751a060c02149f23d1790c2389643dfd8f.pdf"}, "_bibtex": {"value": "@inproceedings{\nhan2024ffb,\ntitle={{FFB}: A Fair Fairness Benchmark for In-Processing Group Fairness Methods},\nauthor={Xiaotian Han and Jianfeng Chi and Yu Chen and Qifan Wang and Han Zhao and Na Zou and Xia Hu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TzAJbTClAz}\n}"}, "TLDR": {"value": "The Fair Fairness Benchmark (FFB) is introduced as a comprehensive framework for assessing in-processing group fairness methods in machine learning."}, "paperhash": {"value": "han|ffb_a_fair_fairness_benchmark_for_inprocessing_group_fairness_methods"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4901/-/Revision", "ICLR.cc/2024/Conference/Submission4901/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4901/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921384, "version": 2}, {"id": "EWTFMkTdkT", "forum": "EWTFMkTdkT", "number": 4895, "cdate": 1695366262734, "tcdate": 1695366262734, "mdate": 1710586638365, "tmdate": 1710586638365, "signatures": ["ICLR.cc/2024/Conference/Submission4895/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4895/Authors"], "content": {"title": {"value": "Invariance-based Learning of Latent Dynamics"}, "authors": {"value": ["Kai Lagemann", "Christian Lagemann", "Sach Mukherjee"]}, "authorids": {"value": ["~Kai_Lagemann1", "~Christian_Lagemann1", "~Sach_Mukherjee1"]}, "keywords": {"value": ["Latent Dynamical Model", "Invariant Decomposition", "Neural Network", "Spatio-Temporal Attention"]}, "abstract": {"value": "We propose a new model class aimed at predicting dynamical trajectories from high-dimensional empirical data. This is done by combining variational autoencoders and (spatio-)temporal transformers within a  framework designed to enforce certain scientifically-motivated invariances. The models allow inference of system behavior at any continuous time and generalization well beyond the data distributions seen during training. Furthermore, the models do not require an explicit neural ODE formulation, making them efficient and highly scalable in practice. We study  behavior through simple theoretical analyses and  extensive empirical experiments. The latter investigate  the ability to predict the trajectories of complicated  systems based on finite data and show that the proposed approaches can outperform existing neural-dynamical models. We study also more general inductive bias in the context of transfer to data obtained under entirely novel system interventions. Overall, our results provide a new framework for efficiently learning complicated dynamics in a data-driven manner, with potential applications in a wide range of fields including physics, biology, and engineering."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/47d3a66119f28b177633ae8db0cbccf367f1b062.pdf"}, "_bibtex": {"value": "@inproceedings{\nlagemann2024invariancebased,\ntitle={Invariance-based Learning of Latent Dynamics},\nauthor={Kai Lagemann and Christian Lagemann and Sach Mukherjee},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EWTFMkTdkT}\n}"}, "paperhash": {"value": "lagemann|invariancebased_learning_of_latent_dynamics"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4895/-/Revision", "ICLR.cc/2024/Conference/Submission4895/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4895/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921155, "version": 2}, {"id": "90yw2uM6J5", "forum": "90yw2uM6J5", "number": 4890, "cdate": 1695365960371, "tcdate": 1695365960371, "mdate": 1711417379394, "tmdate": 1711417379394, "signatures": ["ICLR.cc/2024/Conference/Submission4890/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4890/Authors"], "content": {"title": {"value": "Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer"}, "authors": {"value": ["Youn-Yeol Yu", "Jeongwhan Choi", "Woojin Cho", "Kookjin Lee", "Nayong Kim", "Kiseok Chang", "ChangSeung Woo", "ILHO KIM", "SeokWoo Lee", "Joon Young Yang", "SOOYOUNG YOON", "Noseong Park"]}, "authorids": {"value": ["~Youn-Yeol_Yu1", "~Jeongwhan_Choi1", "~Woojin_Cho1", "~Kookjin_Lee1", "~Nayong_Kim1", "~Kiseok_Chang1", "~ChangSeung_Woo1", "~ILHO_KIM1", "~SeokWoo_Lee1", "~Joon_Young_Yang1", "~SOOYOUNG_YOON1", "~Noseong_Park1"]}, "keywords": {"value": ["graph transformer", "physics-based simulation", "mesh", "collision", "flexible dynamics"]}, "abstract": {"value": "Recently, many mesh-based graph neural network (GNN) models have been proposed for modeling complex high-dimensional physical systems. Remarkable achievements have been made in significantly reducing the solving time compared to traditional numerical solvers. These methods are typically designed to i) reduce the computational cost in solving physical dynamics and/or ii) propose techniques to enhance the solution accuracy in fluid and rigid body dynamics. However, it remains under-explored whether they are effective in addressing the challenges of flexible body dynamics, where instantaneous collisions occur within a very short timeframe. In this paper, we present Hierarchical Contact Mesh Transformer (HCMT), which uses hierarchical mesh structures and can learn long-range dependencies (occurred by collisions) among spatially distant positions of a body --- two close positions in a higher-level mesh correspond to two distant positions in a lower-level mesh. HCMT enables long-range interactions, and the hierarchical mesh structure quickly propagates collision effects to faraway positions. To this end, it consists of a contact mesh Transformer and a hierarchical mesh Transformer (CMT and HMT, respectively). Lastly, we propose a flexible body dynamics dataset,  consisting of trajectories that reflect experimental settings frequently used in the display industry for product designs. We also compare the performance of several baselines using well-known benchmark datasets. Our results show that HCMT provides significant performance improvements over existing methods. Our code is available at https://github.com/yuyudeep/hcmt."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d18f35ad673b7009fdd99c8ae975ce3e0b748511.pdf"}, "_bibtex": {"value": "@inproceedings{\nyu2024learning,\ntitle={Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer},\nauthor={Youn-Yeol Yu and Jeongwhan Choi and Woojin Cho and Kookjin Lee and Nayong Kim and Kiseok Chang and ChangSeung Woo and ILHO KIM and SeokWoo Lee and Joon Young Yang and SOOYOUNG YOON and Noseong Park},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=90yw2uM6J5}\n}"}, "paperhash": {"value": "yu|learning_flexible_body_collision_dynamics_with_hierarchical_contact_mesh_transformer"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4890/-/Revision", "ICLR.cc/2024/Conference/Submission4890/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4890/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921049, "version": 2}, {"id": "rL7xsg1aRn", "forum": "rL7xsg1aRn", "number": 4887, "cdate": 1695365869120, "tcdate": 1695365869120, "mdate": 1709910999717, "tmdate": 1709910999717, "signatures": ["ICLR.cc/2024/Conference/Submission4887/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4887/Authors"], "content": {"title": {"value": "Masked Structural Growth for 2x Faster Language Model Pre-training"}, "authors": {"value": ["Yiqun Yao", "Zheng Zhang", "Jing Li", "Yequan Wang"]}, "authorids": {"value": ["~Yiqun_Yao1", "~Zheng_Zhang12", "~Jing_Li19", "~Yequan_Wang1"]}, "keywords": {"value": ["Progressive Learning", "Large Language Models", "Model Growth"]}, "TLDR": {"value": "We grow up language models in pre-training with efficient schedules and function-preserving operators that yields 2x speedup."}, "abstract": {"value": "Accelerating large language model pre-training is a critical issue in present research. In this paper, we focus on speeding up pre-training by progressively growing from a small Transformer structure to a large one. There are two main research problems associated with progressive growth: determining the optimal growth schedule, and designing efficient growth operators. In terms of growth schedule, the impact of each single dimension on a schedule\u2019s efficiency is underexplored by existing work. Regarding the growth operators, existing methods rely on the initialization of new weights to inherit knowledge, and achieve only non-strict function preservation, limiting further improvements on training dynamics. To address these issues, we propose Masked Structural Growth (MSG), including (i) growth schedules involving all possible dimensions and (ii) strictly function-preserving growth operators that is independent of the initialization of new weights. Experiments show that MSG is significantly faster than related work: we achieve up to 2.2x speedup in pre-training different types of language models while maintaining comparable or better downstream performances. Code is publicly available at https://github.com/cofe-ai/MSG."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 poster"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bbb7c09286b80a46c623073658efbf3411c35198.pdf"}, "_bibtex": {"value": "@inproceedings{\nyao2024masked,\ntitle={Masked Structural Growth for 2x Faster Language Model Pre-training},\nauthor={Yiqun Yao and Zheng Zhang and Jing Li and Yequan Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=rL7xsg1aRn}\n}"}, "paperhash": {"value": "yao|masked_structural_growth_for_2x_faster_language_model_pretraining"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4887/-/Revision", "ICLR.cc/2024/Conference/Submission4887/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4887/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410920954, "version": 2}]}