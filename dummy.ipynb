{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the arXiv ID for SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARXIV:2309.13625',\n",
       " 'ARXIV:2310.13023',\n",
       " 'ARXIV:2310.04560',\n",
       " 'ARXIV:2310.04944',\n",
       " 'ARXIV:2310.00299']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "datas = []\n",
    "unmatch = []\n",
    "# Regular expression pattern to find and capture the numerical parts\n",
    "pattern = r\"https://arxiv.org/pdf/(\\d{4}\\.\\d{5})\\.pdf\"\n",
    "\n",
    "\n",
    "with open('data/reason.md', 'r') as f:\n",
    "    for line in f.readlines():  \n",
    "        if 'https://arxiv' in line:\n",
    "            # Find all matches in the string\n",
    "            matches = re.findall(pattern, line)\n",
    "            datas.append(f'ARXIV:{matches[0]}')\n",
    "        elif 'pdf' in line:\n",
    "            unmatch.append(line)\n",
    "\n",
    "datas[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TL;DR from SemanticScholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "sch = SemanticScholar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data(paper):\n",
    "    domains = ['title', 'authors', 'abstract', 'tldr', 'venue', 'referenceCount', 'citationCount', 'influentialCitationCount']\n",
    "\n",
    "    meta_data = {}\n",
    "    for domain in domains:\n",
    "        if domain in paper.keys():\n",
    "            if domain == 'authors':\n",
    "                authors = []\n",
    "                for author_domain in paper.__getattribute__(domain):\n",
    "                    authors.append(author_domain['name'])\n",
    "                meta_data['authors'] = authors\n",
    "            else:\n",
    "                domain_res = paper.__getattribute__(domain)\n",
    "                if domain == 'tldr':\n",
    "                    domain_res = str(domain_res)\n",
    "                meta_data[domain] = domain_res\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 2/111 [00:22<22:41, 12.49s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import time\n",
    "\n",
    "meta_datas = []\n",
    "with open('result.json', 'a+') as fp:\n",
    "    for data in tqdm(datas):\n",
    "        try:\n",
    "            paper = sch.get_paper(data)\n",
    "            fp.writelines(get_meta_data(paper))\n",
    "        except:\n",
    "            fp.writelines({'Cannot find': data})\n",
    "        \n",
    "        meta_datas.append(get_meta_data(paper))\n",
    "        time.sleep(2) # hold 2 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arXiv searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models 2024-02-29 18:59:58+00:00\n",
      "Single Electron Quantum Dot in Two-Dimensional Transition Metal Dichalcogenides 2024-02-29 18:59:57+00:00\n",
      "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers 2024-02-29 18:59:50+00:00\n",
      "Learning a Generalized Physical Face Model From Data 2024-02-29 18:59:31+00:00\n",
      "Impact of weak lensing on bright standard siren analyses 2024-02-29 18:59:30+00:00\n",
      "The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations? 2024-02-29 18:59:25+00:00\n",
      "The All-Seeing Project V2: Towards General Relation Comprehension of the Open World 2024-02-29 18:59:17+00:00\n",
      "Retrieval-Augmented Generation for AI-Generated Content: A Survey 2024-02-29 18:59:01+00:00\n",
      "Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress 2024-02-29 18:58:26+00:00\n",
      "Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling 2024-02-29 18:58:15+00:00\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "# -----\n",
    "# sort_by\n",
    "# Relevance \n",
    "# LastUpdatedDate \n",
    "# SubmittedDate\n",
    "# -----\n",
    "# order\n",
    "# Ascending\n",
    "# Descending\n",
    "\n",
    "search = arxiv.Search(\n",
    "  query = \"Large Language Models\",\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "  sort_order = arxiv.SortOrder.Descending,\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "for r in client.results(search):\n",
    "  print(r.title, r.published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models\n",
      "Single Electron Quantum Dot in Two-Dimensional Transition Metal Dichalcogenides\n",
      "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers\n",
      "Learning a Generalized Physical Face Model From Data\n",
      "Impact of weak lensing on bright standard siren analyses\n",
      "The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?\n",
      "The All-Seeing Project V2: Towards General Relation Comprehension of the Open World\n",
      "Retrieval-Augmented Generation for AI-Generated Content: A Survey\n",
      "Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress\n",
      "Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling\n",
      "['DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models', 'Single Electron Quantum Dot in Two-Dimensional Transition Metal Dichalcogenides', 'Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers', 'Learning a Generalized Physical Face Model From Data', 'Impact of weak lensing on bright standard siren analyses', 'The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?', 'The All-Seeing Project V2: Towards General Relation Comprehension of the Open World', 'Retrieval-Augmented Generation for AI-Generated Content: A Survey', 'Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress', 'Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling']\n",
      "http://arxiv.org/abs/cond-mat/0603029v1\n",
      "From stripe to checkerboard order on the square lattice in the presence of quenched disorder\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "\n",
    "# Construct the default API client.\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "search = arxiv.Search(\n",
    "  query = \"Large Language Models\",\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "# `results` is a generator; you can iterate over its elements one by one...\n",
    "for r in client.results(search):\n",
    "  print(r.title)\n",
    "# ...or exhaust it into a list. Careful: this is slow for large results sets.\n",
    "all_results = list(results)\n",
    "print([r.title for r in all_results])\n",
    "\n",
    "# For advanced query syntax documentation, see the arXiv API User Manual:\n",
    "# https://arxiv.org/help/api/user-manual#query_details\n",
    "search = arxiv.Search(query = \"au:del_maestro AND ti:checkerboard\")\n",
    "first_result = next(client.results(search))\n",
    "print(first_result)\n",
    "\n",
    "# Search for the paper with ID \"1605.08386v1\"\n",
    "search_by_id = arxiv.Search(id_list=[\"1605.08386v1\"])\n",
    "# Reuse client to fetch the paper, then print its title.\n",
    "first_result = next(client.results(search))\n",
    "print(first_result.title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
